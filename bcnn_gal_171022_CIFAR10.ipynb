{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bcnn_gal_171022 import *\n",
    "import nn_shson\n",
    "from shson_exp_manager import *\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_to_onehot(nums, n_labels):\n",
    "    results = list()\n",
    "    for i in range(len(nums)):\n",
    "        res = np.zeros([n_labels])\n",
    "        res[nums[i]] = 1\n",
    "        results.append(res)\n",
    "    return np.asarray(results, dtype = 'float32')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar = h5py.File('CIFAR10.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'test_imgs',\n",
       " u'test_labels',\n",
       " u'train_imgs',\n",
       " u'train_labels',\n",
       " u'valid_imgs',\n",
       " u'valid_labels']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar['train_imgs'][()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar = h5py.File('CIFAR10.h5', 'r')\n",
    "\n",
    "random.seed(1337)\n",
    "\n",
    "'''\n",
    "perm1 = range(784)\n",
    "perm2 = range(784)\n",
    "perm3 = range(784)\n",
    "perm4 = range(784)\n",
    "perm5 = range(784)\n",
    "perm6 = range(784)\n",
    "\n",
    "random.shuffle(perm1)\n",
    "random.shuffle(perm2)\n",
    "random.shuffle(perm3)\n",
    "random.shuffle(perm4)\n",
    "random.shuffle(perm5)\n",
    "random.shuffle(perm6)\n",
    "\n",
    "print perm1[0:20]\n",
    "print perm2[0:20]\n",
    "\n",
    "'''\n",
    "\n",
    "x_train = list()\n",
    "x_valid = list()\n",
    "x_test = list()\n",
    "\n",
    "x_train.append(cifar['train_imgs'][()])\n",
    "'''\n",
    "x_train.append(mnist['train_data'][()][:, perm1])\n",
    "x_train.append(mnist['train_data'][()][:, perm2])\n",
    "x_train.append(mnist['train_data'][()][:, perm3])\n",
    "x_train.append(mnist['train_data'][()][:, perm4])\n",
    "x_train.append(mnist['train_data'][()][:, perm5])\n",
    "x_train.append(mnist['train_data'][()][:, perm6])\n",
    "'''\n",
    "t_train = num_to_onehot(cifar['train_labels'][()], 10)\n",
    "x_valid.append(cifar['valid_imgs'][()])\n",
    "'''\n",
    "x_valid.append(mnist['valid_data'][()][:, perm1])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm2])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm3])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm4])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm5])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm6])\n",
    "'''\n",
    "t_valid = num_to_onehot(cifar['valid_labels'][()], 10)\n",
    "x_test.append(cifar['test_imgs'][()])\n",
    "'''\n",
    "x_test.append(mnist['test_data'][()][:, perm1])\n",
    "x_test.append(mnist['test_data'][()][:, perm2])\n",
    "x_test.append(mnist['test_data'][()][:, perm3])\n",
    "x_test.append(mnist['test_data'][()][:, perm4])\n",
    "x_test.append(mnist['test_data'][()][:, perm5])\n",
    "x_test.append(mnist['test_data'][()][:, perm6])\n",
    "'''\n",
    "t_test = num_to_onehot(cifar['test_labels'][()], 10)\n",
    "\n",
    "cifar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accs(accs, ep):\n",
    "    res = \"\"\n",
    "    for acc in accs:\n",
    "        res += \" {:.4f}\".format(acc[ep])\n",
    "    \n",
    "    print res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gal's BCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv layer done\n",
      "conv layer done\n",
      "fc layer done\n",
      "fc layer done\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "bcnn_gal = bcnn_gal_model([32, 32, 3], [[5, 5, 3, 32],[3, 3, 32, 64]], [True, True], [8 * 8 * 64, 100, 10], w_stdev = 0.1, n_samples = 10, \\\n",
    "                outact = tf.nn.relu, lr = 1e-3, l2_reg = True, l2_lambda = 0.1)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves_bcnn_gal/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, batch 0, training accuracy 0.065\n",
      "ep 0, batch 50, training accuracy 0.16\n",
      "ep 0, batch 100, training accuracy 0.205\n",
      "ep 0, batch 150, training accuracy 0.235\n",
      "ep 0, batch 200, training accuracy 0.32\n",
      "valid accuracy: 0.344\n",
      "valid accuracy: 0.436\n",
      "valid accuracy: 0.464\n",
      "valid accuracy: 0.4705\n",
      "valid accuracy: 0.494\n",
      "valid accuracy: 0.5045\n",
      "valid accuracy: 0.5125\n",
      "valid accuracy: 0.5385\n",
      "valid accuracy: 0.53575\n",
      "valid accuracy: 0.55275\n",
      "valid accuracy: 0.541\n",
      "valid accuracy: 0.5535\n",
      "valid accuracy: 0.5425\n",
      "valid accuracy: 0.57475\n",
      "valid accuracy: 0.57175\n",
      "valid accuracy: 0.56975\n",
      "valid accuracy: 0.568\n",
      "valid accuracy: 0.56875\n",
      "valid accuracy: 0.5645\n",
      "valid accuracy: 0.55625\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.5425\n",
      "valid accuracy: 0.53225\n",
      "valid accuracy: 0.539\n",
      "valid accuracy: 0.53375\n",
      "valid accuracy: 0.52125\n",
      "valid accuracy: 0.54225\n",
      "valid accuracy: 0.53375\n",
      "valid accuracy: 0.54875\n",
      "valid accuracy: 0.54275\n",
      "valid accuracy: 0.53875\n",
      "valid accuracy: 0.53125\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.509\n",
      "valid accuracy: 0.535\n",
      "valid accuracy: 0.54675\n",
      "valid accuracy: 0.5335\n",
      "valid accuracy: 0.545\n",
      "valid accuracy: 0.54675\n",
      "valid accuracy: 0.5445\n",
      "valid accuracy: 0.544\n",
      "valid accuracy: 0.52175\n",
      "valid accuracy: 0.548\n",
      "valid accuracy: 0.5475\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.52025\n",
      "valid accuracy: 0.5485\n",
      "valid accuracy: 0.54475\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.542\n",
      "ep 50, batch 0, training accuracy 1\n",
      "ep 50, batch 50, training accuracy 0.985\n",
      "ep 50, batch 100, training accuracy 1\n",
      "ep 50, batch 150, training accuracy 0.95\n",
      "ep 50, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.553\n",
      "valid accuracy: 0.55325\n",
      "valid accuracy: 0.5515\n",
      "valid accuracy: 0.554\n",
      "valid accuracy: 0.5565\n",
      "valid accuracy: 0.5575\n",
      "valid accuracy: 0.55575\n",
      "valid accuracy: 0.5535\n",
      "valid accuracy: 0.557\n",
      "valid accuracy: 0.557\n",
      "valid accuracy: 0.5575\n",
      "valid accuracy: 0.556\n",
      "valid accuracy: 0.55725\n",
      "valid accuracy: 0.55675\n",
      "valid accuracy: 0.55675\n",
      "valid accuracy: 0.5565\n",
      "valid accuracy: 0.55825\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5615\n",
      "valid accuracy: 0.5615\n",
      "valid accuracy: 0.56175\n",
      "valid accuracy: 0.56175\n",
      "valid accuracy: 0.56125\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.561\n",
      "valid accuracy: 0.561\n",
      "valid accuracy: 0.5615\n",
      "valid accuracy: 0.5615\n",
      "valid accuracy: 0.5615\n",
      "valid accuracy: 0.5615\n",
      "valid accuracy: 0.56125\n",
      "valid accuracy: 0.561\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.5605\n",
      "valid accuracy: 0.56075\n",
      "valid accuracy: 0.5605\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.5605\n",
      "valid accuracy: 0.5605\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "ep 100, batch 0, training accuracy 1\n",
      "ep 100, batch 50, training accuracy 1\n",
      "ep 100, batch 100, training accuracy 1\n",
      "ep 100, batch 150, training accuracy 1\n",
      "ep 100, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "ep 150, batch 0, training accuracy 1\n",
      "ep 150, batch 50, training accuracy 1\n",
      "ep 150, batch 100, training accuracy 1\n",
      "ep 150, batch 150, training accuracy 1\n",
      "ep 150, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56025\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.56\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.55975\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "ep 200, batch 0, training accuracy 1\n",
      "ep 200, batch 50, training accuracy 1\n",
      "ep 200, batch 100, training accuracy 1\n",
      "ep 200, batch 150, training accuracy 1\n",
      "ep 200, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55825\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.55825\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "ep 250, batch 0, training accuracy 1\n",
      "ep 250, batch 50, training accuracy 1\n",
      "ep 250, batch 100, training accuracy 1\n",
      "ep 250, batch 150, training accuracy 1\n",
      "ep 250, batch 200, training accuracy 1\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5595\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.5585\n",
      "valid accuracy: 0.55825\n",
      "valid accuracy: 0.55825\n",
      "valid accuracy: 0.55825\n",
      "valid accuracy: 0.55875\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.55925\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "ep 300, batch 0, training accuracy 1\n",
      "ep 300, batch 50, training accuracy 1\n",
      "ep 300, batch 100, training accuracy 1\n",
      "ep 300, batch 150, training accuracy 1\n",
      "ep 300, batch 200, training accuracy 1\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "valid accuracy: 0.559\n",
      "=== cannot decay more. stop learning this batch ===\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 1\n",
    "\n",
    "n_epochs = 500\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "taccs_bcnn_gal = list()\n",
    "#taccs_mean = list()\n",
    "vaccs_bcnn_gal = list()\n",
    "epochs_done = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs_bcnn_gal.append(list())\n",
    "    \n",
    "for d in range(n_datas):\n",
    "    bcnn_gal.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            feed = {bcnn_gal.x: np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 32, 32, 3)), \\\n",
    "                    bcnn_gal.t: t_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                    bcnn_gal.keep_probs: [1, 1, 1, 1]}\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bcnn_gal.validate(feed)                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "\n",
    "            bcnn_gal.train(feed)\n",
    "\n",
    "        if ep > 5 and np.mean(taccs_bcnn_gal[-25:]) < taccs_bcnn_gal[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bcnn_gal.get_lr()\n",
    "                bcnn_gal.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bcnn_gal.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    epochs_done.append(ep)\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "        if ep == (n_epochs) - 1: epochs_done.append(ep)\n",
    "                \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            #vaccs_bcnn_gal[i].append(bcnn_gal.validate({bcnn_gal.x: np.reshape(x_valid[i], (-1, 28, 28, 1)), \\\n",
    "             #                                           bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]}))\n",
    "            vaccs_bcnn_gal[i].append(bcnn_gal.validate({bcnn_gal.x: np.reshape(x_valid[i], (-1, 32, 32, 3)), \\\n",
    "                                                        bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [1, 1, 1, 1]}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs_bcnn_gal[i][-1])\n",
    "        \n",
    "        taccs_bcnn_gal.append(train_accuracy)\n",
    "        \n",
    "        print(str_vacc)\n",
    "\n",
    "        #summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "        #                                       bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]})\n",
    "        summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 32, 32, 3)), \\\n",
    "                                               bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [1, 1, 1, 1]})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naJAkSVkMDZIkKYuhQZIkZfkFRiRMOHeaHAIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14506ac310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Gal\\'s Bayesian CNN without Dropout')\n",
    "plt.plot(taccs_bcnn_gal, 'k')\n",
    "plt.plot(vaccs_bcnn_gal[0], 'b')\n",
    "'''\n",
    "plt.plot(vaccs_bcnn_gal[1], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[2], 'r')\n",
    "plt.plot(vaccs_bcnn_gal[3], 'c')\n",
    "plt.plot(vaccs_bcnn_gal[4], 'b')\n",
    "plt.plot(vaccs_bcnn_gal[5], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[6], 'r')\n",
    "'''\n",
    "#plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.legend(['train_acc', 'valid_acc0'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, batch 0, training accuracy 0.125\n",
      "ep 0, batch 50, training accuracy 0.12\n",
      "ep 0, batch 100, training accuracy 0.115\n",
      "ep 0, batch 150, training accuracy 0.1\n",
      "ep 0, batch 200, training accuracy 0.13\n",
      "valid accuracy: 0.0975\n",
      "valid accuracy: 0.105\n",
      "valid accuracy: 0.0985\n",
      "valid accuracy: 0.184\n",
      "valid accuracy: 0.3055\n",
      "valid accuracy: 0.3815\n",
      "valid accuracy: 0.41775\n",
      "valid accuracy: 0.42275\n",
      "valid accuracy: 0.43525\n",
      "valid accuracy: 0.429\n",
      "valid accuracy: 0.45175\n",
      "valid accuracy: 0.4845\n",
      "valid accuracy: 0.4595\n",
      "valid accuracy: 0.459\n",
      "valid accuracy: 0.47075\n",
      "valid accuracy: 0.483\n",
      "valid accuracy: 0.46125\n",
      "valid accuracy: 0.47375\n",
      "valid accuracy: 0.48975\n",
      "valid accuracy: 0.49675\n",
      "valid accuracy: 0.50575\n",
      "valid accuracy: 0.51375\n",
      "valid accuracy: 0.51375\n",
      "valid accuracy: 0.498\n",
      "valid accuracy: 0.5025\n",
      "valid accuracy: 0.4975\n",
      "valid accuracy: 0.51125\n",
      "valid accuracy: 0.494\n",
      "valid accuracy: 0.51775\n",
      "valid accuracy: 0.4985\n",
      "valid accuracy: 0.50075\n",
      "valid accuracy: 0.51275\n",
      "valid accuracy: 0.50575\n",
      "valid accuracy: 0.5015\n",
      "valid accuracy: 0.52625\n",
      "valid accuracy: 0.51325\n",
      "valid accuracy: 0.5055\n",
      "valid accuracy: 0.5155\n",
      "valid accuracy: 0.5235\n",
      "valid accuracy: 0.51625\n",
      "valid accuracy: 0.50825\n",
      "valid accuracy: 0.48325\n",
      "valid accuracy: 0.50375\n",
      "valid accuracy: 0.507\n",
      "valid accuracy: 0.52325\n",
      "valid accuracy: 0.5125\n",
      "valid accuracy: 0.52875\n",
      "valid accuracy: 0.50575\n",
      "valid accuracy: 0.49825\n",
      "valid accuracy: 0.51\n",
      "ep 50, batch 0, training accuracy 0.6\n",
      "ep 50, batch 50, training accuracy 0.61\n",
      "ep 50, batch 100, training accuracy 0.56\n",
      "ep 50, batch 150, training accuracy 0.535\n",
      "ep 50, batch 200, training accuracy 0.59\n",
      "valid accuracy: 0.51375\n",
      "valid accuracy: 0.48425\n",
      "valid accuracy: 0.517\n",
      "valid accuracy: 0.52975\n",
      "valid accuracy: 0.51325\n",
      "valid accuracy: 0.52925\n",
      "valid accuracy: 0.52675\n",
      "valid accuracy: 0.53325\n",
      "valid accuracy: 0.52575\n",
      "valid accuracy: 0.54625\n",
      "valid accuracy: 0.53875\n",
      "valid accuracy: 0.5455\n",
      "valid accuracy: 0.5425\n",
      "valid accuracy: 0.5445\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.549\n",
      "valid accuracy: 0.5515\n",
      "valid accuracy: 0.5515\n",
      "valid accuracy: 0.549\n",
      "valid accuracy: 0.55225\n",
      "valid accuracy: 0.55225\n",
      "valid accuracy: 0.55175\n",
      "valid accuracy: 0.5525\n",
      "valid accuracy: 0.55125\n",
      "valid accuracy: 0.553\n",
      "valid accuracy: 0.55175\n",
      "valid accuracy: 0.55175\n",
      "valid accuracy: 0.55\n",
      "valid accuracy: 0.551\n",
      "valid accuracy: 0.55325\n",
      "valid accuracy: 0.553\n",
      "valid accuracy: 0.55575\n",
      "valid accuracy: 0.552\n",
      "valid accuracy: 0.55375\n",
      "valid accuracy: 0.55225\n",
      "valid accuracy: 0.55375\n",
      "valid accuracy: 0.557\n",
      "valid accuracy: 0.55425\n",
      "valid accuracy: 0.55775\n",
      "valid accuracy: 0.5565\n",
      "valid accuracy: 0.553\n",
      "valid accuracy: 0.556\n",
      "valid accuracy: 0.55675\n",
      "valid accuracy: 0.55675\n",
      "valid accuracy: 0.55575\n",
      "valid accuracy: 0.55525\n",
      "valid accuracy: 0.554\n",
      "valid accuracy: 0.55425\n",
      "valid accuracy: 0.5575\n",
      "valid accuracy: 0.55525\n",
      "ep 100, batch 0, training accuracy 0.64\n",
      "ep 100, batch 50, training accuracy 0.66\n",
      "ep 100, batch 100, training accuracy 0.65\n",
      "ep 100, batch 150, training accuracy 0.59\n",
      "ep 100, batch 200, training accuracy 0.675\n",
      "valid accuracy: 0.55575\n",
      "valid accuracy: 0.554\n",
      "valid accuracy: 0.555\n",
      "valid accuracy: 0.5555\n",
      "valid accuracy: 0.5565\n",
      "valid accuracy: 0.55525\n",
      "valid accuracy: 0.555\n",
      "valid accuracy: 0.554\n",
      "valid accuracy: 0.55325\n",
      "valid accuracy: 0.55175\n",
      "valid accuracy: 0.554\n",
      "valid accuracy: 0.55325\n",
      "valid accuracy: 0.55425\n",
      "valid accuracy: 0.55225\n",
      "valid accuracy: 0.5525\n",
      "valid accuracy: 0.552\n",
      "valid accuracy: 0.5515\n",
      "valid accuracy: 0.5515\n",
      "valid accuracy: 0.55175\n",
      "valid accuracy: 0.5515\n",
      "valid accuracy: 0.552\n",
      "valid accuracy: 0.55225\n",
      "valid accuracy: 0.55225\n",
      "valid accuracy: 0.55225\n",
      "valid accuracy: 0.55125\n",
      "valid accuracy: 0.55125\n",
      "valid accuracy: 0.551\n",
      "valid accuracy: 0.551\n",
      "valid accuracy: 0.55\n",
      "valid accuracy: 0.55125\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.5515\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.55\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.55\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.551\n",
      "ep 150, batch 0, training accuracy 0.645\n",
      "ep 150, batch 50, training accuracy 0.67\n",
      "ep 150, batch 100, training accuracy 0.575\n",
      "ep 150, batch 150, training accuracy 0.64\n",
      "ep 150, batch 200, training accuracy 0.67\n",
      "valid accuracy: 0.551\n",
      "valid accuracy: 0.55175\n",
      "valid accuracy: 0.551\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.551\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.5505\n",
      "valid accuracy: 0.55075\n",
      "valid accuracy: 0.55025\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.54925\n",
      "valid accuracy: 0.54925\n",
      "valid accuracy: 0.549\n",
      "valid accuracy: 0.549\n",
      "valid accuracy: 0.54925\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.54925\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.55\n",
      "valid accuracy: 0.55\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.54975\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "valid accuracy: 0.5495\n",
      "=== cannot decay more. stop learning this batch ===\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 1\n",
    "\n",
    "n_epochs = 500\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "taccs_bcnn_gal = list()\n",
    "#taccs_mean = list()\n",
    "vaccs_bcnn_gal = list()\n",
    "epochs_done = list()\n",
    "\n",
    "for i in range(n_datas):\n",
    "    vaccs_bcnn_gal.append(list())\n",
    "    \n",
    "for d in range(n_datas):\n",
    "    bcnn_gal.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            feed = {bcnn_gal.x: np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 32, 32, 3)), \\\n",
    "                    bcnn_gal.t: t_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                    bcnn_gal.keep_probs: [0.9, 0.9, 0.9, 0.9]}\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bcnn_gal.validate(feed)                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "\n",
    "            bcnn_gal.train(feed)\n",
    "\n",
    "        if ep > 5 and np.mean(taccs_bcnn_gal[-25:]) < taccs_bcnn_gal[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bcnn_gal.get_lr()\n",
    "                bcnn_gal.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bcnn_gal.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    epochs_done.append(ep)\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "        if ep == (n_epochs) - 1: epochs_done.append(ep)\n",
    "                \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            #vaccs_bcnn_gal[i].append(bcnn_gal.validate({bcnn_gal.x: np.reshape(x_valid[i], (-1, 28, 28, 1)), \\\n",
    "             #                                           bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]}))\n",
    "            vaccs_bcnn_gal[i].append(bcnn_gal.validate({bcnn_gal.x: np.reshape(x_valid[i], (-1, 32, 32, 3)), \\\n",
    "                                                        bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [1, 1, 1, 1]}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs_bcnn_gal[i][-1])\n",
    "        \n",
    "        taccs_bcnn_gal.append(train_accuracy)\n",
    "        \n",
    "        print(str_vacc)\n",
    "\n",
    "        #summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "        #                                       bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]})\n",
    "        summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 32, 32, 3)), \\\n",
    "                                               bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [1, 1, 1, 1]})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14506c7990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Gal\\'s Bayesian CNN with Dropout Standard')\n",
    "plt.plot(taccs_bcnn_gal, 'k')\n",
    "plt.plot(vaccs_bcnn_gal[0], 'b')\n",
    "'''\n",
    "plt.plot(vaccs_bcnn_gal[1], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[2], 'r')\n",
    "plt.plot(vaccs_bcnn_gal[3], 'c')\n",
    "plt.plot(vaccs_bcnn_gal[4], 'b')\n",
    "plt.plot(vaccs_bcnn_gal[5], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[6], 'r')\n",
    "'''\n",
    "#plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.legend(['train_acc', 'valid_acc0'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dropout(MC Dropout with sample 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, batch 0, training accuracy 0.075\n",
      "ep 0, batch 50, training accuracy 0.38\n",
      "ep 0, batch 100, training accuracy 0.425\n",
      "ep 0, batch 150, training accuracy 0.495\n",
      "ep 0, batch 200, training accuracy 0.535\n",
      "valid accuracy: 0.5344 0.0998 0.1122 0.0901 0.0938 0.1024 0.092\n",
      "valid accuracy: 0.5515 0.0915 0.1115 0.1031 0.1061 0.1165 0.0875\n",
      "valid accuracy: 0.5585 0.0954 0.0982 0.1048 0.0979 0.108 0.0907\n",
      "valid accuracy: 0.5735 0.0986 0.1032 0.1024 0.0992 0.1076 0.0933\n",
      "valid accuracy: 0.5687 0.095 0.0997 0.105 0.0966 0.1071 0.0898\n",
      "valid accuracy: 0.573 0.0925 0.1061 0.1033 0.1011 0.1132 0.0907\n",
      "valid accuracy: 0.5722 0.0926 0.1011 0.1051 0.0995 0.1089 0.0942\n",
      "valid accuracy: 0.5722 0.0973 0.1064 0.1061 0.0937 0.1101 0.0887\n",
      "valid accuracy: 0.5771 0.093 0.1026 0.1093 0.0992 0.1071 0.0827\n",
      "valid accuracy: 0.5761 0.0979 0.1088 0.1082 0.0966 0.1069 0.0964\n",
      "valid accuracy: 0.5748 0.0951 0.0994 0.1042 0.1039 0.1054 0.0958\n",
      "valid accuracy: 0.5857 0.1021 0.1045 0.1052 0.1104 0.1053 0.0978\n",
      "valid accuracy: 0.5762 0.0937 0.0995 0.0997 0.105 0.1022 0.0962\n",
      "valid accuracy: 0.5774 0.0939 0.1006 0.108 0.1054 0.0973 0.0978\n",
      "valid accuracy: 0.5765 0.0968 0.1039 0.1123 0.1022 0.1054 0.0915\n",
      "valid accuracy: 0.59 0.0965 0.1078 0.1099 0.1054 0.111 0.1\n",
      "valid accuracy: 0.5765 0.1019 0.1057 0.1042 0.1035 0.1044 0.0934\n",
      "valid accuracy: 0.5799 0.0921 0.0993 0.1017 0.1032 0.102 0.0984\n",
      "valid accuracy: 0.5825 0.0933 0.1063 0.1092 0.1024 0.1034 0.0963\n",
      "valid accuracy: 0.589 0.0933 0.1042 0.1073 0.1036 0.1048 0.097\n",
      "valid accuracy: 0.5844 0.0946 0.1023 0.1104 0.1032 0.103 0.0935\n",
      "valid accuracy: 0.5829 0.0977 0.1056 0.1019 0.1108 0.1004 0.1001\n",
      "valid accuracy: 0.5933 0.0926 0.1093 0.1053 0.1021 0.1085 0.0935\n",
      "valid accuracy: 0.5808 0.0949 0.1074 0.1048 0.0995 0.1095 0.0921\n",
      "valid accuracy: 0.588 0.0962 0.1081 0.103 0.1077 0.1065 0.0986\n",
      "valid accuracy: 0.5827 0.096 0.1022 0.1083 0.1026 0.1086 0.0945\n",
      "valid accuracy: 0.5916 0.0992 0.1048 0.0986 0.1047 0.1089 0.0975\n",
      "valid accuracy: 0.5859 0.0954 0.1053 0.1082 0.1125 0.0981 0.0951\n",
      "valid accuracy: 0.587 0.0921 0.1023 0.1043 0.1065 0.1008 0.0949\n",
      "valid accuracy: 0.5869 0.0955 0.1078 0.1109 0.106 0.1041 0.098\n",
      "valid accuracy: 0.585 0.0999 0.1021 0.1104 0.1062 0.1046 0.0956\n",
      "valid accuracy: 0.5849 0.0996 0.1105 0.1078 0.1072 0.1052 0.1009\n",
      "valid accuracy: 0.5815 0.093 0.0984 0.1052 0.1058 0.105 0.1027\n",
      "valid accuracy: 0.5845 0.1011 0.1035 0.1029 0.1087 0.1001 0.0964\n",
      "valid accuracy: 0.5919 0.0912 0.1043 0.102 0.1118 0.0999 0.1002\n",
      "valid accuracy: 0.5812 0.0974 0.1025 0.1017 0.1103 0.1031 0.0956\n",
      "valid accuracy: 0.5866 0.0955 0.0998 0.1046 0.1012 0.1042 0.1027\n",
      "valid accuracy: 0.5854 0.0926 0.1039 0.1079 0.0994 0.1033 0.0976\n",
      "valid accuracy: 0.5876 0.0962 0.1034 0.1097 0.1097 0.1053 0.1011\n",
      "valid accuracy: 0.5869 0.097 0.1059 0.105 0.102 0.1056 0.0986\n",
      "valid accuracy: 0.5774 0.103 0.0999 0.1042 0.1013 0.1036 0.0971\n",
      "valid accuracy: 0.583 0.0964 0.0986 0.1081 0.1029 0.1064 0.1065\n",
      "valid accuracy: 0.5893 0.0997 0.1017 0.1082 0.1103 0.1005 0.0958\n",
      "valid accuracy: 0.5836 0.099 0.1048 0.1015 0.1021 0.109 0.0979\n",
      "valid accuracy: 0.5865 0.1015 0.1016 0.1027 0.1055 0.1099 0.1011\n",
      "valid accuracy: 0.5805 0.0959 0.1011 0.1046 0.1077 0.1037 0.0997\n",
      "valid accuracy: 0.5885 0.0936 0.0984 0.1073 0.108 0.106 0.0983\n",
      "valid accuracy: 0.5857 0.0992 0.1031 0.1034 0.1046 0.1073 0.0997\n",
      "valid accuracy: 0.5841 0.1037 0.106 0.1055 0.1056 0.1084 0.0932\n",
      "valid accuracy: 0.5933 0.0993 0.1014 0.1022 0.1064 0.1063 0.1015\n",
      "ep 50, batch 0, training accuracy 0.605\n",
      "ep 50, batch 50, training accuracy 0.575\n",
      "ep 50, batch 100, training accuracy 0.545\n",
      "ep 50, batch 150, training accuracy 0.595\n",
      "ep 50, batch 200, training accuracy 0.64\n",
      "valid accuracy: 0.5945 0.0992 0.1012 0.1036 0.1092 0.1073 0.1028\n",
      "valid accuracy: 0.5912 0.0996 0.1033 0.1077 0.1046 0.1146 0.0992\n",
      "valid accuracy: 0.5823 0.0956 0.1064 0.107 0.1063 0.1057 0.0962\n",
      "valid accuracy: 0.5887 0.0908 0.1059 0.1035 0.1106 0.1064 0.0951\n",
      "valid accuracy: 0.5751 0.0973 0.1064 0.101 0.1066 0.1028 0.1008\n",
      "valid accuracy: 0.5906 0.0948 0.1065 0.1049 0.1077 0.1051 0.0974\n",
      "valid accuracy: 0.5855 0.1003 0.1069 0.1092 0.1079 0.1043 0.0953\n",
      "valid accuracy: 0.5856 0.0992 0.1017 0.1028 0.11 0.1042 0.0953\n",
      "valid accuracy: 0.5838 0.0993 0.1075 0.1051 0.1043 0.1061 0.096\n",
      "valid accuracy: 0.5882 0.1042 0.1068 0.1045 0.1052 0.108 0.0982\n",
      "valid accuracy: 0.5812 0.1003 0.1053 0.1077 0.1048 0.1059 0.0957\n",
      "valid accuracy: 0.5874 0.0998 0.104 0.1034 0.1031 0.1089 0.1006\n",
      "valid accuracy: 0.5936 0.0986 0.1028 0.1069 0.1112 0.1063 0.0993\n",
      "valid accuracy: 0.5876 0.1031 0.1098 0.1029 0.1047 0.1024 0.0993\n",
      "valid accuracy: 0.5818 0.1006 0.101 0.1113 0.1071 0.1048 0.1023\n",
      "valid accuracy: 0.5904 0.0997 0.1043 0.1015 0.1011 0.108 0.0956\n",
      "valid accuracy: 0.5997 0.0962 0.1057 0.1065 0.1068 0.1059 0.0982\n",
      "valid accuracy: 0.5899 0.0922 0.1054 0.1012 0.1033 0.1094 0.0975\n",
      "valid accuracy: 0.5864 0.0991 0.1095 0.1068 0.1006 0.1092 0.0993\n",
      "valid accuracy: 0.5874 0.0957 0.1029 0.1054 0.107 0.1017 0.1028\n",
      "valid accuracy: 0.5931 0.0972 0.1034 0.1021 0.11 0.1026 0.1035\n",
      "valid accuracy: 0.5861 0.1015 0.1079 0.1069 0.1035 0.1064 0.1005\n",
      "valid accuracy: 0.5957 0.0998 0.1046 0.0994 0.1102 0.1032 0.1005\n",
      "valid accuracy: 0.5918 0.0972 0.106 0.1014 0.1099 0.107 0.0974\n",
      "valid accuracy: 0.5864 0.0943 0.0997 0.101 0.1069 0.1077 0.0991\n",
      "valid accuracy: 0.5889 0.1032 0.0994 0.1046 0.1053 0.1068 0.0991\n",
      "valid accuracy: 0.5846 0.0938 0.0998 0.1042 0.103 0.1044 0.0958\n",
      "valid accuracy: 0.5949 0.0968 0.1098 0.1101 0.1 0.1065 0.1034\n",
      "valid accuracy: 0.5969 0.0957 0.1023 0.1052 0.11 0.1051 0.0991\n",
      "valid accuracy: 0.5851 0.1016 0.1064 0.106 0.1064 0.1045 0.0975\n",
      "valid accuracy: 0.5928 0.0996 0.1009 0.1014 0.1102 0.105 0.0995\n",
      "valid accuracy: 0.5858 0.1008 0.1034 0.1028 0.1083 0.1018 0.0957\n",
      "valid accuracy: 0.593 0.0969 0.1075 0.1082 0.1093 0.109 0.0989\n",
      "valid accuracy: 0.5822 0.0962 0.1052 0.1075 0.109 0.1096 0.1005\n",
      "valid accuracy: 0.5912 0.1002 0.1049 0.1021 0.11 0.1065 0.1017\n",
      "valid accuracy: 0.5915 0.096 0.098 0.1057 0.1052 0.107 0.1018\n",
      "valid accuracy: 0.5866 0.0966 0.1051 0.1085 0.1114 0.1061 0.0953\n",
      "valid accuracy: 0.5805 0.098 0.1105 0.0977 0.1118 0.1047 0.0967\n",
      "valid accuracy: 0.593 0.1012 0.1053 0.1005 0.1094 0.0998 0.098\n",
      "valid accuracy: 0.5908 0.0941 0.1041 0.0995 0.1092 0.0992 0.0978\n",
      "valid accuracy: 0.5868 0.0951 0.0985 0.1069 0.1085 0.104 0.1024\n",
      "valid accuracy: 0.5934 0.0983 0.1026 0.1092 0.111 0.1092 0.0998\n",
      "valid accuracy: 0.5932 0.098 0.1047 0.1032 0.107 0.1068 0.0981\n",
      "valid accuracy: 0.5951 0.101 0.102 0.1076 0.1033 0.1047 0.1052\n",
      "valid accuracy: 0.5916 0.0982 0.1004 0.1085 0.1062 0.1083 0.1028\n",
      "valid accuracy: 0.5967 0.1001 0.1039 0.1048 0.1075 0.107 0.1009\n",
      "valid accuracy: 0.5871 0.096 0.1059 0.102 0.108 0.1061 0.1032\n",
      "valid accuracy: 0.5923 0.0962 0.1028 0.1058 0.1079 0.1073 0.102\n",
      "valid accuracy: 0.592 0.0996 0.0996 0.1038 0.1034 0.1033 0.1004\n",
      "valid accuracy: 0.5852 0.0999 0.0964 0.1057 0.1052 0.1087 0.0951\n",
      "ep 100, batch 0, training accuracy 0.65\n",
      "ep 100, batch 50, training accuracy 0.575\n",
      "ep 100, batch 100, training accuracy 0.605\n",
      "ep 100, batch 150, training accuracy 0.605\n",
      "ep 100, batch 200, training accuracy 0.635\n",
      "valid accuracy: 0.5797 0.0988 0.106 0.1016 0.1126 0.1013 0.0984\n",
      "valid accuracy: 0.5827 0.0998 0.1036 0.1055 0.1042 0.1039 0.0998\n",
      "valid accuracy: 0.5894 0.0971 0.1054 0.1089 0.1058 0.103 0.1003\n",
      "valid accuracy: 0.5889 0.101 0.1106 0.1052 0.1075 0.1108 0.0983\n",
      "valid accuracy: 0.5842 0.1007 0.1043 0.1034 0.1092 0.1082 0.1017\n",
      "valid accuracy: 0.5865 0.0989 0.1074 0.1053 0.1089 0.1032 0.0937\n",
      "valid accuracy: 0.5958 0.0936 0.1063 0.1076 0.1052 0.1065 0.0977\n",
      "valid accuracy: 0.5852 0.0992 0.1013 0.1078 0.1063 0.1034 0.1002\n",
      "valid accuracy: 0.5913 0.096 0.1068 0.1071 0.1124 0.1039 0.1001\n",
      "valid accuracy: 0.5847 0.0976 0.1012 0.1008 0.1102 0.1022 0.1046\n",
      "valid accuracy: 0.5821 0.0984 0.1035 0.101 0.1098 0.0985 0.0979\n",
      "valid accuracy: 0.599 0.1025 0.1038 0.106 0.1087 0.1014 0.1014\n",
      "valid accuracy: 0.5874 0.0987 0.1 0.104 0.1024 0.1105 0.1011\n",
      "valid accuracy: 0.5919 0.0997 0.1044 0.1055 0.1069 0.107 0.0974\n",
      "valid accuracy: 0.5843 0.0984 0.1035 0.1078 0.101 0.105 0.0947\n",
      "valid accuracy: 0.5893 0.0966 0.0992 0.1024 0.1107 0.1005 0.1006\n",
      "valid accuracy: 0.5836 0.0944 0.1058 0.1058 0.1109 0.1006 0.1032\n",
      "valid accuracy: 0.5912 0.0989 0.1044 0.108 0.1082 0.1013 0.1023\n",
      "valid accuracy: 0.5884 0.1008 0.1069 0.108 0.1096 0.1023 0.1038\n",
      "valid accuracy: 0.5929 0.0994 0.109 0.1031 0.1048 0.1062 0.0926\n",
      "valid accuracy: 0.5909 0.0961 0.1088 0.1085 0.105 0.105 0.0988\n",
      "valid accuracy: 0.5908 0.0961 0.1039 0.1008 0.1076 0.1101 0.0954\n",
      "valid accuracy: 0.5847 0.0952 0.1019 0.1028 0.1044 0.1036 0.0934\n",
      "valid accuracy: 0.5879 0.1031 0.1071 0.0994 0.1086 0.1072 0.1041\n",
      "valid accuracy: 0.5919 0.0977 0.1043 0.1038 0.1052 0.1087 0.0946\n",
      "valid accuracy: 0.5845 0.0914 0.1009 0.1093 0.11 0.1035 0.1015\n",
      "valid accuracy: 0.5918 0.1001 0.1074 0.1075 0.1089 0.1067 0.0979\n",
      "valid accuracy: 0.5922 0.0977 0.1011 0.1027 0.1074 0.1046 0.1007\n",
      "valid accuracy: 0.5877 0.0975 0.1065 0.1079 0.1047 0.1031 0.0995\n",
      "valid accuracy: 0.5894 0.0937 0.106 0.1027 0.1058 0.1027 0.1005\n",
      "valid accuracy: 0.5901 0.098 0.1084 0.111 0.1022 0.1021 0.1004\n",
      "valid accuracy: 0.5898 0.0997 0.0993 0.1038 0.1049 0.105 0.096\n",
      "valid accuracy: 0.5832 0.0978 0.0998 0.1071 0.1058 0.0966 0.0982\n",
      "valid accuracy: 0.5918 0.0926 0.1011 0.0996 0.1045 0.1097 0.0976\n",
      "valid accuracy: 0.5947 0.0931 0.1035 0.1028 0.1057 0.1072 0.0921\n",
      "valid accuracy: 0.5884 0.0935 0.0994 0.1088 0.1043 0.1049 0.0991\n",
      "valid accuracy: 0.5973 0.0953 0.1027 0.1003 0.1118 0.1038 0.1028\n",
      "valid accuracy: 0.5903 0.0997 0.1059 0.1062 0.1086 0.1088 0.0988\n",
      "valid accuracy: 0.5895 0.1002 0.1035 0.1026 0.1082 0.1014 0.098\n",
      "valid accuracy: 0.5898 0.0969 0.1069 0.1043 0.1041 0.1124 0.0997\n",
      "valid accuracy: 0.5979 0.1024 0.1039 0.1037 0.1108 0.1055 0.0921\n",
      "valid accuracy: 0.5833 0.0978 0.107 0.1071 0.1077 0.1044 0.0935\n",
      "valid accuracy: 0.589 0.0977 0.1093 0.1092 0.1059 0.104 0.0999\n",
      "valid accuracy: 0.5892 0.0952 0.1004 0.1062 0.1066 0.1007 0.0996\n",
      "valid accuracy: 0.5897 0.099 0.1038 0.1036 0.1036 0.0988 0.0946\n",
      "valid accuracy: 0.5947 0.0965 0.1066 0.1046 0.105 0.1107 0.1001\n",
      "valid accuracy: 0.5839 0.0993 0.1006 0.1008 0.1043 0.1019 0.1002\n",
      "valid accuracy: 0.5845 0.1016 0.1026 0.1073 0.1098 0.1062 0.0959\n",
      "valid accuracy: 0.5893 0.1018 0.1042 0.1056 0.1052 0.1038 0.0966\n",
      "valid accuracy: 0.5888 0.0972 0.1054 0.1089 0.107 0.1095 0.0961\n",
      "ep 150, batch 0, training accuracy 0.58\n",
      "ep 150, batch 50, training accuracy 0.59\n",
      "ep 150, batch 100, training accuracy 0.545\n",
      "ep 150, batch 150, training accuracy 0.59\n",
      "ep 150, batch 200, training accuracy 0.59\n",
      "valid accuracy: 0.5828 0.0969 0.1043 0.1037 0.1058 0.103 0.0973\n",
      "valid accuracy: 0.5829 0.0917 0.1016 0.1038 0.1078 0.1065 0.0946\n",
      "valid accuracy: 0.5958 0.1007 0.1006 0.109 0.105 0.1009 0.1004\n",
      "valid accuracy: 0.5854 0.1018 0.102 0.102 0.1114 0.1035 0.1011\n",
      "valid accuracy: 0.5924 0.0979 0.1084 0.1055 0.1081 0.1045 0.0988\n",
      "valid accuracy: 0.5874 0.0919 0.1078 0.1036 0.1034 0.1057 0.0972\n",
      "valid accuracy: 0.5923 0.0953 0.1013 0.108 0.1105 0.1004 0.0966\n",
      "valid accuracy: 0.5818 0.0955 0.0972 0.1015 0.1053 0.1064 0.0952\n",
      "valid accuracy: 0.5973 0.0983 0.1085 0.106 0.1035 0.1046 0.1001\n",
      "valid accuracy: 0.5895 0.096 0.1045 0.1026 0.1025 0.107 0.0993\n",
      "valid accuracy: 0.5952 0.0934 0.0992 0.1057 0.1076 0.105 0.0972\n",
      "valid accuracy: 0.5883 0.1007 0.1046 0.1002 0.1062 0.1031 0.0994\n",
      "valid accuracy: 0.5922 0.0925 0.1031 0.1048 0.1059 0.1071 0.1003\n",
      "valid accuracy: 0.5885 0.0921 0.1 0.1049 0.1021 0.1035 0.0976\n",
      "valid accuracy: 0.59 0.1008 0.1072 0.1106 0.1071 0.1087 0.099\n",
      "valid accuracy: 0.5969 0.1002 0.1023 0.1033 0.1077 0.1065 0.0988\n",
      "valid accuracy: 0.5854 0.0997 0.1022 0.1091 0.1058 0.1005 0.0959\n",
      "valid accuracy: 0.5896 0.0979 0.0999 0.1002 0.1057 0.1054 0.0992\n",
      "valid accuracy: 0.592 0.0991 0.1033 0.1063 0.1069 0.1017 0.0991\n",
      "valid accuracy: 0.5857 0.0994 0.1019 0.1053 0.1108 0.1014 0.0971\n",
      "valid accuracy: 0.5886 0.1037 0.1097 0.1039 0.1062 0.1031 0.0943\n",
      "valid accuracy: 0.5834 0.0995 0.1041 0.1004 0.1105 0.1017 0.1011\n",
      "valid accuracy: 0.5995 0.1018 0.1048 0.1074 0.1075 0.1067 0.0976\n",
      "valid accuracy: 0.5934 0.0976 0.0997 0.1081 0.1087 0.1053 0.0986\n",
      "valid accuracy: 0.5971 0.0947 0.1018 0.1028 0.1047 0.1039 0.0955\n",
      "valid accuracy: 0.5873 0.0968 0.1003 0.1065 0.109 0.1062 0.0974\n",
      "valid accuracy: 0.5891 0.0987 0.1043 0.1063 0.1062 0.1035 0.0977\n",
      "valid accuracy: 0.5861 0.0978 0.1022 0.1023 0.108 0.109 0.1003\n",
      "valid accuracy: 0.5878 0.0983 0.1053 0.1065 0.1086 0.1035 0.0995\n",
      "valid accuracy: 0.59 0.0977 0.105 0.1021 0.1092 0.1034 0.0979\n",
      "valid accuracy: 0.5862 0.1001 0.1084 0.1051 0.1066 0.1074 0.0981\n",
      "valid accuracy: 0.5926 0.0998 0.1075 0.1001 0.1087 0.1019 0.0994\n",
      "valid accuracy: 0.5838 0.0994 0.1054 0.1073 0.1035 0.1029 0.1001\n",
      "valid accuracy: 0.5939 0.1012 0.1005 0.1047 0.1113 0.1028 0.0991\n",
      "valid accuracy: 0.5807 0.1011 0.1039 0.1018 0.1082 0.1078 0.1038\n",
      "valid accuracy: 0.5845 0.0998 0.1073 0.1029 0.1099 0.1002 0.1\n",
      "valid accuracy: 0.5998 0.1045 0.1028 0.1064 0.1052 0.1029 0.1009\n",
      "valid accuracy: 0.5883 0.1036 0.1003 0.1067 0.1075 0.1047 0.0947\n",
      "valid accuracy: 0.5869 0.0976 0.102 0.0991 0.1114 0.1061 0.1003\n",
      "valid accuracy: 0.5895 0.094 0.1038 0.1035 0.1103 0.1061 0.0986\n",
      "valid accuracy: 0.594 0.0984 0.1025 0.1034 0.1089 0.1056 0.0998\n",
      "valid accuracy: 0.5896 0.0975 0.1022 0.1045 0.1071 0.0994 0.0972\n",
      "valid accuracy: 0.5865 0.101 0.0991 0.1018 0.1028 0.1053 0.1\n",
      "valid accuracy: 0.5931 0.0993 0.1013 0.1077 0.1073 0.1042 0.1004\n",
      "valid accuracy: 0.5941 0.0993 0.1087 0.1049 0.109 0.1071 0.0982\n",
      "valid accuracy: 0.591 0.0961 0.1069 0.1065 0.1061 0.1024 0.0976\n",
      "valid accuracy: 0.5828 0.0975 0.1028 0.1008 0.1073 0.1103 0.0994\n",
      "valid accuracy: 0.5921 0.0985 0.1079 0.1038 0.1021 0.1063 0.1004\n",
      "valid accuracy: 0.5959 0.1003 0.1027 0.1004 0.1056 0.1013 0.0999\n",
      "valid accuracy: 0.5836 0.1019 0.1057 0.1076 0.1022 0.1037 0.0986\n",
      "ep 200, batch 0, training accuracy 0.535\n",
      "ep 200, batch 50, training accuracy 0.585\n",
      "ep 200, batch 100, training accuracy 0.585\n",
      "ep 200, batch 150, training accuracy 0.59\n",
      "ep 200, batch 200, training accuracy 0.655\n",
      "valid accuracy: 0.5834 0.0998 0.1076 0.1035 0.1059 0.1078 0.0966\n",
      "valid accuracy: 0.5788 0.0952 0.1024 0.108 0.1043 0.1054 0.1002\n",
      "valid accuracy: 0.5923 0.0976 0.1025 0.1057 0.1059 0.1036 0.0978\n",
      "valid accuracy: 0.5863 0.0996 0.1062 0.1109 0.1074 0.1024 0.1007\n",
      "valid accuracy: 0.5905 0.1013 0.1007 0.1074 0.1031 0.1037 0.0973\n",
      "valid accuracy: 0.5901 0.0999 0.1024 0.0999 0.1092 0.1077 0.1003\n",
      "valid accuracy: 0.5962 0.0966 0.105 0.102 0.1043 0.1042 0.102\n",
      "valid accuracy: 0.5887 0.0963 0.1067 0.1029 0.1078 0.1053 0.0997\n",
      "valid accuracy: 0.5876 0.0974 0.105 0.1072 0.109 0.1037 0.0996\n",
      "valid accuracy: 0.5842 0.0973 0.1053 0.1076 0.0996 0.1014 0.0965\n",
      "valid accuracy: 0.5889 0.1028 0.1024 0.1099 0.1069 0.1014 0.1054\n",
      "valid accuracy: 0.5925 0.0932 0.1059 0.1044 0.1055 0.1012 0.0952\n",
      "valid accuracy: 0.5942 0.0939 0.105 0.1038 0.1075 0.1026 0.0909\n",
      "valid accuracy: 0.5874 0.1024 0.1093 0.1024 0.1094 0.1013 0.1009\n",
      "valid accuracy: 0.5891 0.0976 0.1021 0.1069 0.1048 0.1057 0.0986\n",
      "valid accuracy: 0.5969 0.1026 0.108 0.1026 0.1061 0.1035 0.0984\n",
      "valid accuracy: 0.585 0.0957 0.103 0.1054 0.1058 0.1088 0.0987\n",
      "valid accuracy: 0.5916 0.0963 0.1014 0.0972 0.1029 0.1091 0.0954\n",
      "valid accuracy: 0.5909 0.0927 0.1099 0.104 0.1094 0.1045 0.0999\n",
      "valid accuracy: 0.5892 0.0982 0.1032 0.1036 0.1073 0.1066 0.0991\n",
      "valid accuracy: 0.5985 0.0962 0.0999 0.106 0.1032 0.1051 0.1011\n",
      "valid accuracy: 0.5918 0.0992 0.1114 0.1141 0.1092 0.1044 0.1023\n",
      "valid accuracy: 0.5888 0.0939 0.1033 0.1049 0.1123 0.1069 0.0967\n",
      "valid accuracy: 0.5909 0.0941 0.1011 0.1043 0.1065 0.1058 0.0968\n",
      "valid accuracy: 0.5876 0.0999 0.1008 0.1048 0.1069 0.1072 0.0991\n",
      "valid accuracy: 0.5864 0.0947 0.1005 0.1038 0.107 0.1005 0.1026\n",
      "valid accuracy: 0.5884 0.0953 0.1056 0.11 0.1101 0.1002 0.0957\n",
      "valid accuracy: 0.5937 0.0965 0.1009 0.1028 0.1128 0.1084 0.0989\n",
      "valid accuracy: 0.5989 0.0953 0.0969 0.1081 0.1133 0.1065 0.1011\n",
      "valid accuracy: 0.5864 0.1001 0.1057 0.1092 0.1103 0.0994 0.1002\n",
      "valid accuracy: 0.5888 0.0972 0.1032 0.1079 0.1099 0.1065 0.0977\n",
      "valid accuracy: 0.5883 0.0984 0.0995 0.1034 0.1003 0.1043 0.0977\n",
      "valid accuracy: 0.5942 0.0971 0.1016 0.1046 0.1057 0.1062 0.0999\n",
      "valid accuracy: 0.5882 0.1014 0.1028 0.1062 0.1101 0.1045 0.0988\n",
      "valid accuracy: 0.5833 0.0928 0.106 0.1056 0.1062 0.1022 0.0959\n",
      "valid accuracy: 0.5934 0.0986 0.1077 0.1053 0.1035 0.1065 0.1013\n",
      "valid accuracy: 0.5782 0.0962 0.1048 0.105 0.1111 0.1028 0.0963\n",
      "valid accuracy: 0.5945 0.1016 0.0962 0.1011 0.105 0.1026 0.1032\n",
      "valid accuracy: 0.5876 0.0953 0.1056 0.1016 0.1095 0.1027 0.0988\n",
      "valid accuracy: 0.5918 0.0972 0.1082 0.1017 0.1084 0.1066 0.0986\n",
      "valid accuracy: 0.5932 0.1016 0.1011 0.1051 0.1127 0.108 0.0957\n",
      "valid accuracy: 0.5858 0.0974 0.102 0.1044 0.1028 0.1056 0.0981\n",
      "valid accuracy: 0.5922 0.1029 0.1092 0.0978 0.1132 0.1071 0.101\n",
      "valid accuracy: 0.5877 0.0993 0.1042 0.1037 0.105 0.1009 0.101\n",
      "valid accuracy: 0.5892 0.1002 0.1055 0.1046 0.1033 0.1045 0.0995\n",
      "valid accuracy: 0.5856 0.0937 0.1015 0.0984 0.1127 0.1046 0.0998\n",
      "valid accuracy: 0.583 0.0981 0.0999 0.1062 0.1066 0.1013 0.0957\n",
      "valid accuracy: 0.5933 0.1011 0.1023 0.1046 0.1076 0.1055 0.0979\n",
      "valid accuracy: 0.5955 0.0983 0.106 0.1051 0.1083 0.1084 0.0994\n",
      "valid accuracy: 0.6017 0.1066 0.1038 0.1073 0.1085 0.1052 0.1037\n",
      "ep 250, batch 0, training accuracy 0.595\n",
      "ep 250, batch 50, training accuracy 0.565\n",
      "ep 250, batch 100, training accuracy 0.625\n",
      "ep 250, batch 150, training accuracy 0.565\n",
      "ep 250, batch 200, training accuracy 0.6\n",
      "valid accuracy: 0.5901 0.1039 0.1004 0.0942 0.1076 0.1077 0.0976\n",
      "valid accuracy: 0.5864 0.0972 0.1036 0.1071 0.1037 0.1043 0.0978\n",
      "valid accuracy: 0.5867 0.0919 0.1052 0.1041 0.1101 0.1057 0.0976\n",
      "valid accuracy: 0.5909 0.0971 0.1011 0.1031 0.1071 0.1069 0.0962\n",
      "valid accuracy: 0.5868 0.0941 0.1096 0.108 0.105 0.1065 0.1018\n",
      "valid accuracy: 0.59 0.0984 0.1052 0.1067 0.1065 0.1012 0.0976\n",
      "valid accuracy: 0.5867 0.101 0.107 0.1062 0.1083 0.101 0.1005\n",
      "valid accuracy: 0.5899 0.0949 0.1056 0.1033 0.1082 0.1072 0.0991\n",
      "valid accuracy: 0.5895 0.1003 0.1034 0.1009 0.1053 0.102 0.0947\n",
      "valid accuracy: 0.5845 0.0974 0.1017 0.1023 0.1071 0.1052 0.1023\n",
      "valid accuracy: 0.5882 0.0959 0.1003 0.1104 0.1054 0.1027 0.1022\n",
      "valid accuracy: 0.5898 0.1043 0.1024 0.1069 0.1044 0.1041 0.0931\n",
      "valid accuracy: 0.6033 0.0984 0.108 0.1036 0.1088 0.1052 0.0959\n",
      "valid accuracy: 0.5849 0.0974 0.1033 0.1028 0.1094 0.108 0.1\n",
      "valid accuracy: 0.5922 0.0944 0.1022 0.1013 0.1062 0.1066 0.0977\n",
      "valid accuracy: 0.5853 0.095 0.1007 0.112 0.1074 0.106 0.0997\n",
      "valid accuracy: 0.5916 0.098 0.1011 0.1029 0.1058 0.1027 0.0923\n",
      "valid accuracy: 0.596 0.1023 0.1018 0.1071 0.1108 0.1017 0.1004\n",
      "valid accuracy: 0.5803 0.0971 0.1018 0.1057 0.1085 0.1005 0.0981\n",
      "valid accuracy: 0.588 0.0938 0.1021 0.1107 0.1125 0.1031 0.0978\n",
      "valid accuracy: 0.5866 0.0948 0.1013 0.1031 0.1056 0.1063 0.0989\n",
      "valid accuracy: 0.5863 0.0975 0.1011 0.1062 0.1053 0.1058 0.1037\n",
      "valid accuracy: 0.5856 0.0975 0.1051 0.1023 0.1057 0.1108 0.0979\n",
      "valid accuracy: 0.5822 0.0977 0.1048 0.105 0.104 0.1055 0.0965\n",
      "valid accuracy: 0.5967 0.1029 0.1065 0.1019 0.1003 0.1068 0.0968\n",
      "valid accuracy: 0.5892 0.0961 0.1059 0.1006 0.1045 0.106 0.0983\n",
      "valid accuracy: 0.589 0.0934 0.1069 0.1114 0.1085 0.1099 0.0982\n",
      "valid accuracy: 0.5844 0.0949 0.1005 0.1036 0.1125 0.1068 0.0997\n",
      "valid accuracy: 0.5956 0.0944 0.108 0.1023 0.1053 0.1039 0.0915\n",
      "valid accuracy: 0.5953 0.0987 0.1056 0.1069 0.1074 0.1022 0.0988\n",
      "valid accuracy: 0.5852 0.1031 0.1058 0.106 0.11 0.1061 0.098\n",
      "valid accuracy: 0.5958 0.0997 0.0986 0.1074 0.1054 0.1071 0.0997\n",
      "valid accuracy: 0.5879 0.093 0.1075 0.102 0.1047 0.1017 0.102\n",
      "valid accuracy: 0.5828 0.0999 0.1049 0.1014 0.1122 0.1025 0.0985\n",
      "valid accuracy: 0.5894 0.099 0.1063 0.1022 0.1026 0.1084 0.1061\n",
      "valid accuracy: 0.5863 0.0989 0.1037 0.1013 0.1083 0.1022 0.0962\n",
      "valid accuracy: 0.5908 0.0996 0.1082 0.1052 0.1072 0.1021 0.101\n",
      "valid accuracy: 0.5916 0.0994 0.1053 0.1017 0.1085 0.1095 0.1011\n",
      "valid accuracy: 0.5834 0.0937 0.1032 0.1047 0.1065 0.1054 0.0962\n",
      "valid accuracy: 0.5916 0.0994 0.1074 0.1077 0.1104 0.1073 0.1023\n",
      "valid accuracy: 0.5839 0.1016 0.104 0.1023 0.109 0.1042 0.1012\n",
      "valid accuracy: 0.5854 0.0986 0.0976 0.1057 0.1105 0.1081 0.0976\n",
      "valid accuracy: 0.5942 0.0939 0.1053 0.1103 0.1013 0.103 0.0981\n",
      "valid accuracy: 0.5942 0.093 0.1005 0.1024 0.0995 0.1007 0.0994\n",
      "valid accuracy: 0.5873 0.1032 0.0983 0.1096 0.103 0.1041 0.1017\n",
      "valid accuracy: 0.5899 0.1007 0.1036 0.1066 0.1113 0.1036 0.1029\n",
      "valid accuracy: 0.5946 0.0955 0.099 0.1038 0.1092 0.1027 0.097\n",
      "valid accuracy: 0.592 0.0965 0.1054 0.1012 0.1073 0.1021 0.0985\n",
      "valid accuracy: 0.5812 0.0935 0.103 0.1079 0.0984 0.105 0.0969\n",
      "valid accuracy: 0.5933 0.0964 0.1089 0.1051 0.1057 0.1002 0.1008\n",
      "ep 300, batch 0, training accuracy 0.635\n",
      "ep 300, batch 50, training accuracy 0.6\n",
      "ep 300, batch 100, training accuracy 0.58\n",
      "ep 300, batch 150, training accuracy 0.605\n",
      "ep 300, batch 200, training accuracy 0.62\n",
      "valid accuracy: 0.5899 0.0979 0.106 0.111 0.1074 0.1039 0.0967\n",
      "valid accuracy: 0.5937 0.1029 0.105 0.1045 0.108 0.1053 0.095\n",
      "valid accuracy: 0.5796 0.0962 0.1097 0.1052 0.1088 0.1077 0.102\n",
      "valid accuracy: 0.5878 0.1027 0.1054 0.1052 0.1042 0.1039 0.1006\n",
      "valid accuracy: 0.5912 0.0988 0.1069 0.1021 0.1036 0.1025 0.0982\n",
      "valid accuracy: 0.5904 0.0987 0.0998 0.102 0.1103 0.1032 0.0962\n",
      "valid accuracy: 0.5872 0.0956 0.1009 0.1035 0.1122 0.1091 0.0984\n",
      "valid accuracy: 0.5915 0.0982 0.0991 0.105 0.1086 0.104 0.1022\n",
      "valid accuracy: 0.5942 0.0976 0.0985 0.1061 0.1095 0.1046 0.0974\n",
      "valid accuracy: 0.5921 0.0979 0.1011 0.1063 0.1094 0.104 0.0995\n",
      "valid accuracy: 0.5916 0.1003 0.1018 0.1072 0.1065 0.1077 0.0977\n",
      "valid accuracy: 0.5842 0.0955 0.1034 0.1036 0.1084 0.1039 0.0995\n",
      "valid accuracy: 0.5849 0.0972 0.1019 0.1012 0.1151 0.1078 0.0995\n",
      "valid accuracy: 0.5898 0.0961 0.1024 0.1045 0.1112 0.1088 0.1006\n",
      "valid accuracy: 0.5903 0.0981 0.1064 0.1019 0.1047 0.101 0.0936\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.115\n",
      "ep 0, batch 50, training accuracy 0.11\n",
      "ep 0, batch 100, training accuracy 0.13\n",
      "ep 0, batch 150, training accuracy 0.17\n",
      "ep 0, batch 200, training accuracy 0.165\n",
      "valid accuracy: 0.2471 0.2114 0.1127 0.1084 0.1272 0.1205 0.1225\n",
      "valid accuracy: 0.2168 0.3166 0.1176 0.1112 0.1265 0.1274 0.1068\n",
      "valid accuracy: 0.2142 0.3756 0.1131 0.1086 0.1133 0.1163 0.1083\n",
      "valid accuracy: 0.1812 0.423 0.1059 0.118 0.1072 0.1065 0.1079\n",
      "valid accuracy: 0.1512 0.4407 0.1204 0.1217 0.1013 0.1198 0.1098\n",
      "valid accuracy: 0.1368 0.4611 0.1117 0.1161 0.1059 0.1039 0.1031\n",
      "valid accuracy: 0.1295 0.4813 0.1199 0.1228 0.1024 0.1111 0.097\n",
      "valid accuracy: 0.1272 0.4835 0.1111 0.1164 0.1005 0.1036 0.1046\n",
      "valid accuracy: 0.1265 0.4976 0.114 0.119 0.0974 0.1045 0.1052\n",
      "valid accuracy: 0.1345 0.4972 0.1188 0.1183 0.1005 0.1044 0.1036\n",
      "valid accuracy: 0.1302 0.5045 0.1116 0.1104 0.1001 0.1035 0.0962\n",
      "valid accuracy: 0.1268 0.5131 0.115 0.1205 0.1002 0.1055 0.1034\n",
      "valid accuracy: 0.1219 0.5011 0.1095 0.1065 0.0918 0.1005 0.0996\n",
      "valid accuracy: 0.124 0.5116 0.1068 0.1165 0.0954 0.1091 0.0976\n",
      "valid accuracy: 0.13 0.5152 0.1073 0.1068 0.0995 0.1019 0.1075\n",
      "valid accuracy: 0.1246 0.5318 0.1172 0.1044 0.0934 0.1008 0.1042\n",
      "valid accuracy: 0.1217 0.5258 0.1076 0.1139 0.0881 0.0981 0.0989\n",
      "valid accuracy: 0.121 0.5316 0.1088 0.1147 0.0918 0.0992 0.1001\n",
      "valid accuracy: 0.1166 0.5264 0.1051 0.1117 0.0952 0.098 0.0987\n",
      "valid accuracy: 0.12 0.5377 0.1059 0.1149 0.0973 0.0957 0.1047\n",
      "valid accuracy: 0.1263 0.5295 0.1104 0.1121 0.088 0.1007 0.1049\n",
      "valid accuracy: 0.1167 0.5287 0.1076 0.1191 0.1013 0.0937 0.0996\n",
      "valid accuracy: 0.1216 0.52 0.1094 0.1161 0.0944 0.0982 0.1037\n",
      "valid accuracy: 0.113 0.5299 0.1126 0.1134 0.0963 0.0939 0.1021\n",
      "valid accuracy: 0.1122 0.5375 0.1114 0.1154 0.0959 0.0965 0.1072\n",
      "valid accuracy: 0.1174 0.5367 0.1087 0.1115 0.0939 0.0988 0.0989\n",
      "valid accuracy: 0.1239 0.5365 0.1045 0.1172 0.0928 0.0984 0.0958\n",
      "valid accuracy: 0.1223 0.5394 0.1067 0.1129 0.0984 0.1007 0.0983\n",
      "valid accuracy: 0.1163 0.5404 0.1071 0.1161 0.0925 0.095 0.1016\n",
      "valid accuracy: 0.1204 0.5393 0.1045 0.1142 0.0986 0.0984 0.1067\n",
      "valid accuracy: 0.1192 0.5372 0.1085 0.109 0.0969 0.0975 0.098\n",
      "valid accuracy: 0.1199 0.5346 0.1116 0.1103 0.0939 0.0948 0.1006\n",
      "valid accuracy: 0.1151 0.5389 0.1021 0.1209 0.0901 0.0962 0.0964\n",
      "valid accuracy: 0.114 0.5427 0.1132 0.1193 0.087 0.0939 0.0932\n",
      "valid accuracy: 0.1204 0.5397 0.1066 0.1178 0.0924 0.1006 0.1008\n",
      "valid accuracy: 0.1231 0.5379 0.1091 0.1154 0.092 0.0945 0.1058\n",
      "valid accuracy: 0.1268 0.5432 0.1068 0.1165 0.0922 0.0971 0.101\n",
      "valid accuracy: 0.1284 0.5442 0.1071 0.122 0.093 0.1 0.0985\n",
      "valid accuracy: 0.1119 0.5348 0.1059 0.1138 0.0934 0.0958 0.0961\n",
      "valid accuracy: 0.1174 0.5455 0.1061 0.1197 0.0974 0.0957 0.0966\n",
      "valid accuracy: 0.1183 0.5458 0.1047 0.124 0.0999 0.0927 0.1008\n",
      "valid accuracy: 0.1153 0.5515 0.1048 0.1155 0.0989 0.0958 0.0964\n",
      "valid accuracy: 0.1185 0.5507 0.1065 0.1233 0.0928 0.0986 0.1009\n",
      "valid accuracy: 0.1124 0.5517 0.1089 0.1143 0.0951 0.0957 0.0971\n",
      "valid accuracy: 0.1169 0.5474 0.1102 0.1262 0.0934 0.0962 0.0974\n",
      "valid accuracy: 0.115 0.5513 0.1063 0.1156 0.0906 0.0969 0.0991\n",
      "valid accuracy: 0.1235 0.5521 0.1064 0.1248 0.0887 0.1008 0.1049\n",
      "valid accuracy: 0.1141 0.55 0.1047 0.1199 0.0972 0.0984 0.1026\n",
      "valid accuracy: 0.1193 0.56 0.1076 0.1227 0.0857 0.1046 0.0946\n",
      "valid accuracy: 0.1123 0.5452 0.1089 0.1197 0.0939 0.0983 0.098\n",
      "ep 50, batch 0, training accuracy 0.555\n",
      "ep 50, batch 50, training accuracy 0.545\n",
      "ep 50, batch 100, training accuracy 0.55\n",
      "ep 50, batch 150, training accuracy 0.585\n",
      "ep 50, batch 200, training accuracy 0.57\n",
      "valid accuracy: 0.109 0.5467 0.1125 0.1185 0.0952 0.0982 0.1007\n",
      "valid accuracy: 0.1126 0.5383 0.1138 0.1187 0.0932 0.0935 0.1\n",
      "valid accuracy: 0.1253 0.5485 0.1123 0.1181 0.0955 0.1003 0.0976\n",
      "valid accuracy: 0.1153 0.5548 0.1114 0.1244 0.0926 0.0954 0.0982\n",
      "valid accuracy: 0.1143 0.5499 0.1143 0.122 0.0958 0.1031 0.1036\n",
      "valid accuracy: 0.114 0.5522 0.1054 0.1261 0.092 0.0966 0.0967\n",
      "valid accuracy: 0.1104 0.5458 0.1105 0.1193 0.096 0.1024 0.1002\n",
      "valid accuracy: 0.1162 0.552 0.1056 0.1295 0.1008 0.0995 0.1024\n",
      "valid accuracy: 0.121 0.5575 0.1094 0.1207 0.0961 0.0989 0.0993\n",
      "valid accuracy: 0.1173 0.5564 0.1056 0.1192 0.0923 0.0988 0.1003\n",
      "valid accuracy: 0.1148 0.5468 0.1141 0.1216 0.0911 0.0992 0.1011\n",
      "valid accuracy: 0.1097 0.5499 0.1056 0.1238 0.0943 0.0984 0.098\n",
      "valid accuracy: 0.1114 0.5493 0.1099 0.1196 0.0904 0.0994 0.0986\n",
      "valid accuracy: 0.1165 0.5562 0.1106 0.1236 0.0967 0.0994 0.1038\n",
      "valid accuracy: 0.1126 0.5566 0.109 0.1248 0.0925 0.1012 0.0969\n",
      "valid accuracy: 0.1197 0.5595 0.1093 0.1196 0.0927 0.0984 0.0955\n",
      "valid accuracy: 0.1108 0.5444 0.1062 0.1229 0.0951 0.096 0.0995\n",
      "valid accuracy: 0.1145 0.5468 0.1052 0.1218 0.0985 0.0943 0.1002\n",
      "valid accuracy: 0.1161 0.5548 0.1106 0.1236 0.0956 0.0939 0.101\n",
      "valid accuracy: 0.1192 0.5556 0.1048 0.1235 0.092 0.0948 0.1006\n",
      "valid accuracy: 0.1165 0.55 0.1085 0.1259 0.0921 0.0968 0.1003\n",
      "valid accuracy: 0.1117 0.5613 0.1069 0.1229 0.0931 0.0992 0.1045\n",
      "valid accuracy: 0.1189 0.5508 0.1104 0.1236 0.0939 0.098 0.1028\n",
      "valid accuracy: 0.1158 0.5445 0.1079 0.119 0.0982 0.0992 0.0998\n",
      "valid accuracy: 0.1127 0.5609 0.1083 0.1197 0.0898 0.0949 0.1012\n",
      "valid accuracy: 0.118 0.5525 0.1083 0.1254 0.0964 0.0986 0.0988\n",
      "valid accuracy: 0.1133 0.5573 0.1046 0.1256 0.0864 0.0997 0.0995\n",
      "valid accuracy: 0.113 0.5494 0.1069 0.1207 0.0899 0.0964 0.0987\n",
      "valid accuracy: 0.114 0.5616 0.1052 0.1253 0.0915 0.1044 0.1021\n",
      "valid accuracy: 0.1074 0.5577 0.1133 0.1262 0.091 0.0993 0.0945\n",
      "valid accuracy: 0.1118 0.5573 0.1095 0.1215 0.0955 0.0993 0.0968\n",
      "valid accuracy: 0.1135 0.544 0.1134 0.121 0.0943 0.0949 0.0991\n",
      "valid accuracy: 0.1127 0.5559 0.1073 0.127 0.0915 0.0983 0.1015\n",
      "valid accuracy: 0.1125 0.5529 0.111 0.1254 0.0924 0.0983 0.0967\n",
      "valid accuracy: 0.1142 0.5546 0.1047 0.122 0.0899 0.0989 0.0937\n",
      "valid accuracy: 0.1133 0.5567 0.1088 0.1249 0.0928 0.1002 0.1022\n",
      "valid accuracy: 0.1138 0.5633 0.1042 0.1179 0.0938 0.0951 0.0997\n",
      "valid accuracy: 0.1122 0.5552 0.1056 0.1234 0.0914 0.096 0.1039\n",
      "valid accuracy: 0.1152 0.5593 0.1049 0.1251 0.0937 0.0969 0.1003\n",
      "valid accuracy: 0.1153 0.5558 0.1053 0.1201 0.0891 0.0954 0.1049\n",
      "valid accuracy: 0.1173 0.5565 0.1053 0.1169 0.0928 0.1005 0.0959\n",
      "valid accuracy: 0.1147 0.5515 0.1125 0.1237 0.0976 0.0992 0.0967\n",
      "valid accuracy: 0.1148 0.5584 0.1105 0.1212 0.0961 0.1025 0.1043\n",
      "valid accuracy: 0.1109 0.5497 0.1108 0.1237 0.0908 0.0994 0.1005\n",
      "valid accuracy: 0.1109 0.5563 0.1089 0.1221 0.093 0.1054 0.1036\n",
      "valid accuracy: 0.1118 0.5555 0.1092 0.1263 0.0912 0.1036 0.0993\n",
      "valid accuracy: 0.1134 0.5547 0.1069 0.1296 0.0949 0.0989 0.1028\n",
      "valid accuracy: 0.1126 0.5578 0.1091 0.1195 0.0916 0.0962 0.0985\n",
      "valid accuracy: 0.1168 0.5572 0.1079 0.1251 0.0924 0.1019 0.0998\n",
      "valid accuracy: 0.1151 0.5572 0.1102 0.1183 0.0951 0.0957 0.0944\n",
      "ep 100, batch 0, training accuracy 0.59\n",
      "ep 100, batch 50, training accuracy 0.565\n",
      "ep 100, batch 100, training accuracy 0.55\n",
      "ep 100, batch 150, training accuracy 0.53\n",
      "ep 100, batch 200, training accuracy 0.63\n",
      "valid accuracy: 0.1095 0.5557 0.112 0.1235 0.0903 0.0983 0.1011\n",
      "valid accuracy: 0.1166 0.5493 0.105 0.1236 0.0946 0.0943 0.1012\n",
      "valid accuracy: 0.1132 0.5595 0.1011 0.1196 0.0918 0.1002 0.1003\n",
      "valid accuracy: 0.1123 0.5564 0.1053 0.1173 0.0963 0.1031 0.1022\n",
      "valid accuracy: 0.1132 0.5566 0.1015 0.1228 0.0931 0.0969 0.1037\n",
      "valid accuracy: 0.1115 0.5524 0.1119 0.1253 0.0921 0.1019 0.1021\n",
      "valid accuracy: 0.113 0.5551 0.1085 0.1261 0.0963 0.1015 0.1014\n",
      "valid accuracy: 0.1118 0.5482 0.1032 0.1273 0.0954 0.1015 0.1006\n",
      "valid accuracy: 0.1112 0.5626 0.1096 0.1222 0.0987 0.0966 0.1024\n",
      "valid accuracy: 0.114 0.5527 0.1028 0.1194 0.0925 0.0988 0.1006\n",
      "valid accuracy: 0.1154 0.5568 0.107 0.121 0.0973 0.1003 0.0952\n",
      "valid accuracy: 0.1177 0.5571 0.1093 0.1229 0.094 0.0996 0.0988\n",
      "valid accuracy: 0.1199 0.5602 0.1078 0.1205 0.0995 0.1006 0.1046\n",
      "valid accuracy: 0.1086 0.5479 0.1054 0.1241 0.0943 0.0955 0.105\n",
      "valid accuracy: 0.1173 0.5562 0.11 0.1227 0.0972 0.0941 0.101\n",
      "valid accuracy: 0.1093 0.554 0.1091 0.1192 0.0958 0.1001 0.1008\n",
      "valid accuracy: 0.1121 0.5447 0.1106 0.126 0.0916 0.1 0.1002\n",
      "valid accuracy: 0.113 0.5498 0.1047 0.1238 0.0928 0.0971 0.1025\n",
      "valid accuracy: 0.1098 0.5544 0.1108 0.1249 0.0903 0.1007 0.0975\n",
      "valid accuracy: 0.1126 0.5631 0.1074 0.1215 0.095 0.0979 0.0997\n",
      "valid accuracy: 0.1049 0.557 0.1124 0.12 0.0878 0.1018 0.1021\n",
      "valid accuracy: 0.1167 0.5578 0.1098 0.1191 0.0865 0.0996 0.0978\n",
      "valid accuracy: 0.1161 0.5601 0.1084 0.121 0.0916 0.1016 0.0978\n",
      "valid accuracy: 0.1161 0.5577 0.1108 0.1256 0.0966 0.0997 0.1069\n",
      "valid accuracy: 0.1151 0.558 0.1103 0.1186 0.0939 0.1015 0.1013\n",
      "valid accuracy: 0.107 0.561 0.106 0.1199 0.0923 0.0999 0.1067\n",
      "valid accuracy: 0.1099 0.5486 0.106 0.1179 0.0901 0.0943 0.1027\n",
      "valid accuracy: 0.1154 0.5519 0.1091 0.1201 0.0906 0.1024 0.1007\n",
      "valid accuracy: 0.1144 0.5563 0.1068 0.1249 0.0878 0.1013 0.0999\n",
      "valid accuracy: 0.1115 0.5543 0.11 0.1176 0.0944 0.1047 0.0943\n",
      "valid accuracy: 0.1126 0.5619 0.1109 0.1287 0.0906 0.0987 0.1003\n",
      "valid accuracy: 0.1137 0.5656 0.1054 0.1179 0.0933 0.0996 0.1081\n",
      "valid accuracy: 0.1152 0.5549 0.105 0.1215 0.0934 0.1013 0.099\n",
      "valid accuracy: 0.1154 0.5569 0.1109 0.1229 0.0996 0.106 0.1059\n",
      "valid accuracy: 0.1124 0.5511 0.105 0.1235 0.0974 0.0947 0.1042\n",
      "valid accuracy: 0.1163 0.5607 0.112 0.1212 0.0957 0.0955 0.0978\n",
      "valid accuracy: 0.1168 0.5586 0.1077 0.1228 0.0962 0.1012 0.1055\n",
      "valid accuracy: 0.1133 0.5563 0.1066 0.1212 0.0939 0.0978 0.1023\n",
      "valid accuracy: 0.1105 0.5613 0.1123 0.1221 0.0946 0.0944 0.1028\n",
      "valid accuracy: 0.1154 0.547 0.1071 0.1246 0.0912 0.0925 0.1005\n",
      "valid accuracy: 0.1138 0.5589 0.1027 0.1248 0.0925 0.0998 0.1029\n",
      "valid accuracy: 0.1137 0.5529 0.1113 0.1158 0.0916 0.0991 0.0965\n",
      "valid accuracy: 0.1111 0.5513 0.1072 0.1216 0.0956 0.0927 0.0971\n",
      "valid accuracy: 0.1163 0.5546 0.107 0.1267 0.0982 0.1001 0.0995\n",
      "valid accuracy: 0.1169 0.5583 0.1086 0.1209 0.0908 0.0991 0.1041\n",
      "valid accuracy: 0.111 0.5526 0.1103 0.1225 0.0926 0.1029 0.1023\n",
      "valid accuracy: 0.1145 0.5619 0.1117 0.1226 0.0913 0.0982 0.1032\n",
      "valid accuracy: 0.1115 0.5552 0.1143 0.123 0.0893 0.0992 0.1043\n",
      "valid accuracy: 0.1172 0.5517 0.1053 0.122 0.0914 0.0942 0.1\n",
      "valid accuracy: 0.1098 0.5596 0.1102 0.1285 0.095 0.0996 0.0976\n",
      "ep 150, batch 0, training accuracy 0.59\n",
      "ep 150, batch 50, training accuracy 0.59\n",
      "ep 150, batch 100, training accuracy 0.56\n",
      "ep 150, batch 150, training accuracy 0.545\n",
      "ep 150, batch 200, training accuracy 0.56\n",
      "valid accuracy: 0.1156 0.5504 0.1124 0.1262 0.087 0.0982 0.1013\n",
      "valid accuracy: 0.1143 0.5552 0.1051 0.1289 0.0952 0.096 0.1066\n",
      "valid accuracy: 0.1102 0.5609 0.1093 0.1154 0.0929 0.1004 0.1043\n",
      "valid accuracy: 0.1131 0.5566 0.1072 0.1252 0.0947 0.0985 0.1006\n",
      "valid accuracy: 0.1186 0.5552 0.1073 0.1268 0.0956 0.0936 0.0997\n",
      "valid accuracy: 0.1106 0.5604 0.1041 0.1224 0.0934 0.097 0.1008\n",
      "valid accuracy: 0.1119 0.56 0.1072 0.1235 0.0937 0.1004 0.0987\n",
      "valid accuracy: 0.1103 0.5554 0.1092 0.1271 0.0968 0.0966 0.0945\n",
      "valid accuracy: 0.1108 0.5631 0.1116 0.1217 0.0861 0.1035 0.0994\n",
      "valid accuracy: 0.1142 0.5539 0.105 0.1221 0.0945 0.1024 0.1059\n",
      "valid accuracy: 0.1128 0.5541 0.1102 0.1221 0.0928 0.1009 0.0977\n",
      "valid accuracy: 0.1217 0.5552 0.1096 0.1199 0.0899 0.099 0.0995\n",
      "valid accuracy: 0.1132 0.553 0.1144 0.1208 0.0958 0.0966 0.1069\n",
      "valid accuracy: 0.1196 0.5571 0.1069 0.1236 0.0948 0.1011 0.0978\n",
      "valid accuracy: 0.118 0.5533 0.1053 0.1229 0.0927 0.1024 0.1035\n",
      "valid accuracy: 0.1216 0.5518 0.1063 0.1233 0.0986 0.1004 0.0993\n",
      "valid accuracy: 0.115 0.5649 0.108 0.1212 0.0954 0.1001 0.1019\n",
      "valid accuracy: 0.1152 0.5552 0.111 0.1233 0.097 0.1022 0.1006\n",
      "valid accuracy: 0.1129 0.5561 0.1093 0.1213 0.0908 0.0999 0.1023\n",
      "valid accuracy: 0.1116 0.5562 0.111 0.1255 0.0925 0.1022 0.1048\n",
      "valid accuracy: 0.1127 0.5539 0.1094 0.1267 0.0922 0.1032 0.1094\n",
      "valid accuracy: 0.1142 0.5576 0.1121 0.1217 0.0948 0.0997 0.1009\n",
      "valid accuracy: 0.1115 0.5538 0.1097 0.1209 0.0954 0.0925 0.0989\n",
      "valid accuracy: 0.1116 0.5566 0.1046 0.1233 0.0924 0.1014 0.0993\n",
      "valid accuracy: 0.1138 0.561 0.1127 0.1185 0.0914 0.1036 0.0983\n",
      "valid accuracy: 0.112 0.5524 0.1086 0.1188 0.0944 0.0978 0.1017\n",
      "valid accuracy: 0.1119 0.56 0.1127 0.1202 0.0912 0.0951 0.0964\n",
      "valid accuracy: 0.1092 0.5544 0.1054 0.1209 0.089 0.1008 0.1024\n",
      "valid accuracy: 0.1157 0.56 0.1038 0.1252 0.0945 0.1022 0.1024\n",
      "valid accuracy: 0.1128 0.5512 0.1048 0.1213 0.0933 0.0998 0.1043\n",
      "valid accuracy: 0.1064 0.5478 0.1105 0.1289 0.0959 0.1015 0.1002\n",
      "valid accuracy: 0.1089 0.5573 0.1112 0.1168 0.0972 0.0945 0.1011\n",
      "valid accuracy: 0.1146 0.5529 0.1062 0.1221 0.0936 0.096 0.1029\n",
      "valid accuracy: 0.1098 0.555 0.1034 0.1194 0.096 0.0973 0.1082\n",
      "valid accuracy: 0.1078 0.5584 0.1187 0.1202 0.0934 0.0955 0.1022\n",
      "valid accuracy: 0.1177 0.555 0.1036 0.126 0.096 0.1024 0.0978\n",
      "valid accuracy: 0.1124 0.5572 0.1065 0.1239 0.093 0.104 0.103\n",
      "valid accuracy: 0.1179 0.5546 0.1064 0.123 0.0927 0.0997 0.0975\n",
      "valid accuracy: 0.1077 0.5567 0.1086 0.1233 0.0957 0.0988 0.0963\n",
      "valid accuracy: 0.1087 0.5656 0.1061 0.1279 0.0959 0.1033 0.1028\n",
      "valid accuracy: 0.1209 0.5626 0.1087 0.1229 0.0926 0.099 0.1028\n",
      "valid accuracy: 0.1041 0.5636 0.1149 0.1256 0.0907 0.0991 0.0983\n",
      "valid accuracy: 0.117 0.5535 0.1119 0.126 0.0954 0.0985 0.1034\n",
      "valid accuracy: 0.1137 0.5493 0.1042 0.1235 0.0955 0.0987 0.1028\n",
      "valid accuracy: 0.1146 0.554 0.1097 0.1244 0.0962 0.0992 0.1048\n",
      "valid accuracy: 0.1171 0.5524 0.1038 0.1224 0.0922 0.0985 0.1067\n",
      "valid accuracy: 0.1133 0.5596 0.1066 0.1216 0.0947 0.0969 0.0978\n",
      "valid accuracy: 0.113 0.5613 0.1061 0.1188 0.0889 0.0986 0.099\n",
      "valid accuracy: 0.1177 0.5578 0.111 0.1185 0.0892 0.0942 0.1061\n",
      "valid accuracy: 0.1111 0.5543 0.104 0.1218 0.0958 0.0944 0.1014\n",
      "ep 200, batch 0, training accuracy 0.575\n",
      "ep 200, batch 50, training accuracy 0.48\n",
      "ep 200, batch 100, training accuracy 0.5\n",
      "ep 200, batch 150, training accuracy 0.545\n",
      "ep 200, batch 200, training accuracy 0.535\n",
      "valid accuracy: 0.1155 0.5585 0.1121 0.1229 0.0952 0.097 0.1029\n",
      "valid accuracy: 0.1117 0.5603 0.1092 0.1226 0.0942 0.1038 0.101\n",
      "valid accuracy: 0.1123 0.5567 0.1115 0.1258 0.0898 0.0963 0.1005\n",
      "valid accuracy: 0.1118 0.5524 0.1103 0.1174 0.0921 0.1016 0.0997\n",
      "valid accuracy: 0.1124 0.5475 0.1052 0.1245 0.0934 0.1013 0.1041\n",
      "valid accuracy: 0.1154 0.546 0.1065 0.1259 0.0956 0.0979 0.0981\n",
      "valid accuracy: 0.1093 0.5699 0.1081 0.1214 0.0937 0.0994 0.106\n",
      "valid accuracy: 0.1108 0.5562 0.1122 0.1136 0.0939 0.0979 0.0992\n",
      "valid accuracy: 0.1127 0.5516 0.1092 0.1254 0.0922 0.1018 0.1021\n",
      "valid accuracy: 0.1134 0.5575 0.1087 0.123 0.0957 0.0952 0.1034\n",
      "valid accuracy: 0.1187 0.5508 0.1096 0.1186 0.0945 0.0986 0.1047\n",
      "valid accuracy: 0.1116 0.5594 0.1084 0.1277 0.093 0.1025 0.1054\n",
      "valid accuracy: 0.1159 0.5576 0.1142 0.1226 0.0925 0.0988 0.0986\n",
      "valid accuracy: 0.1132 0.5527 0.1093 0.1194 0.0883 0.0953 0.1015\n",
      "valid accuracy: 0.1115 0.5607 0.1084 0.1295 0.0951 0.098 0.0983\n",
      "valid accuracy: 0.1134 0.5562 0.1074 0.1244 0.0941 0.1003 0.1023\n",
      "valid accuracy: 0.1171 0.5562 0.1067 0.1277 0.0922 0.1008 0.1055\n",
      "valid accuracy: 0.1163 0.5545 0.1081 0.121 0.0929 0.1031 0.0992\n",
      "valid accuracy: 0.1109 0.5473 0.1112 0.1268 0.0949 0.0971 0.098\n",
      "valid accuracy: 0.1115 0.557 0.1094 0.1292 0.0903 0.1013 0.1047\n",
      "valid accuracy: 0.1139 0.5617 0.1063 0.1268 0.0935 0.0987 0.1066\n",
      "valid accuracy: 0.1218 0.5531 0.1055 0.1285 0.093 0.1022 0.0979\n",
      "valid accuracy: 0.1176 0.5605 0.1101 0.1235 0.0954 0.1011 0.1017\n",
      "valid accuracy: 0.1072 0.5603 0.1126 0.123 0.0932 0.0979 0.0984\n",
      "valid accuracy: 0.1109 0.5502 0.11 0.1195 0.0904 0.0984 0.1013\n",
      "valid accuracy: 0.1094 0.5546 0.1111 0.1216 0.0921 0.0941 0.1017\n",
      "valid accuracy: 0.1197 0.555 0.1135 0.1268 0.0951 0.096 0.1005\n",
      "valid accuracy: 0.1057 0.5521 0.1104 0.1237 0.0912 0.0999 0.1017\n",
      "valid accuracy: 0.1208 0.5492 0.1085 0.1219 0.0904 0.0975 0.1002\n",
      "valid accuracy: 0.1142 0.5531 0.1081 0.121 0.0956 0.0985 0.0995\n",
      "valid accuracy: 0.1163 0.5515 0.1109 0.1201 0.0948 0.0981 0.1036\n",
      "valid accuracy: 0.1095 0.5553 0.114 0.1288 0.0935 0.1002 0.1034\n",
      "valid accuracy: 0.1127 0.5594 0.1046 0.1218 0.0898 0.0974 0.1012\n",
      "valid accuracy: 0.1129 0.5555 0.1071 0.1241 0.0911 0.1007 0.1026\n",
      "valid accuracy: 0.1124 0.5507 0.1087 0.1176 0.0893 0.0961 0.1044\n",
      "valid accuracy: 0.1103 0.5573 0.1121 0.1238 0.0956 0.1042 0.0988\n",
      "valid accuracy: 0.1076 0.5604 0.1059 0.1265 0.0986 0.0984 0.0973\n",
      "valid accuracy: 0.113 0.5545 0.111 0.1266 0.0906 0.0985 0.1014\n",
      "valid accuracy: 0.112 0.5577 0.1124 0.1199 0.0954 0.0995 0.0981\n",
      "valid accuracy: 0.109 0.5547 0.1101 0.1234 0.1023 0.101 0.1007\n",
      "valid accuracy: 0.1127 0.5492 0.1066 0.1235 0.0925 0.0997 0.1027\n",
      "valid accuracy: 0.1084 0.56 0.1104 0.1249 0.0881 0.1018 0.1011\n",
      "valid accuracy: 0.115 0.5546 0.1046 0.1248 0.0953 0.1022 0.0976\n",
      "valid accuracy: 0.1167 0.5534 0.1062 0.1255 0.0884 0.0972 0.1019\n",
      "valid accuracy: 0.1137 0.5503 0.1079 0.1237 0.0897 0.1014 0.1038\n",
      "valid accuracy: 0.1119 0.5646 0.105 0.1286 0.0961 0.0984 0.0968\n",
      "valid accuracy: 0.1042 0.56 0.1062 0.123 0.0943 0.1003 0.1095\n",
      "valid accuracy: 0.1133 0.5579 0.1074 0.1198 0.09 0.1033 0.0972\n",
      "valid accuracy: 0.1124 0.5569 0.1052 0.1217 0.0975 0.0976 0.0992\n",
      "valid accuracy: 0.1132 0.5441 0.1128 0.1256 0.0952 0.1003 0.0982\n",
      "ep 250, batch 0, training accuracy 0.515\n",
      "ep 250, batch 50, training accuracy 0.54\n",
      "ep 250, batch 100, training accuracy 0.545\n",
      "ep 250, batch 150, training accuracy 0.51\n",
      "ep 250, batch 200, training accuracy 0.625\n",
      "valid accuracy: 0.1083 0.5535 0.1134 0.126 0.0929 0.0992 0.0962\n",
      "valid accuracy: 0.1166 0.5563 0.1086 0.1225 0.0976 0.098 0.101\n",
      "valid accuracy: 0.1078 0.5552 0.1081 0.1218 0.0948 0.0985 0.0995\n",
      "valid accuracy: 0.1135 0.5604 0.1071 0.1207 0.0937 0.0942 0.0999\n",
      "valid accuracy: 0.1116 0.5566 0.1078 0.1202 0.0977 0.0954 0.0973\n",
      "valid accuracy: 0.1103 0.557 0.1061 0.1257 0.0917 0.0969 0.1011\n",
      "valid accuracy: 0.1159 0.5619 0.1061 0.1206 0.0927 0.0966 0.1002\n",
      "valid accuracy: 0.111 0.5571 0.1066 0.1267 0.0906 0.0993 0.0991\n",
      "valid accuracy: 0.1081 0.5541 0.1097 0.118 0.0946 0.1011 0.0985\n",
      "valid accuracy: 0.1087 0.558 0.1134 0.1242 0.0957 0.0994 0.0983\n",
      "valid accuracy: 0.1143 0.55 0.1042 0.1221 0.0912 0.0935 0.1003\n",
      "valid accuracy: 0.1139 0.5557 0.1156 0.1232 0.0906 0.0932 0.0998\n",
      "valid accuracy: 0.1127 0.5571 0.1107 0.119 0.0928 0.1068 0.1026\n",
      "valid accuracy: 0.1207 0.5515 0.1114 0.1215 0.0952 0.1023 0.0965\n",
      "valid accuracy: 0.1147 0.5585 0.1129 0.1245 0.0954 0.1011 0.0985\n",
      "valid accuracy: 0.1131 0.5588 0.1145 0.1298 0.0938 0.0979 0.0965\n",
      "valid accuracy: 0.1148 0.5588 0.1063 0.1218 0.0962 0.099 0.1056\n",
      "valid accuracy: 0.1059 0.5556 0.1043 0.1274 0.0915 0.0986 0.1002\n",
      "valid accuracy: 0.1081 0.5557 0.107 0.1239 0.0934 0.0952 0.0965\n",
      "valid accuracy: 0.1151 0.5544 0.1098 0.1221 0.0955 0.0974 0.0999\n",
      "valid accuracy: 0.118 0.5488 0.1048 0.1246 0.0998 0.1002 0.1004\n",
      "valid accuracy: 0.1127 0.5565 0.1056 0.1196 0.0885 0.0987 0.1046\n",
      "valid accuracy: 0.1091 0.5547 0.1097 0.1224 0.0907 0.0968 0.0986\n",
      "valid accuracy: 0.1167 0.5646 0.1053 0.1251 0.0911 0.0997 0.0994\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.1\n",
      "ep 0, batch 50, training accuracy 0.24\n",
      "ep 0, batch 100, training accuracy 0.305\n",
      "ep 0, batch 150, training accuracy 0.23\n",
      "ep 0, batch 200, training accuracy 0.38\n",
      "valid accuracy: 0.1085 0.4279 0.3654 0.1381 0.1195 0.1135 0.1072\n",
      "valid accuracy: 0.1058 0.3694 0.4209 0.1258 0.1035 0.1011 0.096\n",
      "valid accuracy: 0.11 0.3626 0.4361 0.1157 0.1078 0.0978 0.1068\n",
      "valid accuracy: 0.1013 0.3451 0.4527 0.1119 0.1088 0.1041 0.0964\n",
      "valid accuracy: 0.1015 0.3391 0.4698 0.108 0.105 0.1062 0.0999\n",
      "valid accuracy: 0.1032 0.338 0.4642 0.1117 0.109 0.1003 0.0915\n",
      "valid accuracy: 0.1041 0.3133 0.4735 0.1071 0.1133 0.1054 0.0878\n",
      "valid accuracy: 0.1012 0.3117 0.4925 0.099 0.112 0.1036 0.0949\n",
      "valid accuracy: 0.0941 0.3212 0.489 0.1115 0.1064 0.1011 0.0918\n",
      "valid accuracy: 0.1043 0.3037 0.4962 0.1026 0.1092 0.1037 0.091\n",
      "valid accuracy: 0.1025 0.3122 0.4915 0.1025 0.1098 0.1121 0.0899\n",
      "valid accuracy: 0.0973 0.2876 0.4987 0.1009 0.1052 0.098 0.0903\n",
      "valid accuracy: 0.099 0.2806 0.5007 0.1127 0.1129 0.1104 0.0971\n",
      "valid accuracy: 0.1094 0.2779 0.5047 0.1 0.1154 0.1076 0.0923\n",
      "valid accuracy: 0.1049 0.274 0.5128 0.1036 0.1054 0.1083 0.0911\n",
      "valid accuracy: 0.1022 0.2614 0.5122 0.1013 0.106 0.1065 0.0928\n",
      "valid accuracy: 0.1061 0.2698 0.5108 0.1019 0.1188 0.1137 0.0958\n",
      "valid accuracy: 0.0973 0.2476 0.5137 0.1006 0.1096 0.1106 0.0875\n",
      "valid accuracy: 0.1076 0.2519 0.5066 0.1015 0.1145 0.1079 0.0981\n",
      "valid accuracy: 0.1058 0.2321 0.5162 0.1064 0.1128 0.1083 0.0933\n",
      "valid accuracy: 0.1 0.2419 0.5182 0.1036 0.1089 0.1086 0.0991\n",
      "valid accuracy: 0.0996 0.2319 0.5164 0.0989 0.1154 0.1083 0.0923\n",
      "valid accuracy: 0.0967 0.2463 0.5186 0.1019 0.1125 0.1087 0.0902\n",
      "valid accuracy: 0.0968 0.2428 0.5254 0.104 0.1064 0.1061 0.0931\n",
      "valid accuracy: 0.1068 0.2294 0.5206 0.1104 0.1133 0.1049 0.1028\n",
      "valid accuracy: 0.1049 0.2341 0.5279 0.1024 0.1082 0.111 0.0933\n",
      "valid accuracy: 0.0962 0.2421 0.5187 0.1039 0.1096 0.1031 0.0969\n",
      "valid accuracy: 0.1039 0.2237 0.5289 0.1037 0.11 0.1099 0.0898\n",
      "valid accuracy: 0.11 0.2029 0.5225 0.1078 0.1095 0.1061 0.0934\n",
      "valid accuracy: 0.1092 0.2218 0.529 0.1107 0.1123 0.1133 0.0934\n",
      "valid accuracy: 0.1111 0.2045 0.5301 0.1014 0.1079 0.1069 0.0878\n",
      "valid accuracy: 0.1063 0.2163 0.5206 0.0965 0.1111 0.1112 0.0935\n",
      "valid accuracy: 0.1096 0.214 0.5342 0.1043 0.1147 0.1105 0.1013\n",
      "valid accuracy: 0.1011 0.1992 0.5286 0.1023 0.1134 0.1071 0.1019\n",
      "valid accuracy: 0.1096 0.2067 0.5409 0.1124 0.1125 0.1056 0.0937\n",
      "valid accuracy: 0.1127 0.2121 0.5331 0.1061 0.1108 0.1097 0.0964\n",
      "valid accuracy: 0.112 0.224 0.5355 0.1043 0.109 0.1069 0.0992\n",
      "valid accuracy: 0.1032 0.2206 0.5355 0.0968 0.1108 0.1065 0.097\n",
      "valid accuracy: 0.1103 0.2197 0.5284 0.0982 0.1129 0.1091 0.1001\n",
      "valid accuracy: 0.1066 0.2213 0.5396 0.0967 0.1109 0.0995 0.0991\n",
      "valid accuracy: 0.1087 0.1902 0.543 0.0983 0.1118 0.1048 0.1\n",
      "valid accuracy: 0.1041 0.2085 0.541 0.0997 0.1138 0.1018 0.0982\n",
      "valid accuracy: 0.1065 0.2098 0.5323 0.1071 0.1135 0.106 0.0972\n",
      "valid accuracy: 0.1048 0.2208 0.525 0.1104 0.1091 0.1126 0.1064\n",
      "valid accuracy: 0.1032 0.215 0.537 0.1118 0.1115 0.1059 0.1005\n",
      "valid accuracy: 0.1047 0.2147 0.5385 0.106 0.1158 0.1033 0.097\n",
      "valid accuracy: 0.1036 0.2102 0.5393 0.103 0.1124 0.1035 0.1047\n",
      "valid accuracy: 0.1048 0.21 0.541 0.1109 0.1161 0.1068 0.0988\n",
      "valid accuracy: 0.1008 0.2015 0.5348 0.1009 0.118 0.1017 0.1015\n",
      "valid accuracy: 0.1099 0.2135 0.5432 0.1045 0.1179 0.1055 0.0928\n",
      "ep 50, batch 0, training accuracy 0.57\n",
      "ep 50, batch 50, training accuracy 0.515\n",
      "ep 50, batch 100, training accuracy 0.475\n",
      "ep 50, batch 150, training accuracy 0.54\n",
      "ep 50, batch 200, training accuracy 0.5\n",
      "valid accuracy: 0.0998 0.215 0.5368 0.0998 0.1145 0.1011 0.1012\n",
      "valid accuracy: 0.112 0.2006 0.5394 0.0942 0.1155 0.1047 0.0988\n",
      "valid accuracy: 0.1001 0.1984 0.5411 0.1031 0.1098 0.1028 0.0994\n",
      "valid accuracy: 0.1006 0.1955 0.5309 0.0978 0.1153 0.1038 0.0978\n",
      "valid accuracy: 0.1027 0.2119 0.5439 0.1018 0.1158 0.1081 0.1047\n",
      "valid accuracy: 0.0985 0.2048 0.5452 0.0978 0.1074 0.1056 0.1\n",
      "valid accuracy: 0.1018 0.2084 0.5457 0.105 0.1156 0.1035 0.0983\n",
      "valid accuracy: 0.1053 0.2051 0.5457 0.1041 0.1123 0.1052 0.0965\n",
      "valid accuracy: 0.1065 0.1974 0.5404 0.1049 0.1158 0.1052 0.1045\n",
      "valid accuracy: 0.101 0.2026 0.5395 0.1027 0.1189 0.1005 0.0987\n",
      "valid accuracy: 0.1068 0.2015 0.5365 0.1032 0.1159 0.1081 0.1009\n",
      "valid accuracy: 0.1037 0.1951 0.5451 0.1047 0.1177 0.111 0.1016\n",
      "valid accuracy: 0.104 0.2024 0.5411 0.1084 0.1186 0.1065 0.0971\n",
      "valid accuracy: 0.1008 0.2007 0.5506 0.1045 0.1197 0.1041 0.0984\n",
      "valid accuracy: 0.1025 0.1971 0.5476 0.105 0.1197 0.1062 0.0963\n",
      "valid accuracy: 0.1046 0.1987 0.5391 0.1034 0.1185 0.104 0.0998\n",
      "valid accuracy: 0.1059 0.2047 0.5398 0.1047 0.1218 0.1067 0.0954\n",
      "valid accuracy: 0.1053 0.1974 0.5375 0.1054 0.1155 0.104 0.0982\n",
      "valid accuracy: 0.106 0.2032 0.5481 0.1018 0.1187 0.1052 0.0976\n",
      "valid accuracy: 0.1022 0.1926 0.5371 0.1045 0.1147 0.1047 0.0949\n",
      "valid accuracy: 0.1028 0.1953 0.5447 0.1054 0.1183 0.1072 0.1001\n",
      "valid accuracy: 0.0991 0.194 0.5436 0.1077 0.1131 0.1038 0.0959\n",
      "valid accuracy: 0.1023 0.1974 0.5473 0.107 0.1185 0.1065 0.094\n",
      "valid accuracy: 0.1082 0.2038 0.544 0.099 0.1194 0.1069 0.0992\n",
      "valid accuracy: 0.098 0.2002 0.5469 0.1042 0.1139 0.1041 0.098\n",
      "valid accuracy: 0.1016 0.1991 0.5478 0.1026 0.1206 0.105 0.1023\n",
      "valid accuracy: 0.0995 0.2018 0.5486 0.1039 0.1154 0.1068 0.0966\n",
      "valid accuracy: 0.1047 0.1972 0.5479 0.1023 0.1151 0.1094 0.1012\n",
      "valid accuracy: 0.1019 0.1976 0.5479 0.1039 0.1235 0.1035 0.0976\n",
      "valid accuracy: 0.1009 0.2015 0.5513 0.103 0.1125 0.1052 0.1008\n",
      "valid accuracy: 0.1055 0.1998 0.5438 0.1019 0.1131 0.1026 0.0962\n",
      "valid accuracy: 0.1021 0.2029 0.545 0.1054 0.1173 0.1027 0.0946\n",
      "valid accuracy: 0.1031 0.1973 0.5378 0.1075 0.1149 0.104 0.0995\n",
      "valid accuracy: 0.1022 0.193 0.5492 0.1042 0.1174 0.1078 0.0965\n",
      "valid accuracy: 0.1012 0.1988 0.5437 0.1071 0.1158 0.1021 0.0963\n",
      "valid accuracy: 0.1 0.1918 0.5552 0.1022 0.1193 0.103 0.1007\n",
      "valid accuracy: 0.1037 0.2015 0.5415 0.1074 0.1154 0.1039 0.0995\n",
      "valid accuracy: 0.0987 0.2052 0.5568 0.1048 0.1166 0.1092 0.096\n",
      "valid accuracy: 0.1016 0.1899 0.5489 0.0998 0.115 0.1042 0.0934\n",
      "valid accuracy: 0.1058 0.1979 0.549 0.1083 0.1192 0.1024 0.101\n",
      "valid accuracy: 0.0983 0.2031 0.5432 0.1008 0.1179 0.1079 0.0967\n",
      "valid accuracy: 0.1007 0.2015 0.5494 0.1027 0.1122 0.1092 0.0963\n",
      "valid accuracy: 0.1058 0.1989 0.5551 0.1033 0.1189 0.104 0.0977\n",
      "valid accuracy: 0.104 0.1939 0.5408 0.0974 0.1214 0.1047 0.1027\n",
      "valid accuracy: 0.0993 0.2052 0.5478 0.1041 0.1143 0.1081 0.1007\n",
      "valid accuracy: 0.1044 0.2008 0.5491 0.0982 0.1144 0.1021 0.0977\n",
      "valid accuracy: 0.104 0.2011 0.543 0.103 0.1168 0.103 0.0987\n",
      "valid accuracy: 0.1 0.2012 0.5406 0.1081 0.1183 0.1046 0.0952\n",
      "valid accuracy: 0.1028 0.1958 0.5463 0.1129 0.1217 0.1061 0.0916\n",
      "valid accuracy: 0.1031 0.1962 0.5483 0.104 0.1185 0.1061 0.098\n",
      "ep 100, batch 0, training accuracy 0.54\n",
      "ep 100, batch 50, training accuracy 0.52\n",
      "ep 100, batch 100, training accuracy 0.59\n",
      "ep 100, batch 150, training accuracy 0.57\n",
      "ep 100, batch 200, training accuracy 0.505\n",
      "valid accuracy: 0.1023 0.2009 0.551 0.104 0.1174 0.1051 0.0968\n",
      "valid accuracy: 0.1038 0.1945 0.5482 0.1029 0.1164 0.102 0.0969\n",
      "valid accuracy: 0.1059 0.2007 0.5465 0.103 0.1157 0.1061 0.0995\n",
      "valid accuracy: 0.1013 0.1984 0.5565 0.1045 0.12 0.0992 0.0951\n",
      "valid accuracy: 0.1027 0.2013 0.5476 0.1116 0.1139 0.1063 0.0943\n",
      "valid accuracy: 0.1008 0.1978 0.5457 0.1051 0.1158 0.1069 0.1003\n",
      "valid accuracy: 0.1001 0.2032 0.5443 0.1032 0.1147 0.1038 0.0973\n",
      "valid accuracy: 0.1044 0.1956 0.5429 0.102 0.1168 0.1071 0.0981\n",
      "valid accuracy: 0.1024 0.1924 0.5518 0.1078 0.1176 0.1083 0.098\n",
      "valid accuracy: 0.0968 0.1913 0.5512 0.1011 0.1236 0.1021 0.1053\n",
      "valid accuracy: 0.1022 0.1979 0.5434 0.1009 0.1189 0.1051 0.0935\n",
      "valid accuracy: 0.1055 0.1932 0.5511 0.1028 0.1165 0.1092 0.0967\n",
      "valid accuracy: 0.104 0.1941 0.5398 0.1056 0.1194 0.1111 0.101\n",
      "valid accuracy: 0.1078 0.206 0.544 0.1023 0.1121 0.1104 0.1047\n",
      "valid accuracy: 0.1028 0.1937 0.5527 0.1047 0.1146 0.1026 0.0961\n",
      "valid accuracy: 0.0991 0.193 0.5416 0.1025 0.1196 0.1096 0.0996\n",
      "valid accuracy: 0.1091 0.2014 0.5466 0.1051 0.1219 0.1034 0.0995\n",
      "valid accuracy: 0.1054 0.2015 0.549 0.1008 0.1231 0.106 0.1017\n",
      "valid accuracy: 0.1003 0.2017 0.5384 0.1072 0.1116 0.1097 0.0974\n",
      "valid accuracy: 0.1006 0.2007 0.5421 0.1 0.1223 0.1036 0.098\n",
      "valid accuracy: 0.1023 0.1951 0.5404 0.1068 0.1209 0.1076 0.0959\n",
      "valid accuracy: 0.1012 0.2013 0.559 0.1035 0.1122 0.1061 0.1015\n",
      "valid accuracy: 0.1005 0.1937 0.5459 0.1005 0.1099 0.1062 0.1013\n",
      "valid accuracy: 0.1031 0.1972 0.5458 0.1095 0.1174 0.1074 0.1012\n",
      "valid accuracy: 0.1017 0.1963 0.5424 0.1086 0.1139 0.1094 0.0957\n",
      "valid accuracy: 0.1013 0.1984 0.5466 0.1028 0.1166 0.1095 0.103\n",
      "valid accuracy: 0.1073 0.198 0.551 0.1015 0.1142 0.1077 0.1005\n",
      "valid accuracy: 0.0985 0.1937 0.5504 0.0995 0.1152 0.1081 0.0977\n",
      "valid accuracy: 0.1031 0.1926 0.539 0.104 0.1157 0.1043 0.0999\n",
      "valid accuracy: 0.1011 0.2007 0.5408 0.1031 0.1139 0.1063 0.0975\n",
      "valid accuracy: 0.0974 0.2015 0.535 0.1029 0.118 0.1053 0.1002\n",
      "valid accuracy: 0.1019 0.1999 0.544 0.1002 0.1177 0.1104 0.0962\n",
      "valid accuracy: 0.1065 0.1949 0.546 0.1006 0.1174 0.1035 0.0996\n",
      "valid accuracy: 0.1035 0.195 0.5416 0.1064 0.1132 0.11 0.0958\n",
      "valid accuracy: 0.1022 0.2036 0.5464 0.1059 0.1163 0.1076 0.1004\n",
      "valid accuracy: 0.1041 0.1911 0.553 0.1028 0.1175 0.1107 0.1009\n",
      "valid accuracy: 0.1043 0.2044 0.5505 0.101 0.1238 0.0988 0.1012\n",
      "valid accuracy: 0.1036 0.2002 0.5467 0.1023 0.1183 0.108 0.0985\n",
      "valid accuracy: 0.0969 0.1975 0.549 0.1077 0.1208 0.1067 0.0981\n",
      "valid accuracy: 0.1042 0.1989 0.5402 0.1014 0.1149 0.098 0.0967\n",
      "valid accuracy: 0.1022 0.1968 0.5471 0.1027 0.1155 0.1029 0.0988\n",
      "valid accuracy: 0.1054 0.1964 0.5449 0.1042 0.1197 0.1065 0.0957\n",
      "valid accuracy: 0.1027 0.197 0.5497 0.1003 0.1182 0.1034 0.1003\n",
      "valid accuracy: 0.1046 0.1951 0.5464 0.1025 0.1145 0.1085 0.1055\n",
      "valid accuracy: 0.1011 0.1971 0.5543 0.0996 0.1197 0.1018 0.0964\n",
      "valid accuracy: 0.1015 0.1985 0.5508 0.102 0.1165 0.1049 0.0921\n",
      "valid accuracy: 0.1043 0.1942 0.5536 0.1051 0.1195 0.1002 0.0949\n",
      "valid accuracy: 0.1014 0.2003 0.5485 0.1075 0.116 0.1044 0.0931\n",
      "valid accuracy: 0.1036 0.1968 0.5437 0.1005 0.1194 0.1067 0.0981\n",
      "valid accuracy: 0.0974 0.1953 0.5495 0.1077 0.1127 0.1066 0.1005\n",
      "ep 150, batch 0, training accuracy 0.57\n",
      "ep 150, batch 50, training accuracy 0.505\n",
      "ep 150, batch 100, training accuracy 0.575\n",
      "ep 150, batch 150, training accuracy 0.535\n",
      "ep 150, batch 200, training accuracy 0.57\n",
      "valid accuracy: 0.1082 0.1951 0.548 0.1033 0.119 0.1084 0.1014\n",
      "valid accuracy: 0.1049 0.1957 0.5527 0.1008 0.1129 0.105 0.0939\n",
      "valid accuracy: 0.1035 0.1944 0.5408 0.1014 0.1165 0.1072 0.102\n",
      "valid accuracy: 0.1002 0.1994 0.5418 0.1003 0.1186 0.1072 0.0982\n",
      "valid accuracy: 0.1029 0.1881 0.5469 0.0985 0.1192 0.1061 0.1012\n",
      "valid accuracy: 0.102 0.1953 0.5424 0.1015 0.1209 0.1008 0.0984\n",
      "valid accuracy: 0.1035 0.1925 0.5426 0.1024 0.1092 0.1057 0.0976\n",
      "valid accuracy: 0.0974 0.2025 0.5508 0.0999 0.1163 0.1064 0.1016\n",
      "valid accuracy: 0.1057 0.1949 0.5418 0.1021 0.1179 0.1058 0.105\n",
      "valid accuracy: 0.1025 0.2053 0.545 0.1033 0.1249 0.104 0.101\n",
      "valid accuracy: 0.1039 0.1931 0.5488 0.1042 0.1114 0.1042 0.0977\n",
      "valid accuracy: 0.1033 0.196 0.5526 0.1037 0.1097 0.1014 0.0998\n",
      "valid accuracy: 0.0998 0.1957 0.5455 0.1066 0.1149 0.1035 0.1015\n",
      "valid accuracy: 0.1066 0.1981 0.5491 0.0994 0.1096 0.1076 0.1007\n",
      "valid accuracy: 0.1059 0.203 0.5471 0.1 0.1099 0.1071 0.101\n",
      "valid accuracy: 0.102 0.1963 0.5415 0.0969 0.1116 0.1032 0.1016\n",
      "valid accuracy: 0.1038 0.1957 0.5484 0.1003 0.1212 0.1076 0.1008\n",
      "valid accuracy: 0.1021 0.198 0.5501 0.1043 0.1114 0.104 0.0985\n",
      "valid accuracy: 0.1042 0.2029 0.5498 0.1 0.1117 0.108 0.0971\n",
      "valid accuracy: 0.1019 0.1957 0.5498 0.1071 0.116 0.1029 0.094\n",
      "valid accuracy: 0.106 0.1959 0.5486 0.1024 0.117 0.1019 0.1007\n",
      "valid accuracy: 0.0988 0.1935 0.5497 0.1028 0.1124 0.1049 0.104\n",
      "valid accuracy: 0.099 0.1945 0.5427 0.1017 0.1123 0.1063 0.0963\n",
      "valid accuracy: 0.1004 0.1985 0.5429 0.1055 0.1193 0.1034 0.0972\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.12\n",
      "ep 0, batch 50, training accuracy 0.255\n",
      "ep 0, batch 100, training accuracy 0.315\n",
      "ep 0, batch 150, training accuracy 0.255\n",
      "ep 0, batch 200, training accuracy 0.31\n",
      "valid accuracy: 0.1052 0.1853 0.4506 0.3587 0.114 0.1074 0.1063\n",
      "valid accuracy: 0.1051 0.1724 0.3895 0.428 0.1084 0.1055 0.1017\n",
      "valid accuracy: 0.1102 0.1736 0.3671 0.4534 0.1061 0.098 0.1032\n",
      "valid accuracy: 0.1074 0.174 0.3526 0.469 0.0988 0.1005 0.0993\n",
      "valid accuracy: 0.1091 0.1576 0.3401 0.4835 0.0962 0.0959 0.0982\n",
      "valid accuracy: 0.105 0.1518 0.3294 0.487 0.096 0.0958 0.0977\n",
      "valid accuracy: 0.109 0.1553 0.3277 0.4924 0.0925 0.1028 0.0982\n",
      "valid accuracy: 0.1105 0.1584 0.3196 0.4989 0.0902 0.0972 0.1043\n",
      "valid accuracy: 0.1109 0.1536 0.2989 0.5003 0.0921 0.0973 0.1082\n",
      "valid accuracy: 0.1093 0.1423 0.2734 0.5137 0.0915 0.1025 0.1041\n",
      "valid accuracy: 0.1111 0.1522 0.279 0.5123 0.0908 0.0961 0.1066\n",
      "valid accuracy: 0.1064 0.1436 0.2694 0.5214 0.0866 0.1017 0.1041\n",
      "valid accuracy: 0.1052 0.1523 0.2876 0.5251 0.0921 0.0977 0.1045\n",
      "valid accuracy: 0.1028 0.1392 0.2751 0.5188 0.0971 0.1014 0.1006\n",
      "valid accuracy: 0.1021 0.1457 0.2623 0.5216 0.0871 0.0989 0.1031\n",
      "valid accuracy: 0.1011 0.1505 0.2563 0.5211 0.0859 0.0957 0.1029\n",
      "valid accuracy: 0.0999 0.1474 0.2612 0.5307 0.0927 0.0987 0.1088\n",
      "valid accuracy: 0.0979 0.1492 0.2563 0.5232 0.0854 0.1011 0.1065\n",
      "valid accuracy: 0.1011 0.1446 0.2433 0.5265 0.093 0.0992 0.1023\n",
      "valid accuracy: 0.0999 0.1389 0.2429 0.5234 0.0828 0.1034 0.108\n",
      "valid accuracy: 0.0997 0.1414 0.2377 0.534 0.0917 0.1024 0.1073\n",
      "valid accuracy: 0.096 0.1511 0.2434 0.5331 0.0887 0.104 0.1084\n",
      "valid accuracy: 0.0975 0.1348 0.2347 0.5266 0.0875 0.0951 0.1036\n",
      "valid accuracy: 0.0985 0.1541 0.2391 0.5353 0.0849 0.1019 0.1075\n",
      "valid accuracy: 0.0947 0.1483 0.2327 0.5343 0.08 0.1019 0.1057\n",
      "valid accuracy: 0.1006 0.1505 0.2336 0.5303 0.0904 0.1052 0.1103\n",
      "valid accuracy: 0.0935 0.1454 0.2291 0.5328 0.0884 0.1043 0.1073\n",
      "valid accuracy: 0.0809 0.1409 0.2433 0.5363 0.092 0.1059 0.1053\n",
      "valid accuracy: 0.0877 0.1382 0.2241 0.5397 0.0815 0.1028 0.1061\n",
      "valid accuracy: 0.0826 0.141 0.234 0.54 0.0955 0.101 0.1121\n",
      "valid accuracy: 0.0841 0.1525 0.233 0.5421 0.0907 0.1045 0.1094\n",
      "valid accuracy: 0.0819 0.1409 0.2267 0.5442 0.0888 0.1023 0.1056\n",
      "valid accuracy: 0.0792 0.1383 0.2171 0.5372 0.0921 0.0998 0.1146\n",
      "valid accuracy: 0.0799 0.1538 0.2168 0.543 0.0822 0.1067 0.1066\n",
      "valid accuracy: 0.0782 0.1386 0.2142 0.5427 0.0869 0.1025 0.1142\n",
      "valid accuracy: 0.0838 0.143 0.2119 0.5437 0.0917 0.101 0.1086\n",
      "valid accuracy: 0.0751 0.1369 0.2175 0.5386 0.092 0.1045 0.109\n",
      "valid accuracy: 0.0893 0.1487 0.2197 0.5387 0.0894 0.0989 0.1047\n",
      "valid accuracy: 0.087 0.1434 0.2152 0.5523 0.0922 0.1021 0.111\n",
      "valid accuracy: 0.0858 0.1502 0.2154 0.5371 0.0879 0.1032 0.1118\n",
      "valid accuracy: 0.0871 0.1387 0.2191 0.5375 0.0893 0.106 0.1099\n",
      "valid accuracy: 0.0889 0.1403 0.2003 0.5459 0.0901 0.1006 0.1073\n",
      "valid accuracy: 0.0816 0.1431 0.2135 0.5486 0.0909 0.1092 0.1169\n",
      "valid accuracy: 0.0842 0.1419 0.2157 0.5504 0.09 0.1018 0.1082\n",
      "valid accuracy: 0.0846 0.1336 0.2043 0.544 0.0903 0.1052 0.1124\n",
      "valid accuracy: 0.0808 0.1409 0.2063 0.5524 0.0879 0.1032 0.1112\n",
      "valid accuracy: 0.0837 0.1416 0.2027 0.5488 0.0855 0.102 0.1127\n",
      "valid accuracy: 0.0884 0.1441 0.1947 0.5492 0.0883 0.107 0.1114\n",
      "valid accuracy: 0.0845 0.144 0.2031 0.5556 0.0883 0.1072 0.1119\n",
      "valid accuracy: 0.0796 0.1407 0.2058 0.545 0.095 0.1046 0.112\n",
      "ep 50, batch 0, training accuracy 0.59\n",
      "ep 50, batch 50, training accuracy 0.6\n",
      "ep 50, batch 100, training accuracy 0.535\n",
      "ep 50, batch 150, training accuracy 0.53\n",
      "ep 50, batch 200, training accuracy 0.565\n",
      "valid accuracy: 0.0808 0.1352 0.1929 0.5535 0.0866 0.1078 0.1049\n",
      "valid accuracy: 0.0784 0.1395 0.1964 0.5456 0.0953 0.1014 0.1086\n",
      "valid accuracy: 0.0831 0.1403 0.1999 0.5573 0.081 0.1085 0.1114\n",
      "valid accuracy: 0.0841 0.1394 0.1877 0.5475 0.0848 0.1073 0.1088\n",
      "valid accuracy: 0.0825 0.1357 0.186 0.5566 0.0894 0.1061 0.1115\n",
      "valid accuracy: 0.0832 0.1418 0.1837 0.5578 0.0883 0.1046 0.1103\n",
      "valid accuracy: 0.0839 0.1407 0.1966 0.548 0.0847 0.1111 0.1109\n",
      "valid accuracy: 0.0777 0.1361 0.1914 0.5453 0.0878 0.1039 0.1141\n",
      "valid accuracy: 0.0695 0.144 0.1961 0.556 0.0888 0.1063 0.1122\n",
      "valid accuracy: 0.078 0.1445 0.1884 0.5539 0.0835 0.1087 0.1136\n",
      "valid accuracy: 0.0821 0.1389 0.191 0.5526 0.0827 0.1091 0.1098\n",
      "valid accuracy: 0.0788 0.1346 0.1885 0.5434 0.0868 0.1009 0.1107\n",
      "valid accuracy: 0.0794 0.141 0.192 0.5475 0.0915 0.1057 0.1139\n",
      "valid accuracy: 0.0772 0.1384 0.1862 0.5584 0.0848 0.1063 0.1106\n",
      "valid accuracy: 0.0825 0.1454 0.1831 0.5583 0.0842 0.1081 0.106\n",
      "valid accuracy: 0.0822 0.1397 0.1911 0.554 0.0928 0.1044 0.1125\n",
      "valid accuracy: 0.0812 0.1407 0.1932 0.5543 0.0855 0.1081 0.1112\n",
      "valid accuracy: 0.0769 0.1369 0.1887 0.5498 0.0866 0.1017 0.1135\n",
      "valid accuracy: 0.0788 0.1359 0.19 0.5522 0.0868 0.111 0.1098\n",
      "valid accuracy: 0.0801 0.1366 0.1861 0.5505 0.0847 0.114 0.111\n",
      "valid accuracy: 0.081 0.1331 0.1888 0.5574 0.0873 0.1105 0.1089\n",
      "valid accuracy: 0.0792 0.1328 0.1895 0.554 0.0855 0.1068 0.1091\n",
      "valid accuracy: 0.0763 0.1377 0.1842 0.5551 0.0802 0.1034 0.1182\n",
      "valid accuracy: 0.0774 0.1366 0.1885 0.5544 0.0835 0.1133 0.1114\n",
      "valid accuracy: 0.0795 0.1375 0.192 0.5459 0.0889 0.1122 0.1169\n",
      "valid accuracy: 0.0757 0.1385 0.1862 0.5548 0.0867 0.1072 0.1118\n",
      "valid accuracy: 0.0759 0.1388 0.1875 0.5621 0.0879 0.1021 0.1088\n",
      "valid accuracy: 0.0767 0.1332 0.1865 0.5481 0.083 0.1043 0.1093\n",
      "valid accuracy: 0.0762 0.1387 0.1855 0.5552 0.0805 0.1055 0.1119\n",
      "valid accuracy: 0.0781 0.1421 0.1885 0.5554 0.0821 0.1044 0.111\n",
      "valid accuracy: 0.0793 0.1373 0.187 0.5526 0.0844 0.108 0.1134\n",
      "valid accuracy: 0.0814 0.1417 0.1863 0.5538 0.0863 0.1085 0.1103\n",
      "valid accuracy: 0.0793 0.1374 0.196 0.5576 0.0904 0.1038 0.1104\n",
      "valid accuracy: 0.0757 0.1422 0.1853 0.5619 0.0915 0.1087 0.1104\n",
      "valid accuracy: 0.0833 0.141 0.1841 0.5565 0.0885 0.1105 0.1071\n",
      "valid accuracy: 0.0769 0.1358 0.1868 0.5626 0.085 0.1077 0.1126\n",
      "valid accuracy: 0.0784 0.1349 0.1876 0.5542 0.084 0.1052 0.1149\n",
      "valid accuracy: 0.0767 0.1428 0.1882 0.5583 0.0856 0.1091 0.1113\n",
      "valid accuracy: 0.0765 0.1357 0.1871 0.5558 0.0855 0.107 0.1164\n",
      "valid accuracy: 0.0818 0.1366 0.184 0.5512 0.0858 0.1103 0.1187\n",
      "valid accuracy: 0.0749 0.1378 0.1913 0.5583 0.0857 0.1092 0.1118\n",
      "valid accuracy: 0.0774 0.1349 0.1925 0.5598 0.0818 0.1073 0.1113\n",
      "valid accuracy: 0.0752 0.1391 0.1874 0.5481 0.0915 0.108 0.1111\n",
      "valid accuracy: 0.0795 0.1368 0.1916 0.5504 0.0859 0.1132 0.1107\n",
      "valid accuracy: 0.0773 0.1395 0.1922 0.5562 0.0893 0.1076 0.1146\n",
      "valid accuracy: 0.0771 0.1445 0.183 0.5589 0.0858 0.1123 0.1147\n",
      "valid accuracy: 0.0792 0.14 0.1904 0.5521 0.0845 0.1077 0.1088\n",
      "valid accuracy: 0.0806 0.1406 0.1884 0.5497 0.0885 0.1043 0.1121\n",
      "valid accuracy: 0.0769 0.1313 0.1922 0.5493 0.0838 0.1053 0.1124\n",
      "valid accuracy: 0.0761 0.1415 0.1851 0.5695 0.0854 0.11 0.1108\n",
      "ep 100, batch 0, training accuracy 0.605\n",
      "ep 100, batch 50, training accuracy 0.525\n",
      "ep 100, batch 100, training accuracy 0.585\n",
      "ep 100, batch 150, training accuracy 0.525\n",
      "ep 100, batch 200, training accuracy 0.545\n",
      "valid accuracy: 0.0779 0.1367 0.1841 0.5586 0.0854 0.1142 0.1108\n",
      "valid accuracy: 0.0766 0.1371 0.1847 0.5518 0.0881 0.1046 0.1175\n",
      "valid accuracy: 0.079 0.1373 0.1815 0.5565 0.0864 0.1026 0.1134\n",
      "valid accuracy: 0.076 0.1382 0.1886 0.5572 0.0843 0.1108 0.1138\n",
      "valid accuracy: 0.0803 0.138 0.1939 0.5604 0.0867 0.1069 0.1144\n",
      "valid accuracy: 0.0765 0.1388 0.1856 0.5599 0.0857 0.1133 0.1163\n",
      "valid accuracy: 0.08 0.1372 0.1904 0.5589 0.0862 0.1066 0.1096\n",
      "valid accuracy: 0.0772 0.1412 0.188 0.5561 0.081 0.108 0.1135\n",
      "valid accuracy: 0.0804 0.1414 0.1945 0.5466 0.0896 0.1055 0.1148\n",
      "valid accuracy: 0.0781 0.1388 0.1908 0.5668 0.0861 0.1065 0.1122\n",
      "valid accuracy: 0.0745 0.1393 0.1866 0.5547 0.0864 0.1094 0.114\n",
      "valid accuracy: 0.0811 0.1385 0.1839 0.5488 0.0882 0.1041 0.1095\n",
      "valid accuracy: 0.0766 0.1366 0.1884 0.5549 0.085 0.1114 0.108\n",
      "valid accuracy: 0.0765 0.1338 0.1832 0.5663 0.0848 0.108 0.1124\n",
      "valid accuracy: 0.0811 0.1363 0.1889 0.5481 0.0841 0.1088 0.1108\n",
      "valid accuracy: 0.0785 0.1336 0.1884 0.5466 0.0866 0.1026 0.1101\n",
      "valid accuracy: 0.0773 0.1368 0.186 0.5493 0.0902 0.1038 0.1196\n",
      "valid accuracy: 0.0792 0.1402 0.1906 0.5576 0.0882 0.1119 0.1159\n",
      "valid accuracy: 0.0792 0.136 0.1875 0.5534 0.0875 0.1085 0.1096\n",
      "valid accuracy: 0.0785 0.1308 0.1914 0.5586 0.0881 0.1077 0.1097\n",
      "valid accuracy: 0.0789 0.136 0.1923 0.5655 0.0888 0.1091 0.1111\n",
      "valid accuracy: 0.079 0.1351 0.1869 0.5548 0.0907 0.1104 0.1116\n",
      "valid accuracy: 0.0797 0.1366 0.1898 0.5565 0.0845 0.1103 0.1124\n",
      "valid accuracy: 0.0766 0.1374 0.1856 0.5518 0.085 0.112 0.1104\n",
      "valid accuracy: 0.0744 0.1347 0.1862 0.5539 0.0853 0.1073 0.1115\n",
      "valid accuracy: 0.0752 0.1376 0.1904 0.5511 0.0859 0.1061 0.1078\n",
      "valid accuracy: 0.0803 0.1385 0.1762 0.5586 0.0805 0.104 0.1075\n",
      "valid accuracy: 0.0754 0.1369 0.1887 0.5647 0.0826 0.1056 0.11\n",
      "valid accuracy: 0.0794 0.1371 0.1924 0.5547 0.0851 0.1059 0.1099\n",
      "valid accuracy: 0.0803 0.1422 0.1896 0.5541 0.0873 0.1113 0.1117\n",
      "valid accuracy: 0.0767 0.1404 0.1813 0.5485 0.0893 0.1078 0.1163\n",
      "valid accuracy: 0.085 0.1366 0.1912 0.5584 0.09 0.1094 0.1135\n",
      "valid accuracy: 0.0795 0.136 0.1958 0.5572 0.0865 0.1177 0.1124\n",
      "valid accuracy: 0.0758 0.1397 0.186 0.5593 0.0863 0.1098 0.1127\n",
      "valid accuracy: 0.0742 0.1386 0.1899 0.5531 0.089 0.1058 0.1219\n",
      "valid accuracy: 0.0798 0.134 0.1888 0.5646 0.084 0.107 0.1116\n",
      "valid accuracy: 0.0765 0.1397 0.1883 0.5537 0.0872 0.1068 0.114\n",
      "valid accuracy: 0.0782 0.1351 0.1867 0.5591 0.0823 0.1074 0.1098\n",
      "valid accuracy: 0.0723 0.1392 0.1943 0.5471 0.0886 0.1118 0.1155\n",
      "valid accuracy: 0.0798 0.1352 0.1875 0.5588 0.0855 0.1077 0.1192\n",
      "valid accuracy: 0.0803 0.1429 0.1835 0.5584 0.0882 0.1126 0.1168\n",
      "valid accuracy: 0.0801 0.1403 0.1876 0.5549 0.09 0.1079 0.1144\n",
      "valid accuracy: 0.0751 0.1403 0.1889 0.5558 0.0895 0.1068 0.1133\n",
      "valid accuracy: 0.0794 0.141 0.191 0.5533 0.0871 0.1111 0.1072\n",
      "valid accuracy: 0.0769 0.1392 0.1799 0.5622 0.0832 0.1125 0.1093\n",
      "valid accuracy: 0.0809 0.1406 0.1829 0.5596 0.0915 0.1084 0.1132\n",
      "valid accuracy: 0.0768 0.1412 0.1891 0.5538 0.0862 0.1162 0.1134\n",
      "valid accuracy: 0.0772 0.1368 0.1805 0.5637 0.0885 0.1104 0.1067\n",
      "valid accuracy: 0.0746 0.1343 0.1861 0.5503 0.0824 0.1057 0.1076\n",
      "valid accuracy: 0.0776 0.1386 0.1839 0.5604 0.0867 0.1108 0.1132\n",
      "ep 150, batch 0, training accuracy 0.555\n",
      "ep 150, batch 50, training accuracy 0.53\n",
      "ep 150, batch 100, training accuracy 0.605\n",
      "ep 150, batch 150, training accuracy 0.57\n",
      "ep 150, batch 200, training accuracy 0.615\n",
      "valid accuracy: 0.0745 0.1354 0.1802 0.5531 0.091 0.1156 0.1134\n",
      "valid accuracy: 0.079 0.1352 0.1864 0.5518 0.0844 0.1104 0.1215\n",
      "valid accuracy: 0.0798 0.1387 0.1914 0.5559 0.0897 0.1107 0.1076\n",
      "valid accuracy: 0.0805 0.1376 0.1855 0.5578 0.0779 0.1062 0.1137\n",
      "valid accuracy: 0.0807 0.1384 0.1869 0.5519 0.0864 0.1087 0.1131\n",
      "valid accuracy: 0.0783 0.1425 0.1848 0.5528 0.0856 0.1067 0.1095\n",
      "valid accuracy: 0.0777 0.1381 0.193 0.553 0.0847 0.1053 0.1117\n",
      "valid accuracy: 0.0784 0.1352 0.1835 0.5552 0.0843 0.1067 0.1148\n",
      "valid accuracy: 0.0733 0.1383 0.1914 0.5572 0.0918 0.1106 0.1159\n",
      "valid accuracy: 0.0758 0.1376 0.1883 0.5477 0.0824 0.1049 0.1096\n",
      "valid accuracy: 0.0778 0.1407 0.187 0.5497 0.0843 0.108 0.1119\n",
      "valid accuracy: 0.081 0.1382 0.1925 0.5512 0.0818 0.1056 0.1111\n",
      "valid accuracy: 0.0767 0.1295 0.1817 0.5392 0.0831 0.1077 0.1107\n",
      "valid accuracy: 0.0791 0.1407 0.1901 0.5508 0.0885 0.1096 0.109\n",
      "valid accuracy: 0.0794 0.1435 0.1878 0.5521 0.0851 0.1065 0.1072\n",
      "valid accuracy: 0.0807 0.1352 0.191 0.5501 0.0857 0.1134 0.1133\n",
      "valid accuracy: 0.0784 0.1407 0.1835 0.5569 0.0853 0.1035 0.1128\n",
      "valid accuracy: 0.0812 0.133 0.1907 0.5591 0.0845 0.1113 0.1099\n",
      "valid accuracy: 0.0817 0.1316 0.189 0.5586 0.0839 0.1023 0.1138\n",
      "valid accuracy: 0.0772 0.1422 0.188 0.547 0.0859 0.1099 0.1155\n",
      "valid accuracy: 0.0797 0.1387 0.1892 0.5549 0.0849 0.1029 0.1168\n",
      "valid accuracy: 0.0792 0.1394 0.1881 0.5552 0.0857 0.1086 0.1102\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.045\n",
      "ep 0, batch 50, training accuracy 0.26\n",
      "ep 0, batch 100, training accuracy 0.28\n",
      "ep 0, batch 150, training accuracy 0.315\n",
      "ep 0, batch 200, training accuracy 0.32\n",
      "valid accuracy: 0.0726 0.1669 0.1674 0.3907 0.3529 0.1315 0.1323\n",
      "valid accuracy: 0.0839 0.1532 0.1536 0.3544 0.4068 0.1342 0.1287\n",
      "valid accuracy: 0.0914 0.1404 0.1359 0.3286 0.427 0.1284 0.1262\n",
      "valid accuracy: 0.1142 0.1225 0.1275 0.3019 0.4482 0.1277 0.1174\n",
      "valid accuracy: 0.1176 0.1294 0.1451 0.3226 0.4622 0.1187 0.1281\n",
      "valid accuracy: 0.1195 0.132 0.1369 0.3233 0.4705 0.1275 0.1214\n",
      "valid accuracy: 0.1243 0.1358 0.1378 0.3262 0.4711 0.1243 0.122\n",
      "valid accuracy: 0.1313 0.1285 0.1281 0.31 0.4778 0.1201 0.1103\n",
      "valid accuracy: 0.1238 0.1318 0.1232 0.3095 0.4831 0.1288 0.1186\n",
      "valid accuracy: 0.1135 0.1548 0.1383 0.2972 0.4866 0.1303 0.1206\n",
      "valid accuracy: 0.1286 0.1448 0.1311 0.313 0.4946 0.1283 0.1204\n",
      "valid accuracy: 0.1321 0.1537 0.1435 0.2989 0.4996 0.1276 0.1228\n",
      "valid accuracy: 0.1361 0.1399 0.1311 0.2871 0.5164 0.1217 0.1138\n",
      "valid accuracy: 0.1362 0.1422 0.1298 0.2828 0.4972 0.1149 0.1198\n",
      "valid accuracy: 0.1279 0.1515 0.1335 0.2902 0.5098 0.1184 0.1158\n",
      "valid accuracy: 0.1402 0.1488 0.13 0.2997 0.5037 0.1132 0.1148\n",
      "valid accuracy: 0.1285 0.1483 0.1273 0.3008 0.5146 0.118 0.1142\n",
      "valid accuracy: 0.1327 0.1466 0.1313 0.2849 0.5138 0.1203 0.1202\n",
      "valid accuracy: 0.1328 0.1409 0.1329 0.2988 0.5048 0.1259 0.1063\n",
      "valid accuracy: 0.1305 0.1415 0.1381 0.2982 0.5213 0.124 0.1157\n",
      "valid accuracy: 0.1303 0.149 0.1323 0.2671 0.5166 0.1141 0.1155\n",
      "valid accuracy: 0.1305 0.1377 0.1284 0.2723 0.5222 0.1158 0.118\n",
      "valid accuracy: 0.1394 0.1514 0.1311 0.2778 0.5248 0.1149 0.1234\n",
      "valid accuracy: 0.1336 0.136 0.1265 0.2696 0.5255 0.1174 0.1179\n",
      "valid accuracy: 0.1281 0.142 0.1232 0.2767 0.5242 0.1196 0.116\n",
      "valid accuracy: 0.1296 0.1451 0.1335 0.2695 0.5315 0.1181 0.1125\n",
      "valid accuracy: 0.1312 0.1512 0.133 0.267 0.5219 0.1168 0.111\n",
      "valid accuracy: 0.1397 0.1491 0.134 0.2648 0.5259 0.1209 0.1159\n",
      "valid accuracy: 0.1447 0.1478 0.1276 0.2577 0.5371 0.1175 0.1167\n",
      "valid accuracy: 0.1512 0.1451 0.1289 0.2544 0.5274 0.1281 0.114\n",
      "valid accuracy: 0.1466 0.1456 0.131 0.2531 0.5302 0.1175 0.1179\n",
      "valid accuracy: 0.1414 0.1416 0.1313 0.2537 0.5255 0.1183 0.109\n",
      "valid accuracy: 0.1531 0.1388 0.126 0.2422 0.5312 0.1149 0.1112\n",
      "valid accuracy: 0.1474 0.1441 0.1376 0.2545 0.5379 0.1165 0.1091\n",
      "valid accuracy: 0.1422 0.1416 0.1279 0.2576 0.5441 0.1174 0.1112\n",
      "valid accuracy: 0.1399 0.1243 0.1197 0.2426 0.5412 0.1107 0.1108\n",
      "valid accuracy: 0.1397 0.1337 0.1118 0.2326 0.5405 0.1141 0.1131\n",
      "valid accuracy: 0.1432 0.1403 0.1298 0.2455 0.5318 0.1212 0.118\n",
      "valid accuracy: 0.1416 0.1324 0.1205 0.2339 0.5386 0.1155 0.1131\n",
      "valid accuracy: 0.1424 0.1284 0.1252 0.2235 0.5434 0.1092 0.1197\n",
      "valid accuracy: 0.1447 0.1345 0.1136 0.2289 0.5439 0.1153 0.1119\n",
      "valid accuracy: 0.1418 0.1299 0.1215 0.2367 0.5434 0.1211 0.1084\n",
      "valid accuracy: 0.1421 0.1323 0.1177 0.2241 0.5373 0.1178 0.11\n",
      "valid accuracy: 0.1443 0.1302 0.1267 0.2317 0.5458 0.1182 0.1141\n",
      "valid accuracy: 0.1477 0.1402 0.1366 0.2392 0.5353 0.1188 0.1171\n",
      "valid accuracy: 0.1436 0.1382 0.1271 0.2354 0.5485 0.125 0.111\n",
      "valid accuracy: 0.1447 0.1365 0.1423 0.2281 0.5446 0.1212 0.1142\n",
      "valid accuracy: 0.1445 0.1334 0.1289 0.2187 0.5381 0.12 0.112\n",
      "valid accuracy: 0.1511 0.1306 0.1189 0.2207 0.5442 0.1177 0.109\n",
      "valid accuracy: 0.1466 0.1246 0.1141 0.2018 0.5503 0.1165 0.1027\n",
      "ep 50, batch 0, training accuracy 0.605\n",
      "ep 50, batch 50, training accuracy 0.585\n",
      "ep 50, batch 100, training accuracy 0.465\n",
      "ep 50, batch 150, training accuracy 0.51\n",
      "ep 50, batch 200, training accuracy 0.565\n",
      "valid accuracy: 0.1475 0.135 0.1141 0.2137 0.5434 0.1164 0.1154\n",
      "valid accuracy: 0.1469 0.1371 0.1196 0.2071 0.5462 0.123 0.1112\n",
      "valid accuracy: 0.1452 0.1313 0.1159 0.2198 0.5527 0.1199 0.1096\n",
      "valid accuracy: 0.1439 0.1249 0.1102 0.2153 0.5456 0.1179 0.108\n",
      "valid accuracy: 0.1471 0.1299 0.1086 0.2174 0.5376 0.1226 0.1072\n",
      "valid accuracy: 0.1382 0.1346 0.1198 0.2112 0.5526 0.1206 0.1103\n",
      "valid accuracy: 0.1452 0.1252 0.1148 0.2138 0.5599 0.1198 0.115\n",
      "valid accuracy: 0.1509 0.1298 0.1253 0.2244 0.5525 0.1165 0.1089\n",
      "valid accuracy: 0.1498 0.1266 0.1128 0.2067 0.5599 0.118 0.1083\n",
      "valid accuracy: 0.1526 0.1268 0.1154 0.2129 0.5569 0.1195 0.1048\n",
      "valid accuracy: 0.1448 0.1243 0.114 0.2102 0.5533 0.1249 0.1118\n",
      "valid accuracy: 0.144 0.1286 0.1111 0.2128 0.5547 0.1175 0.1091\n",
      "valid accuracy: 0.1507 0.1283 0.1151 0.2101 0.5593 0.1194 0.1082\n",
      "valid accuracy: 0.151 0.1281 0.1183 0.2103 0.5543 0.1196 0.1167\n",
      "valid accuracy: 0.148 0.1322 0.111 0.2147 0.5474 0.1204 0.1113\n",
      "valid accuracy: 0.1494 0.138 0.1188 0.2063 0.556 0.12 0.1107\n",
      "valid accuracy: 0.1437 0.1304 0.1188 0.2173 0.5577 0.1215 0.1075\n",
      "valid accuracy: 0.1492 0.1347 0.116 0.2102 0.5535 0.1207 0.111\n",
      "valid accuracy: 0.149 0.1287 0.11 0.2158 0.5561 0.1213 0.1125\n",
      "valid accuracy: 0.1528 0.1263 0.1131 0.2151 0.5543 0.1209 0.1117\n",
      "valid accuracy: 0.1539 0.1312 0.1174 0.2094 0.5552 0.1191 0.1065\n",
      "valid accuracy: 0.1494 0.1228 0.1164 0.213 0.5491 0.1199 0.1061\n",
      "valid accuracy: 0.1496 0.1324 0.1158 0.2081 0.5496 0.1239 0.1087\n",
      "valid accuracy: 0.1493 0.1291 0.1139 0.2096 0.5604 0.1199 0.1094\n",
      "valid accuracy: 0.1487 0.1335 0.1161 0.2072 0.5492 0.12 0.1153\n",
      "valid accuracy: 0.1529 0.1315 0.1157 0.2078 0.5491 0.1214 0.1131\n",
      "valid accuracy: 0.1511 0.1287 0.1178 0.2117 0.5488 0.1211 0.1176\n",
      "valid accuracy: 0.1529 0.1246 0.1099 0.2053 0.5556 0.1261 0.1105\n",
      "valid accuracy: 0.1516 0.1306 0.1201 0.2049 0.5516 0.1253 0.113\n",
      "valid accuracy: 0.1476 0.1358 0.1151 0.2107 0.5575 0.122 0.1082\n",
      "valid accuracy: 0.156 0.1305 0.117 0.2109 0.5458 0.1229 0.1096\n",
      "valid accuracy: 0.1521 0.1272 0.1135 0.2132 0.551 0.1191 0.1084\n",
      "valid accuracy: 0.1458 0.1282 0.1215 0.2131 0.559 0.1233 0.1045\n",
      "valid accuracy: 0.1527 0.1302 0.1175 0.2186 0.5521 0.1224 0.1074\n",
      "valid accuracy: 0.1484 0.1245 0.1214 0.2059 0.554 0.1216 0.109\n",
      "valid accuracy: 0.1513 0.1235 0.1226 0.2103 0.5604 0.1206 0.1066\n",
      "valid accuracy: 0.1484 0.1292 0.1149 0.2114 0.5471 0.1199 0.1094\n",
      "valid accuracy: 0.1526 0.1282 0.1184 0.2075 0.5528 0.1261 0.1114\n",
      "valid accuracy: 0.1482 0.1292 0.1177 0.2151 0.5607 0.1236 0.1085\n",
      "valid accuracy: 0.1536 0.125 0.1162 0.2104 0.5582 0.1231 0.1062\n",
      "valid accuracy: 0.1529 0.1287 0.1165 0.2078 0.5495 0.1238 0.1058\n",
      "valid accuracy: 0.1461 0.1259 0.1173 0.2161 0.5536 0.1201 0.1077\n",
      "valid accuracy: 0.1533 0.1312 0.1212 0.2091 0.5553 0.1208 0.1088\n",
      "valid accuracy: 0.1528 0.1345 0.1188 0.208 0.5544 0.1208 0.1091\n",
      "valid accuracy: 0.1597 0.1289 0.115 0.209 0.5544 0.1222 0.1112\n",
      "valid accuracy: 0.1485 0.1348 0.1187 0.2126 0.5579 0.1219 0.1075\n",
      "valid accuracy: 0.1521 0.1291 0.1152 0.2135 0.5531 0.1231 0.1103\n",
      "valid accuracy: 0.1496 0.13 0.1169 0.2081 0.5498 0.1206 0.1096\n",
      "valid accuracy: 0.1485 0.1269 0.1158 0.2065 0.5512 0.1277 0.1085\n",
      "valid accuracy: 0.1524 0.1341 0.1137 0.2114 0.5515 0.1231 0.1099\n",
      "ep 100, batch 0, training accuracy 0.59\n",
      "ep 100, batch 50, training accuracy 0.57\n",
      "ep 100, batch 100, training accuracy 0.61\n",
      "ep 100, batch 150, training accuracy 0.54\n",
      "ep 100, batch 200, training accuracy 0.585\n",
      "valid accuracy: 0.1533 0.1303 0.1197 0.2102 0.5526 0.1237 0.1141\n",
      "valid accuracy: 0.15 0.1283 0.118 0.2129 0.5502 0.1202 0.1079\n",
      "valid accuracy: 0.1549 0.1307 0.1182 0.2064 0.5588 0.1246 0.1095\n",
      "valid accuracy: 0.1547 0.1318 0.1159 0.2113 0.5529 0.1131 0.1127\n",
      "valid accuracy: 0.1522 0.1314 0.1171 0.2141 0.5576 0.1236 0.1113\n",
      "valid accuracy: 0.1472 0.1258 0.1191 0.2085 0.5561 0.1162 0.1075\n",
      "valid accuracy: 0.1461 0.1266 0.1174 0.2075 0.5424 0.1195 0.1083\n",
      "valid accuracy: 0.1499 0.1295 0.119 0.2074 0.5541 0.1249 0.1113\n",
      "valid accuracy: 0.1456 0.1244 0.114 0.2091 0.5558 0.1239 0.1126\n",
      "valid accuracy: 0.1539 0.1288 0.1218 0.2117 0.5489 0.1244 0.1092\n",
      "valid accuracy: 0.1548 0.1349 0.118 0.2129 0.5562 0.1203 0.107\n",
      "valid accuracy: 0.1546 0.126 0.1147 0.2109 0.5535 0.1206 0.1101\n",
      "valid accuracy: 0.1458 0.1261 0.1196 0.2154 0.5532 0.1212 0.1129\n",
      "valid accuracy: 0.1517 0.1298 0.1186 0.2121 0.554 0.1191 0.1058\n",
      "valid accuracy: 0.152 0.1326 0.1127 0.2065 0.5533 0.1258 0.1127\n",
      "valid accuracy: 0.1503 0.1237 0.1178 0.212 0.5611 0.1202 0.1092\n",
      "valid accuracy: 0.1555 0.1289 0.1245 0.2111 0.5566 0.1269 0.1108\n",
      "valid accuracy: 0.15 0.1253 0.1198 0.2183 0.5497 0.1167 0.11\n",
      "valid accuracy: 0.1523 0.1333 0.1203 0.2164 0.5585 0.1218 0.1109\n",
      "valid accuracy: 0.153 0.1305 0.1201 0.2083 0.5565 0.1254 0.1117\n",
      "valid accuracy: 0.1541 0.1279 0.1211 0.2161 0.5543 0.1243 0.1099\n",
      "valid accuracy: 0.1564 0.1312 0.1134 0.2151 0.5487 0.1174 0.1135\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.13\n",
      "ep 0, batch 50, training accuracy 0.32\n",
      "ep 0, batch 100, training accuracy 0.29\n",
      "ep 0, batch 150, training accuracy 0.275\n",
      "ep 0, batch 200, training accuracy 0.345\n",
      "valid accuracy: 0.1404 0.1494 0.1289 0.1787 0.4695 0.3784 0.1181\n",
      "valid accuracy: 0.1244 0.1424 0.1125 0.1749 0.4268 0.4161 0.111\n",
      "valid accuracy: 0.1213 0.1298 0.1103 0.1556 0.396 0.4294 0.1107\n",
      "valid accuracy: 0.1244 0.1202 0.1118 0.1645 0.3777 0.448 0.1076\n",
      "valid accuracy: 0.126 0.1358 0.1286 0.1598 0.3679 0.4738 0.1163\n",
      "valid accuracy: 0.1301 0.1323 0.122 0.1547 0.3671 0.4821 0.1067\n",
      "valid accuracy: 0.118 0.1242 0.1242 0.1504 0.3521 0.4794 0.107\n",
      "valid accuracy: 0.1235 0.1172 0.1226 0.1519 0.352 0.4747 0.1039\n",
      "valid accuracy: 0.1227 0.1189 0.1182 0.1407 0.3316 0.4864 0.1096\n",
      "valid accuracy: 0.1081 0.1086 0.1135 0.1405 0.3372 0.4941 0.1036\n",
      "valid accuracy: 0.1166 0.107 0.1172 0.1371 0.3354 0.4981 0.1074\n",
      "valid accuracy: 0.1137 0.1221 0.1216 0.1525 0.3328 0.4991 0.1111\n",
      "valid accuracy: 0.1173 0.1214 0.1222 0.1361 0.3326 0.4975 0.0977\n",
      "valid accuracy: 0.109 0.1199 0.1166 0.1437 0.3233 0.5098 0.0979\n",
      "valid accuracy: 0.1236 0.1117 0.1215 0.1415 0.3148 0.508 0.1035\n",
      "valid accuracy: 0.1107 0.1157 0.1234 0.1347 0.3221 0.5217 0.1062\n",
      "valid accuracy: 0.1032 0.1191 0.1257 0.1281 0.307 0.5064 0.1056\n",
      "valid accuracy: 0.1119 0.1141 0.1162 0.1347 0.3103 0.5166 0.1007\n",
      "valid accuracy: 0.1166 0.1166 0.1225 0.1365 0.3116 0.513 0.101\n",
      "valid accuracy: 0.1097 0.1147 0.1115 0.1324 0.3089 0.5128 0.1069\n",
      "valid accuracy: 0.1033 0.11 0.1181 0.1413 0.2952 0.5246 0.1056\n",
      "valid accuracy: 0.1094 0.1167 0.1204 0.1248 0.2876 0.5189 0.1032\n",
      "valid accuracy: 0.1082 0.1081 0.1159 0.1249 0.2949 0.522 0.109\n",
      "valid accuracy: 0.1041 0.1125 0.1164 0.1255 0.2875 0.5171 0.1074\n",
      "valid accuracy: 0.1155 0.122 0.1181 0.1356 0.2999 0.5305 0.1066\n",
      "valid accuracy: 0.1168 0.1235 0.1202 0.1323 0.2951 0.52 0.1056\n",
      "valid accuracy: 0.1151 0.1171 0.1082 0.1285 0.2816 0.5321 0.102\n",
      "valid accuracy: 0.11 0.1158 0.1214 0.127 0.2801 0.5232 0.1059\n",
      "valid accuracy: 0.114 0.1191 0.1134 0.1342 0.2797 0.5234 0.1087\n",
      "valid accuracy: 0.1047 0.1163 0.1129 0.1288 0.2834 0.5246 0.1042\n",
      "valid accuracy: 0.1145 0.1178 0.1158 0.1274 0.2732 0.5266 0.1098\n",
      "valid accuracy: 0.1087 0.1204 0.1234 0.1287 0.2835 0.5234 0.0995\n",
      "valid accuracy: 0.1103 0.1154 0.124 0.1315 0.27 0.5267 0.1036\n",
      "valid accuracy: 0.1096 0.1125 0.1171 0.1286 0.2728 0.527 0.1053\n",
      "valid accuracy: 0.1089 0.1247 0.1181 0.1279 0.2674 0.5242 0.1091\n",
      "valid accuracy: 0.1112 0.1064 0.114 0.1242 0.251 0.5358 0.1001\n",
      "valid accuracy: 0.1084 0.1141 0.1159 0.1238 0.2579 0.5282 0.1043\n",
      "valid accuracy: 0.1204 0.1133 0.1152 0.1224 0.2516 0.537 0.0977\n",
      "valid accuracy: 0.1129 0.1145 0.114 0.125 0.2629 0.5345 0.1029\n",
      "valid accuracy: 0.1137 0.1215 0.1128 0.1267 0.2582 0.5402 0.1054\n",
      "valid accuracy: 0.1162 0.1196 0.1133 0.1349 0.2552 0.5383 0.1024\n",
      "valid accuracy: 0.1096 0.1101 0.1125 0.1229 0.2665 0.5266 0.1073\n",
      "valid accuracy: 0.1081 0.1092 0.112 0.1237 0.2472 0.5301 0.1021\n",
      "valid accuracy: 0.1077 0.1125 0.1101 0.131 0.2504 0.5373 0.1022\n",
      "valid accuracy: 0.1127 0.1102 0.1154 0.1296 0.2527 0.5419 0.1089\n",
      "valid accuracy: 0.1103 0.1054 0.1129 0.1174 0.2465 0.5273 0.1038\n",
      "valid accuracy: 0.1123 0.1109 0.1129 0.1183 0.2509 0.5309 0.1039\n",
      "valid accuracy: 0.1151 0.1075 0.1059 0.122 0.2485 0.5387 0.0983\n",
      "valid accuracy: 0.1151 0.1119 0.1184 0.1147 0.2444 0.5324 0.099\n",
      "valid accuracy: 0.1129 0.1055 0.1104 0.1228 0.2382 0.5366 0.103\n",
      "ep 50, batch 0, training accuracy 0.535\n",
      "ep 50, batch 50, training accuracy 0.545\n",
      "ep 50, batch 100, training accuracy 0.525\n",
      "ep 50, batch 150, training accuracy 0.54\n",
      "ep 50, batch 200, training accuracy 0.62\n",
      "valid accuracy: 0.1069 0.1116 0.105 0.1233 0.2343 0.5327 0.105\n",
      "valid accuracy: 0.109 0.1175 0.1137 0.122 0.232 0.5421 0.101\n",
      "valid accuracy: 0.1067 0.1136 0.1129 0.1196 0.2247 0.5329 0.0992\n",
      "valid accuracy: 0.1097 0.1055 0.1132 0.1307 0.2439 0.5391 0.0998\n",
      "valid accuracy: 0.1088 0.1124 0.1137 0.1196 0.246 0.544 0.104\n",
      "valid accuracy: 0.1153 0.1138 0.1133 0.1217 0.2397 0.5392 0.1032\n",
      "valid accuracy: 0.1137 0.108 0.112 0.1219 0.2402 0.5359 0.1007\n",
      "valid accuracy: 0.1149 0.1064 0.1068 0.1192 0.2383 0.5454 0.0961\n",
      "valid accuracy: 0.1146 0.1134 0.1141 0.1271 0.239 0.5399 0.0988\n",
      "valid accuracy: 0.1122 0.1103 0.1144 0.124 0.2332 0.5414 0.1069\n",
      "valid accuracy: 0.115 0.1088 0.1155 0.1249 0.2384 0.5463 0.1054\n",
      "valid accuracy: 0.112 0.1049 0.1172 0.124 0.2358 0.5406 0.1017\n",
      "valid accuracy: 0.1118 0.108 0.11 0.1212 0.2349 0.5427 0.0995\n",
      "valid accuracy: 0.1153 0.1121 0.1084 0.1199 0.2324 0.5418 0.1002\n",
      "valid accuracy: 0.1123 0.1067 0.1099 0.122 0.2328 0.5411 0.1022\n",
      "valid accuracy: 0.1176 0.1092 0.1113 0.1213 0.2369 0.5499 0.1064\n",
      "valid accuracy: 0.1145 0.1099 0.1115 0.1202 0.2406 0.5479 0.1007\n",
      "valid accuracy: 0.1183 0.1108 0.1148 0.1143 0.2397 0.5532 0.1016\n",
      "valid accuracy: 0.1109 0.114 0.1186 0.1242 0.2457 0.5444 0.1016\n",
      "valid accuracy: 0.1157 0.1134 0.1145 0.1207 0.2342 0.5463 0.1028\n",
      "valid accuracy: 0.1121 0.1055 0.1117 0.123 0.2335 0.5465 0.1027\n",
      "valid accuracy: 0.1134 0.1086 0.1145 0.1181 0.2462 0.5454 0.1013\n",
      "valid accuracy: 0.1148 0.1161 0.114 0.1273 0.2266 0.5441 0.1023\n",
      "valid accuracy: 0.1125 0.1115 0.1097 0.1201 0.2355 0.5449 0.1032\n",
      "valid accuracy: 0.1106 0.1175 0.1169 0.1263 0.2363 0.5444 0.1026\n",
      "valid accuracy: 0.1162 0.1122 0.1139 0.121 0.236 0.54 0.1033\n",
      "valid accuracy: 0.1145 0.1117 0.1133 0.1247 0.2322 0.5456 0.1019\n",
      "valid accuracy: 0.1128 0.1095 0.1086 0.1254 0.2371 0.5385 0.1028\n",
      "valid accuracy: 0.1145 0.1101 0.1144 0.1157 0.2407 0.5467 0.1051\n",
      "valid accuracy: 0.1142 0.1124 0.1124 0.1194 0.2427 0.5395 0.1045\n",
      "valid accuracy: 0.1147 0.1139 0.1139 0.1252 0.2395 0.5499 0.0997\n",
      "valid accuracy: 0.1099 0.1084 0.1077 0.1206 0.238 0.5465 0.1034\n",
      "valid accuracy: 0.1156 0.1094 0.1095 0.1235 0.2386 0.5522 0.1034\n",
      "valid accuracy: 0.1192 0.1116 0.1105 0.1181 0.2378 0.5431 0.1031\n",
      "valid accuracy: 0.1135 0.1085 0.1108 0.1221 0.2301 0.5502 0.0989\n",
      "valid accuracy: 0.109 0.1167 0.1057 0.1252 0.233 0.5389 0.1053\n",
      "valid accuracy: 0.1154 0.1147 0.1101 0.122 0.2351 0.5495 0.105\n",
      "valid accuracy: 0.1161 0.1085 0.1158 0.1201 0.2337 0.5478 0.1008\n",
      "valid accuracy: 0.1184 0.1097 0.1091 0.1249 0.2382 0.5515 0.1033\n",
      "valid accuracy: 0.1145 0.1098 0.1126 0.1192 0.2301 0.5501 0.1007\n",
      "valid accuracy: 0.1077 0.1132 0.1078 0.1282 0.2381 0.555 0.1009\n",
      "valid accuracy: 0.1157 0.1121 0.1115 0.1211 0.234 0.5436 0.0975\n",
      "valid accuracy: 0.1099 0.1114 0.1074 0.1252 0.2411 0.5474 0.1062\n",
      "valid accuracy: 0.1107 0.1136 0.1096 0.1204 0.2346 0.5514 0.1004\n",
      "valid accuracy: 0.1105 0.1135 0.1156 0.1237 0.2367 0.5457 0.1089\n",
      "valid accuracy: 0.1127 0.1099 0.1076 0.1265 0.2304 0.5508 0.0953\n",
      "valid accuracy: 0.1209 0.1135 0.111 0.1253 0.2347 0.5403 0.1016\n",
      "valid accuracy: 0.114 0.1164 0.1079 0.1244 0.2343 0.5447 0.1022\n",
      "valid accuracy: 0.1123 0.1149 0.1135 0.1238 0.2432 0.5491 0.1047\n",
      "valid accuracy: 0.118 0.1096 0.1138 0.1223 0.2351 0.5472 0.1024\n",
      "ep 100, batch 0, training accuracy 0.565\n",
      "ep 100, batch 50, training accuracy 0.57\n",
      "ep 100, batch 100, training accuracy 0.49\n",
      "ep 100, batch 150, training accuracy 0.485\n",
      "ep 100, batch 200, training accuracy 0.595\n",
      "valid accuracy: 0.1087 0.1092 0.1121 0.1148 0.231 0.5559 0.1057\n",
      "valid accuracy: 0.1104 0.117 0.1083 0.1249 0.23 0.5522 0.1089\n",
      "valid accuracy: 0.1135 0.1116 0.1099 0.1246 0.2419 0.5458 0.1005\n",
      "valid accuracy: 0.1185 0.1153 0.1067 0.1203 0.2307 0.5503 0.107\n",
      "valid accuracy: 0.1109 0.1086 0.1106 0.1234 0.2357 0.5359 0.1042\n",
      "valid accuracy: 0.1117 0.1148 0.1108 0.1214 0.2314 0.5403 0.1027\n",
      "valid accuracy: 0.111 0.1174 0.1132 0.1223 0.2339 0.5418 0.1049\n",
      "valid accuracy: 0.1107 0.1096 0.111 0.1209 0.2412 0.5559 0.0974\n",
      "valid accuracy: 0.1184 0.1069 0.1129 0.1243 0.2403 0.5508 0.1006\n",
      "valid accuracy: 0.1086 0.113 0.1068 0.1238 0.2387 0.5458 0.1004\n",
      "valid accuracy: 0.1139 0.1156 0.1125 0.1185 0.2367 0.5541 0.1037\n",
      "valid accuracy: 0.1107 0.1067 0.1122 0.1218 0.2474 0.5495 0.1021\n",
      "valid accuracy: 0.116 0.1092 0.1139 0.1198 0.2372 0.5451 0.1003\n",
      "valid accuracy: 0.1095 0.1088 0.1142 0.1208 0.2339 0.5589 0.103\n",
      "valid accuracy: 0.1154 0.1103 0.1089 0.1251 0.2417 0.5502 0.0978\n",
      "valid accuracy: 0.1156 0.1088 0.1068 0.1234 0.2351 0.5514 0.0993\n",
      "valid accuracy: 0.117 0.1108 0.1173 0.1168 0.2361 0.5511 0.103\n",
      "valid accuracy: 0.1151 0.1153 0.1149 0.1205 0.2326 0.5482 0.1055\n",
      "valid accuracy: 0.1111 0.1136 0.1182 0.1209 0.2374 0.5453 0.1053\n",
      "valid accuracy: 0.1117 0.1081 0.1091 0.1203 0.2377 0.5526 0.1036\n",
      "valid accuracy: 0.1154 0.1102 0.114 0.125 0.24 0.5478 0.1037\n",
      "valid accuracy: 0.1117 0.1096 0.111 0.1244 0.2324 0.5462 0.1034\n",
      "valid accuracy: 0.1161 0.1085 0.1124 0.122 0.2337 0.5481 0.1054\n",
      "valid accuracy: 0.1133 0.1036 0.1167 0.1222 0.2365 0.5446 0.1034\n",
      "valid accuracy: 0.1123 0.1103 0.1124 0.1234 0.2326 0.5497 0.1089\n",
      "valid accuracy: 0.117 0.119 0.1157 0.1238 0.2341 0.5527 0.0993\n",
      "valid accuracy: 0.1152 0.1111 0.1105 0.1195 0.233 0.5465 0.1012\n",
      "valid accuracy: 0.1138 0.1111 0.1136 0.126 0.2333 0.5411 0.1066\n",
      "valid accuracy: 0.1113 0.112 0.1086 0.1182 0.2408 0.5442 0.1004\n",
      "valid accuracy: 0.113 0.1129 0.1189 0.1212 0.2322 0.5507 0.1026\n",
      "valid accuracy: 0.1112 0.1125 0.1069 0.122 0.2332 0.551 0.0995\n",
      "valid accuracy: 0.1109 0.1106 0.1138 0.1231 0.2352 0.5381 0.1014\n",
      "valid accuracy: 0.1102 0.1125 0.1105 0.1251 0.2377 0.5473 0.0999\n",
      "valid accuracy: 0.11 0.1166 0.108 0.1221 0.2378 0.5492 0.0981\n",
      "valid accuracy: 0.1084 0.1145 0.1108 0.1252 0.2384 0.5515 0.1097\n",
      "valid accuracy: 0.1107 0.1133 0.1079 0.1205 0.2283 0.5511 0.1051\n",
      "valid accuracy: 0.1164 0.1105 0.1099 0.1248 0.2439 0.5434 0.1022\n",
      "valid accuracy: 0.1105 0.1072 0.1127 0.1246 0.2391 0.5483 0.0993\n",
      "valid accuracy: 0.1141 0.1095 0.1079 0.1255 0.2358 0.5444 0.0995\n",
      "valid accuracy: 0.1117 0.1118 0.1066 0.1239 0.2334 0.5535 0.1067\n",
      "valid accuracy: 0.1146 0.1124 0.1092 0.1169 0.237 0.545 0.1011\n",
      "valid accuracy: 0.1149 0.111 0.1063 0.1217 0.2328 0.5535 0.1016\n",
      "valid accuracy: 0.1097 0.1142 0.1129 0.1179 0.2357 0.5449 0.1037\n",
      "valid accuracy: 0.1138 0.1064 0.1127 0.1224 0.2416 0.5449 0.1003\n",
      "valid accuracy: 0.1135 0.1113 0.1084 0.1207 0.2286 0.5485 0.102\n",
      "valid accuracy: 0.11 0.1097 0.1097 0.1243 0.2278 0.5364 0.1061\n",
      "valid accuracy: 0.1164 0.1128 0.1107 0.117 0.2335 0.5482 0.1045\n",
      "valid accuracy: 0.118 0.114 0.114 0.1185 0.2379 0.5455 0.1028\n",
      "valid accuracy: 0.1116 0.1145 0.1105 0.1204 0.2276 0.5443 0.1029\n",
      "valid accuracy: 0.1103 0.1106 0.1112 0.1183 0.2396 0.5405 0.1063\n",
      "ep 150, batch 0, training accuracy 0.515\n",
      "ep 150, batch 50, training accuracy 0.52\n",
      "ep 150, batch 100, training accuracy 0.54\n",
      "ep 150, batch 150, training accuracy 0.53\n",
      "ep 150, batch 200, training accuracy 0.555\n",
      "valid accuracy: 0.1155 0.1139 0.1126 0.1294 0.2378 0.5507 0.1034\n",
      "valid accuracy: 0.1098 0.111 0.111 0.1187 0.2305 0.55 0.1071\n",
      "valid accuracy: 0.1165 0.1115 0.1093 0.1244 0.2335 0.5546 0.1001\n",
      "valid accuracy: 0.1104 0.1147 0.1113 0.1264 0.2285 0.5439 0.1032\n",
      "valid accuracy: 0.1129 0.1096 0.1126 0.1213 0.2344 0.5447 0.101\n",
      "valid accuracy: 0.1123 0.1146 0.1115 0.1232 0.2334 0.5594 0.1008\n",
      "valid accuracy: 0.1169 0.1113 0.1073 0.1227 0.2391 0.55 0.0979\n",
      "valid accuracy: 0.1112 0.1177 0.1113 0.1188 0.2415 0.5485 0.1012\n",
      "valid accuracy: 0.1112 0.1149 0.1107 0.1222 0.2333 0.55 0.1069\n",
      "valid accuracy: 0.1132 0.1133 0.1099 0.1228 0.2354 0.5398 0.1038\n",
      "valid accuracy: 0.107 0.1157 0.1163 0.1263 0.2359 0.5445 0.0988\n",
      "valid accuracy: 0.1087 0.1166 0.1126 0.1223 0.2458 0.5512 0.1027\n",
      "valid accuracy: 0.1117 0.1103 0.1107 0.1208 0.2386 0.546 0.105\n",
      "valid accuracy: 0.1145 0.1083 0.111 0.1195 0.2316 0.5474 0.1039\n",
      "valid accuracy: 0.1119 0.1136 0.1103 0.1177 0.2369 0.5434 0.1011\n",
      "valid accuracy: 0.1121 0.1105 0.1149 0.1275 0.2429 0.5503 0.0983\n",
      "valid accuracy: 0.1156 0.1186 0.1098 0.1201 0.2291 0.5429 0.1017\n",
      "valid accuracy: 0.1157 0.1125 0.1067 0.1223 0.2324 0.5417 0.1028\n",
      "valid accuracy: 0.1104 0.107 0.1109 0.1245 0.2375 0.5471 0.1039\n",
      "valid accuracy: 0.1122 0.1114 0.1051 0.1272 0.2343 0.5405 0.1011\n",
      "valid accuracy: 0.1085 0.11 0.1068 0.1204 0.2343 0.5455 0.107\n",
      "valid accuracy: 0.109 0.1141 0.1118 0.1189 0.2353 0.5471 0.1007\n",
      "valid accuracy: 0.1126 0.1134 0.1086 0.1198 0.2348 0.5474 0.1062\n",
      "valid accuracy: 0.1164 0.1144 0.1093 0.1211 0.2348 0.5497 0.1058\n",
      "valid accuracy: 0.1179 0.1048 0.1111 0.1197 0.2393 0.5437 0.0951\n",
      "valid accuracy: 0.1085 0.1141 0.1111 0.1155 0.2306 0.5493 0.1032\n",
      "valid accuracy: 0.1143 0.1068 0.1071 0.1213 0.2404 0.5472 0.0998\n",
      "valid accuracy: 0.1082 0.1081 0.1087 0.1203 0.2281 0.545 0.1012\n",
      "valid accuracy: 0.1113 0.113 0.1113 0.1192 0.2336 0.5561 0.098\n",
      "valid accuracy: 0.1158 0.1165 0.1078 0.1175 0.2332 0.5466 0.1015\n",
      "valid accuracy: 0.1147 0.1124 0.1119 0.126 0.2387 0.5501 0.102\n",
      "valid accuracy: 0.1098 0.1096 0.1117 0.1138 0.2346 0.5426 0.0977\n",
      "valid accuracy: 0.1114 0.1104 0.1078 0.114 0.235 0.5461 0.1045\n",
      "valid accuracy: 0.119 0.1135 0.1143 0.122 0.2371 0.5384 0.1056\n",
      "valid accuracy: 0.1112 0.1142 0.1151 0.1157 0.2388 0.5458 0.107\n",
      "valid accuracy: 0.1203 0.1186 0.1179 0.1186 0.2283 0.545 0.099\n",
      "valid accuracy: 0.1061 0.1138 0.1084 0.1219 0.2348 0.5455 0.1028\n",
      "valid accuracy: 0.1127 0.1122 0.1085 0.1218 0.2359 0.5474 0.1035\n",
      "valid accuracy: 0.1128 0.1078 0.1109 0.1227 0.2355 0.5389 0.1011\n",
      "valid accuracy: 0.1133 0.1169 0.1131 0.1229 0.235 0.5514 0.1032\n",
      "valid accuracy: 0.1127 0.1124 0.1114 0.126 0.2289 0.5538 0.0974\n",
      "valid accuracy: 0.1118 0.1131 0.1118 0.1196 0.2294 0.5573 0.0981\n",
      "valid accuracy: 0.1125 0.1103 0.1123 0.1227 0.2416 0.5486 0.1052\n",
      "valid accuracy: 0.1131 0.1168 0.1119 0.1208 0.2365 0.5429 0.1045\n",
      "valid accuracy: 0.1099 0.1152 0.1109 0.1212 0.2347 0.5467 0.1033\n",
      "valid accuracy: 0.1141 0.1095 0.1119 0.1201 0.2327 0.5438 0.1056\n",
      "valid accuracy: 0.1169 0.1116 0.1091 0.121 0.2392 0.5498 0.0997\n",
      "valid accuracy: 0.1125 0.1124 0.1068 0.1163 0.2342 0.5435 0.107\n",
      "valid accuracy: 0.1114 0.1174 0.1058 0.1207 0.2368 0.5485 0.0999\n",
      "valid accuracy: 0.1118 0.1123 0.1123 0.1195 0.2338 0.5468 0.1013\n",
      "ep 200, batch 0, training accuracy 0.56\n",
      "ep 200, batch 50, training accuracy 0.62\n",
      "ep 200, batch 100, training accuracy 0.6\n",
      "ep 200, batch 150, training accuracy 0.53\n",
      "ep 200, batch 200, training accuracy 0.51\n",
      "valid accuracy: 0.1151 0.1161 0.1102 0.1183 0.2315 0.5463 0.1005\n",
      "valid accuracy: 0.1153 0.1121 0.1088 0.1205 0.2327 0.545 0.1016\n",
      "valid accuracy: 0.1122 0.1183 0.1165 0.1195 0.2315 0.5457 0.1018\n",
      "valid accuracy: 0.1154 0.1142 0.1121 0.1166 0.2373 0.5383 0.1009\n",
      "valid accuracy: 0.1144 0.1172 0.1101 0.125 0.2399 0.5402 0.1007\n",
      "valid accuracy: 0.1066 0.1175 0.1105 0.1231 0.2475 0.5452 0.0992\n",
      "valid accuracy: 0.1123 0.1146 0.1094 0.1248 0.2401 0.55 0.1037\n",
      "valid accuracy: 0.1131 0.1151 0.1134 0.1183 0.2379 0.5513 0.1041\n",
      "valid accuracy: 0.1083 0.1102 0.1132 0.1176 0.2395 0.555 0.1072\n",
      "valid accuracy: 0.1128 0.1145 0.1101 0.1184 0.2309 0.5496 0.1028\n",
      "valid accuracy: 0.1136 0.1126 0.1164 0.1184 0.2338 0.5495 0.0953\n",
      "valid accuracy: 0.1141 0.1095 0.111 0.1267 0.236 0.5504 0.1061\n",
      "valid accuracy: 0.1135 0.1115 0.1119 0.1257 0.2386 0.5519 0.1023\n",
      "valid accuracy: 0.107 0.112 0.1104 0.1297 0.2329 0.5505 0.0983\n",
      "valid accuracy: 0.1163 0.1093 0.1055 0.1174 0.234 0.5493 0.0988\n",
      "valid accuracy: 0.1161 0.1122 0.1081 0.1262 0.2362 0.5467 0.1066\n",
      "valid accuracy: 0.1121 0.1127 0.1133 0.1299 0.2348 0.5544 0.1035\n",
      "valid accuracy: 0.1132 0.1111 0.1106 0.1224 0.2276 0.5443 0.1032\n",
      "valid accuracy: 0.1146 0.1149 0.1081 0.1218 0.2319 0.5496 0.1007\n",
      "valid accuracy: 0.1086 0.1092 0.1082 0.1218 0.2289 0.547 0.0987\n",
      "valid accuracy: 0.113 0.1065 0.1094 0.1198 0.239 0.5402 0.0991\n",
      "valid accuracy: 0.1122 0.1125 0.1112 0.1215 0.2402 0.5533 0.1009\n",
      "valid accuracy: 0.1104 0.1126 0.1109 0.1206 0.2323 0.5516 0.1023\n",
      "valid accuracy: 0.1186 0.1137 0.1107 0.1265 0.2289 0.5534 0.1008\n",
      "valid accuracy: 0.1086 0.1119 0.1082 0.1216 0.2402 0.542 0.1032\n",
      "valid accuracy: 0.1078 0.1077 0.1093 0.1197 0.2319 0.5545 0.101\n",
      "valid accuracy: 0.1099 0.1083 0.1145 0.1211 0.2362 0.5487 0.104\n",
      "valid accuracy: 0.1149 0.1137 0.1104 0.1211 0.233 0.5419 0.0997\n",
      "valid accuracy: 0.1128 0.1123 0.1044 0.1186 0.2381 0.5509 0.1016\n",
      "valid accuracy: 0.1121 0.1094 0.113 0.1178 0.2313 0.5472 0.103\n",
      "valid accuracy: 0.1147 0.1091 0.1145 0.1154 0.2402 0.5479 0.0982\n",
      "valid accuracy: 0.1137 0.1167 0.1143 0.1224 0.2321 0.5438 0.0983\n",
      "valid accuracy: 0.1115 0.1103 0.1126 0.1167 0.2296 0.5459 0.1026\n",
      "valid accuracy: 0.1136 0.1146 0.1071 0.126 0.2339 0.5456 0.1009\n",
      "valid accuracy: 0.1143 0.1138 0.1107 0.1205 0.24 0.547 0.1046\n",
      "valid accuracy: 0.1128 0.1112 0.1167 0.1212 0.2295 0.5418 0.1062\n",
      "valid accuracy: 0.1106 0.1193 0.1114 0.1186 0.2362 0.5382 0.109\n",
      "valid accuracy: 0.1174 0.1097 0.1101 0.1205 0.2359 0.5498 0.1058\n",
      "valid accuracy: 0.1158 0.1084 0.1103 0.1214 0.2303 0.5456 0.1019\n",
      "valid accuracy: 0.1124 0.1117 0.1139 0.1196 0.2378 0.5486 0.1042\n",
      "valid accuracy: 0.1119 0.1099 0.111 0.1179 0.2293 0.544 0.1025\n",
      "valid accuracy: 0.1123 0.1142 0.1104 0.1204 0.2349 0.5471 0.1038\n",
      "valid accuracy: 0.1131 0.1144 0.1141 0.1149 0.2329 0.5444 0.0971\n",
      "valid accuracy: 0.1138 0.1111 0.1152 0.1204 0.2315 0.5458 0.1015\n",
      "valid accuracy: 0.1168 0.1064 0.1131 0.1248 0.2347 0.5471 0.0998\n",
      "valid accuracy: 0.1113 0.1153 0.1081 0.1169 0.2325 0.5406 0.1067\n",
      "valid accuracy: 0.1149 0.1119 0.107 0.1194 0.2361 0.5539 0.1019\n",
      "valid accuracy: 0.1074 0.1123 0.1094 0.1195 0.2393 0.5466 0.1051\n",
      "valid accuracy: 0.1114 0.1099 0.1137 0.1184 0.229 0.551 0.1068\n",
      "valid accuracy: 0.1131 0.1114 0.1107 0.1243 0.2389 0.5411 0.1081\n",
      "ep 250, batch 0, training accuracy 0.605\n",
      "ep 250, batch 50, training accuracy 0.575\n",
      "ep 250, batch 100, training accuracy 0.54\n",
      "ep 250, batch 150, training accuracy 0.595\n",
      "ep 250, batch 200, training accuracy 0.555\n",
      "valid accuracy: 0.1147 0.1147 0.1092 0.1183 0.2396 0.5478 0.1001\n",
      "valid accuracy: 0.1145 0.1078 0.1101 0.1225 0.2377 0.5407 0.1032\n",
      "valid accuracy: 0.1124 0.114 0.1082 0.1217 0.2322 0.5354 0.1031\n",
      "valid accuracy: 0.1099 0.1119 0.1125 0.1211 0.2352 0.5465 0.1063\n",
      "valid accuracy: 0.1099 0.1146 0.109 0.1196 0.2351 0.5421 0.1019\n",
      "valid accuracy: 0.1162 0.1162 0.1075 0.1241 0.2291 0.5388 0.1035\n",
      "valid accuracy: 0.1125 0.1183 0.1103 0.1214 0.2328 0.5506 0.1074\n",
      "valid accuracy: 0.1128 0.1117 0.1089 0.1235 0.2351 0.5444 0.1055\n",
      "valid accuracy: 0.1114 0.1127 0.1109 0.1177 0.2403 0.5411 0.1047\n",
      "valid accuracy: 0.1138 0.1074 0.1079 0.1197 0.2364 0.5454 0.1027\n",
      "valid accuracy: 0.1116 0.1137 0.107 0.1208 0.2299 0.5557 0.1051\n",
      "valid accuracy: 0.1119 0.1201 0.1125 0.1211 0.231 0.5499 0.1004\n",
      "valid accuracy: 0.114 0.1155 0.1154 0.1133 0.2326 0.5505 0.1018\n",
      "valid accuracy: 0.1086 0.1163 0.1136 0.1225 0.2384 0.5535 0.1065\n",
      "valid accuracy: 0.1117 0.1117 0.1118 0.1205 0.2247 0.5569 0.1014\n",
      "valid accuracy: 0.1143 0.1108 0.1102 0.1224 0.2311 0.5442 0.1064\n",
      "valid accuracy: 0.115 0.118 0.1128 0.1179 0.236 0.55 0.107\n",
      "valid accuracy: 0.1116 0.1117 0.1105 0.125 0.2286 0.5519 0.1031\n",
      "valid accuracy: 0.1141 0.1141 0.1092 0.1214 0.2312 0.5444 0.1003\n",
      "valid accuracy: 0.1143 0.1156 0.1085 0.1226 0.2368 0.5443 0.1021\n",
      "valid accuracy: 0.1087 0.116 0.1039 0.12 0.234 0.5411 0.1021\n",
      "valid accuracy: 0.1157 0.1077 0.1181 0.1214 0.2346 0.5418 0.0997\n",
      "valid accuracy: 0.1086 0.1159 0.1071 0.1225 0.2246 0.5423 0.0994\n",
      "valid accuracy: 0.1103 0.1088 0.1122 0.1239 0.2261 0.5479 0.1055\n",
      "valid accuracy: 0.1146 0.114 0.108 0.1207 0.2347 0.5464 0.1036\n",
      "valid accuracy: 0.1175 0.1106 0.1122 0.126 0.2345 0.5388 0.1059\n",
      "valid accuracy: 0.1134 0.1132 0.1122 0.1228 0.2328 0.5357 0.1032\n",
      "valid accuracy: 0.1117 0.112 0.109 0.1191 0.2312 0.5434 0.1025\n",
      "valid accuracy: 0.1061 0.1125 0.1106 0.1195 0.2356 0.5447 0.1021\n",
      "valid accuracy: 0.114 0.1171 0.1144 0.1198 0.2277 0.5457 0.0993\n",
      "valid accuracy: 0.1107 0.1138 0.1108 0.1175 0.2397 0.5482 0.0986\n",
      "valid accuracy: 0.1058 0.11 0.1145 0.1206 0.2354 0.5432 0.0978\n",
      "valid accuracy: 0.1179 0.1156 0.118 0.1187 0.2313 0.5409 0.1022\n",
      "valid accuracy: 0.111 0.1103 0.1113 0.1195 0.2322 0.5517 0.1004\n",
      "valid accuracy: 0.1096 0.1114 0.1165 0.1233 0.2372 0.5496 0.1046\n",
      "valid accuracy: 0.1117 0.1141 0.11 0.1197 0.2379 0.5476 0.1077\n",
      "valid accuracy: 0.1049 0.1122 0.1115 0.1202 0.2297 0.5498 0.1006\n",
      "valid accuracy: 0.1142 0.1119 0.1155 0.1229 0.2361 0.5581 0.1043\n",
      "valid accuracy: 0.1117 0.1149 0.1106 0.119 0.2332 0.5479 0.1033\n",
      "valid accuracy: 0.1052 0.1139 0.1125 0.121 0.2309 0.5423 0.1043\n",
      "valid accuracy: 0.1173 0.1139 0.1119 0.1217 0.2401 0.5517 0.1065\n",
      "valid accuracy: 0.1078 0.111 0.1137 0.1211 0.2357 0.5455 0.107\n",
      "valid accuracy: 0.1183 0.1132 0.1106 0.1226 0.2366 0.5507 0.1012\n",
      "valid accuracy: 0.1106 0.1122 0.112 0.1177 0.2285 0.5514 0.1056\n",
      "valid accuracy: 0.1143 0.1082 0.1131 0.1224 0.2293 0.549 0.1033\n",
      "valid accuracy: 0.1126 0.1109 0.1105 0.1175 0.2385 0.5359 0.1032\n",
      "valid accuracy: 0.1121 0.1115 0.1113 0.1199 0.2347 0.5506 0.1049\n",
      "valid accuracy: 0.1103 0.112 0.1147 0.1148 0.2321 0.5482 0.0993\n",
      "valid accuracy: 0.1133 0.1143 0.1047 0.1232 0.2354 0.5486 0.1011\n",
      "valid accuracy: 0.1121 0.1079 0.111 0.1171 0.232 0.5528 0.1035\n",
      "ep 300, batch 0, training accuracy 0.535\n",
      "ep 300, batch 50, training accuracy 0.525\n",
      "ep 300, batch 100, training accuracy 0.5\n",
      "ep 300, batch 150, training accuracy 0.59\n",
      "ep 300, batch 200, training accuracy 0.58\n",
      "valid accuracy: 0.1098 0.1095 0.1112 0.1201 0.2359 0.5578 0.1056\n",
      "valid accuracy: 0.1115 0.1075 0.1129 0.1147 0.2394 0.5442 0.0997\n",
      "valid accuracy: 0.1157 0.115 0.1098 0.1199 0.2296 0.5523 0.1037\n",
      "valid accuracy: 0.1092 0.1121 0.1112 0.1187 0.2315 0.5524 0.1016\n",
      "valid accuracy: 0.1141 0.1116 0.1099 0.1267 0.2297 0.5483 0.0992\n",
      "valid accuracy: 0.1153 0.1134 0.112 0.1212 0.237 0.5495 0.1012\n",
      "valid accuracy: 0.1042 0.1103 0.1008 0.1212 0.2338 0.5493 0.1068\n",
      "valid accuracy: 0.1124 0.1161 0.1086 0.1186 0.236 0.5516 0.1008\n",
      "valid accuracy: 0.1091 0.1123 0.1136 0.1199 0.2363 0.5515 0.1021\n",
      "valid accuracy: 0.1142 0.1134 0.1145 0.1245 0.2286 0.5407 0.0965\n",
      "valid accuracy: 0.1117 0.1124 0.1128 0.1202 0.23 0.5468 0.1014\n",
      "valid accuracy: 0.112 0.1125 0.111 0.1193 0.2362 0.5499 0.1076\n",
      "valid accuracy: 0.1147 0.1159 0.1135 0.1243 0.2341 0.5469 0.0991\n",
      "valid accuracy: 0.1128 0.1068 0.1118 0.12 0.2399 0.5457 0.1006\n",
      "valid accuracy: 0.1127 0.1188 0.1182 0.1266 0.2355 0.5452 0.1025\n",
      "valid accuracy: 0.1189 0.1114 0.1105 0.1183 0.2299 0.5551 0.1052\n",
      "valid accuracy: 0.1036 0.1152 0.1116 0.1223 0.2343 0.5495 0.1063\n",
      "valid accuracy: 0.1124 0.1089 0.108 0.1203 0.2264 0.5447 0.101\n",
      "valid accuracy: 0.1134 0.1048 0.113 0.1178 0.2296 0.5527 0.1008\n",
      "valid accuracy: 0.1087 0.1165 0.1121 0.12 0.227 0.5436 0.104\n",
      "valid accuracy: 0.1073 0.1121 0.1131 0.1159 0.2391 0.5497 0.1002\n",
      "valid accuracy: 0.11 0.1123 0.1064 0.1238 0.2318 0.5549 0.1087\n",
      "valid accuracy: 0.1033 0.1171 0.1099 0.1257 0.2323 0.5497 0.1026\n",
      "valid accuracy: 0.1125 0.1055 0.1089 0.1186 0.2368 0.5418 0.1008\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.115\n",
      "ep 0, batch 50, training accuracy 0.235\n",
      "ep 0, batch 100, training accuracy 0.19\n",
      "ep 0, batch 150, training accuracy 0.32\n",
      "ep 0, batch 200, training accuracy 0.41\n",
      "valid accuracy: 0.0994 0.1065 0.1151 0.1224 0.1909 0.4553 0.3596\n",
      "valid accuracy: 0.0959 0.1071 0.1104 0.1214 0.1739 0.4279 0.4149\n",
      "valid accuracy: 0.08 0.1123 0.1091 0.1203 0.1873 0.4177 0.4305\n",
      "valid accuracy: 0.0787 0.1165 0.1085 0.1121 0.1879 0.3994 0.451\n",
      "valid accuracy: 0.073 0.1246 0.109 0.1217 0.1945 0.4027 0.4694\n",
      "valid accuracy: 0.0782 0.1109 0.1111 0.1139 0.1723 0.3816 0.4893\n",
      "valid accuracy: 0.0759 0.1181 0.0983 0.1114 0.1697 0.3749 0.4986\n",
      "valid accuracy: 0.0796 0.1139 0.1083 0.0971 0.1698 0.3657 0.4966\n",
      "valid accuracy: 0.0743 0.1215 0.1135 0.109 0.1814 0.3692 0.4981\n",
      "valid accuracy: 0.0782 0.1127 0.1017 0.1107 0.1765 0.3535 0.4994\n",
      "valid accuracy: 0.0745 0.1112 0.0984 0.1028 0.1573 0.3277 0.4931\n",
      "valid accuracy: 0.0779 0.1119 0.1042 0.1096 0.1686 0.3263 0.5057\n",
      "valid accuracy: 0.0828 0.1176 0.1055 0.1046 0.1729 0.3406 0.507\n",
      "valid accuracy: 0.0756 0.1119 0.0953 0.1143 0.1747 0.329 0.5091\n",
      "valid accuracy: 0.0773 0.1139 0.1044 0.1138 0.1823 0.3113 0.5047\n",
      "valid accuracy: 0.0785 0.115 0.1024 0.116 0.1642 0.3136 0.5116\n",
      "valid accuracy: 0.0797 0.1178 0.0965 0.1123 0.1621 0.3054 0.5087\n",
      "valid accuracy: 0.0769 0.1162 0.0964 0.1078 0.1581 0.2942 0.5154\n",
      "valid accuracy: 0.086 0.1178 0.1042 0.1146 0.1662 0.3021 0.519\n",
      "valid accuracy: 0.0879 0.1166 0.0981 0.1085 0.1633 0.2898 0.5169\n",
      "valid accuracy: 0.093 0.1092 0.1004 0.1161 0.1557 0.2742 0.5161\n",
      "valid accuracy: 0.0937 0.1247 0.1105 0.1197 0.1649 0.2795 0.5253\n",
      "valid accuracy: 0.0959 0.1162 0.0975 0.1163 0.1641 0.2827 0.5239\n",
      "valid accuracy: 0.088 0.1196 0.1006 0.1127 0.1627 0.2914 0.5216\n",
      "valid accuracy: 0.0959 0.1224 0.0987 0.1186 0.1766 0.2863 0.5268\n",
      "valid accuracy: 0.0879 0.1153 0.1039 0.1167 0.1638 0.2594 0.5235\n",
      "valid accuracy: 0.0895 0.1203 0.1025 0.1128 0.162 0.2733 0.5234\n",
      "valid accuracy: 0.0905 0.1188 0.1018 0.116 0.1559 0.2601 0.5266\n",
      "valid accuracy: 0.0888 0.1128 0.0947 0.1143 0.1459 0.2646 0.5256\n",
      "valid accuracy: 0.0869 0.1207 0.1062 0.1127 0.1579 0.2668 0.5185\n",
      "valid accuracy: 0.0809 0.1189 0.1006 0.1149 0.1471 0.2545 0.5379\n",
      "valid accuracy: 0.097 0.1201 0.1021 0.1216 0.1525 0.2657 0.5299\n",
      "valid accuracy: 0.088 0.1146 0.1015 0.1169 0.1458 0.2666 0.5386\n",
      "valid accuracy: 0.0865 0.1175 0.0992 0.1127 0.1457 0.2601 0.5215\n",
      "valid accuracy: 0.0887 0.1249 0.0993 0.1215 0.1445 0.2537 0.5355\n",
      "valid accuracy: 0.0934 0.1175 0.0999 0.1056 0.1362 0.2508 0.5388\n",
      "valid accuracy: 0.0926 0.113 0.0938 0.119 0.1408 0.2283 0.5434\n",
      "valid accuracy: 0.0903 0.1115 0.1028 0.1171 0.1479 0.2384 0.5432\n",
      "valid accuracy: 0.0901 0.1132 0.1007 0.1167 0.1409 0.2399 0.5317\n",
      "valid accuracy: 0.0915 0.1185 0.096 0.1146 0.1493 0.2532 0.5324\n",
      "valid accuracy: 0.0909 0.1134 0.0953 0.1146 0.1406 0.2324 0.5386\n",
      "valid accuracy: 0.0886 0.1225 0.1009 0.1106 0.1364 0.2257 0.5338\n",
      "valid accuracy: 0.0857 0.1103 0.1048 0.115 0.1466 0.2466 0.5383\n",
      "valid accuracy: 0.0872 0.1228 0.1047 0.1198 0.1434 0.2335 0.5356\n",
      "valid accuracy: 0.092 0.1137 0.0976 0.1184 0.1401 0.2275 0.5319\n",
      "valid accuracy: 0.0897 0.1128 0.0979 0.1131 0.1433 0.2204 0.539\n",
      "valid accuracy: 0.0889 0.1128 0.0986 0.1107 0.1403 0.2202 0.5395\n",
      "valid accuracy: 0.0929 0.1131 0.0953 0.1152 0.1386 0.2186 0.539\n",
      "valid accuracy: 0.0956 0.1123 0.0967 0.114 0.1393 0.2319 0.5434\n",
      "valid accuracy: 0.0855 0.104 0.0994 0.1088 0.1364 0.2254 0.5413\n",
      "ep 50, batch 0, training accuracy 0.515\n",
      "ep 50, batch 50, training accuracy 0.55\n",
      "ep 50, batch 100, training accuracy 0.54\n",
      "ep 50, batch 150, training accuracy 0.545\n",
      "ep 50, batch 200, training accuracy 0.57\n",
      "valid accuracy: 0.0972 0.1092 0.0928 0.1141 0.1353 0.206 0.5459\n",
      "valid accuracy: 0.0885 0.1025 0.1007 0.1193 0.1408 0.2055 0.541\n",
      "valid accuracy: 0.0938 0.115 0.1037 0.1203 0.1452 0.2275 0.5438\n",
      "valid accuracy: 0.0954 0.1117 0.1028 0.1165 0.1317 0.1903 0.541\n",
      "valid accuracy: 0.095 0.108 0.1001 0.1145 0.147 0.2131 0.533\n",
      "valid accuracy: 0.0971 0.1132 0.0985 0.114 0.1405 0.211 0.5471\n",
      "valid accuracy: 0.0943 0.1056 0.1018 0.1188 0.1385 0.2104 0.5428\n",
      "valid accuracy: 0.0933 0.108 0.0991 0.1184 0.1328 0.2018 0.5426\n",
      "valid accuracy: 0.0927 0.1123 0.1008 0.1207 0.1419 0.2002 0.547\n",
      "valid accuracy: 0.0959 0.1129 0.1025 0.1129 0.1469 0.2039 0.5511\n",
      "valid accuracy: 0.0941 0.1125 0.1036 0.1144 0.141 0.1998 0.5503\n",
      "valid accuracy: 0.0929 0.1096 0.1047 0.1162 0.1428 0.2024 0.5379\n",
      "valid accuracy: 0.0923 0.1067 0.1043 0.1171 0.1378 0.2115 0.5456\n",
      "valid accuracy: 0.0906 0.1079 0.098 0.1103 0.1315 0.2176 0.5528\n",
      "valid accuracy: 0.0942 0.1064 0.1015 0.1143 0.1373 0.2128 0.5565\n",
      "valid accuracy: 0.094 0.1074 0.1061 0.1142 0.1407 0.2103 0.5544\n",
      "valid accuracy: 0.0846 0.1138 0.1025 0.1171 0.1377 0.2026 0.5426\n",
      "valid accuracy: 0.0937 0.111 0.101 0.1174 0.1395 0.204 0.546\n",
      "valid accuracy: 0.0999 0.1145 0.1027 0.11 0.1346 0.216 0.545\n",
      "valid accuracy: 0.0955 0.113 0.0971 0.1169 0.1402 0.2128 0.5535\n",
      "valid accuracy: 0.0902 0.1158 0.1002 0.1122 0.1399 0.2068 0.5478\n",
      "valid accuracy: 0.0962 0.1099 0.1009 0.1078 0.1403 0.2086 0.5398\n",
      "valid accuracy: 0.0963 0.1154 0.1008 0.1096 0.136 0.2119 0.5515\n",
      "valid accuracy: 0.095 0.1135 0.0991 0.1091 0.1424 0.2101 0.5438\n",
      "valid accuracy: 0.0914 0.1156 0.1049 0.12 0.1364 0.2106 0.545\n",
      "valid accuracy: 0.0976 0.1099 0.0968 0.1122 0.1354 0.2125 0.5511\n",
      "valid accuracy: 0.0961 0.1157 0.1057 0.1129 0.1363 0.2094 0.544\n",
      "valid accuracy: 0.0911 0.11 0.101 0.108 0.138 0.209 0.5554\n",
      "valid accuracy: 0.0931 0.1099 0.1005 0.1139 0.144 0.2107 0.547\n",
      "valid accuracy: 0.1012 0.1064 0.1076 0.11 0.1406 0.2135 0.5517\n",
      "valid accuracy: 0.0946 0.1138 0.0986 0.1137 0.137 0.2163 0.5434\n",
      "valid accuracy: 0.0978 0.108 0.1022 0.1138 0.1424 0.213 0.5394\n",
      "valid accuracy: 0.0913 0.1098 0.0986 0.119 0.1395 0.2086 0.5473\n",
      "valid accuracy: 0.0961 0.1078 0.1008 0.1148 0.1436 0.2118 0.554\n",
      "valid accuracy: 0.0986 0.1118 0.1011 0.1153 0.1294 0.2139 0.5487\n",
      "valid accuracy: 0.087 0.1052 0.0963 0.1125 0.1351 0.2077 0.5551\n",
      "valid accuracy: 0.0951 0.1129 0.0995 0.1151 0.1408 0.2061 0.5433\n",
      "valid accuracy: 0.0972 0.1055 0.1014 0.1136 0.1424 0.2105 0.5517\n",
      "valid accuracy: 0.0948 0.1103 0.1009 0.1141 0.1422 0.2098 0.5522\n",
      "valid accuracy: 0.0979 0.1093 0.1055 0.1141 0.1341 0.2136 0.5427\n",
      "valid accuracy: 0.0941 0.1102 0.1053 0.1138 0.1401 0.2061 0.5509\n",
      "valid accuracy: 0.0924 0.1061 0.1027 0.1114 0.1403 0.2154 0.5526\n",
      "valid accuracy: 0.0955 0.1068 0.0989 0.12 0.1371 0.2052 0.5501\n",
      "valid accuracy: 0.0921 0.1075 0.0978 0.1154 0.1365 0.2061 0.5512\n",
      "valid accuracy: 0.1004 0.1106 0.1014 0.1143 0.1417 0.2098 0.5415\n",
      "valid accuracy: 0.0954 0.1115 0.1057 0.1134 0.1401 0.2096 0.5442\n",
      "valid accuracy: 0.0937 0.117 0.102 0.1129 0.1362 0.2136 0.5567\n",
      "valid accuracy: 0.0915 0.1155 0.102 0.1102 0.141 0.2123 0.5475\n",
      "valid accuracy: 0.0988 0.1116 0.1013 0.1188 0.1355 0.2112 0.5458\n",
      "valid accuracy: 0.0948 0.11 0.1041 0.1154 0.1431 0.2099 0.547\n",
      "ep 100, batch 0, training accuracy 0.58\n",
      "ep 100, batch 50, training accuracy 0.555\n",
      "ep 100, batch 100, training accuracy 0.51\n",
      "ep 100, batch 150, training accuracy 0.52\n",
      "ep 100, batch 200, training accuracy 0.575\n",
      "valid accuracy: 0.0906 0.108 0.0971 0.1146 0.1329 0.2056 0.5476\n",
      "valid accuracy: 0.0929 0.1136 0.103 0.1115 0.1375 0.2111 0.5557\n",
      "valid accuracy: 0.094 0.11 0.1018 0.1197 0.1411 0.2127 0.5397\n",
      "valid accuracy: 0.0913 0.1135 0.1074 0.1143 0.14 0.2061 0.5472\n",
      "valid accuracy: 0.0984 0.111 0.1012 0.1177 0.1373 0.2067 0.5494\n",
      "valid accuracy: 0.0972 0.1147 0.1 0.1136 0.1371 0.2091 0.548\n",
      "valid accuracy: 0.0959 0.1094 0.1009 0.1173 0.1405 0.2047 0.5485\n",
      "valid accuracy: 0.0964 0.1116 0.1047 0.1077 0.1387 0.2088 0.553\n",
      "valid accuracy: 0.0953 0.11 0.1008 0.1147 0.1419 0.2091 0.5448\n",
      "valid accuracy: 0.0971 0.1098 0.1021 0.1081 0.1385 0.2079 0.5502\n",
      "valid accuracy: 0.0961 0.1152 0.1033 0.1151 0.1389 0.2105 0.5493\n",
      "valid accuracy: 0.0955 0.1133 0.0985 0.1141 0.1397 0.2066 0.5456\n",
      "valid accuracy: 0.094 0.1077 0.1019 0.1155 0.1441 0.2159 0.5427\n",
      "valid accuracy: 0.0978 0.1091 0.101 0.113 0.1387 0.2117 0.5463\n",
      "valid accuracy: 0.0914 0.1067 0.1047 0.1144 0.138 0.2112 0.543\n",
      "valid accuracy: 0.094 0.1105 0.0995 0.1126 0.1413 0.2141 0.5492\n",
      "valid accuracy: 0.0984 0.1127 0.0987 0.1168 0.1407 0.2024 0.5547\n",
      "valid accuracy: 0.092 0.1099 0.0992 0.1161 0.1399 0.2098 0.5541\n",
      "valid accuracy: 0.0931 0.1121 0.1063 0.1114 0.14 0.2075 0.5539\n",
      "valid accuracy: 0.1016 0.1151 0.101 0.1086 0.1388 0.204 0.5515\n",
      "valid accuracy: 0.0941 0.107 0.1059 0.1054 0.1467 0.2117 0.5479\n",
      "valid accuracy: 0.0921 0.1087 0.106 0.1195 0.1412 0.2076 0.5482\n",
      "valid accuracy: 0.0945 0.1089 0.1038 0.1105 0.1402 0.2053 0.5448\n",
      "valid accuracy: 0.0963 0.1159 0.0984 0.1151 0.1403 0.2112 0.5405\n",
      "valid accuracy: 0.092 0.1123 0.1012 0.1152 0.1416 0.2082 0.543\n",
      "valid accuracy: 0.0968 0.1102 0.1007 0.1081 0.1414 0.207 0.5519\n",
      "valid accuracy: 0.0913 0.1087 0.099 0.1176 0.141 0.217 0.5449\n",
      "valid accuracy: 0.0918 0.1114 0.0964 0.112 0.1385 0.207 0.5534\n",
      "valid accuracy: 0.1005 0.1148 0.1065 0.1132 0.1345 0.2154 0.5566\n",
      "valid accuracy: 0.0919 0.1178 0.1035 0.1139 0.1383 0.2157 0.5468\n",
      "valid accuracy: 0.0924 0.112 0.1017 0.1135 0.1367 0.2091 0.5467\n",
      "valid accuracy: 0.0951 0.1107 0.1029 0.1187 0.135 0.2098 0.5447\n",
      "valid accuracy: 0.093 0.11 0.105 0.1138 0.1426 0.2046 0.5504\n",
      "valid accuracy: 0.0917 0.1144 0.1043 0.115 0.1402 0.2142 0.5456\n",
      "valid accuracy: 0.0925 0.1089 0.1015 0.1159 0.1402 0.2059 0.5451\n",
      "valid accuracy: 0.094 0.1085 0.1038 0.108 0.1401 0.2065 0.5501\n",
      "valid accuracy: 0.0887 0.1068 0.0948 0.1126 0.1396 0.2112 0.5482\n",
      "valid accuracy: 0.0959 0.1043 0.1 0.1169 0.1364 0.2095 0.5439\n",
      "valid accuracy: 0.0903 0.1122 0.1033 0.1163 0.1404 0.2122 0.5485\n",
      "valid accuracy: 0.0946 0.1154 0.1009 0.1144 0.1384 0.2128 0.5404\n",
      "valid accuracy: 0.096 0.1104 0.1046 0.1172 0.1325 0.215 0.5458\n",
      "valid accuracy: 0.0898 0.1153 0.1053 0.1201 0.1331 0.2133 0.5537\n",
      "valid accuracy: 0.0911 0.1119 0.1003 0.1127 0.1436 0.2029 0.546\n",
      "valid accuracy: 0.0977 0.1071 0.1016 0.1129 0.1365 0.2084 0.5405\n",
      "valid accuracy: 0.0913 0.1106 0.1009 0.1154 0.1394 0.2168 0.5516\n",
      "valid accuracy: 0.0937 0.1097 0.104 0.1184 0.133 0.2111 0.5487\n",
      "valid accuracy: 0.0977 0.1125 0.1031 0.1072 0.1358 0.2109 0.5486\n",
      "valid accuracy: 0.0932 0.1071 0.0988 0.1206 0.144 0.2107 0.5428\n",
      "valid accuracy: 0.0988 0.1075 0.0999 0.1107 0.1393 0.2096 0.541\n",
      "valid accuracy: 0.0904 0.108 0.1051 0.1142 0.1347 0.2134 0.5532\n",
      "ep 150, batch 0, training accuracy 0.59\n",
      "ep 150, batch 50, training accuracy 0.52\n",
      "ep 150, batch 100, training accuracy 0.53\n",
      "ep 150, batch 150, training accuracy 0.575\n",
      "ep 150, batch 200, training accuracy 0.51\n",
      "valid accuracy: 0.0897 0.1096 0.1044 0.1135 0.1394 0.2037 0.5475\n",
      "valid accuracy: 0.0958 0.1133 0.1026 0.1165 0.1372 0.2034 0.552\n",
      "valid accuracy: 0.0943 0.1081 0.1011 0.115 0.1403 0.214 0.5489\n",
      "valid accuracy: 0.0943 0.12 0.0996 0.1161 0.1453 0.2086 0.5467\n",
      "valid accuracy: 0.0932 0.1146 0.0944 0.1152 0.1427 0.21 0.5469\n",
      "valid accuracy: 0.098 0.118 0.104 0.1123 0.1492 0.2064 0.5493\n",
      "valid accuracy: 0.0948 0.11 0.1035 0.1166 0.1353 0.2123 0.5426\n",
      "valid accuracy: 0.0921 0.1166 0.1015 0.1087 0.1424 0.2039 0.5473\n",
      "valid accuracy: 0.097 0.1113 0.1058 0.1126 0.1396 0.2117 0.5442\n",
      "valid accuracy: 0.0936 0.1131 0.1028 0.1157 0.1383 0.2108 0.5496\n",
      "valid accuracy: 0.0911 0.108 0.101 0.1149 0.1353 0.2069 0.5479\n",
      "valid accuracy: 0.0944 0.1083 0.1022 0.1118 0.1413 0.209 0.5567\n",
      "valid accuracy: 0.0924 0.1122 0.1068 0.115 0.1383 0.2086 0.5438\n",
      "valid accuracy: 0.0933 0.1113 0.0985 0.1132 0.1349 0.206 0.5444\n",
      "valid accuracy: 0.0937 0.115 0.0994 0.1168 0.141 0.2168 0.5445\n",
      "valid accuracy: 0.0895 0.112 0.0952 0.116 0.1397 0.214 0.5455\n",
      "valid accuracy: 0.0918 0.1094 0.0944 0.1083 0.1409 0.2087 0.5563\n",
      "valid accuracy: 0.0957 0.1102 0.1028 0.113 0.1422 0.2095 0.5489\n",
      "valid accuracy: 0.0949 0.1106 0.1011 0.1142 0.1413 0.2128 0.5446\n",
      "valid accuracy: 0.0948 0.1104 0.101 0.1206 0.1351 0.2093 0.5429\n",
      "valid accuracy: 0.0924 0.104 0.1011 0.1157 0.1399 0.2129 0.5494\n",
      "valid accuracy: 0.0949 0.1116 0.1046 0.1191 0.1395 0.2099 0.5397\n",
      "valid accuracy: 0.0956 0.1116 0.1041 0.1122 0.134 0.2069 0.5574\n",
      "valid accuracy: 0.0967 0.109 0.1016 0.1123 0.1401 0.2126 0.5427\n",
      "valid accuracy: 0.0966 0.1139 0.1 0.1123 0.137 0.207 0.5466\n",
      "valid accuracy: 0.0929 0.1148 0.1076 0.1219 0.1339 0.2048 0.5422\n",
      "valid accuracy: 0.0898 0.108 0.099 0.1144 0.144 0.2038 0.5497\n",
      "valid accuracy: 0.09 0.1124 0.1029 0.1134 0.1445 0.2114 0.5488\n",
      "valid accuracy: 0.0914 0.1134 0.0992 0.1146 0.1355 0.2068 0.5538\n",
      "valid accuracy: 0.0943 0.1126 0.1054 0.1088 0.139 0.2067 0.5391\n",
      "valid accuracy: 0.0931 0.1173 0.0999 0.1158 0.1412 0.2096 0.5384\n",
      "valid accuracy: 0.093 0.1131 0.1057 0.1103 0.1401 0.2128 0.5517\n",
      "valid accuracy: 0.0923 0.1101 0.1005 0.1131 0.1341 0.2107 0.5438\n",
      "valid accuracy: 0.0973 0.1079 0.1002 0.1136 0.1347 0.2103 0.5428\n",
      "valid accuracy: 0.0913 0.1114 0.1016 0.1146 0.1409 0.2149 0.5469\n",
      "valid accuracy: 0.0921 0.1065 0.1008 0.1163 0.1406 0.2115 0.5527\n",
      "valid accuracy: 0.0994 0.1095 0.1035 0.1181 0.1398 0.2138 0.5527\n",
      "valid accuracy: 0.0932 0.1138 0.0985 0.1084 0.1362 0.2056 0.5469\n",
      "valid accuracy: 0.1015 0.1104 0.103 0.1131 0.136 0.2162 0.5518\n",
      "valid accuracy: 0.0953 0.1073 0.1049 0.1129 0.1438 0.2057 0.5454\n",
      "valid accuracy: 0.0965 0.1105 0.1072 0.1139 0.133 0.208 0.5467\n",
      "valid accuracy: 0.0947 0.1112 0.1064 0.1108 0.1405 0.2126 0.5433\n",
      "valid accuracy: 0.0984 0.1053 0.1036 0.1116 0.1396 0.2077 0.5452\n",
      "valid accuracy: 0.0925 0.1086 0.0998 0.1135 0.1342 0.2178 0.5377\n",
      "valid accuracy: 0.0891 0.1068 0.1018 0.1216 0.1412 0.2157 0.5507\n",
      "valid accuracy: 0.0905 0.111 0.1054 0.1173 0.1383 0.2164 0.5469\n",
      "valid accuracy: 0.0927 0.1141 0.1012 0.1123 0.1393 0.2108 0.5469\n",
      "valid accuracy: 0.0958 0.1104 0.1031 0.1115 0.1437 0.2062 0.541\n",
      "valid accuracy: 0.0951 0.1128 0.1061 0.1096 0.1418 0.2071 0.5391\n",
      "valid accuracy: 0.0956 0.1139 0.1024 0.1157 0.1328 0.2097 0.555\n",
      "ep 200, batch 0, training accuracy 0.55\n",
      "ep 200, batch 50, training accuracy 0.55\n",
      "ep 200, batch 100, training accuracy 0.545\n",
      "ep 200, batch 150, training accuracy 0.54\n",
      "ep 200, batch 200, training accuracy 0.585\n",
      "valid accuracy: 0.0959 0.1084 0.1009 0.1067 0.14 0.2028 0.5496\n",
      "valid accuracy: 0.0898 0.1123 0.1022 0.1099 0.1433 0.2084 0.5462\n",
      "valid accuracy: 0.0937 0.1092 0.1046 0.1167 0.1414 0.2091 0.5424\n",
      "valid accuracy: 0.0922 0.1089 0.1047 0.1104 0.1334 0.2116 0.5471\n",
      "valid accuracy: 0.0943 0.1091 0.1006 0.112 0.1388 0.2114 0.5412\n",
      "valid accuracy: 0.0962 0.1104 0.0999 0.1131 0.1371 0.208 0.5492\n",
      "valid accuracy: 0.0933 0.1156 0.1045 0.1135 0.1347 0.2116 0.5457\n",
      "valid accuracy: 0.0951 0.1081 0.1031 0.1123 0.142 0.2166 0.5474\n",
      "valid accuracy: 0.0947 0.1108 0.0994 0.1158 0.1428 0.2125 0.5452\n",
      "valid accuracy: 0.0955 0.1063 0.0988 0.1152 0.1416 0.2149 0.5511\n",
      "valid accuracy: 0.0936 0.1109 0.1055 0.1155 0.1375 0.2086 0.5501\n",
      "valid accuracy: 0.0928 0.1142 0.1058 0.112 0.141 0.2033 0.5482\n",
      "valid accuracy: 0.0944 0.1105 0.1043 0.1079 0.1363 0.2086 0.5507\n",
      "valid accuracy: 0.0959 0.1153 0.104 0.1169 0.1356 0.2148 0.5458\n",
      "valid accuracy: 0.0915 0.1124 0.102 0.1146 0.1407 0.2103 0.5463\n",
      "valid accuracy: 0.0929 0.1118 0.1053 0.1134 0.1389 0.2086 0.5486\n",
      "valid accuracy: 0.0952 0.1107 0.1006 0.1087 0.1374 0.2083 0.5471\n",
      "valid accuracy: 0.0935 0.1107 0.1028 0.1149 0.1401 0.2132 0.5488\n",
      "valid accuracy: 0.0934 0.1089 0.104 0.1123 0.1465 0.2077 0.543\n",
      "valid accuracy: 0.0944 0.1146 0.1043 0.1095 0.1405 0.2149 0.553\n",
      "valid accuracy: 0.0957 0.1128 0.1056 0.1137 0.1377 0.2161 0.5478\n",
      "valid accuracy: 0.0915 0.1101 0.0999 0.1124 0.136 0.2071 0.542\n",
      "valid accuracy: 0.094 0.1131 0.0965 0.1161 0.1368 0.2097 0.5356\n",
      "valid accuracy: 0.0931 0.1143 0.1014 0.1097 0.1334 0.2098 0.5525\n",
      "=== cannot decay more. stop learning this batch ===\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 500\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "taccs_bcnn_gal = list()\n",
    "#taccs_mean = list()\n",
    "vaccs_bcnn_gal = list()\n",
    "epochs_done = list()\n",
    "\n",
    "for i in range(n_datas):\n",
    "    vaccs_bcnn_gal.append(list())\n",
    "    \n",
    "for d in range(n_datas):\n",
    "    bcnn_gal.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            feed = {bcnn_gal.x: np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 28, 28, 1)), \\\n",
    "                    bcnn_gal.t: t_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                    bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]}\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bcnn_gal.validate(feed)                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "\n",
    "            bcnn_gal.train(feed)\n",
    "\n",
    "        if ep > 5 and np.mean(taccs_bcnn_gal[-25:]) < taccs_bcnn_gal[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bcnn_gal.get_lr()\n",
    "                bcnn_gal.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bcnn_gal.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    epochs_done.append(ep)\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "        if ep == (n_epochs) - 1: epochs_done.append(ep)\n",
    "                \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs_bcnn_gal[i].append(bcnn_gal.validate({bcnn_gal.x: np.reshape(x_valid[i], (-1, 28, 28, 1)), \\\n",
    "                                                       bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]}))\n",
    "            #vaccs_bcnn_gal[i].append(bcnn_gal.validate({bcnn_gal.x: np.reshape(x_valid[i], (-1, 28, 28, 1)), \\\n",
    "            #                                            bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [1, 1, 1, 1]}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs_bcnn_gal[i][-1])\n",
    "        \n",
    "        taccs_bcnn_gal.append(train_accuracy)\n",
    "        \n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "                                              bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]})\n",
    "#         summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "#                                                bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [1, 1, 1, 1]})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFyCAYAAACgITN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfjYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2194a783d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Gal\\'s Bayesian CNN with 1 sample MC Dropout')\n",
    "plt.plot(taccs_bcnn_gal, 'k')\n",
    "plt.plot(vaccs_bcnn_gal[0], 'b')\n",
    "plt.plot(vaccs_bcnn_gal[1], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[2], 'r')\n",
    "plt.plot(vaccs_bcnn_gal[3], 'c')\n",
    "plt.plot(vaccs_bcnn_gal[4], 'b')\n",
    "plt.plot(vaccs_bcnn_gal[5], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blundell version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-1.0, 5.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = True, train_rho = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "# train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "# test_writer = tf.train.SummaryWriter(savedir + 'test')\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "    \n",
    "for d in range(n_datas):\n",
    "    bnn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "        bnn.reset_klrw()\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            \n",
    "            bnn.decay_klrw()\n",
    "\n",
    "            feed = {bnn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "            fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bnn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "                \n",
    "            bnn.train(feed)\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "                \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(bnn.validate({bnn.x: x_valid[i], bnn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        \n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={bnn.x: x_valid[d], bnn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeff_klrw = 1 / n_batches\n",
    "\n",
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs*coeff_klrw, 'b')\n",
    "plt.plot(ps*coeff_klrw, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Blundell\\'s Bayesian NN')\n",
    "plt.plot(taccs, 'k')\n",
    "plt.plot(vaccs[0], 'tab:blue')\n",
    "plt.plot(vaccs[1], 'tab:orange')\n",
    "plt.plot(vaccs[2], 'tab:green')\n",
    "plt.plot(vaccs[3], 'tab:red')\n",
    "plt.plot(vaccs[4], 'tab:purple')\n",
    "plt.plot(vaccs[5], 'tab:brown')\n",
    "plt.plot(vaccs[6], 'tab:pink')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-5.0, 1.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False, train_rho = True, only_loglike = False)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    bnn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {bnn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "            fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "            bnn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bnn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "\n",
    "\n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(bnn.validate({bnn.x: x_valid[i], bnn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={bnn.x: x_valid[d], bnn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taccs_BNN_OL = taccs\n",
    "vaccs_BNN_OL = vaccs\n",
    "\n",
    "plt.title('Bayesian NN')\n",
    "\n",
    "plt.plot(taccs_BNN_OL, 'k')\n",
    "plt.plot(vaccs_BNN_OL[0], 'b')\n",
    "plt.plot(vaccs_BNN_OL[1], 'g')\n",
    "plt.plot(vaccs_BNN_OL[2], 'r')\n",
    "plt.plot(vaccs_BNN_OL[3], 'c')\n",
    "plt.plot(vaccs_BNN_OL[4], 'b')\n",
    "plt.plot(vaccs_BNN_OL[5], 'g')\n",
    "plt.plot(vaccs_BNN_OL[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_BNN_OL, 0)\n",
    "print_accs(vaccs_BNN_OL, 199)\n",
    "print_accs(vaccs_BNN_OL, 399)\n",
    "print_accs(vaccs_BNN_OL, 599)\n",
    "print_accs(vaccs_BNN_OL, 799)\n",
    "print_accs(vaccs_BNN_OL, 999)\n",
    "print_accs(vaccs_BNN_OL, 1199)\n",
    "print_accs(vaccs_BNN_OL, 1399)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Online version + EWC with rho_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-5.0, 1.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False, train_rho = True, only_loglike = False, ewc = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bnn.p_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    bnn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {bnn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "            fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "            bnn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bnn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "\n",
    "\n",
    "        if ep % 50 == 0: bnn.print_ewcgrads(feed)\n",
    "        \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(bnn.validate({bnn.x: x_valid[i], bnn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={bnn.x: x_valid[d], bnn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_BNN_MG = taccs\n",
    "vaccs_BNN_MG = vaccs\n",
    "\n",
    "plt.title('Bayesian NN with Modified Gradients')\n",
    "plt.plot(taccs_BNN_MG, 'k')\n",
    "plt.plot(vaccs_BNN_MG[0], 'b')\n",
    "plt.plot(vaccs_BNN_MG[1], 'g')\n",
    "plt.plot(vaccs_BNN_MG[2], 'r')\n",
    "plt.plot(vaccs_BNN_MG[3], 'c')\n",
    "plt.plot(vaccs_BNN_MG[4], 'b')\n",
    "plt.plot(vaccs_BNN_MG[5], 'g')\n",
    "plt.plot(vaccs_BNN_MG[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_BNN_MG, 0)\n",
    "print_accs(vaccs_BNN_MG, 199)\n",
    "print_accs(vaccs_BNN_MG, 399)\n",
    "print_accs(vaccs_BNN_MG, 599)\n",
    "print_accs(vaccs_BNN_MG, 799)\n",
    "print_accs(vaccs_BNN_MG, 999)\n",
    "print_accs(vaccs_BNN_MG, 1199)\n",
    "print_accs(vaccs_BNN_MG, 1399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_BNN_MG = taccs\n",
    "vaccs_BNN_MG = vaccs\n",
    "\n",
    "plt.title('Bayesian NN with Modified Gradients')\n",
    "plt.plot(taccs_BNN_MG, 'k')\n",
    "plt.plot(vaccs_BNN_MG[0], 'b')\n",
    "plt.plot(vaccs_BNN_MG[1], 'g')\n",
    "plt.plot(vaccs_BNN_MG[2], 'r')\n",
    "plt.plot(vaccs_BNN_MG[3], 'c')\n",
    "plt.plot(vaccs_BNN_MG[4], 'b')\n",
    "plt.plot(vaccs_BNN_MG[5], 'g')\n",
    "plt.plot(vaccs_BNN_MG[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_BNN_MG, 0)\n",
    "print_accs(vaccs_BNN_MG, 199)\n",
    "print_accs(vaccs_BNN_MG, 399)\n",
    "print_accs(vaccs_BNN_MG, 599)\n",
    "print_accs(vaccs_BNN_MG, 799)\n",
    "print_accs(vaccs_BNN_MG, 999)\n",
    "print_accs(vaccs_BNN_MG, 1199)\n",
    "print_accs(vaccs_BNN_MG, 1399)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "nn = nn_shson.nn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, only_loglike = True, ewc = False)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 2000\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    nn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {nn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    nn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_l = nn.get_fqpl(feed)\n",
    "            fs.append(v_f), ls.append(v_l)\n",
    "\n",
    "            nn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = nn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                #print(\"f : {}, l : {}\".format(v_f, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = nn.get_lr()\n",
    "                nn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if nn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "        \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(nn.validate({nn.x: x_valid[i], nn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={nn.x: x_valid[d], nn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    nn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_nNN = taccs\n",
    "vaccs_nNN = vaccs\n",
    "\n",
    "plt.title('Normal NN')\n",
    "\n",
    "plt.plot(taccs_nNN, 'k')\n",
    "plt.plot(vaccs_nNN[0], 'b')\n",
    "plt.plot(vaccs_nNN[1], 'g')\n",
    "plt.plot(vaccs_nNN[2], 'r')\n",
    "plt.plot(vaccs_nNN[3], 'c')\n",
    "plt.plot(vaccs_nNN[4], 'b')\n",
    "plt.plot(vaccs_nNN[5], 'g')\n",
    "plt.plot(vaccs_nNN[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_nNN, 0)\n",
    "print_accs(vaccs_nNN, 1999)\n",
    "print_accs(vaccs_nNN, 3999)\n",
    "print_accs(vaccs_nNN, 5999)\n",
    "print_accs(vaccs_nNN, 7999)\n",
    "print_accs(vaccs_nNN, 9999)\n",
    "print_accs(vaccs_nNN, 11999)\n",
    "print_accs(vaccs_nNN, 13999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal NN + EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "enn = nn_shson.nn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, only_loglike = False, ewc = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 2000\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    enn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {enn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    enn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_l = enn.get_fqpl(feed)\n",
    "            fs.append(v_f), ls.append(v_l)\n",
    "\n",
    "            enn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = enn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                #print(\"f : {}, l : {}\".format(v_f, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = enn.get_lr()\n",
    "                enn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if enn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "        \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(enn.validate({enn.x: x_valid[i], enn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={enn.x: x_valid[d], enn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    enn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_NNEWC = taccs\n",
    "vaccs_NNEWC = vaccs\n",
    "\n",
    "plt.title('Normal NN with EWC')\n",
    "plt.plot(taccs_NNEWC, 'k')\n",
    "plt.plot(vaccs_NNEWC[0], 'b')\n",
    "plt.plot(vaccs_NNEWC[1], 'g')\n",
    "plt.plot(vaccs_NNEWC[2], 'r')\n",
    "plt.plot(vaccs_NNEWC[3], 'c')\n",
    "plt.plot(vaccs_NNEWC[4], 'b')\n",
    "plt.plot(vaccs_NNEWC[5], 'g')\n",
    "plt.plot(vaccs_NNEWC[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_NNEWC, 0)\n",
    "print_accs(vaccs_NNEWC, 1999)\n",
    "print_accs(vaccs_NNEWC, 3999)\n",
    "print_accs(vaccs_NNEWC, 5999)\n",
    "print_accs(vaccs_NNEWC, 7999)\n",
    "print_accs(vaccs_NNEWC, 9999)\n",
    "print_accs(vaccs_NNEWC, 11999)\n",
    "print_accs(vaccs_NNEWC, 13999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_NNEWC = taccs\n",
    "vaccs_NNEWC = vaccs\n",
    "\n",
    "plt.title('Normal NN with EWC')\n",
    "plt.plot(taccs_NNEWC, 'k')\n",
    "plt.plot(vaccs_NNEWC[0], 'b')\n",
    "plt.plot(vaccs_NNEWC[1], 'g')\n",
    "plt.plot(vaccs_NNEWC[2], 'r')\n",
    "plt.plot(vaccs_NNEWC[3], 'c')\n",
    "plt.plot(vaccs_NNEWC[4], 'b')\n",
    "plt.plot(vaccs_NNEWC[5], 'g')\n",
    "plt.plot(vaccs_NNEWC[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_NNEWC, 0)\n",
    "print_accs(vaccs_NNEWC, 1999)\n",
    "print_accs(vaccs_NNEWC, 3999)\n",
    "print_accs(vaccs_NNEWC, 5999)\n",
    "print_accs(vaccs_NNEWC, 7999)\n",
    "print_accs(vaccs_NNEWC, 9999)\n",
    "print_accs(vaccs_NNEWC, 11999)\n",
    "print_accs(vaccs_NNEWC, 13999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
