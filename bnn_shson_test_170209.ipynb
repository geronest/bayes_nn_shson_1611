{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bnn_shson import *\n",
    "from shson_exp_manager import *\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_to_onehot(nums, n_labels):\n",
    "    results = list()\n",
    "    for i in range(len(nums)):\n",
    "        res = np.zeros([n_labels])\n",
    "        res[nums[i]] = 1\n",
    "        results.append(res)\n",
    "    return np.asarray(results, dtype = 'float32')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = h5py.File('mnist.hdf5', 'r')\n",
    "\n",
    "x_train = mnist['train_data'][()]\n",
    "t_train = num_to_onehot(mnist['train_label'][()], 10)\n",
    "x_valid = mnist['valid_data'][()]\n",
    "t_valid = num_to_onehot(mnist['valid_label'][()], 10)\n",
    "x_test = mnist['test_data'][()]\n",
    "t_test = num_to_onehot(mnist['test_label'][()], 10)\n",
    "\n",
    "mnist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blundell version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-6-034d484d9759>:5 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-034d484d9759>:5 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-034d484d9759>:6 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-034d484d9759>:6 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    }
   ],
   "source": [
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-1.0, 5.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = True, train_rho = True)\n",
    "\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(savedir + 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, step 0, training accuracy 0.09\n",
      "f : 342753.9375, q : -396712.15625, p : -1053698.125, l : 15243.0556641\n",
      "ep 0, step 50, training accuracy 0.11\n",
      "f : 5254.85253906, q : -397183.75, p : -1053747.125, l : 5367.71044922\n",
      "ep 0, step 100, training accuracy 0.21\n",
      "f : 4880.13476562, q : -396997.96875, p : -1053788.75, l : 4680.85839844\n",
      "ep 0, step 150, training accuracy 0.305\n",
      "f : 4209.20800781, q : -397949.15625, p : -1053781.875, l : 4347.71582031\n",
      "ep 0, step 200, training accuracy 0.435\n",
      "f : 3554.81445312, q : -396265.0, p : -1053758.5, l : 3499.11132812\n",
      "valid accuracy 0.4561\n",
      "ep 1, step 0, training accuracy 0.525\n",
      "f : 331995.8125, q : -395683.71875, p : -1053776.5, l : 3251.41040039\n",
      "ep 1, step 50, training accuracy 0.54\n",
      "f : 3027.59790039, q : -397743.3125, p : -1053827.625, l : 3075.49560547\n",
      "ep 1, step 100, training accuracy 0.57\n",
      "f : 2878.13232422, q : -397659.125, p : -1053827.0, l : 2746.05444336\n",
      "ep 1, step 150, training accuracy 0.625\n",
      "f : 2951.79833984, q : -397298.84375, p : -1053870.125, l : 3098.48046875\n",
      "ep 1, step 200, training accuracy 0.74\n",
      "f : 2159.57592773, q : -397001.46875, p : -1053877.875, l : 2243.45654297\n",
      "valid accuracy 0.7249\n",
      "ep 2, step 0, training accuracy 0.78\n",
      "f : 330599.875, q : -396863.09375, p : -1053882.625, l : 2254.78515625\n",
      "ep 2, step 50, training accuracy 0.775\n",
      "f : 2114.43408203, q : -397601.40625, p : -1053931.625, l : 2059.64306641\n",
      "ep 2, step 100, training accuracy 0.705\n",
      "f : 2166.54394531, q : -398806.03125, p : -1053972.375, l : 2114.91918945\n",
      "ep 2, step 150, training accuracy 0.715\n",
      "f : 2462.5769043, q : -397802.75, p : -1053942.875, l : 2306.91748047\n",
      "ep 2, step 200, training accuracy 0.85\n",
      "f : 1631.5111084, q : -398240.34375, p : -1053974.75, l : 1650.54589844\n",
      "valid accuracy 0.8363\n",
      "ep 3, step 0, training accuracy 0.83\n",
      "f : 330099.71875, q : -397917.125, p : -1053976.375, l : 1764.24536133\n",
      "ep 3, step 50, training accuracy 0.82\n",
      "f : 1637.5657959, q : -399246.78125, p : -1054006.5, l : 1592.07800293\n",
      "ep 3, step 100, training accuracy 0.775\n",
      "f : 1714.61254883, q : -398582.90625, p : -1054032.875, l : 1748.31713867\n",
      "ep 3, step 150, training accuracy 0.765\n",
      "f : 1930.89758301, q : -399518.90625, p : -1054025.25, l : 1860.76000977\n",
      "ep 3, step 200, training accuracy 0.855\n",
      "f : 1289.99462891, q : -398485.15625, p : -1054019.75, l : 1283.078125\n",
      "valid accuracy 0.8757\n",
      "ep 4, step 0, training accuracy 0.87\n",
      "f : 329164.3125, q : -399286.84375, p : -1054061.875, l : 1394.62109375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-eda5ff42f221>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mbnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecay_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m#         if (i+1) % 20 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#             print(\"klrw index : %g\"%(bnn.get_klrw()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/bayes_nn_shson/bnn_shson_br.py\u001b[0m in \u001b[0;36mdecay_klrw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecay_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoeff_kl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoeff_kl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3631\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3633\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_epochs = 100\n",
    "n_batches = len(t_train) / batch_size\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for ep in range(n_epochs):\n",
    "    bnn.reset_klrw()\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        bnn.decay_klrw()\n",
    "#         if (i+1) % 20 == 0:\n",
    "#             print(\"klrw index : %g\"%(bnn.get_klrw()))\n",
    "        \n",
    "        feed = {bnn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "        \n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "        \n",
    "#         if i > 50 and np.mean(fs[-50:-25]) < np.mean(fs[-25:]):\n",
    "#             bnn.decay_lr()\n",
    "#             print (\"--- learning rate decayed : %g ---\"%(bnn.get_lr()))\n",
    "        \n",
    "            \n",
    "\n",
    "        if i%50 == 0:\n",
    "            train_accuracy = bnn.validate(feed)\n",
    "\n",
    "            print(\"ep %d, step %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "            print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "            #print v_q - v_p + v_l\n",
    "\n",
    "        bnn.train(feed)\n",
    "    \n",
    "    vacc = bnn.validate({bnn.x: x_valid, bnn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict ={bnn.x: x_valid, bnn.t: t_valid})\n",
    "    test_writer.add_summary(summary, ep)\n",
    "    \n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    if ep > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "        bnn.decay_lr()\n",
    "        print (\"--- learning rate decayed : %g ---\"%(bnn.get_lr()))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEACAYAAACUMoD1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f449a7b5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coeff_klrw = 1 / n_batches\n",
    "\n",
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs*coeff_klrw, 'b')\n",
    "plt.plot(ps*coeff_klrw, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f449a7978d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:9 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:9 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    }
   ],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-5.0, 1.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False, train_rho = True, only_loglike = False)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, ep 0, training accuracy 0.1\n",
      "f : 202075.15625, q : 142556.53125, p : -54964.1367188, l : 4614.22753906\n",
      "batch 0, ep 50, training accuracy 0.995\n",
      "f : 195851.8125, q : 140581.421875, p : -55005.390625, l : 338.313293457\n",
      "batch 0, ep 100, training accuracy 1\n",
      "f : 193669.015625, q : 138568.765625, p : -55024.6875, l : 83.1640777588\n",
      "batch 0, ep 150, training accuracy 1\n",
      "f : 191672.21875, q : 136465.4375, p : -55032.6953125, l : 45.8235168457\n",
      "valid accuracy 0.7855\n",
      "batch 1, ep 0, training accuracy 0.845\n",
      "f : 9938.27929688, q : 134565.203125, p : 125749.96875, l : 1091.68847656\n",
      "batch 1, ep 50, training accuracy 0.985\n",
      "f : 320976.34375, q : 134166.890625, p : -186605.125, l : 241.655303955\n",
      "batch 1, ep 100, training accuracy 0.99\n",
      "f : 318606.3125, q : 134078.671875, p : -184275.375, l : 215.447280884\n",
      "batch 1, ep 150, training accuracy 0.99\n",
      "f : 316796.90625, q : 134001.4375, p : -182541.484375, l : 194.12878418\n",
      "valid accuracy 0.8274\n",
      "batch 2, ep 0, training accuracy 0.765\n",
      "f : 10223.7861328, q : 133943.203125, p : 125113.328125, l : 1385.89709473\n",
      "batch 2, ep 50, training accuracy 0.995\n",
      "f : 320183.90625, q : 133460.0, p : -186443.109375, l : 273.858032227\n",
      "batch 2, ep 100, training accuracy 0.995\n",
      "f : 318114.34375, q : 133395.3125, p : -184524.90625, l : 243.684143066\n",
      "batch 2, ep 150, training accuracy 0.995\n",
      "f : 316385.09375, q : 133441.8125, p : -182775.5625, l : 219.176864624\n",
      "valid accuracy 0.8407\n",
      "batch 3, ep 0, training accuracy 0.82\n",
      "f : 10132.1914062, q : 133271.015625, p : 124417.929688, l : 1288.88671875\n",
      "batch 3, ep 50, training accuracy 0.975\n",
      "f : 319144.15625, q : 132756.1875, p : -186080.84375, l : 277.915893555\n",
      "batch 3, ep 100, training accuracy 0.99\n",
      "f : 316961.875, q : 132674.828125, p : -184003.234375, l : 246.710540771\n",
      "batch 3, ep 150, training accuracy 0.995\n",
      "f : 315334.84375, q : 132655.09375, p : -182389.703125, l : 220.299377441\n",
      "valid accuracy 0.8357\n",
      "batch 4, ep 0, training accuracy 0.83\n",
      "f : 10053.3212891, q : 132664.40625, p : 123804.546875, l : 1208.97729492\n",
      "batch 4, ep 50, training accuracy 0.995\n",
      "f : 318219.28125, q : 132100.421875, p : -185819.96875, l : 213.613037109\n",
      "batch 4, ep 100, training accuracy 0.995\n",
      "f : 315950.375, q : 132006.296875, p : -183684.59375, l : 190.57119751\n",
      "batch 4, ep 150, training accuracy 0.995\n",
      "f : 314248.0, q : 131921.390625, p : -182109.203125, l : 172.720077515\n",
      "valid accuracy 0.8314\n",
      "batch 5, ep 0, training accuracy 0.76\n",
      "f : 10367.8720703, q : 131921.53125, p : 123121.539062, l : 1520.87133789\n",
      "batch 5, ep 50, training accuracy 0.99\n",
      "f : 317381.09375, q : 131498.015625, p : -185610.46875, l : 256.840759277\n",
      "batch 5, ep 100, training accuracy 1\n",
      "f : 315134.84375, q : 131317.203125, p : -183482.53125, l : 228.857086182\n",
      "batch 5, ep 150, training accuracy 1\n",
      "f : 313155.34375, q : 131387.421875, p : -181689.875, l : 206.55255127\n",
      "valid accuracy 0.8342\n",
      "batch 6, ep 0, training accuracy 0.815\n",
      "f : 10179.8427734, q : 131381.140625, p : 122481.960938, l : 1342.07958984\n",
      "batch 6, ep 50, training accuracy 0.975\n",
      "f : 317614.34375, q : 130779.023438, p : -186578.828125, l : 281.680480957\n",
      "batch 6, ep 100, training accuracy 0.985\n",
      "f : 315543.4375, q : 130743.984375, p : -184570.578125, l : 244.49407959\n",
      "batch 6, ep 150, training accuracy 0.99\n",
      "f : 313926.875, q : 130635.820312, p : -183002.8125, l : 215.796447754\n",
      "valid accuracy 0.8321\n",
      "batch 7, ep 0, training accuracy 0.825\n",
      "f : 10028.3007812, q : 130695.695312, p : 121786.953125, l : 1190.90625\n",
      "batch 7, ep 50, training accuracy 0.995\n",
      "f : 316449.25, q : 130135.96875, p : -186138.578125, l : 210.082000732\n",
      "batch 7, ep 100, training accuracy 1\n",
      "f : 314657.8125, q : 130057.90625, p : -184306.6875, l : 184.380599976\n",
      "batch 7, ep 150, training accuracy 1\n",
      "f : 312773.15625, q : 130012.054688, p : -182638.5, l : 163.592636108\n",
      "valid accuracy 0.8468\n",
      "batch 8, ep 0, training accuracy 0.87\n",
      "f : 9693.1953125, q : 129965.289062, p : 121094.828125, l : 846.125183105\n",
      "batch 8, ep 50, training accuracy 0.995\n",
      "f : 316137.5, q : 129419.65625, p : -186446.703125, l : 146.51776123\n",
      "batch 8, ep 100, training accuracy 0.995\n",
      "f : 313877.125, q : 129415.398438, p : -184393.1875, l : 133.458328247\n",
      "batch 8, ep 150, training accuracy 0.995\n",
      "f : 312318.0625, q : 129319.28125, p : -182890.015625, l : 122.05330658\n",
      "valid accuracy 0.8342\n",
      "batch 9, ep 0, training accuracy 0.78\n",
      "f : 10031.1826172, q : 129320.21875, p : 120445.890625, l : 1188.11889648\n",
      "batch 9, ep 50, training accuracy 0.99\n",
      "f : 314735.1875, q : 128872.523438, p : -185758.1875, l : 185.100006104\n",
      "batch 9, ep 100, training accuracy 0.995\n",
      "f : 312626.09375, q : 128799.828125, p : -183744.5625, l : 163.329040527\n",
      "batch 9, ep 150, training accuracy 0.995\n",
      "f : 310744.84375, q : 128708.632812, p : -181927.34375, l : 145.71824646\n",
      "valid accuracy 0.8511\n",
      "batch 10, ep 0, training accuracy 0.87\n",
      "f : 9713.93847656, q : 128575.953125, p : 119773.632812, l : 872.927062988\n",
      "batch 10, ep 50, training accuracy 0.99\n",
      "f : 313710.0625, q : 128091.851562, p : -185400.234375, l : 172.296005249\n",
      "batch 10, ep 100, training accuracy 0.99\n",
      "f : 311837.0625, q : 128063.679688, p : -183570.734375, l : 152.85043335\n",
      "batch 10, ep 150, training accuracy 0.99\n",
      "f : 310170.0625, q : 127972.6875, p : -181933.3125, l : 137.672607422\n",
      "valid accuracy 0.841\n",
      "batch 11, ep 0, training accuracy 0.82\n",
      "f : 9827.1171875, q : 127914.007812, p : 119067.03125, l : 986.954711914\n",
      "batch 11, ep 50, training accuracy 0.985\n",
      "f : 312863.875, q : 127552.335938, p : -185285.1875, l : 165.64364624\n",
      "batch 11, ep 100, training accuracy 0.99\n",
      "f : 310815.3125, q : 127435.679688, p : -183252.53125, l : 148.995819092\n",
      "batch 11, ep 150, training accuracy 0.99\n",
      "f : 309244.6875, q : 127331.125, p : -181782.640625, l : 134.839904785\n",
      "valid accuracy 0.8279\n",
      "batch 12, ep 0, training accuracy 0.855\n",
      "f : 9829.22363281, q : 127330.351562, p : 118527.625, l : 987.421020508\n",
      "batch 12, ep 50, training accuracy 1\n",
      "f : 311647.8125, q : 126884.546875, p : -184715.53125, l : 155.420227051\n",
      "batch 12, ep 100, training accuracy 1\n",
      "f : 309322.71875, q : 126771.65625, p : -182581.609375, l : 135.985870361\n",
      "batch 12, ep 150, training accuracy 1\n",
      "f : 307903.53125, q : 126649.710938, p : -180989.109375, l : 122.023178101\n",
      "valid accuracy 0.8375\n",
      "batch 13, ep 0, training accuracy 0.825\n",
      "f : 10206.4511719, q : 126641.1875, p : 117822.265625, l : 1368.98706055\n",
      "batch 13, ep 50, training accuracy 0.985\n",
      "f : 310854.34375, q : 126127.179688, p : -184495.28125, l : 264.271057129\n",
      "batch 13, ep 100, training accuracy 0.99\n",
      "f : 308413.90625, q : 126066.257812, p : -182118.53125, l : 230.901031494\n",
      "batch 13, ep 150, training accuracy 0.99\n",
      "f : 306628.1875, q : 126039.40625, p : -180427.375, l : 205.383422852\n",
      "valid accuracy 0.8341\n",
      "batch 14, ep 0, training accuracy 0.85\n",
      "f : 9828.109375, q : 125981.8125, p : 117149.4375, l : 990.622680664\n",
      "batch 14, ep 50, training accuracy 0.995\n",
      "f : 309766.5, q : 125464.117188, p : -184072.0625, l : 177.983291626\n",
      "batch 14, ep 100, training accuracy 0.995\n",
      "f : 307346.40625, q : 125443.148438, p : -181773.09375, l : 158.34979248\n",
      "batch 14, ep 150, training accuracy 0.995\n",
      "f : 305528.875, q : 125323.21875, p : -179950.515625, l : 142.931518555\n",
      "valid accuracy 0.8374\n",
      "batch 15, ep 0, training accuracy 0.83\n",
      "f : 9854.57421875, q : 125289.578125, p : 116479.226562, l : 1018.10870361\n",
      "batch 15, ep 50, training accuracy 1\n",
      "f : 308461.5625, q : 124923.125, p : -183506.484375, l : 140.844650269\n",
      "batch 15, ep 100, training accuracy 1\n",
      "f : 306003.3125, q : 124762.679688, p : -181142.375, l : 122.54901123\n",
      "batch 15, ep 150, training accuracy 1\n",
      "f : 304409.9375, q : 124717.992188, p : -179586.234375, l : 110.833946228\n",
      "valid accuracy 0.8448\n",
      "batch 16, ep 0, training accuracy 0.84\n",
      "f : 9904.02636719, q : 124659.117188, p : 115767.164062, l : 1065.8458252\n",
      "batch 16, ep 50, training accuracy 1\n",
      "f : 306970.1875, q : 124207.585938, p : -182631.84375, l : 153.962860107\n",
      "batch 16, ep 100, training accuracy 1\n",
      "f : 304617.96875, q : 124073.421875, p : -180400.90625, l : 137.279602051\n",
      "batch 16, ep 150, training accuracy 1\n",
      "f : 302685.59375, q : 124044.039062, p : -178496.140625, l : 124.723999023\n",
      "valid accuracy 0.8434\n",
      "batch 17, ep 0, training accuracy 0.845\n",
      "f : 9622.81835938, q : 123953.625, p : 115161.3125, l : 784.401062012\n",
      "batch 17, ep 50, training accuracy 1\n",
      "f : 305479.15625, q : 123561.9375, p : -181839.3125, l : 126.716178894\n",
      "batch 17, ep 100, training accuracy 1\n",
      "f : 302801.40625, q : 123491.40625, p : -179260.9375, l : 110.861778259\n",
      "batch 17, ep 150, training accuracy 1\n",
      "f : 300733.125, q : 123406.453125, p : -177234.8125, l : 99.8332824707\n",
      "valid accuracy 0.8469\n",
      "batch 18, ep 0, training accuracy 0.835\n",
      "f : 10105.4013672, q : 123259.34375, p : 114570.054688, l : 1267.83032227\n",
      "batch 18, ep 50, training accuracy 0.985\n",
      "f : 303305.90625, q : 122812.140625, p : -180355.703125, l : 204.866592407\n",
      "batch 18, ep 100, training accuracy 0.985\n",
      "f : 300696.6875, q : 122826.101562, p : -177725.4375, l : 179.670303345\n",
      "batch 18, ep 150, training accuracy 0.985\n",
      "f : 298498.90625, q : 122754.023438, p : -175593.15625, l : 159.813903809\n",
      "valid accuracy 0.8358\n",
      "batch 19, ep 0, training accuracy 0.85\n",
      "f : 9772.15039062, q : 122728.328125, p : 113856.0625, l : 942.674804688\n",
      "batch 19, ep 50, training accuracy 0.995\n",
      "f : 301491.59375, q : 122203.328125, p : -179182.796875, l : 126.200164795\n",
      "batch 19, ep 100, training accuracy 1\n",
      "f : 298586.25, q : 122198.46875, p : -176403.9375, l : 108.65737915\n",
      "batch 19, ep 150, training accuracy 1\n",
      "f : 296689.3125, q : 122007.953125, p : -174450.125, l : 96.441947937\n",
      "valid accuracy 0.8532\n",
      "batch 20, ep 0, training accuracy 0.835\n",
      "f : 9976.19628906, q : 122057.5, p : 113144.492188, l : 1144.24597168\n",
      "batch 20, ep 50, training accuracy 0.99\n",
      "f : 299170.375, q : 121579.210938, p : -177418.671875, l : 194.382324219\n",
      "batch 20, ep 100, training accuracy 0.995\n",
      "f : 296135.6875, q : 121532.09375, p : -174503.4375, l : 167.824676514\n",
      "batch 20, ep 150, training accuracy 0.995\n",
      "f : 294002.0, q : 121481.015625, p : -172437.8125, l : 150.701675415\n",
      "valid accuracy 0.8449\n",
      "batch 21, ep 0, training accuracy 0.815\n",
      "f : 10079.0761719, q : 121400.164062, p : 112551.960938, l : 1239.91137695\n",
      "batch 21, ep 50, training accuracy 0.985\n",
      "f : 296954.375, q : 120835.632812, p : -175844.609375, l : 183.260986328\n",
      "batch 21, ep 100, training accuracy 0.985\n",
      "f : 293947.21875, q : 120821.585938, p : -172923.21875, l : 164.456817627\n",
      "batch 21, ep 150, training accuracy 0.99\n",
      "f : 291336.1875, q : 120836.601562, p : -170428.015625, l : 150.597747803\n",
      "valid accuracy 0.8429\n",
      "batch 22, ep 0, training accuracy 0.895\n",
      "f : 9572.8515625, q : 120738.976562, p : 111954.40625, l : 739.93963623\n",
      "batch 22, ep 50, training accuracy 1\n",
      "f : 295431.1875, q : 120244.085938, p : -175123.515625, l : 92.5924377441\n",
      "batch 22, ep 100, training accuracy 1\n",
      "f : 292327.40625, q : 120231.898438, p : -172112.703125, l : 82.2629089355\n",
      "batch 22, ep 150, training accuracy 1\n",
      "f : 290088.375, q : 120199.804688, p : -169865.28125, l : 75.1778182983\n",
      "valid accuracy 0.8568\n",
      "batch 23, ep 0, training accuracy 0.82\n",
      "f : 10001.2304688, q : 120128.601562, p : 111242.703125, l : 1165.27734375\n",
      "batch 23, ep 50, training accuracy 0.985\n",
      "f : 292067.40625, q : 119602.023438, p : -172310.4375, l : 167.255477905\n",
      "batch 23, ep 100, training accuracy 0.99\n",
      "f : 288718.8125, q : 119498.078125, p : -169016.859375, l : 145.854370117\n",
      "batch 23, ep 150, training accuracy 0.995\n",
      "f : 286205.0625, q : 119440.007812, p : -166529.296875, l : 128.518859863\n",
      "valid accuracy 0.8492\n",
      "batch 24, ep 0, training accuracy 0.79\n",
      "f : 10147.3769531, q : 119470.578125, p : 110564.59375, l : 1315.00305176\n",
      "batch 24, ep 50, training accuracy 0.99\n",
      "f : 290149.75, q : 119003.695312, p : -171085.3125, l : 146.481887817\n",
      "batch 24, ep 100, training accuracy 0.99\n",
      "f : 286526.875, q : 118870.671875, p : -167526.15625, l : 126.731040955\n",
      "batch 24, ep 150, training accuracy 0.995\n",
      "f : 284051.1875, q : 118863.570312, p : -165038.78125, l : 112.83115387\n",
      "valid accuracy 0.8446\n",
      "batch 25, ep 0, training accuracy 0.785\n",
      "f : 10329.4003906, q : 118803.359375, p : 109996.34375, l : 1495.72900391\n",
      "batch 25, ep 50, training accuracy 0.97\n",
      "f : 287058.875, q : 118369.945312, p : -168495.609375, l : 250.440505981\n",
      "batch 25, ep 100, training accuracy 0.97\n",
      "f : 283326.375, q : 118254.125, p : -164890.28125, l : 219.270263672\n",
      "batch 25, ep 150, training accuracy 0.975\n",
      "f : 280384.125, q : 118258.398438, p : -161938.0625, l : 195.327362061\n",
      "valid accuracy 0.8415\n",
      "batch 26, ep 0, training accuracy 0.84\n",
      "f : 9955.87792969, q : 118155.398438, p : 109375.078125, l : 1127.94494629\n",
      "batch 26, ep 50, training accuracy 0.99\n",
      "f : 283662.46875, q : 117631.554688, p : -165760.671875, l : 168.69380188\n",
      "batch 26, ep 100, training accuracy 0.99\n",
      "f : 279692.09375, q : 117701.171875, p : -161925.75, l : 136.014648438\n",
      "batch 26, ep 150, training accuracy 0.99\n",
      "f : 276463.15625, q : 117519.1875, p : -158765.71875, l : 113.902427673\n",
      "valid accuracy 0.8485\n",
      "batch 27, ep 0, training accuracy 0.85\n",
      "f : 9854.58886719, q : 117474.367188, p : 108733.46875, l : 1023.63879395\n",
      "batch 27, ep 50, training accuracy 1\n",
      "f : 280696.34375, q : 117023.320312, p : -163520.34375, l : 89.8798828125\n",
      "batch 27, ep 100, training accuracy 1\n",
      "f : 276405.40625, q : 117027.414062, p : -159274.953125, l : 78.7478790283\n",
      "batch 27, ep 150, training accuracy 1\n",
      "f : 272925.875, q : 116951.164062, p : -155908.078125, l : 69.6899185181\n",
      "valid accuracy 0.8526\n",
      "batch 28, ep 0, training accuracy 0.81\n",
      "f : 9956.06445312, q : 116935.875, p : 108087.289062, l : 1133.98632812\n",
      "batch 28, ep 50, training accuracy 0.995\n",
      "f : 275920.625, q : 116403.445312, p : -159264.25, l : 142.134887695\n",
      "batch 28, ep 100, training accuracy 0.995\n",
      "f : 270956.25, q : 116430.382812, p : -154462.65625, l : 125.56803894\n",
      "batch 28, ep 150, training accuracy 0.995\n",
      "f : 267080.71875, q : 116305.710938, p : -150623.84375, l : 110.940658569\n",
      "valid accuracy 0.8523\n",
      "batch 29, ep 0, training accuracy 0.91\n",
      "f : 9698.93359375, q : 116262.585938, p : 107489.734375, l : 870.778320312\n",
      "batch 29, ep 50, training accuracy 0.985\n",
      "f : 271261.21875, q : 115704.765625, p : -155292.4375, l : 206.977233887\n",
      "batch 29, ep 100, training accuracy 0.985\n",
      "f : 265753.90625, q : 115747.054688, p : -149829.4375, l : 179.646575928\n",
      "batch 29, ep 150, training accuracy 0.99\n",
      "f : 261357.953125, q : 115680.4375, p : -145479.65625, l : 159.25567627\n",
      "valid accuracy 0.8592\n",
      "batch 30, ep 0, training accuracy 0.92\n",
      "f : 9635.44824219, q : 115674.09375, p : 106891.828125, l : 805.966308594\n",
      "batch 30, ep 50, training accuracy 0.995\n",
      "f : 262704.09375, q : 115111.367188, p : -147558.984375, l : 80.9360198975\n",
      "batch 30, ep 100, training accuracy 1\n",
      "f : 253480.6875, q : 115039.757812, p : -138343.828125, l : 54.1732711792\n",
      "batch 30, ep 150, training accuracy 1\n",
      "f : 246991.859375, q : 114956.554688, p : -132032.09375, l : 43.8620910645\n",
      "valid accuracy 0.8496\n",
      "batch 31, ep 0, training accuracy 0.895\n",
      "f : 9507.27148438, q : 114821.210938, p : 105966.6875, l : 682.372192383\n",
      "batch 31, ep 50, training accuracy 0.99\n",
      "f : 233062.640625, q : 114619.96875, p : -118505.734375, l : 112.607391357\n",
      "batch 31, ep 100, training accuracy 0.995\n",
      "f : 226039.359375, q : 114518.742188, p : -111547.195312, l : 97.1412963867\n",
      "batch 31, ep 150, training accuracy 0.995\n",
      "f : 220552.28125, q : 114478.1875, p : -106099.929688, l : 84.1557617188\n",
      "valid accuracy 0.8505\n",
      "batch 32, ep 0, training accuracy 0.905\n",
      "f : 9510.08105469, q : 114377.3125, p : 105582.734375, l : 684.556396484\n",
      "batch 32, ep 50, training accuracy 0.995\n",
      "f : 236595.03125, q : 114034.0625, p : -122554.734375, l : 89.3507995605\n",
      "batch 32, ep 100, training accuracy 0.995\n",
      "f : 229255.703125, q : 113969.742188, p : -115164.203125, l : 76.8374786377\n",
      "batch 32, ep 150, training accuracy 1\n",
      "f : 222924.109375, q : 113850.78125, p : -108953.664062, l : 66.5896606445\n",
      "valid accuracy 0.8594\n",
      "batch 33, ep 0, training accuracy 0.855\n",
      "f : 9804.76074219, q : 113833.453125, p : 105043.835938, l : 981.753234863\n",
      "batch 33, ep 50, training accuracy 0.99\n",
      "f : 236908.65625, q : 113502.484375, p : -123303.625, l : 122.255256653\n",
      "batch 33, ep 100, training accuracy 0.99\n",
      "f : 228865.828125, q : 113367.820312, p : -115345.96875, l : 108.01398468\n",
      "batch 33, ep 150, training accuracy 0.99\n",
      "f : 222550.34375, q : 113354.671875, p : -109090.039062, l : 96.6392822266\n",
      "valid accuracy 0.8618\n",
      "batch 34, ep 0, training accuracy 0.83\n",
      "f : 10210.5839844, q : 113329.8125, p : 104447.289062, l : 1385.61474609\n",
      "batch 34, ep 50, training accuracy 0.99\n",
      "f : 227402.4375, q : 112866.671875, p : -114476.695312, l : 133.358123779\n",
      "batch 34, ep 100, training accuracy 0.99\n",
      "f : 214103.875, q : 112863.023438, p : -101223.617188, l : 104.866928101\n",
      "batch 34, ep 150, training accuracy 0.995\n",
      "f : 203729.390625, q : 112672.359375, p : -90997.2578125, l : 87.6545715332\n",
      "valid accuracy 0.855\n",
      "batch 35, ep 0, training accuracy 0.855\n",
      "f : 9898.12890625, q : 112542.148438, p : 103714.296875, l : 1072.31066895\n",
      "batch 35, ep 50, training accuracy 0.98\n",
      "f : 185990.578125, q : 112174.726562, p : -73520.15625, l : 255.362823486\n",
      "batch 35, ep 100, training accuracy 0.99\n",
      "f : 165268.984375, q : 111992.265625, p : -53079.671875, l : 202.483917236\n",
      "batch 35, ep 150, training accuracy 0.99\n",
      "f : 152975.65625, q : 111945.9375, p : -40812.59375, l : 170.98046875\n",
      "valid accuracy 0.8571\n",
      "batch 36, ep 0, training accuracy 0.805\n",
      "f : 10285.4882812, q : 111813.304688, p : 102945.34375, l : 1451.50170898\n",
      "batch 36, ep 50, training accuracy 0.99\n",
      "f : 160278.09375, q : 111389.398438, p : -48740.8789062, l : 185.422637939\n",
      "batch 36, ep 100, training accuracy 0.995\n",
      "f : 138387.203125, q : 111156.71875, p : -26971.3671875, l : 129.680892944\n",
      "batch 36, ep 150, training accuracy 0.995\n",
      "f : 126245.445312, q : 111083.125, p : -14993.2050781, l : 104.961021423\n",
      "valid accuracy 0.8694\n",
      "batch 37, ep 0, training accuracy 0.88\n",
      "f : 9674.98535156, q : 111037.664062, p : 102208.710938, l : 849.001525879\n",
      "batch 37, ep 50, training accuracy 0.995\n",
      "f : 137241.546875, q : 110737.453125, p : -26523.6484375, l : 91.911529541\n",
      "batch 37, ep 100, training accuracy 1\n",
      "f : 115568.453125, q : 110503.851562, p : -4858.2734375, l : 71.2910614014\n",
      "batch 37, ep 150, training accuracy 1\n",
      "f : 103262.335938, q : 110481.054688, p : 7205.44189453, l : 60.3767852783\n",
      "valid accuracy 0.8636\n",
      "batch 38, ep 0, training accuracy 0.78\n",
      "f : 10601.9550781, q : 110278.09375, p : 101603.289062, l : 1771.82299805\n",
      "batch 38, ep 50, training accuracy 0.995\n",
      "f : 123366.992188, q : 109945.570312, p : -13236.4082031, l : 146.823028564\n",
      "batch 38, ep 100, training accuracy 0.995\n",
      "f : 101387.226562, q : 109884.835938, p : 8682.76660156, l : 112.119338989\n",
      "batch 38, ep 150, training accuracy 1\n",
      "f : 89737.34375, q : 109743.929688, p : 20203.0859375, l : 93.1372756958\n",
      "valid accuracy 0.8639\n",
      "batch 39, ep 0, training accuracy 0.83\n",
      "f : 10223.5732422, q : 109707.5, p : 100806.703125, l : 1406.13500977\n",
      "batch 39, ep 50, training accuracy 0.995\n",
      "f : 94087.5859375, q : 109209.804688, p : 15298.7783203, l : 114.541488647\n",
      "batch 39, ep 100, training accuracy 1\n",
      "f : 71790.6484375, q : 109119.820312, p : 37326.5, l : 79.8889312744\n",
      "batch 39, ep 150, training accuracy 1\n",
      "f : 62262.2734375, q : 108988.234375, p : 46832.7148438, l : 63.1287994385\n",
      "valid accuracy 0.8679\n",
      "batch 40, ep 0, training accuracy 0.89\n",
      "f : 9624.28222656, q : 108871.953125, p : 100103.296875, l : 808.629882812\n",
      "batch 40, ep 50, training accuracy 0.995\n",
      "f : 58018.1679688, q : 108535.3125, p : 50665.9570312, l : 96.0211181641\n",
      "batch 40, ep 100, training accuracy 1\n",
      "f : 43475.0507812, q : 108457.640625, p : 65093.359375, l : 69.8210754395\n",
      "batch 40, ep 150, training accuracy 1\n",
      "f : 37649.8554688, q : 108498.210938, p : 70807.8984375, l : 57.4604949951\n",
      "valid accuracy 0.8659\n",
      "batch 41, ep 0, training accuracy 0.855\n",
      "f : 10074.3925781, q : 108336.875, p : 99578.71875, l : 1257.77880859\n",
      "batch 41, ep 50, training accuracy 0.965\n",
      "f : 50259.140625, q : 108086.992188, p : 58006.9609375, l : 243.475570679\n",
      "batch 41, ep 100, training accuracy 0.985\n",
      "f : 37875.1992188, q : 108079.71875, p : 70316.5, l : 179.08605957\n",
      "batch 41, ep 150, training accuracy 0.99\n",
      "f : 33028.5507812, q : 107945.882812, p : 75133.9453125, l : 142.777191162\n",
      "valid accuracy 0.8647\n",
      "batch 42, ep 0, training accuracy 0.9\n",
      "f : 9832.76464844, q : 107864.984375, p : 99065.71875, l : 1008.33349609\n",
      "batch 42, ep 50, training accuracy 0.96\n",
      "f : 40405.5195312, q : 107474.828125, p : 67260.5390625, l : 288.700836182\n",
      "batch 42, ep 100, training accuracy 0.975\n",
      "f : 30124.0917969, q : 107429.765625, p : 77662.7421875, l : 229.114044189\n",
      "batch 42, ep 150, training accuracy 0.98\n",
      "f : 26404.3027344, q : 107430.023438, p : 81204.7109375, l : 186.197021484\n",
      "valid accuracy 0.8583\n",
      "batch 43, ep 0, training accuracy 0.76\n",
      "f : 10981.1367188, q : 107296.984375, p : 98593.9921875, l : 2160.40283203\n",
      "batch 43, ep 50, training accuracy 0.915\n",
      "f : 36360.7890625, q : 106953.75, p : 71177.765625, l : 464.507720947\n",
      "batch 43, ep 100, training accuracy 0.965\n",
      "f : 29280.4648438, q : 106972.5625, p : 78003.046875, l : 338.977325439\n",
      "batch 43, ep 150, training accuracy 0.975\n",
      "f : 26907.8457031, q : 106984.179688, p : 80201.046875, l : 267.414428711\n",
      "valid accuracy 0.8458\n",
      "batch 44, ep 0, training accuracy 0.785\n",
      "f : 10681.203125, q : 106920.242188, p : 98038.421875, l : 1869.61376953\n",
      "batch 44, ep 50, training accuracy 0.945\n",
      "f : 38672.5742188, q : 106493.546875, p : 68170.1953125, l : 421.414306641\n",
      "batch 44, ep 100, training accuracy 0.97\n",
      "f : 35333.7304688, q : 106435.34375, p : 71141.609375, l : 216.189666748\n",
      "batch 44, ep 150, training accuracy 0.995\n",
      "f : 34445.7734375, q : 106326.476562, p : 71936.40625, l : 133.136322021\n",
      "valid accuracy 0.8453\n",
      "batch 45, ep 0, training accuracy 0.87\n",
      "f : 9667.05761719, q : 106393.328125, p : 97509.3671875, l : 856.809082031\n",
      "batch 45, ep 50, training accuracy 0.975\n",
      "f : 28390.7871094, q : 105979.976562, p : 77766.234375, l : 195.053436279\n",
      "batch 45, ep 100, training accuracy 0.99\n",
      "f : 26986.6074219, q : 105850.140625, p : 79201.890625, l : 138.893814087\n",
      "batch 45, ep 150, training accuracy 1\n",
      "f : 14572.3535156, q : 105876.554688, p : 91374.1484375, l : 111.226463318\n",
      "valid accuracy 0.8627\n",
      "batch 46, ep 0, training accuracy 0.87\n",
      "f : 9868.36425781, q : 105867.820312, p : 97094.703125, l : 1055.68359375\n",
      "batch 46, ep 50, training accuracy 0.875\n",
      "f : 25806.3828125, q : 105665.78125, p : 80562.140625, l : 752.377380371\n",
      "batch 46, ep 100, training accuracy 0.935\n",
      "f : 13538.3837891, q : 105637.09375, p : 92531.1171875, l : 428.865112305\n",
      "batch 46, ep 150, training accuracy 0.94\n",
      "f : 12442.9960938, q : 105674.828125, p : 93588.3046875, l : 389.378875732\n",
      "valid accuracy 0.8592\n",
      "batch 47, ep 0, training accuracy 0.84\n",
      "f : 10266.4882812, q : 105607.773438, p : 96800.921875, l : 1450.08666992\n",
      "batch 47, ep 50, training accuracy 0.91\n",
      "f : 25653.1210938, q : 105321.195312, p : 80193.6953125, l : 574.355102539\n",
      "batch 47, ep 100, training accuracy 0.95\n",
      "f : 24543.1289062, q : 105235.140625, p : 81067.7734375, l : 305.903900146\n",
      "batch 47, ep 150, training accuracy 0.975\n",
      "f : 14485.1191406, q : 105252.484375, p : 91014.203125, l : 215.161010742\n",
      "valid accuracy 0.8584\n",
      "batch 48, ep 0, training accuracy 0.865\n",
      "f : 9727.07617188, q : 105196.390625, p : 96528.796875, l : 901.010314941\n",
      "batch 48, ep 50, training accuracy 0.94\n",
      "f : 21518.3320312, q : 104916.164062, p : 83894.8671875, l : 445.609344482\n",
      "batch 48, ep 100, training accuracy 0.965\n",
      "f : 12667.0244141, q : 104878.890625, p : 92575.234375, l : 357.852294922\n",
      "batch 48, ep 150, training accuracy 0.97\n",
      "f : 11718.9189453, q : 104893.046875, p : 93518.1953125, l : 334.585662842\n",
      "valid accuracy 0.8502\n",
      "batch 49, ep 0, training accuracy 0.895\n",
      "f : 9649.75, q : 104877.601562, p : 96092.265625, l : 837.806152344\n",
      "batch 49, ep 50, training accuracy 0.95\n",
      "f : 19750.1367188, q : 104671.34375, p : 85295.28125, l : 401.597290039\n",
      "batch 49, ep 100, training accuracy 0.96\n",
      "f : 11856.5644531, q : 104712.34375, p : 93161.6171875, l : 330.17086792\n",
      "batch 49, ep 150, training accuracy 0.96\n",
      "f : 10936.2744141, q : 104574.265625, p : 94071.5703125, l : 305.906707764\n",
      "valid accuracy 0.8611\n",
      "batch 50, ep 0, training accuracy 0.905\n",
      "f : 9693.73242188, q : 104641.101562, p : 95814.5390625, l : 875.309143066\n",
      "batch 50, ep 50, training accuracy 0.92\n",
      "f : 19485.3457031, q : 104445.054688, p : 85409.8046875, l : 478.016845703\n",
      "batch 50, ep 100, training accuracy 0.93\n",
      "f : 11955.2675781, q : 104361.5625, p : 92754.8046875, l : 398.970062256\n",
      "batch 50, ep 150, training accuracy 0.93\n",
      "f : 10778.6416016, q : 104461.890625, p : 93977.609375, l : 379.85144043\n",
      "valid accuracy 0.8598\n",
      "batch 51, ep 0, training accuracy 0.825\n",
      "f : 10203.5673828, q : 104274.1875, p : 95521.9140625, l : 1384.78967285\n",
      "batch 51, ep 50, training accuracy 0.91\n",
      "f : 18949.2578125, q : 104045.304688, p : 85772.953125, l : 495.39666748\n",
      "batch 51, ep 100, training accuracy 0.96\n",
      "f : 11820.6064453, q : 104063.695312, p : 92606.8203125, l : 368.462036133\n",
      "batch 51, ep 150, training accuracy 0.965\n",
      "f : 10941.8837891, q : 104096.132812, p : 93528.3515625, l : 344.321166992\n",
      "valid accuracy 0.8571\n",
      "batch 52, ep 0, training accuracy 0.895\n",
      "f : 9459.79003906, q : 104030.84375, p : 95244.2265625, l : 643.715209961\n",
      "batch 52, ep 50, training accuracy 0.955\n",
      "f : 17119.375, q : 103761.273438, p : 86844.1875, l : 286.981079102\n",
      "batch 52, ep 100, training accuracy 0.95\n",
      "f : 10126.5996094, q : 103763.273438, p : 93826.5078125, l : 256.541931152\n",
      "batch 52, ep 150, training accuracy 0.955\n",
      "f : 9825.44042969, q : 103844.695312, p : 94325.609375, l : 248.450775146\n",
      "valid accuracy 0.8708\n",
      "batch 53, ep 0, training accuracy 0.835\n",
      "f : 10038.8818359, q : 103810.539062, p : 95021.3671875, l : 1224.47045898\n",
      "batch 53, ep 50, training accuracy 0.87\n",
      "f : 17416.6289062, q : 103540.476562, p : 86965.5, l : 869.852294922\n",
      "batch 53, ep 100, training accuracy 0.87\n",
      "f : 10752.0390625, q : 103507.710938, p : 93570.59375, l : 820.435913086\n",
      "batch 53, ep 150, training accuracy 0.88\n",
      "f : 10473.7695312, q : 103455.179688, p : 93890.328125, l : 805.69921875\n",
      "valid accuracy 0.8698\n",
      "batch 54, ep 0, training accuracy 0.89\n",
      "f : 9766.87988281, q : 103479.054688, p : 94748.53125, l : 954.096557617\n",
      "batch 54, ep 50, training accuracy 0.92\n",
      "f : 11407.3134766, q : 103327.328125, p : 92515.609375, l : 622.372558594\n",
      "batch 54, ep 100, training accuracy 0.93\n",
      "f : 10321.1220703, q : 103301.90625, p : 93539.6953125, l : 589.90246582\n",
      "batch 54, ep 150, training accuracy 0.93\n",
      "f : 10043.7568359, q : 103310.65625, p : 93842.578125, l : 580.35546875\n",
      "valid accuracy 0.8747\n",
      "batch 55, ep 0, training accuracy 0.9\n",
      "f : 9493.35644531, q : 103292.46875, p : 94468.40625, l : 673.58770752\n",
      "batch 55, ep 50, training accuracy 0.93\n",
      "f : 10747.5380859, q : 103072.828125, p : 92904.0859375, l : 518.191833496\n",
      "batch 55, ep 100, training accuracy 0.93\n",
      "f : 9965.4609375, q : 103102.8125, p : 93623.1953125, l : 503.534118652\n",
      "batch 55, ep 150, training accuracy 0.93\n",
      "f : 9708.07226562, q : 103077.4375, p : 93893.8359375, l : 503.002502441\n",
      "valid accuracy 0.8752\n",
      "batch 56, ep 0, training accuracy 0.88\n",
      "f : 9838.69335938, q : 103144.679688, p : 94331.90625, l : 1023.4942627\n",
      "batch 56, ep 50, training accuracy 0.885\n",
      "f : 16007.2568359, q : 102884.023438, p : 87841.5546875, l : 886.810974121\n",
      "batch 56, ep 100, training accuracy 0.895\n",
      "f : 10400.6464844, q : 102847.460938, p : 93318.53125, l : 853.512145996\n",
      "batch 56, ep 150, training accuracy 0.895\n",
      "f : 10105.6132812, q : 102854.40625, p : 93631.28125, l : 851.522705078\n",
      "valid accuracy 0.8721\n",
      "batch 57, ep 0, training accuracy 0.845\n",
      "f : 10228.3886719, q : 102866.5625, p : 94027.5859375, l : 1411.61535645\n",
      "batch 57, ep 50, training accuracy 0.875\n",
      "f : 15944.4550781, q : 102614.476562, p : 87641.390625, l : 878.567138672\n",
      "batch 57, ep 100, training accuracy 0.875\n",
      "f : 10513.0986328, q : 102633.140625, p : 92810.6796875, l : 836.318237305\n",
      "batch 57, ep 150, training accuracy 0.88\n",
      "f : 10274.2832031, q : 102506.390625, p : 93144.8046875, l : 826.323730469\n",
      "valid accuracy 0.8724\n",
      "batch 58, ep 0, training accuracy 0.88\n",
      "f : 10086.2578125, q : 102568.703125, p : 93875.984375, l : 1275.43457031\n",
      "batch 58, ep 50, training accuracy 0.885\n",
      "f : 15644.3535156, q : 102406.695312, p : 87748.6640625, l : 1072.18359375\n",
      "batch 58, ep 100, training accuracy 0.89\n",
      "f : 10503.7744141, q : 102357.195312, p : 92835.7421875, l : 1022.95812988\n",
      "batch 58, ep 150, training accuracy 0.89\n",
      "f : 10252.1328125, q : 102417.75, p : 93183.40625, l : 1015.86022949\n",
      "valid accuracy 0.8753\n",
      "batch 59, ep 0, training accuracy 0.89\n",
      "f : 9636.09179688, q : 102317.710938, p : 93511.6953125, l : 825.629150391\n",
      "batch 59, ep 50, training accuracy 0.905\n",
      "f : 10793.0869141, q : 102127.476562, p : 91998.0625, l : 716.514282227\n",
      "batch 59, ep 100, training accuracy 0.91\n",
      "f : 10088.3789062, q : 102118.703125, p : 92869.578125, l : 701.880493164\n",
      "batch 59, ep 150, training accuracy 0.91\n",
      "f : 9801.39355469, q : 102162.96875, p : 93042.4296875, l : 698.624572754\n",
      "valid accuracy 0.8735\n",
      "batch 60, ep 0, training accuracy 0.865\n",
      "f : 9642.53417969, q : 102092.921875, p : 93378.5078125, l : 826.567138672\n",
      "batch 60, ep 50, training accuracy 0.925\n",
      "f : 10757.3359375, q : 101972.578125, p : 91754.3046875, l : 606.606872559\n",
      "batch 60, ep 100, training accuracy 0.925\n",
      "f : 10051.5634766, q : 101944.757812, p : 92515.0546875, l : 585.075622559\n",
      "batch 60, ep 150, training accuracy 0.925\n",
      "f : 9777.87695312, q : 101969.9375, p : 92683.3984375, l : 581.065307617\n",
      "valid accuracy 0.8702\n",
      "batch 61, ep 0, training accuracy 0.855\n",
      "f : 10177.2792969, q : 101908.421875, p : 93064.2734375, l : 1368.26928711\n",
      "batch 61, ep 50, training accuracy 0.87\n",
      "f : 14996.5185547, q : 101718.34375, p : 87741.390625, l : 1052.84924316\n",
      "batch 61, ep 100, training accuracy 0.865\n",
      "f : 10440.8779297, q : 101684.570312, p : 92302.078125, l : 1029.33166504\n",
      "batch 61, ep 150, training accuracy 0.865\n",
      "f : 10205.6269531, q : 101689.46875, p : 92563.109375, l : 1021.14306641\n",
      "valid accuracy 0.8705\n",
      "batch 62, ep 0, training accuracy 0.825\n",
      "f : 10255.0166016, q : 101694.835938, p : 92872.375, l : 1459.20288086\n",
      "batch 62, ep 50, training accuracy 0.835\n",
      "f : 11217.2705078, q : 101583.890625, p : 91482.53125, l : 1138.15454102\n",
      "batch 62, ep 100, training accuracy 0.84\n",
      "f : 10533.0214844, q : 101536.648438, p : 92078.625, l : 1118.58569336\n",
      "batch 62, ep 150, training accuracy 0.835\n",
      "f : 10288.265625, q : 101464.492188, p : 92318.0703125, l : 1107.31542969\n",
      "valid accuracy 0.8786\n",
      "batch 63, ep 0, training accuracy 0.835\n",
      "f : 10211.3447266, q : 101529.132812, p : 92659.3515625, l : 1395.99230957\n",
      "batch 63, ep 50, training accuracy 0.85\n",
      "f : 11149.6826172, q : 101453.484375, p : 91395.3359375, l : 1181.8737793\n",
      "batch 63, ep 100, training accuracy 0.855\n",
      "f : 10496.2236328, q : 101440.46875, p : 92089.9609375, l : 1156.80688477\n",
      "batch 63, ep 150, training accuracy 0.855\n",
      "f : 10256.4199219, q : 101396.789062, p : 92200.6953125, l : 1145.10424805\n",
      "valid accuracy 0.8792\n",
      "batch 64, ep 0, training accuracy 0.83\n",
      "f : 9897.59179688, q : 101325.804688, p : 92522.140625, l : 1093.55932617\n",
      "batch 64, ep 50, training accuracy 0.84\n",
      "f : 14281.9599609, q : 101154.507812, p : 87856.359375, l : 936.829467773\n",
      "batch 64, ep 100, training accuracy 0.84\n",
      "f : 10229.2734375, q : 101192.820312, p : 91929.59375, l : 930.310241699\n",
      "batch 64, ep 150, training accuracy 0.845\n",
      "f : 10006.8544922, q : 101177.109375, p : 92144.7890625, l : 925.199401855\n",
      "valid accuracy 0.8774\n",
      "batch 65, ep 0, training accuracy 0.75\n",
      "f : 10694.7802734, q : 101190.757812, p : 92438.8359375, l : 1892.38110352\n",
      "batch 65, ep 50, training accuracy 0.805\n",
      "f : 14879.6513672, q : 101121.179688, p : 87600.546875, l : 1460.70593262\n",
      "batch 65, ep 100, training accuracy 0.83\n",
      "f : 11542.4365234, q : 100983.390625, p : 91037.3359375, l : 1379.23339844\n",
      "batch 65, ep 150, training accuracy 0.835\n",
      "f : 10847.9199219, q : 101119.585938, p : 91632.4375, l : 1362.30969238\n",
      "valid accuracy 0.8802\n",
      "batch 66, ep 0, training accuracy 0.905\n",
      "f : 9646.21582031, q : 101060.046875, p : 92249.4921875, l : 838.525024414\n",
      "batch 66, ep 50, training accuracy 0.91\n",
      "f : 10660.9951172, q : 100877.460938, p : 90993.46875, l : 763.980163574\n",
      "batch 66, ep 100, training accuracy 0.91\n",
      "f : 10033.8603516, q : 100894.796875, p : 91569.9921875, l : 756.08795166\n",
      "batch 66, ep 150, training accuracy 0.91\n",
      "f : 9811.25488281, q : 100997.085938, p : 91830.2109375, l : 760.272094727\n",
      "valid accuracy 0.8791\n",
      "batch 67, ep 0, training accuracy 0.9\n",
      "f : 9562.84765625, q : 100940.070312, p : 92073.453125, l : 753.702209473\n",
      "batch 67, ep 50, training accuracy 0.905\n",
      "f : 10558.5175781, q : 100752.78125, p : 90895.7890625, l : 676.979003906\n",
      "batch 67, ep 100, training accuracy 0.91\n",
      "f : 9914.89160156, q : 100742.046875, p : 91460.90625, l : 665.870239258\n",
      "batch 67, ep 150, training accuracy 0.905\n",
      "f : 9614.29882812, q : 100634.625, p : 91713.46875, l : 666.919616699\n",
      "valid accuracy 0.8815\n",
      "batch 68, ep 0, training accuracy 0.835\n",
      "f : 10005.5820312, q : 100729.71875, p : 91910.5390625, l : 1198.95629883\n",
      "batch 68, ep 50, training accuracy 0.87\n",
      "f : 10969.4453125, q : 100542.203125, p : 90600.296875, l : 1030.41015625\n",
      "batch 68, ep 100, training accuracy 0.87\n",
      "f : 10305.7324219, q : 100557.3125, p : 91284.984375, l : 1015.12524414\n",
      "batch 68, ep 150, training accuracy 0.87\n",
      "f : 10089.3291016, q : 100485.75, p : 91382.6953125, l : 1005.40863037\n",
      "valid accuracy 0.8777\n",
      "batch 69, ep 0, training accuracy 0.83\n",
      "f : 10027.2050781, q : 100548.195312, p : 91709.1328125, l : 1221.41357422\n",
      "batch 69, ep 50, training accuracy 0.87\n",
      "f : 11273.5439453, q : 100415.351562, p : 90161.7109375, l : 1032.53833008\n",
      "batch 69, ep 100, training accuracy 0.885\n",
      "f : 10307.1044922, q : 100450.132812, p : 91128.8359375, l : 1024.05285645\n",
      "batch 69, ep 150, training accuracy 0.885\n",
      "f : 10109.4677734, q : 100352.429688, p : 91268.21875, l : 1016.00775146\n",
      "valid accuracy 0.8779\n",
      "batch 70, ep 0, training accuracy 0.825\n",
      "f : 10135.7265625, q : 100441.992188, p : 91671.4375, l : 1333.36413574\n",
      "batch 70, ep 50, training accuracy 0.86\n",
      "f : 13825.2060547, q : 100267.757812, p : 87458.84375, l : 984.54498291\n",
      "batch 70, ep 100, training accuracy 0.86\n",
      "f : 10343.5722656, q : 100238.15625, p : 90908.2109375, l : 969.770263672\n",
      "batch 70, ep 150, training accuracy 0.87\n",
      "f : 10102.6103516, q : 100267.078125, p : 91062.28125, l : 962.093322754\n",
      "valid accuracy 0.8752\n",
      "batch 71, ep 0, training accuracy 0.82\n",
      "f : 10284.8789062, q : 100237.382812, p : 91609.53125, l : 1472.20117188\n",
      "batch 71, ep 50, training accuracy 0.835\n",
      "f : 11037.9492188, q : 100182.085938, p : 90244.0625, l : 1111.7121582\n",
      "batch 71, ep 100, training accuracy 0.84\n",
      "f : 10410.7578125, q : 100144.460938, p : 90708.3984375, l : 1093.94592285\n",
      "batch 71, ep 150, training accuracy 0.835\n",
      "f : 10189.8671875, q : 100114.9375, p : 91058.7421875, l : 1080.88256836\n",
      "valid accuracy 0.8756\n",
      "batch 72, ep 0, training accuracy 0.855\n",
      "f : 9646.47070312, q : 100204.804688, p : 91387.703125, l : 856.077880859\n",
      "batch 72, ep 50, training accuracy 0.87\n",
      "f : 10533.3349609, q : 100021.359375, p : 90099.25, l : 624.204711914\n",
      "batch 72, ep 100, training accuracy 0.88\n",
      "f : 9966.54589844, q : 100092.914062, p : 90615.6640625, l : 619.405883789\n",
      "batch 72, ep 150, training accuracy 0.88\n",
      "f : 9691.31640625, q : 100009.484375, p : 90952.9921875, l : 614.689453125\n",
      "valid accuracy 0.8814\n",
      "batch 73, ep 0, training accuracy 0.775\n",
      "f : 10428.6777344, q : 99985.03125, p : 91115.7734375, l : 1623.05310059\n",
      "batch 73, ep 50, training accuracy 0.815\n",
      "f : 11256.1289062, q : 99823.3046875, p : 89901.75, l : 1302.00549316\n",
      "batch 73, ep 100, training accuracy 0.825\n",
      "f : 10626.4628906, q : 99778.0703125, p : 90531.28125, l : 1272.2019043\n",
      "batch 73, ep 150, training accuracy 0.835\n",
      "f : 10404.7958984, q : 99860.890625, p : 90762.6953125, l : 1263.12145996\n",
      "valid accuracy 0.873\n",
      "batch 74, ep 0, training accuracy 0.845\n",
      "f : 9783.27441406, q : 99809.390625, p : 90968.234375, l : 981.671203613\n",
      "batch 74, ep 50, training accuracy 0.91\n",
      "f : 10917.8964844, q : 99642.6484375, p : 89433.6484375, l : 704.669799805\n",
      "batch 74, ep 100, training accuracy 0.91\n",
      "f : 10010.3125, q : 99654.3984375, p : 90380.6796875, l : 697.61541748\n",
      "batch 74, ep 150, training accuracy 0.91\n",
      "f : 9746.86816406, q : 99646.0234375, p : 90600.1640625, l : 695.831542969\n",
      "valid accuracy 0.8816\n",
      "batch 75, ep 0, training accuracy 0.88\n",
      "f : 9719.41113281, q : 99675.7734375, p : 90807.6796875, l : 924.060119629\n",
      "batch 75, ep 50, training accuracy 0.89\n",
      "f : 10635.6132812, q : 99537.28125, p : 89732.4453125, l : 815.453735352\n",
      "batch 75, ep 100, training accuracy 0.89\n",
      "f : 10050.0732422, q : 99460.3125, p : 90302.8515625, l : 820.428710938\n",
      "batch 75, ep 150, training accuracy 0.885\n",
      "f : 9849.27148438, q : 99552.0078125, p : 90378.4375, l : 822.291809082\n",
      "valid accuracy 0.8821\n",
      "batch 76, ep 0, training accuracy 0.89\n",
      "f : 9780.93652344, q : 99561.9296875, p : 90739.5703125, l : 980.202636719\n",
      "batch 76, ep 50, training accuracy 0.905\n",
      "f : 10713.2294922, q : 99318.546875, p : 89567.8203125, l : 888.042663574\n",
      "batch 76, ep 100, training accuracy 0.9\n",
      "f : 10103.6933594, q : 99375.390625, p : 90237.7890625, l : 899.739990234\n",
      "batch 76, ep 150, training accuracy 0.905\n",
      "f : 9911.20410156, q : 99310.609375, p : 90353.0, l : 889.473999023\n",
      "valid accuracy 0.8817\n",
      "batch 77, ep 0, training accuracy 0.885\n",
      "f : 9780.94726562, q : 99279.8125, p : 90531.7109375, l : 977.407104492\n",
      "batch 77, ep 50, training accuracy 0.9\n",
      "f : 10649.7099609, q : 99302.625, p : 89364.8125, l : 874.989440918\n",
      "batch 77, ep 100, training accuracy 0.89\n",
      "f : 10101.6933594, q : 99194.640625, p : 89947.40625, l : 873.12097168\n",
      "batch 77, ep 150, training accuracy 0.89\n",
      "f : 9908.70703125, q : 99225.734375, p : 90170.1875, l : 867.182861328\n",
      "valid accuracy 0.8836\n",
      "batch 78, ep 0, training accuracy 0.835\n",
      "f : 10067.9902344, q : 99223.34375, p : 90462.546875, l : 1253.45544434\n",
      "batch 78, ep 50, training accuracy 0.855\n",
      "f : 10849.2460938, q : 99041.6484375, p : 89316.203125, l : 1079.43188477\n",
      "batch 78, ep 100, training accuracy 0.855\n",
      "f : 10321.1582031, q : 99144.484375, p : 89850.75, l : 1075.00366211\n",
      "batch 78, ep 150, training accuracy 0.855\n",
      "f : 10105.2001953, q : 99053.0625, p : 90090.0, l : 1073.03295898\n",
      "valid accuracy 0.8826\n",
      "batch 79, ep 0, training accuracy 0.82\n",
      "f : 10400.6367188, q : 99066.3046875, p : 90210.2421875, l : 1595.53100586\n",
      "batch 79, ep 50, training accuracy 0.81\n",
      "f : 13448.2226562, q : 98927.6328125, p : 86786.8125, l : 1355.59521484\n",
      "batch 79, ep 100, training accuracy 0.825\n",
      "f : 10624.5869141, q : 98905.1640625, p : 89634.8828125, l : 1350.90405273\n",
      "batch 79, ep 150, training accuracy 0.82\n",
      "f : 10431.3720703, q : 98982.9609375, p : 89909.578125, l : 1338.38378906\n",
      "valid accuracy 0.8762\n",
      "batch 80, ep 0, training accuracy 0.865\n",
      "f : 10006.6005859, q : 98920.3203125, p : 90095.90625, l : 1192.82397461\n",
      "batch 80, ep 50, training accuracy 0.87\n",
      "f : 10827.0615234, q : 98794.375, p : 89021.03125, l : 1015.3180542\n",
      "batch 80, ep 100, training accuracy 0.875\n",
      "f : 10287.8515625, q : 98791.9921875, p : 89482.640625, l : 1011.90795898\n",
      "batch 80, ep 150, training accuracy 0.875\n",
      "f : 10039.9130859, q : 98826.3515625, p : 89781.328125, l : 1008.83935547\n",
      "valid accuracy 0.8804\n",
      "batch 81, ep 0, training accuracy 0.91\n",
      "f : 9500.421875, q : 98798.78125, p : 89983.2109375, l : 690.128417969\n",
      "batch 81, ep 50, training accuracy 0.925\n",
      "f : 10342.1748047, q : 98749.328125, p : 88991.828125, l : 608.895812988\n",
      "batch 81, ep 100, training accuracy 0.915\n",
      "f : 9815.65234375, q : 98704.9375, p : 89483.609375, l : 608.647216797\n",
      "batch 81, ep 150, training accuracy 0.925\n",
      "f : 9607.46679688, q : 98700.0546875, p : 89695.3359375, l : 617.613464355\n",
      "valid accuracy 0.8812\n",
      "batch 82, ep 0, training accuracy 0.88\n",
      "f : 9801.64941406, q : 98726.6328125, p : 89978.5703125, l : 982.553894043\n",
      "batch 82, ep 50, training accuracy 0.88\n",
      "f : 10607.4277344, q : 98545.1796875, p : 88874.375, l : 899.298950195\n",
      "batch 82, ep 100, training accuracy 0.88\n",
      "f : 10096.4384766, q : 98526.171875, p : 89436.9609375, l : 897.85559082\n",
      "batch 82, ep 150, training accuracy 0.88\n",
      "f : 9909.50097656, q : 98544.8671875, p : 89585.6328125, l : 901.556518555\n",
      "valid accuracy 0.8822\n",
      "batch 83, ep 0, training accuracy 0.815\n",
      "f : 9916.16699219, q : 98573.375, p : 89774.3671875, l : 1108.97094727\n",
      "batch 83, ep 50, training accuracy 0.835\n",
      "f : 10661.0761719, q : 98449.2890625, p : 88729.5625, l : 929.033569336\n",
      "batch 83, ep 100, training accuracy 0.84\n",
      "f : 10158.2460938, q : 98516.0234375, p : 89269.0, l : 933.424194336\n",
      "batch 83, ep 150, training accuracy 0.835\n",
      "f : 9923.01855469, q : 98489.4140625, p : 89452.4765625, l : 919.990539551\n",
      "valid accuracy 0.8844\n",
      "batch 84, ep 0, training accuracy 0.83\n",
      "f : 9943.8828125, q : 98422.4921875, p : 89670.265625, l : 1147.64746094\n",
      "batch 84, ep 50, training accuracy 0.87\n",
      "f : 10679.3876953, q : 98360.828125, p : 88538.1953125, l : 845.25793457\n",
      "batch 84, ep 100, training accuracy 0.875\n",
      "f : 10134.0107422, q : 98474.3828125, p : 89023.8671875, l : 817.169311523\n",
      "batch 84, ep 150, training accuracy 0.86\n",
      "f : 9935.69628906, q : 98342.2109375, p : 89208.1328125, l : 813.828857422\n",
      "valid accuracy 0.8823\n",
      "batch 85, ep 0, training accuracy 0.85\n",
      "f : 9878.87695312, q : 98344.515625, p : 89551.0234375, l : 1070.44799805\n",
      "batch 85, ep 50, training accuracy 0.865\n",
      "f : 10646.4794922, q : 98266.390625, p : 88437.734375, l : 948.212280273\n",
      "batch 85, ep 100, training accuracy 0.855\n",
      "f : 10165.3095703, q : 98211.765625, p : 89047.6484375, l : 946.403442383\n",
      "batch 85, ep 150, training accuracy 0.865\n",
      "f : 9966.06835938, q : 98264.15625, p : 89214.0625, l : 935.504150391\n",
      "valid accuracy 0.8851\n",
      "batch 86, ep 0, training accuracy 0.91\n",
      "f : 9485.04492188, q : 98204.609375, p : 89363.2421875, l : 679.169677734\n",
      "batch 86, ep 50, training accuracy 0.925\n",
      "f : 10296.1796875, q : 98108.6953125, p : 88390.109375, l : 610.499267578\n",
      "batch 86, ep 100, training accuracy 0.925\n",
      "f : 9789.80957031, q : 98188.921875, p : 88962.1640625, l : 605.112304688\n",
      "batch 86, ep 150, training accuracy 0.925\n",
      "f : 9541.68652344, q : 98193.0078125, p : 89226.1640625, l : 604.957641602\n",
      "valid accuracy 0.8865\n",
      "batch 87, ep 0, training accuracy 0.83\n",
      "f : 9963.27929688, q : 98223.3828125, p : 89383.8203125, l : 1155.31030273\n",
      "batch 87, ep 50, training accuracy 0.87\n",
      "f : 10712.5498047, q : 97947.375, p : 88271.4140625, l : 958.950927734\n",
      "batch 87, ep 100, training accuracy 0.87\n",
      "f : 10210.3125, q : 98054.7265625, p : 88725.7109375, l : 949.572631836\n",
      "batch 87, ep 150, training accuracy 0.865\n",
      "f : 10022.8652344, q : 98092.8046875, p : 88909.828125, l : 942.089111328\n",
      "valid accuracy 0.887\n",
      "batch 88, ep 0, training accuracy 0.8\n",
      "f : 10074.7050781, q : 98084.0234375, p : 89224.1875, l : 1262.11157227\n",
      "batch 88, ep 50, training accuracy 0.83\n",
      "f : 10787.3398438, q : 97933.9765625, p : 88225.1875, l : 1087.74743652\n",
      "batch 88, ep 100, training accuracy 0.825\n",
      "f : 10295.5087891, q : 97957.296875, p : 88818.046875, l : 1088.21313477\n",
      "batch 88, ep 150, training accuracy 0.835\n",
      "f : 10107.2822266, q : 97927.75, p : 88883.4375, l : 1084.50891113\n",
      "valid accuracy 0.8862\n",
      "batch 89, ep 0, training accuracy 0.865\n",
      "f : 9882.12304688, q : 98035.6875, p : 89122.1875, l : 1077.74353027\n",
      "batch 89, ep 50, training accuracy 0.88\n",
      "f : 10611.4052734, q : 97853.5859375, p : 88203.703125, l : 949.55065918\n",
      "batch 89, ep 100, training accuracy 0.875\n",
      "f : 10148.1796875, q : 97865.1796875, p : 88616.1171875, l : 955.070922852\n",
      "batch 89, ep 150, training accuracy 0.875\n",
      "f : 9937.32617188, q : 97811.3359375, p : 88874.9296875, l : 961.741333008\n",
      "valid accuracy 0.8852\n",
      "batch 90, ep 0, training accuracy 0.905\n",
      "f : 9505.64941406, q : 97927.4453125, p : 89050.3125, l : 700.424438477\n",
      "batch 90, ep 50, training accuracy 0.9\n",
      "f : 12162.0, q : 97833.0390625, p : 86107.0, l : 556.645202637\n",
      "batch 90, ep 100, training accuracy 0.905\n",
      "f : 9758.60644531, q : 97767.578125, p : 88483.046875, l : 540.044921875\n",
      "batch 90, ep 150, training accuracy 0.905\n",
      "f : 9568.41992188, q : 97771.515625, p : 88699.96875, l : 533.30279541\n",
      "valid accuracy 0.8827\n",
      "batch 91, ep 0, training accuracy 0.905\n",
      "f : 9513.98828125, q : 97805.4765625, p : 88951.1328125, l : 708.4609375\n",
      "batch 91, ep 50, training accuracy 0.915\n",
      "f : 10277.4121094, q : 97705.3359375, p : 88027.5625, l : 611.572631836\n",
      "batch 91, ep 100, training accuracy 0.91\n",
      "f : 9773.40039062, q : 97679.078125, p : 88484.8046875, l : 601.196777344\n",
      "batch 91, ep 150, training accuracy 0.915\n",
      "f : 9604.64746094, q : 97611.8046875, p : 88661.5703125, l : 596.140075684\n",
      "valid accuracy 0.8852\n",
      "batch 92, ep 0, training accuracy 0.85\n",
      "f : 10047.4199219, q : 97622.703125, p : 88824.7109375, l : 1244.0612793\n",
      "batch 92, ep 50, training accuracy 0.875\n",
      "f : 10806.1699219, q : 97664.1953125, p : 87829.9453125, l : 1055.20361328\n",
      "batch 92, ep 100, training accuracy 0.875\n",
      "f : 10260.1171875, q : 97549.125, p : 88351.0390625, l : 1043.11645508\n",
      "batch 92, ep 150, training accuracy 0.88\n",
      "f : 10064.4609375, q : 97476.5703125, p : 88587.78125, l : 1038.16174316\n",
      "valid accuracy 0.8879\n",
      "batch 93, ep 0, training accuracy 0.905\n",
      "f : 9583.75585938, q : 97547.6875, p : 88700.4140625, l : 778.371520996\n",
      "batch 93, ep 50, training accuracy 0.91\n",
      "f : 10316.1591797, q : 97565.1171875, p : 87842.5234375, l : 685.44519043\n",
      "batch 93, ep 100, training accuracy 0.915\n",
      "f : 9747.66308594, q : 97612.3671875, p : 88501.9296875, l : 684.846679688\n",
      "batch 93, ep 150, training accuracy 0.915\n",
      "f : 9615.43359375, q : 97582.453125, p : 88509.8984375, l : 679.35559082\n",
      "valid accuracy 0.8893\n",
      "batch 94, ep 0, training accuracy 0.89\n",
      "f : 9475.84570312, q : 97418.1640625, p : 88694.5, l : 676.93371582\n",
      "batch 94, ep 50, training accuracy 0.9\n",
      "f : 10213.2119141, q : 97412.3125, p : 87719.375, l : 550.877380371\n",
      "batch 94, ep 100, training accuracy 0.91\n",
      "f : 9726.72363281, q : 97484.46875, p : 88257.859375, l : 543.004882812\n",
      "batch 94, ep 150, training accuracy 0.91\n",
      "f : 9532.36816406, q : 97447.0, p : 88373.3203125, l : 547.97088623\n",
      "valid accuracy 0.8886\n",
      "batch 95, ep 0, training accuracy 0.85\n",
      "f : 9844.65527344, q : 97464.7421875, p : 88581.84375, l : 1039.90234375\n",
      "batch 95, ep 50, training accuracy 0.865\n",
      "f : 12265.1191406, q : 97331.78125, p : 85818.1015625, l : 764.707885742\n",
      "batch 95, ep 100, training accuracy 0.855\n",
      "f : 9993.24902344, q : 97322.5703125, p : 88042.4921875, l : 753.307678223\n",
      "batch 95, ep 150, training accuracy 0.86\n",
      "f : 9821.68164062, q : 97246.25, p : 88301.328125, l : 745.929260254\n",
      "valid accuracy 0.8873\n",
      "batch 96, ep 0, training accuracy 0.875\n",
      "f : 9707.60839844, q : 97310.21875, p : 88483.2265625, l : 901.891845703\n",
      "batch 96, ep 50, training accuracy 0.915\n",
      "f : 12096.8818359, q : 97343.5234375, p : 85837.2421875, l : 710.55847168\n",
      "batch 96, ep 100, training accuracy 0.91\n",
      "f : 9901.89550781, q : 97287.1875, p : 87988.46875, l : 687.223876953\n",
      "batch 96, ep 150, training accuracy 0.905\n",
      "f : 9709.08984375, q : 97254.9765625, p : 88226.78125, l : 682.774414062\n",
      "valid accuracy 0.8921\n",
      "batch 97, ep 0, training accuracy 0.87\n",
      "f : 9679.83203125, q : 97227.6484375, p : 88436.890625, l : 868.206542969\n",
      "batch 97, ep 50, training accuracy 0.905\n",
      "f : 10369.9970703, q : 97133.96875, p : 87591.4375, l : 714.252807617\n",
      "batch 97, ep 100, training accuracy 0.9\n",
      "f : 9912.39746094, q : 97168.9453125, p : 87943.8828125, l : 712.309875488\n",
      "batch 97, ep 150, training accuracy 0.91\n",
      "f : 9725.27148438, q : 97141.125, p : 88096.2578125, l : 710.984680176\n",
      "valid accuracy 0.8915\n",
      "batch 98, ep 0, training accuracy 0.93\n",
      "f : 9209.83007812, q : 97128.1875, p : 88373.4375, l : 407.10534668\n",
      "batch 98, ep 50, training accuracy 0.95\n",
      "f : 9937.87207031, q : 97145.171875, p : 87568.3828125, l : 350.699401855\n",
      "batch 98, ep 100, training accuracy 0.955\n",
      "f : 9503.23730469, q : 97136.6171875, p : 87984.4609375, l : 355.204589844\n",
      "batch 98, ep 150, training accuracy 0.945\n",
      "f : 9269.03808594, q : 97083.296875, p : 88245.578125, l : 350.511779785\n",
      "valid accuracy 0.892\n",
      "batch 99, ep 0, training accuracy 0.815\n",
      "f : 10001.0585938, q : 97167.2734375, p : 88302.46875, l : 1195.72900391\n",
      "batch 99, ep 50, training accuracy 0.86\n",
      "f : 10609.6318359, q : 97021.390625, p : 87279.2109375, l : 924.745544434\n",
      "batch 99, ep 100, training accuracy 0.855\n",
      "f : 10163.03125, q : 97018.390625, p : 87748.5625, l : 914.887573242\n",
      "batch 99, ep 150, training accuracy 0.86\n",
      "f : 9985.18359375, q : 97077.5703125, p : 87915.1640625, l : 904.795471191\n",
      "valid accuracy 0.8912\n",
      "batch 100, ep 0, training accuracy 0.84\n",
      "f : 9928.47265625, q : 97040.640625, p : 88221.8515625, l : 1119.35546875\n",
      "batch 100, ep 50, training accuracy 0.86\n",
      "f : 10621.6152344, q : 96918.5703125, p : 87329.4765625, l : 906.953491211\n",
      "batch 100, ep 100, training accuracy 0.865\n",
      "f : 10158.7548828, q : 96899.7109375, p : 87725.1328125, l : 900.575683594\n",
      "batch 100, ep 150, training accuracy 0.86\n",
      "f : 9965.53613281, q : 96931.515625, p : 87912.15625, l : 902.248413086\n",
      "valid accuracy 0.894\n",
      "batch 101, ep 0, training accuracy 0.88\n",
      "f : 9534.13476562, q : 96994.359375, p : 88079.7109375, l : 733.635375977\n",
      "batch 101, ep 50, training accuracy 0.915\n",
      "f : 10195.8193359, q : 96907.3359375, p : 87245.40625, l : 590.58404541\n",
      "batch 101, ep 100, training accuracy 0.91\n",
      "f : 9777.0859375, q : 96968.3671875, p : 87751.953125, l : 583.067260742\n",
      "batch 101, ep 150, training accuracy 0.91\n",
      "f : 9589.1640625, q : 96925.6875, p : 87859.1953125, l : 581.213867188\n",
      "valid accuracy 0.8919\n",
      "batch 102, ep 0, training accuracy 0.905\n",
      "f : 9484.92089844, q : 96841.9296875, p : 88123.1875, l : 685.693603516\n",
      "batch 102, ep 50, training accuracy 0.92\n",
      "f : 10196.03125, q : 96823.515625, p : 87287.7734375, l : 625.861999512\n",
      "batch 102, ep 100, training accuracy 0.92\n",
      "f : 9732.24902344, q : 96839.5859375, p : 87707.78125, l : 626.56652832\n",
      "batch 102, ep 150, training accuracy 0.92\n",
      "f : 9533.35839844, q : 96897.0390625, p : 87905.5078125, l : 624.320861816\n",
      "valid accuracy 0.8912\n",
      "batch 103, ep 0, training accuracy 0.875\n",
      "f : 9914.58398438, q : 96827.4921875, p : 88089.9375, l : 1115.45178223\n",
      "batch 103, ep 50, training accuracy 0.875\n",
      "f : 10604.7021484, q : 96730.53125, p : 87116.6640625, l : 956.661804199\n",
      "batch 103, ep 100, training accuracy 0.875\n",
      "f : 10158.3525391, q : 96763.171875, p : 87565.671875, l : 955.512939453\n",
      "batch 103, ep 150, training accuracy 0.87\n",
      "f : 9988.30078125, q : 96821.765625, p : 87689.15625, l : 953.63269043\n",
      "valid accuracy 0.892\n",
      "batch 104, ep 0, training accuracy 0.825\n",
      "f : 9960.60449219, q : 96784.0546875, p : 87976.0234375, l : 1142.21240234\n",
      "batch 104, ep 50, training accuracy 0.86\n",
      "f : 10588.4306641, q : 96773.4609375, p : 86960.0859375, l : 938.585510254\n",
      "batch 104, ep 100, training accuracy 0.865\n",
      "f : 10134.4316406, q : 96732.4375, p : 87540.6953125, l : 931.805908203\n",
      "batch 104, ep 150, training accuracy 0.865\n",
      "f : 9979.43164062, q : 96741.0078125, p : 87713.0625, l : 929.43560791\n",
      "valid accuracy 0.89\n",
      "batch 105, ep 0, training accuracy 0.905\n",
      "f : 9442.50585938, q : 96717.6484375, p : 87951.6328125, l : 647.683410645\n",
      "batch 105, ep 50, training accuracy 0.915\n",
      "f : 10161.8085938, q : 96621.40625, p : 87076.796875, l : 564.897705078\n",
      "batch 105, ep 100, training accuracy 0.915\n",
      "f : 9712.76464844, q : 96654.3671875, p : 87528.6484375, l : 567.224243164\n",
      "batch 105, ep 150, training accuracy 0.915\n",
      "f : 9546.84277344, q : 96602.21875, p : 87645.515625, l : 562.745056152\n",
      "valid accuracy 0.8908\n",
      "batch 106, ep 0, training accuracy 0.88\n",
      "f : 9689.43261719, q : 96719.6484375, p : 87864.359375, l : 889.13848877\n",
      "batch 106, ep 50, training accuracy 0.885\n",
      "f : 10368.34375, q : 96568.65625, p : 86923.15625, l : 752.564086914\n",
      "batch 106, ep 100, training accuracy 0.885\n",
      "f : 9924.7890625, q : 96654.265625, p : 87397.7890625, l : 747.864868164\n",
      "batch 106, ep 150, training accuracy 0.885\n",
      "f : 9754.40136719, q : 96542.1640625, p : 87645.3125, l : 752.350708008\n",
      "valid accuracy 0.8913\n",
      "batch 107, ep 0, training accuracy 0.88\n",
      "f : 9651.31640625, q : 96532.0703125, p : 87719.3046875, l : 849.062072754\n",
      "batch 107, ep 50, training accuracy 0.89\n",
      "f : 11886.4335938, q : 96396.0625, p : 85330.5546875, l : 706.686767578\n",
      "batch 107, ep 100, training accuracy 0.895\n",
      "f : 9870.54980469, q : 96508.140625, p : 87334.4765625, l : 699.030944824\n",
      "batch 107, ep 150, training accuracy 0.89\n",
      "f : 9707.75683594, q : 96466.5703125, p : 87469.453125, l : 704.243164062\n",
      "valid accuracy 0.8892\n",
      "batch 108, ep 0, training accuracy 0.905\n",
      "f : 9465.41894531, q : 96446.8671875, p : 87642.765625, l : 664.720825195\n",
      "batch 108, ep 50, training accuracy 0.92\n",
      "f : 10128.8730469, q : 96375.3046875, p : 86828.8203125, l : 558.038635254\n",
      "batch 108, ep 100, training accuracy 0.92\n",
      "f : 9743.37207031, q : 96344.7734375, p : 87280.7578125, l : 561.840148926\n",
      "batch 108, ep 150, training accuracy 0.92\n",
      "f : 9514.65429688, q : 96342.078125, p : 87531.078125, l : 557.809387207\n",
      "valid accuracy 0.8907\n",
      "batch 109, ep 0, training accuracy 0.895\n",
      "f : 9538.23144531, q : 96455.859375, p : 87669.234375, l : 732.375671387\n",
      "batch 109, ep 50, training accuracy 0.925\n",
      "f : 10218.4277344, q : 96368.4609375, p : 86850.921875, l : 642.065307617\n",
      "batch 109, ep 100, training accuracy 0.925\n",
      "f : 9778.54296875, q : 96367.7109375, p : 87217.875, l : 640.510681152\n",
      "batch 109, ep 150, training accuracy 0.925\n",
      "f : 9604.58203125, q : 96350.1171875, p : 87400.9375, l : 637.344909668\n",
      "valid accuracy 0.8897\n",
      "batch 110, ep 0, training accuracy 0.895\n",
      "f : 9435.57324219, q : 96293.03125, p : 87518.5546875, l : 639.938476562\n",
      "batch 110, ep 50, training accuracy 0.9\n",
      "f : 10124.890625, q : 96385.8671875, p : 86665.609375, l : 540.087219238\n",
      "batch 110, ep 100, training accuracy 0.895\n",
      "f : 9698.33984375, q : 96345.796875, p : 87145.8046875, l : 533.48638916\n",
      "batch 110, ep 150, training accuracy 0.895\n",
      "f : 9478.06347656, q : 96252.5703125, p : 87356.7734375, l : 541.058105469\n",
      "valid accuracy 0.8922\n",
      "batch 111, ep 0, training accuracy 0.895\n",
      "f : 9623.04296875, q : 96228.4921875, p : 87424.5625, l : 810.65625\n",
      "batch 111, ep 50, training accuracy 0.91\n",
      "f : 10266.921875, q : 96276.78125, p : 86665.78125, l : 711.957214355\n",
      "batch 111, ep 100, training accuracy 0.91\n",
      "f : 9871.18164062, q : 96223.0234375, p : 87099.921875, l : 708.630615234\n",
      "batch 111, ep 150, training accuracy 0.905\n",
      "f : 9655.88183594, q : 96228.859375, p : 87229.8671875, l : 710.102416992\n",
      "valid accuracy 0.893\n",
      "batch 112, ep 0, training accuracy 0.825\n",
      "f : 10267.8222656, q : 96243.5078125, p : 87379.96875, l : 1473.85266113\n",
      "batch 112, ep 50, training accuracy 0.825\n",
      "f : 10927.9238281, q : 96131.6640625, p : 86453.7734375, l : 1333.93322754\n",
      "batch 112, ep 100, training accuracy 0.825\n",
      "f : 10518.8896484, q : 96157.78125, p : 87023.40625, l : 1322.65429688\n",
      "batch 112, ep 150, training accuracy 0.83\n",
      "f : 10324.0224609, q : 96250.890625, p : 87139.1953125, l : 1337.63195801\n",
      "valid accuracy 0.8938\n",
      "batch 113, ep 0, training accuracy 0.885\n",
      "f : 9686.29394531, q : 96188.5234375, p : 87412.734375, l : 884.32824707\n",
      "batch 113, ep 50, training accuracy 0.885\n",
      "f : 10403.3652344, q : 96057.421875, p : 86433.90625, l : 784.489318848\n",
      "batch 113, ep 100, training accuracy 0.885\n",
      "f : 9943.71972656, q : 96149.953125, p : 87060.7734375, l : 791.830566406\n",
      "batch 113, ep 150, training accuracy 0.885\n",
      "f : 9778.80761719, q : 96101.2734375, p : 87105.25, l : 791.3828125\n",
      "valid accuracy 0.8927\n",
      "batch 114, ep 0, training accuracy 0.925\n",
      "f : 9192.00976562, q : 96067.0703125, p : 87367.4296875, l : 390.520324707\n",
      "batch 114, ep 50, training accuracy 0.955\n",
      "f : 9889.54785156, q : 96099.984375, p : 86486.5, l : 332.938598633\n",
      "batch 114, ep 100, training accuracy 0.955\n",
      "f : 9461.78125, q : 96079.515625, p : 86908.265625, l : 337.192993164\n",
      "batch 114, ep 150, training accuracy 0.95\n",
      "f : 9302.02441406, q : 96074.7734375, p : 87032.0625, l : 334.599975586\n",
      "valid accuracy 0.8914\n",
      "batch 115, ep 0, training accuracy 0.88\n",
      "f : 9614.81347656, q : 96109.84375, p : 87158.40625, l : 802.989624023\n",
      "batch 115, ep 50, training accuracy 0.9\n",
      "f : 10321.2382812, q : 95992.1328125, p : 86353.9921875, l : 663.635131836\n",
      "batch 115, ep 100, training accuracy 0.89\n",
      "f : 9814.68164062, q : 95909.8125, p : 86825.6953125, l : 653.117980957\n",
      "batch 115, ep 150, training accuracy 0.9\n",
      "f : 9638.17773438, q : 96000.84375, p : 86967.7421875, l : 653.04699707\n",
      "valid accuracy 0.891\n",
      "batch 116, ep 0, training accuracy 0.9\n",
      "f : 9549.81152344, q : 95973.21875, p : 87175.59375, l : 746.053100586\n",
      "batch 116, ep 50, training accuracy 0.925\n",
      "f : 10221.84375, q : 95937.65625, p : 86369.5859375, l : 647.290710449\n",
      "batch 116, ep 100, training accuracy 0.93\n",
      "f : 9788.89941406, q : 95937.5625, p : 86876.484375, l : 648.498657227\n",
      "batch 116, ep 150, training accuracy 0.93\n",
      "f : 9594.43359375, q : 95941.6953125, p : 86982.03125, l : 649.592773438\n",
      "valid accuracy 0.8919\n",
      "batch 117, ep 0, training accuracy 0.865\n",
      "f : 9720.13378906, q : 95880.1875, p : 87068.6171875, l : 915.258056641\n",
      "batch 117, ep 50, training accuracy 0.895\n",
      "f : 10358.3671875, q : 95887.375, p : 86356.4453125, l : 778.620300293\n",
      "batch 117, ep 100, training accuracy 0.9\n",
      "f : 9938.9921875, q : 95884.0390625, p : 86710.796875, l : 779.216796875\n",
      "batch 117, ep 150, training accuracy 0.895\n",
      "f : 9768.53515625, q : 95871.8125, p : 86985.7734375, l : 777.54510498\n",
      "valid accuracy 0.8931\n",
      "batch 118, ep 0, training accuracy 0.89\n",
      "f : 9611.37695312, q : 95859.109375, p : 87052.3046875, l : 811.624145508\n",
      "batch 118, ep 50, training accuracy 0.91\n",
      "f : 10281.2929688, q : 95815.5546875, p : 86202.3359375, l : 728.636901855\n",
      "batch 118, ep 100, training accuracy 0.91\n",
      "f : 9882.86621094, q : 95755.3984375, p : 86682.5390625, l : 736.328613281\n",
      "batch 118, ep 150, training accuracy 0.905\n",
      "f : 9672.88671875, q : 95746.5078125, p : 86824.421875, l : 733.987304688\n",
      "valid accuracy 0.8933\n",
      "batch 119, ep 0, training accuracy 0.905\n",
      "f : 9660.75195312, q : 95855.9609375, p : 87037.5390625, l : 863.270996094\n",
      "batch 119, ep 50, training accuracy 0.92\n",
      "f : 10379.9072266, q : 95717.40625, p : 86091.484375, l : 716.270141602\n",
      "batch 119, ep 100, training accuracy 0.92\n",
      "f : 9872.91601562, q : 95724.4140625, p : 86495.5546875, l : 707.365234375\n",
      "batch 119, ep 150, training accuracy 0.92\n",
      "f : 9722.52246094, q : 95861.734375, p : 86734.1796875, l : 708.774841309\n",
      "valid accuracy 0.8917\n",
      "batch 120, ep 0, training accuracy 0.9\n",
      "f : 9474.64648438, q : 95717.3359375, p : 87006.3984375, l : 678.475891113\n",
      "batch 120, ep 50, training accuracy 0.91\n",
      "f : 10114.5214844, q : 95731.7734375, p : 86155.0703125, l : 610.888977051\n",
      "batch 120, ep 100, training accuracy 0.91\n",
      "f : 9729.62597656, q : 95749.0390625, p : 86596.296875, l : 605.657409668\n",
      "batch 120, ep 150, training accuracy 0.91\n",
      "f : 9530.70898438, q : 95724.7265625, p : 86795.421875, l : 610.800537109\n",
      "valid accuracy 0.8923\n",
      "batch 121, ep 0, training accuracy 0.895\n",
      "f : 9676.75683594, q : 95761.0234375, p : 86937.4765625, l : 869.450378418\n",
      "batch 121, ep 50, training accuracy 0.9\n",
      "f : 10343.8818359, q : 95694.0703125, p : 86191.96875, l : 787.663208008\n",
      "batch 121, ep 100, training accuracy 0.905\n",
      "f : 9909.89453125, q : 95719.28125, p : 86519.9921875, l : 789.42755127\n",
      "batch 121, ep 150, training accuracy 0.905\n",
      "f : 9717.97460938, q : 95654.09375, p : 86681.1796875, l : 789.344055176\n",
      "valid accuracy 0.8923\n",
      "batch 122, ep 0, training accuracy 0.885\n",
      "f : 9789.34375, q : 95609.59375, p : 86830.8671875, l : 997.608520508\n",
      "batch 122, ep 50, training accuracy 0.885\n",
      "f : 10394.1640625, q : 95577.9609375, p : 85931.09375, l : 808.284362793\n",
      "batch 122, ep 100, training accuracy 0.885\n",
      "f : 10005.6074219, q : 95586.65625, p : 86364.21875, l : 799.507324219\n",
      "batch 122, ep 150, training accuracy 0.875\n",
      "f : 9850.83007812, q : 95595.015625, p : 86553.6640625, l : 801.19708252\n",
      "valid accuracy 0.8914\n",
      "batch 123, ep 0, training accuracy 0.85\n",
      "f : 10189.2705078, q : 95649.296875, p : 86816.9375, l : 1388.10705566\n",
      "batch 123, ep 50, training accuracy 0.855\n",
      "f : 10775.4550781, q : 95563.53125, p : 85874.5546875, l : 1145.99975586\n",
      "batch 123, ep 100, training accuracy 0.86\n",
      "f : 10330.4111328, q : 95577.828125, p : 86357.546875, l : 1138.51696777\n",
      "batch 123, ep 150, training accuracy 0.86\n",
      "f : 10162.5234375, q : 95504.84375, p : 86538.1875, l : 1144.63598633\n",
      "valid accuracy 0.8905\n",
      "batch 124, ep 0, training accuracy 0.85\n",
      "f : 9836.05175781, q : 95521.3984375, p : 86786.9921875, l : 1028.32214355\n",
      "batch 124, ep 50, training accuracy 0.87\n",
      "f : 10454.2158203, q : 95526.375, p : 85915.7578125, l : 882.963012695\n",
      "batch 124, ep 100, training accuracy 0.875\n",
      "f : 10032.2314453, q : 95497.40625, p : 86351.7421875, l : 871.729553223\n",
      "batch 124, ep 150, training accuracy 0.875\n",
      "f : 9882.74121094, q : 95551.8671875, p : 86461.9921875, l : 872.414916992\n",
      "valid accuracy 0.8903\n",
      "batch 125, ep 0, training accuracy 0.91\n",
      "f : 9462.75683594, q : 95544.03125, p : 86699.6796875, l : 652.514282227\n",
      "batch 125, ep 50, training accuracy 0.92\n",
      "f : 10086.2441406, q : 95484.6640625, p : 85879.703125, l : 569.139831543\n",
      "batch 125, ep 100, training accuracy 0.92\n",
      "f : 9709.31738281, q : 95404.28125, p : 86349.1328125, l : 571.667785645\n",
      "batch 125, ep 150, training accuracy 0.92\n",
      "f : 9548.40722656, q : 95522.515625, p : 86437.953125, l : 575.895446777\n",
      "valid accuracy 0.8905\n",
      "batch 126, ep 0, training accuracy 0.875\n",
      "f : 9519.68554688, q : 95433.2421875, p : 86749.8046875, l : 722.284484863\n",
      "batch 126, ep 50, training accuracy 0.88\n",
      "f : 10146.1103516, q : 95504.390625, p : 85862.7734375, l : 626.239624023\n",
      "batch 126, ep 100, training accuracy 0.88\n",
      "f : 9761.88867188, q : 95416.21875, p : 86241.390625, l : 629.314880371\n",
      "batch 126, ep 150, training accuracy 0.88\n",
      "f : 9595.48242188, q : 95438.5, p : 86459.5859375, l : 622.188903809\n",
      "valid accuracy 0.8889\n",
      "batch 127, ep 0, training accuracy 0.92\n",
      "f : 9520.66601562, q : 95388.203125, p : 86708.953125, l : 714.249145508\n",
      "batch 127, ep 50, training accuracy 0.92\n",
      "f : 10160.7558594, q : 95277.7578125, p : 85815.9375, l : 631.18762207\n",
      "batch 127, ep 100, training accuracy 0.92\n",
      "f : 9779.5703125, q : 95449.3671875, p : 86230.5703125, l : 629.122924805\n",
      "batch 127, ep 150, training accuracy 0.92\n",
      "f : 9616.7421875, q : 95252.171875, p : 86478.1640625, l : 629.664367676\n",
      "valid accuracy 0.8914\n",
      "batch 128, ep 0, training accuracy 0.895\n",
      "f : 9468.40527344, q : 95348.5546875, p : 86593.265625, l : 670.278808594\n",
      "batch 128, ep 50, training accuracy 0.9\n",
      "f : 10205.6884766, q : 95349.8359375, p : 85642.1015625, l : 602.718383789\n",
      "batch 128, ep 100, training accuracy 0.9\n",
      "f : 9714.96289062, q : 95315.859375, p : 86208.2578125, l : 597.665222168\n",
      "batch 128, ep 150, training accuracy 0.9\n",
      "f : 9571.54492188, q : 95349.609375, p : 86377.0625, l : 598.91027832\n",
      "valid accuracy 0.8927\n",
      "batch 129, ep 0, training accuracy 0.895\n",
      "f : 9574.7109375, q : 95308.40625, p : 86485.3203125, l : 771.445617676\n",
      "batch 129, ep 50, training accuracy 0.91\n",
      "f : 10208.2880859, q : 95364.2734375, p : 85777.34375, l : 685.072631836\n",
      "batch 129, ep 100, training accuracy 0.91\n",
      "f : 9813.33789062, q : 95275.609375, p : 86089.9140625, l : 686.847290039\n",
      "batch 129, ep 150, training accuracy 0.91\n",
      "f : 9661.9296875, q : 95248.578125, p : 86303.4609375, l : 686.724853516\n",
      "valid accuracy 0.8953\n",
      "batch 130, ep 0, training accuracy 0.93\n",
      "f : 9388.61816406, q : 95263.7578125, p : 86423.1640625, l : 593.398620605\n",
      "batch 130, ep 50, training accuracy 0.93\n",
      "f : 10004.9580078, q : 95198.5859375, p : 85734.578125, l : 496.57913208\n",
      "batch 130, ep 100, training accuracy 0.935\n",
      "f : 9623.53125, q : 95247.21875, p : 86125.9921875, l : 505.270141602\n",
      "batch 130, ep 150, training accuracy 0.94\n",
      "f : 9437.38964844, q : 95245.703125, p : 86189.609375, l : 500.888366699\n",
      "valid accuracy 0.8939\n",
      "batch 131, ep 0, training accuracy 0.895\n",
      "f : 9683.12402344, q : 95232.25, p : 86410.4453125, l : 885.000305176\n",
      "batch 131, ep 50, training accuracy 0.91\n",
      "f : 10317.9199219, q : 95192.1875, p : 85647.2578125, l : 787.80065918\n",
      "batch 131, ep 100, training accuracy 0.91\n",
      "f : 9925.94921875, q : 95079.7578125, p : 86088.859375, l : 786.730651855\n",
      "batch 131, ep 150, training accuracy 0.915\n",
      "f : 9763.61230469, q : 95169.90625, p : 86171.84375, l : 786.2890625\n",
      "valid accuracy 0.8953\n",
      "batch 132, ep 0, training accuracy 0.865\n",
      "f : 9679.78417969, q : 95222.203125, p : 86328.03125, l : 884.133544922\n",
      "batch 132, ep 50, training accuracy 0.87\n",
      "f : 10275.375, q : 95219.9375, p : 85674.96875, l : 764.775146484\n",
      "batch 132, ep 100, training accuracy 0.87\n",
      "f : 9911.51660156, q : 95188.1640625, p : 85938.625, l : 767.79699707\n",
      "batch 132, ep 150, training accuracy 0.87\n",
      "f : 9705.65039062, q : 95192.421875, p : 86296.34375, l : 758.283203125\n",
      "valid accuracy 0.8945\n",
      "batch 133, ep 0, training accuracy 0.825\n",
      "f : 10181.4980469, q : 95165.1328125, p : 86333.1328125, l : 1386.74487305\n",
      "batch 133, ep 50, training accuracy 0.84\n",
      "f : 10775.9970703, q : 95092.6015625, p : 85645.4921875, l : 1238.17993164\n",
      "batch 133, ep 100, training accuracy 0.84\n",
      "f : 10382.8085938, q : 95155.6796875, p : 86036.5625, l : 1234.59570312\n",
      "batch 133, ep 150, training accuracy 0.84\n",
      "f : 10196.3125, q : 95110.1875, p : 86168.6484375, l : 1230.57971191\n",
      "valid accuracy 0.896\n",
      "batch 134, ep 0, training accuracy 0.885\n",
      "f : 9812.27734375, q : 95166.5234375, p : 86333.28125, l : 1010.94299316\n",
      "batch 134, ep 50, training accuracy 0.895\n",
      "f : 10406.7910156, q : 95211.796875, p : 85545.6640625, l : 873.213867188\n",
      "batch 134, ep 100, training accuracy 0.895\n",
      "f : 10031.671875, q : 95088.015625, p : 85899.859375, l : 870.507446289\n",
      "batch 134, ep 150, training accuracy 0.895\n",
      "f : 9883.875, q : 95097.7421875, p : 85976.4140625, l : 872.761230469\n",
      "valid accuracy 0.8955\n",
      "batch 135, ep 0, training accuracy 0.86\n",
      "f : 9771.86621094, q : 95054.96875, p : 86305.359375, l : 960.045654297\n",
      "batch 135, ep 50, training accuracy 0.875\n",
      "f : 10349.703125, q : 95056.21875, p : 85507.5546875, l : 814.319641113\n",
      "batch 135, ep 100, training accuracy 0.88\n",
      "f : 9976.39160156, q : 95057.7421875, p : 85913.375, l : 823.424560547\n",
      "batch 135, ep 150, training accuracy 0.885\n",
      "f : 9826.39648438, q : 95126.84375, p : 85991.0625, l : 822.23248291\n",
      "valid accuracy 0.8941\n",
      "batch 136, ep 0, training accuracy 0.87\n",
      "f : 9663.29492188, q : 95070.0390625, p : 86276.3125, l : 861.824584961\n",
      "batch 136, ep 50, training accuracy 0.9\n",
      "f : 10246.7988281, q : 95007.828125, p : 85373.3203125, l : 697.228515625\n",
      "batch 136, ep 100, training accuracy 0.895\n",
      "f : 9884.47851562, q : 94982.078125, p : 85752.171875, l : 688.036743164\n",
      "batch 136, ep 150, training accuracy 0.895\n",
      "f : 9701.49414062, q : 95022.4765625, p : 85952.0546875, l : 692.527099609\n",
      "valid accuracy 0.8933\n",
      "batch 137, ep 0, training accuracy 0.85\n",
      "f : 9812.67871094, q : 94881.984375, p : 86202.390625, l : 1004.86132812\n",
      "batch 137, ep 50, training accuracy 0.86\n",
      "f : 10406.5332031, q : 94975.046875, p : 85417.5234375, l : 888.965820312\n",
      "batch 137, ep 100, training accuracy 0.86\n",
      "f : 10021.3173828, q : 95029.9140625, p : 85746.7890625, l : 881.922607422\n",
      "batch 137, ep 150, training accuracy 0.865\n",
      "f : 9885.3671875, q : 94991.3515625, p : 85905.734375, l : 889.570556641\n",
      "valid accuracy 0.8942\n",
      "batch 138, ep 0, training accuracy 0.85\n",
      "f : 9946.66601562, q : 94877.375, p : 86181.6796875, l : 1148.15148926\n",
      "batch 138, ep 50, training accuracy 0.875\n",
      "f : 11779.2148438, q : 94983.78125, p : 83990.265625, l : 920.102478027\n",
      "batch 138, ep 100, training accuracy 0.875\n",
      "f : 10057.3808594, q : 94974.203125, p : 85751.0625, l : 892.122009277\n",
      "batch 138, ep 150, training accuracy 0.875\n",
      "f : 9897.07617188, q : 94933.0546875, p : 85856.1875, l : 894.804931641\n",
      "valid accuracy 0.8947\n",
      "batch 139, ep 0, training accuracy 0.87\n",
      "f : 9666.61328125, q : 94859.4921875, p : 86079.4453125, l : 867.770996094\n",
      "batch 139, ep 50, training accuracy 0.895\n",
      "f : 10270.8408203, q : 94851.4140625, p : 85285.03125, l : 750.428466797\n",
      "batch 139, ep 100, training accuracy 0.89\n",
      "f : 9882.29199219, q : 94896.8671875, p : 85750.2890625, l : 753.181213379\n",
      "batch 139, ep 150, training accuracy 0.895\n",
      "f : 9737.30273438, q : 94819.4921875, p : 85803.640625, l : 756.399047852\n",
      "valid accuracy 0.8948\n",
      "batch 140, ep 0, training accuracy 0.925\n",
      "f : 9452.95019531, q : 94832.3046875, p : 86023.703125, l : 647.365722656\n",
      "batch 140, ep 50, training accuracy 0.925\n",
      "f : 10088.4960938, q : 94822.78125, p : 85288.671875, l : 605.905212402\n",
      "batch 140, ep 100, training accuracy 0.925\n",
      "f : 9706.44433594, q : 94796.7265625, p : 85710.8125, l : 603.242248535\n",
      "batch 140, ep 150, training accuracy 0.925\n",
      "f : 9533.39648438, q : 94851.765625, p : 85934.7421875, l : 605.128967285\n",
      "valid accuracy 0.895\n",
      "batch 141, ep 0, training accuracy 0.87\n",
      "f : 9700.76171875, q : 94812.9453125, p : 86048.234375, l : 897.367126465\n",
      "batch 141, ep 50, training accuracy 0.88\n",
      "f : 10288.6289062, q : 94810.5625, p : 85179.6953125, l : 768.626464844\n",
      "batch 141, ep 100, training accuracy 0.89\n",
      "f : 9917.85839844, q : 94855.046875, p : 85672.8125, l : 770.64074707\n",
      "batch 141, ep 150, training accuracy 0.89\n",
      "f : 9722.47753906, q : 94807.390625, p : 85692.3125, l : 766.130126953\n",
      "valid accuracy 0.8945\n",
      "batch 142, ep 0, training accuracy 0.895\n",
      "f : 9666.68945312, q : 94771.671875, p : 85923.7578125, l : 860.589599609\n",
      "batch 142, ep 50, training accuracy 0.895\n",
      "f : 10272.5878906, q : 94693.2109375, p : 85240.9296875, l : 788.379272461\n",
      "batch 142, ep 100, training accuracy 0.895\n",
      "f : 9903.81640625, q : 94747.5546875, p : 85549.703125, l : 781.842895508\n",
      "batch 142, ep 150, training accuracy 0.895\n",
      "f : 9732.20996094, q : 94792.6875, p : 85770.0625, l : 781.531494141\n",
      "valid accuracy 0.8935\n",
      "batch 143, ep 0, training accuracy 0.89\n",
      "f : 9888.44824219, q : 94697.3671875, p : 85928.2890625, l : 1089.85058594\n",
      "batch 143, ep 50, training accuracy 0.9\n",
      "f : 10451.6396484, q : 94765.7265625, p : 85215.546875, l : 961.416503906\n",
      "batch 143, ep 100, training accuracy 0.905\n",
      "f : 10090.3789062, q : 94698.3671875, p : 85526.421875, l : 960.41003418\n",
      "batch 143, ep 150, training accuracy 0.905\n",
      "f : 9941.78515625, q : 94651.421875, p : 85674.328125, l : 959.980957031\n",
      "valid accuracy 0.8969\n",
      "batch 144, ep 0, training accuracy 0.875\n",
      "f : 9585.92382812, q : 94762.5234375, p : 85925.421875, l : 789.815002441\n",
      "batch 144, ep 50, training accuracy 0.91\n",
      "f : 10192.4980469, q : 94673.28125, p : 85180.8359375, l : 667.58581543\n",
      "batch 144, ep 100, training accuracy 0.91\n",
      "f : 9808.90527344, q : 94689.578125, p : 85490.046875, l : 664.744262695\n",
      "batch 144, ep 150, training accuracy 0.905\n",
      "f : 9631.16015625, q : 94574.4296875, p : 85643.9453125, l : 672.772277832\n",
      "valid accuracy 0.8966\n",
      "batch 145, ep 0, training accuracy 0.86\n",
      "f : 9760.73632812, q : 94664.3203125, p : 85821.3359375, l : 972.903381348\n",
      "batch 145, ep 50, training accuracy 0.875\n",
      "f : 10347.2587891, q : 94609.1953125, p : 85088.2265625, l : 822.104431152\n",
      "batch 145, ep 100, training accuracy 0.88\n",
      "f : 9965.58496094, q : 94643.484375, p : 85475.2578125, l : 825.948364258\n",
      "batch 145, ep 150, training accuracy 0.875\n",
      "f : 9777.98632812, q : 94601.6484375, p : 85678.2109375, l : 822.111755371\n",
      "valid accuracy 0.8973\n",
      "batch 146, ep 0, training accuracy 0.85\n",
      "f : 9814.68164062, q : 94591.46875, p : 85794.6015625, l : 1017.86450195\n",
      "batch 146, ep 50, training accuracy 0.87\n",
      "f : 10377.8056641, q : 94596.9765625, p : 85047.46875, l : 898.618408203\n",
      "batch 146, ep 100, training accuracy 0.865\n",
      "f : 10026.4042969, q : 94593.015625, p : 85516.53125, l : 891.865661621\n",
      "batch 146, ep 150, training accuracy 0.87\n",
      "f : 9873.40917969, q : 94661.890625, p : 85608.2890625, l : 899.849182129\n",
      "valid accuracy 0.8994\n",
      "batch 147, ep 0, training accuracy 0.9\n",
      "f : 9487.3359375, q : 94537.765625, p : 85751.8203125, l : 690.964477539\n",
      "batch 147, ep 50, training accuracy 0.91\n",
      "f : 10078.0136719, q : 94612.0703125, p : 85042.9296875, l : 585.171569824\n",
      "batch 147, ep 100, training accuracy 0.91\n",
      "f : 9701.22167969, q : 94593.765625, p : 85408.7109375, l : 589.315063477\n",
      "batch 147, ep 150, training accuracy 0.91\n",
      "f : 9550.71875, q : 94501.5625, p : 85551.9453125, l : 586.392456055\n",
      "valid accuracy 0.8991\n",
      "batch 148, ep 0, training accuracy 0.925\n",
      "f : 9361.71289062, q : 94595.40625, p : 85808.7890625, l : 561.526611328\n",
      "batch 148, ep 50, training accuracy 0.93\n",
      "f : 9967.28320312, q : 94539.203125, p : 84988.0625, l : 485.864227295\n",
      "batch 148, ep 100, training accuracy 0.935\n",
      "f : 9591.54199219, q : 94440.09375, p : 85550.6015625, l : 485.512634277\n",
      "batch 148, ep 150, training accuracy 0.93\n",
      "f : 9445.57617188, q : 94476.5625, p : 85528.96875, l : 484.754577637\n",
      "valid accuracy 0.8983\n",
      "batch 149, ep 0, training accuracy 0.825\n",
      "f : 10218.4794922, q : 94484.0546875, p : 85689.7578125, l : 1425.30859375\n",
      "batch 149, ep 50, training accuracy 0.84\n",
      "f : 10759.9423828, q : 94502.796875, p : 84980.1875, l : 1229.77209473\n",
      "batch 149, ep 100, training accuracy 0.84\n",
      "f : 10376.6494141, q : 94441.640625, p : 85326.234375, l : 1222.80957031\n",
      "batch 149, ep 150, training accuracy 0.84\n",
      "f : 10188.53125, q : 94437.7109375, p : 85527.9140625, l : 1226.06005859\n",
      "valid accuracy 0.8962\n",
      "batch 150, ep 0, training accuracy 0.825\n",
      "f : 9858.52441406, q : 94460.796875, p : 85697.953125, l : 1060.26464844\n",
      "batch 150, ep 50, training accuracy 0.87\n",
      "f : 10375.2441406, q : 94462.7421875, p : 84895.2578125, l : 854.272094727\n",
      "batch 150, ep 100, training accuracy 0.875\n",
      "f : 10002.6835938, q : 94454.0625, p : 85337.8359375, l : 853.474731445\n",
      "batch 150, ep 150, training accuracy 0.88\n",
      "f : 9860.84375, q : 94458.84375, p : 85447.0546875, l : 851.993713379\n",
      "valid accuracy 0.8958\n",
      "batch 151, ep 0, training accuracy 0.91\n",
      "f : 9423.07617188, q : 94384.3203125, p : 85589.5078125, l : 622.197875977\n",
      "batch 151, ep 50, training accuracy 0.92\n",
      "f : 9996.69335938, q : 94409.9453125, p : 84920.046875, l : 523.891601562\n",
      "batch 151, ep 100, training accuracy 0.92\n",
      "f : 9633.40332031, q : 94288.75, p : 85341.28125, l : 526.587524414\n",
      "batch 151, ep 150, training accuracy 0.92\n",
      "f : 9494.17675781, q : 94448.34375, p : 85334.9140625, l : 524.789306641\n",
      "valid accuracy 0.8987\n",
      "batch 152, ep 0, training accuracy 0.85\n",
      "f : 9772.16113281, q : 94385.28125, p : 85637.171875, l : 973.555480957\n",
      "batch 152, ep 50, training accuracy 0.875\n",
      "f : 10309.2558594, q : 94373.859375, p : 84918.421875, l : 794.694458008\n",
      "batch 152, ep 100, training accuracy 0.87\n",
      "f : 9941.50976562, q : 94395.953125, p : 85218.7890625, l : 790.977172852\n",
      "batch 152, ep 150, training accuracy 0.875\n",
      "f : 9784.34472656, q : 94384.3515625, p : 85409.3515625, l : 794.226806641\n",
      "valid accuracy 0.8975\n",
      "batch 153, ep 0, training accuracy 0.865\n",
      "f : 9731.96582031, q : 94393.296875, p : 85574.5546875, l : 939.568115234\n",
      "batch 153, ep 50, training accuracy 0.9\n",
      "f : 10292.3886719, q : 94323.5078125, p : 84807.0390625, l : 791.961303711\n",
      "batch 153, ep 100, training accuracy 0.895\n",
      "f : 9928.546875, q : 94301.0078125, p : 85201.3046875, l : 789.29095459\n",
      "batch 153, ep 150, training accuracy 0.895\n",
      "f : 9744.35058594, q : 94250.875, p : 85344.1015625, l : 788.878051758\n",
      "valid accuracy 0.8887\n",
      "batch 154, ep 0, training accuracy 0.9\n",
      "f : 9805.65625, q : 94300.6171875, p : 85476.4765625, l : 1001.62823486\n",
      "batch 154, ep 50, training accuracy 0.92\n",
      "f : 10352.0625, q : 94271.890625, p : 84866.6171875, l : 841.931762695\n",
      "batch 154, ep 100, training accuracy 0.92\n",
      "f : 9976.5234375, q : 94315.7578125, p : 85137.15625, l : 838.851745605\n",
      "batch 154, ep 150, training accuracy 0.92\n",
      "f : 9818.98339844, q : 94280.34375, p : 85374.6015625, l : 841.806884766\n",
      "valid accuracy 0.8922\n",
      "batch 155, ep 0, training accuracy 0.87\n",
      "f : 10031.6416016, q : 94212.5703125, p : 85455.2421875, l : 1235.81738281\n",
      "batch 155, ep 50, training accuracy 0.89\n",
      "f : 10594.4570312, q : 94189.9453125, p : 84788.90625, l : 1111.77026367\n",
      "batch 155, ep 100, training accuracy 0.89\n",
      "f : 10233.5087891, q : 94219.1484375, p : 85136.7578125, l : 1110.77587891\n",
      "batch 155, ep 150, training accuracy 0.89\n",
      "f : 10089.8105469, q : 94217.25, p : 85271.4765625, l : 1097.00305176\n",
      "valid accuracy 0.8949\n",
      "batch 156, ep 0, training accuracy 0.825\n",
      "f : 10123.8271484, q : 94195.8671875, p : 85397.4921875, l : 1327.33483887\n",
      "batch 156, ep 50, training accuracy 0.84\n",
      "f : 10642.7431641, q : 94170.9140625, p : 84646.328125, l : 1131.32580566\n",
      "batch 156, ep 100, training accuracy 0.835\n",
      "f : 10271.7050781, q : 94206.3203125, p : 85076.578125, l : 1119.09875488\n",
      "batch 156, ep 150, training accuracy 0.835\n",
      "f : 10119.4082031, q : 94197.6640625, p : 85148.0078125, l : 1114.05322266\n",
      "valid accuracy 0.8984\n",
      "batch 157, ep 0, training accuracy 0.89\n",
      "f : 9795.46777344, q : 94246.625, p : 85457.234375, l : 997.845092773\n",
      "batch 157, ep 50, training accuracy 0.89\n",
      "f : 10371.7890625, q : 94227.0234375, p : 84691.2265625, l : 866.020202637\n",
      "batch 157, ep 100, training accuracy 0.89\n",
      "f : 9994.08105469, q : 94149.2421875, p : 85000.6796875, l : 871.793579102\n",
      "batch 157, ep 150, training accuracy 0.89\n",
      "f : 9830.73925781, q : 94192.9375, p : 85184.3515625, l : 867.039428711\n",
      "valid accuracy 0.8979\n",
      "batch 158, ep 0, training accuracy 0.825\n",
      "f : 10037.6816406, q : 94181.7734375, p : 85336.2109375, l : 1245.63842773\n",
      "batch 158, ep 50, training accuracy 0.845\n",
      "f : 10593.0019531, q : 94146.1953125, p : 84570.140625, l : 1071.93640137\n",
      "batch 158, ep 100, training accuracy 0.85\n",
      "f : 10232.3417969, q : 94102.5859375, p : 84911.8984375, l : 1081.87902832\n",
      "batch 158, ep 150, training accuracy 0.84\n",
      "f : 10074.8994141, q : 94211.015625, p : 85099.3515625, l : 1088.89477539\n",
      "valid accuracy 0.8977\n",
      "batch 159, ep 0, training accuracy 0.86\n",
      "f : 9665.15332031, q : 94209.265625, p : 85337.765625, l : 867.805419922\n",
      "batch 159, ep 50, training accuracy 0.885\n",
      "f : 11408.5957031, q : 94082.4453125, p : 83496.6640625, l : 691.275512695\n",
      "batch 159, ep 100, training accuracy 0.89\n",
      "f : 9814.40625, q : 94137.421875, p : 85045.1953125, l : 677.804199219\n",
      "batch 159, ep 150, training accuracy 0.89\n",
      "f : 9663.45214844, q : 94107.8984375, p : 85116.2109375, l : 679.94519043\n",
      "valid accuracy 0.8943\n",
      "batch 160, ep 0, training accuracy 0.875\n",
      "f : 9755.81640625, q : 94125.6171875, p : 85336.1484375, l : 956.710876465\n",
      "batch 160, ep 50, training accuracy 0.89\n",
      "f : 10303.2597656, q : 94062.6875, p : 84660.28125, l : 823.798095703\n",
      "batch 160, ep 100, training accuracy 0.89\n",
      "f : 9941.63769531, q : 94064.40625, p : 84968.6796875, l : 820.202941895\n",
      "batch 160, ep 150, training accuracy 0.89\n",
      "f : 9771.19726562, q : 94099.625, p : 85111.8671875, l : 819.032958984\n",
      "valid accuracy 0.8959\n",
      "batch 161, ep 0, training accuracy 0.845\n",
      "f : 9886.26660156, q : 94130.4453125, p : 85256.5546875, l : 1096.48046875\n",
      "batch 161, ep 50, training accuracy 0.865\n",
      "f : 10435.3779297, q : 94131.0546875, p : 84623.34375, l : 937.816650391\n",
      "batch 161, ep 100, training accuracy 0.855\n",
      "f : 10077.5068359, q : 94047.859375, p : 84898.8828125, l : 931.133728027\n",
      "batch 161, ep 150, training accuracy 0.855\n",
      "f : 9891.67480469, q : 94100.2734375, p : 85109.3671875, l : 925.555053711\n",
      "valid accuracy 0.896\n",
      "batch 162, ep 0, training accuracy 0.84\n",
      "f : 9917.16113281, q : 94113.7578125, p : 85323.0546875, l : 1113.60791016\n",
      "batch 162, ep 50, training accuracy 0.87\n",
      "f : 10425.7910156, q : 94047.3828125, p : 84515.703125, l : 944.803222656\n",
      "batch 162, ep 100, training accuracy 0.87\n",
      "f : 10101.7568359, q : 94105.5546875, p : 84875.0546875, l : 948.794311523\n",
      "batch 162, ep 150, training accuracy 0.87\n",
      "f : 9949.78222656, q : 93946.9453125, p : 85051.140625, l : 948.364990234\n",
      "valid accuracy 0.8983\n",
      "batch 163, ep 0, training accuracy 0.9\n",
      "f : 9675.88183594, q : 94034.0625, p : 85175.328125, l : 865.990661621\n",
      "batch 163, ep 50, training accuracy 0.92\n",
      "f : 10237.0185547, q : 93935.1875, p : 84511.703125, l : 753.80078125\n",
      "batch 163, ep 100, training accuracy 0.92\n",
      "f : 9872.72265625, q : 94009.3828125, p : 84907.0234375, l : 756.032470703\n",
      "batch 163, ep 150, training accuracy 0.92\n",
      "f : 9728.24316406, q : 93961.8671875, p : 85008.4375, l : 759.12109375\n",
      "valid accuracy 0.8997\n",
      "batch 164, ep 0, training accuracy 0.91\n",
      "f : 9422.37695312, q : 93998.078125, p : 85235.171875, l : 622.926269531\n",
      "batch 164, ep 50, training accuracy 0.92\n",
      "f : 10000.8535156, q : 93973.203125, p : 84528.4921875, l : 519.516296387\n",
      "batch 164, ep 100, training accuracy 0.925\n",
      "f : 9630.75488281, q : 93906.3359375, p : 84821.125, l : 510.902587891\n",
      "batch 164, ep 150, training accuracy 0.925\n",
      "f : 9485.58398438, q : 93971.84375, p : 84900.734375, l : 512.77532959\n",
      "valid accuracy 0.8981\n",
      "batch 165, ep 0, training accuracy 0.9\n",
      "f : 9462.44238281, q : 93954.046875, p : 85140.5703125, l : 667.283569336\n",
      "batch 165, ep 50, training accuracy 0.93\n",
      "f : 10032.9169922, q : 93907.015625, p : 84406.015625, l : 547.204956055\n",
      "batch 165, ep 100, training accuracy 0.93\n",
      "f : 9670.67480469, q : 93823.7734375, p : 84773.34375, l : 547.063720703\n",
      "batch 165, ep 150, training accuracy 0.93\n",
      "f : 9499.59960938, q : 93967.015625, p : 84957.1171875, l : 556.753723145\n",
      "valid accuracy 0.8978\n",
      "batch 166, ep 0, training accuracy 0.865\n",
      "f : 9662.55859375, q : 93904.1484375, p : 85115.40625, l : 859.426025391\n",
      "batch 166, ep 50, training accuracy 0.895\n",
      "f : 10201.7460938, q : 93845.40625, p : 84539.84375, l : 729.874267578\n",
      "batch 166, ep 100, training accuracy 0.895\n",
      "f : 9849.75683594, q : 93850.5859375, p : 84794.3203125, l : 736.69519043\n",
      "batch 166, ep 150, training accuracy 0.89\n",
      "f : 9707.83984375, q : 93998.3515625, p : 84931.875, l : 724.989990234\n",
      "valid accuracy 0.8997\n",
      "batch 167, ep 0, training accuracy 0.905\n",
      "f : 9554.94335938, q : 93908.296875, p : 85149.234375, l : 757.528503418\n",
      "batch 167, ep 50, training accuracy 0.92\n",
      "f : 10112.9228516, q : 93827.484375, p : 84396.4453125, l : 664.981994629\n",
      "batch 167, ep 100, training accuracy 0.92\n",
      "f : 9772.30859375, q : 93834.2734375, p : 84769.4453125, l : 672.134277344\n",
      "batch 167, ep 150, training accuracy 0.915\n",
      "f : 9630.70898438, q : 93869.1015625, p : 84899.9296875, l : 664.426025391\n",
      "valid accuracy 0.8986\n",
      "batch 168, ep 0, training accuracy 0.91\n",
      "f : 9359.37011719, q : 93767.8125, p : 85046.796875, l : 559.318115234\n",
      "batch 168, ep 50, training accuracy 0.915\n",
      "f : 9955.05273438, q : 93843.40625, p : 84431.375, l : 509.644042969\n",
      "batch 168, ep 100, training accuracy 0.92\n",
      "f : 9613.43457031, q : 93832.4140625, p : 84725.6328125, l : 506.97833252\n",
      "batch 168, ep 150, training accuracy 0.92\n",
      "f : 9465.0078125, q : 93742.875, p : 84929.84375, l : 508.644104004\n",
      "valid accuracy 0.8998\n",
      "batch 169, ep 0, training accuracy 0.94\n",
      "f : 9119.77734375, q : 93801.8515625, p : 85057.6953125, l : 325.651672363\n",
      "batch 169, ep 50, training accuracy 0.95\n",
      "f : 9714.99902344, q : 93818.90625, p : 84423.328125, l : 294.145843506\n",
      "batch 169, ep 100, training accuracy 0.95\n",
      "f : 9381.15527344, q : 93759.21875, p : 84743.59375, l : 295.73248291\n",
      "batch 169, ep 150, training accuracy 0.945\n",
      "f : 9214.71386719, q : 93841.703125, p : 84865.453125, l : 294.20993042\n",
      "valid accuracy 0.9007\n",
      "batch 170, ep 0, training accuracy 0.88\n",
      "f : 9483.93164062, q : 93774.234375, p : 85051.453125, l : 683.321228027\n",
      "batch 170, ep 50, training accuracy 0.89\n",
      "f : 10057.0605469, q : 93778.6796875, p : 84292.078125, l : 604.153442383\n",
      "batch 170, ep 100, training accuracy 0.89\n",
      "f : 9703.90039062, q : 93823.921875, p : 84676.578125, l : 608.805480957\n",
      "batch 170, ep 150, training accuracy 0.89\n",
      "f : 9568.265625, q : 93777.9296875, p : 84831.6015625, l : 609.481872559\n",
      "valid accuracy 0.9002\n",
      "batch 171, ep 0, training accuracy 0.94\n",
      "f : 9228.44335938, q : 93815.6953125, p : 85017.3828125, l : 429.900787354\n",
      "batch 171, ep 50, training accuracy 0.945\n",
      "f : 9806.33105469, q : 93761.8203125, p : 84291.1640625, l : 373.15234375\n",
      "batch 171, ep 100, training accuracy 0.945\n",
      "f : 9456.93554688, q : 93751.03125, p : 84726.296875, l : 372.787841797\n",
      "batch 171, ep 150, training accuracy 0.945\n",
      "f : 9291.80859375, q : 93695.515625, p : 84771.75, l : 372.289794922\n",
      "valid accuracy 0.9007\n",
      "batch 172, ep 0, training accuracy 0.86\n",
      "f : 9699.6953125, q : 93706.3515625, p : 84860.984375, l : 896.319824219\n",
      "batch 172, ep 50, training accuracy 0.88\n",
      "f : 10295.9052734, q : 93660.7265625, p : 84154.0390625, l : 791.157409668\n",
      "batch 172, ep 100, training accuracy 0.87\n",
      "f : 9902.46289062, q : 93740.8828125, p : 84587.359375, l : 784.160522461\n",
      "batch 172, ep 150, training accuracy 0.875\n",
      "f : 9762.40136719, q : 93637.9375, p : 84675.671875, l : 784.512817383\n",
      "valid accuracy 0.9001\n",
      "batch 173, ep 0, training accuracy 0.865\n",
      "f : 9728.75488281, q : 93658.296875, p : 84764.53125, l : 935.453613281\n",
      "batch 173, ep 50, training accuracy 0.895\n",
      "f : 10361.1865234, q : 93637.25, p : 84111.0625, l : 818.19128418\n",
      "batch 173, ep 100, training accuracy 0.895\n",
      "f : 9916.36132812, q : 93607.71875, p : 84576.390625, l : 817.408874512\n",
      "batch 173, ep 150, training accuracy 0.9\n",
      "f : 9793.24121094, q : 93583.7734375, p : 84661.7265625, l : 817.831787109\n",
      "valid accuracy 0.8982\n",
      "batch 174, ep 0, training accuracy 0.875\n",
      "f : 9751.54296875, q : 93617.546875, p : 84902.3359375, l : 946.501342773\n",
      "batch 174, ep 50, training accuracy 0.89\n",
      "f : 10290.8300781, q : 93605.0546875, p : 84135.53125, l : 824.607543945\n",
      "batch 174, ep 100, training accuracy 0.89\n",
      "f : 9948.53515625, q : 93699.5, p : 84452.515625, l : 827.022155762\n",
      "batch 174, ep 150, training accuracy 0.89\n",
      "f : 9811.51953125, q : 93599.046875, p : 84708.8125, l : 820.063354492\n",
      "valid accuracy 0.8999\n",
      "batch 175, ep 0, training accuracy 0.9\n",
      "f : 9405.73535156, q : 93664.5859375, p : 84886.2109375, l : 598.995056152\n",
      "batch 175, ep 50, training accuracy 0.91\n",
      "f : 9961.5, q : 93622.265625, p : 84174.8828125, l : 523.613952637\n",
      "batch 175, ep 100, training accuracy 0.915\n",
      "f : 9609.88378906, q : 93598.34375, p : 84435.1875, l : 524.649108887\n",
      "batch 175, ep 150, training accuracy 0.915\n",
      "f : 9479.89160156, q : 93647.8203125, p : 84624.703125, l : 520.305175781\n",
      "valid accuracy 0.9002\n",
      "batch 176, ep 0, training accuracy 0.92\n",
      "f : 9397.41113281, q : 93585.1640625, p : 84867.3984375, l : 603.971008301\n",
      "batch 176, ep 50, training accuracy 0.935\n",
      "f : 9958.21679688, q : 93594.9921875, p : 84162.0, l : 532.244262695\n",
      "batch 176, ep 100, training accuracy 0.93\n",
      "f : 9630.09960938, q : 93584.2109375, p : 84482.6015625, l : 535.46484375\n",
      "batch 176, ep 150, training accuracy 0.925\n",
      "f : 9441.59765625, q : 93528.8515625, p : 84630.4453125, l : 532.200439453\n",
      "valid accuracy 0.9017\n",
      "batch 177, ep 0, training accuracy 0.865\n",
      "f : 9880.80078125, q : 93587.5859375, p : 84747.8671875, l : 1079.70959473\n",
      "batch 177, ep 50, training accuracy 0.88\n",
      "f : 10441.984375, q : 93501.65625, p : 84066.0234375, l : 951.11730957\n",
      "batch 177, ep 100, training accuracy 0.88\n",
      "f : 10075.5771484, q : 93507.4140625, p : 84395.6015625, l : 961.405517578\n",
      "batch 177, ep 150, training accuracy 0.885\n",
      "f : 9911.16308594, q : 93612.84375, p : 84586.90625, l : 955.419311523\n",
      "valid accuracy 0.9007\n",
      "batch 178, ep 0, training accuracy 0.9\n",
      "f : 9384.52734375, q : 93565.3203125, p : 84782.71875, l : 587.855529785\n",
      "batch 178, ep 50, training accuracy 0.915\n",
      "f : 9944.1640625, q : 93549.796875, p : 84139.9765625, l : 498.214874268\n",
      "batch 178, ep 100, training accuracy 0.92\n",
      "f : 9602.05957031, q : 93488.6015625, p : 84470.1640625, l : 505.059997559\n",
      "batch 178, ep 150, training accuracy 0.925\n",
      "f : 9406.60449219, q : 93605.0, p : 84628.421875, l : 497.321258545\n",
      "valid accuracy 0.8995\n",
      "batch 179, ep 0, training accuracy 0.9\n",
      "f : 9357.02734375, q : 93577.015625, p : 84674.9453125, l : 571.133056641\n",
      "batch 179, ep 50, training accuracy 0.905\n",
      "f : 9919.30371094, q : 93505.46875, p : 84063.3203125, l : 491.111633301\n",
      "batch 179, ep 100, training accuracy 0.91\n",
      "f : 9589.68652344, q : 93528.7421875, p : 84419.609375, l : 493.372924805\n",
      "batch 179, ep 150, training accuracy 0.9\n",
      "f : 9402.1796875, q : 93491.375, p : 84613.0859375, l : 491.664367676\n",
      "valid accuracy 0.8991\n",
      "batch 180, ep 0, training accuracy 0.88\n",
      "f : 9750.67871094, q : 93504.7578125, p : 84693.28125, l : 954.348449707\n",
      "batch 180, ep 50, training accuracy 0.885\n",
      "f : 10285.0234375, q : 93448.453125, p : 84003.6796875, l : 849.807250977\n",
      "batch 180, ep 100, training accuracy 0.89\n",
      "f : 9959.9296875, q : 93326.7265625, p : 84392.859375, l : 842.219970703\n",
      "batch 180, ep 150, training accuracy 0.89\n",
      "f : 9825.15820312, q : 93411.703125, p : 84491.625, l : 844.296386719\n",
      "valid accuracy 0.8988\n",
      "batch 181, ep 0, training accuracy 0.89\n",
      "f : 9428.88769531, q : 93471.3125, p : 84678.7890625, l : 628.826293945\n",
      "batch 181, ep 50, training accuracy 0.895\n",
      "f : 9969.44335938, q : 93428.8125, p : 83982.6953125, l : 532.782836914\n",
      "batch 181, ep 100, training accuracy 0.905\n",
      "f : 9629.45703125, q : 93339.8125, p : 84330.1953125, l : 536.239013672\n",
      "batch 181, ep 150, training accuracy 0.91\n",
      "f : 9477.875, q : 93445.796875, p : 84530.765625, l : 535.564941406\n",
      "valid accuracy 0.9001\n",
      "batch 182, ep 0, training accuracy 0.865\n",
      "f : 9709.36523438, q : 93338.2890625, p : 84533.875, l : 908.416687012\n",
      "batch 182, ep 50, training accuracy 0.88\n",
      "f : 10239.6601562, q : 93376.7421875, p : 83985.109375, l : 756.628356934\n",
      "batch 182, ep 100, training accuracy 0.88\n",
      "f : 9894.96386719, q : 93399.25, p : 84298.453125, l : 763.402954102\n",
      "batch 182, ep 150, training accuracy 0.88\n",
      "f : 9735.07128906, q : 93370.9765625, p : 84364.78125, l : 760.424194336\n",
      "valid accuracy 0.8995\n",
      "batch 183, ep 0, training accuracy 0.92\n",
      "f : 9405.26757812, q : 93433.109375, p : 84648.9609375, l : 601.01550293\n",
      "batch 183, ep 50, training accuracy 0.93\n",
      "f : 9954.92285156, q : 93514.2421875, p : 83928.8515625, l : 522.152587891\n",
      "batch 183, ep 100, training accuracy 0.925\n",
      "f : 9623.75878906, q : 93288.2265625, p : 84418.5546875, l : 527.10736084\n",
      "batch 183, ep 150, training accuracy 0.925\n",
      "f : 9479.56445312, q : 93405.0234375, p : 84449.4921875, l : 522.775634766\n",
      "valid accuracy 0.8985\n",
      "batch 184, ep 0, training accuracy 0.915\n",
      "f : 9390.04296875, q : 93372.125, p : 84632.9609375, l : 600.916015625\n",
      "batch 184, ep 50, training accuracy 0.92\n",
      "f : 9958.72167969, q : 93442.390625, p : 83900.15625, l : 505.764648438\n",
      "batch 184, ep 100, training accuracy 0.92\n",
      "f : 9615.10253906, q : 93361.6015625, p : 84237.6328125, l : 507.294647217\n",
      "batch 184, ep 150, training accuracy 0.92\n",
      "f : 9444.64453125, q : 93268.890625, p : 84346.2265625, l : 507.273376465\n",
      "valid accuracy 0.8998\n",
      "batch 185, ep 0, training accuracy 0.89\n",
      "f : 9583.97460938, q : 93337.765625, p : 84515.984375, l : 785.075195312\n",
      "batch 185, ep 50, training accuracy 0.91\n",
      "f : 10146.3759766, q : 93316.3359375, p : 83838.0078125, l : 673.999206543\n",
      "batch 185, ep 100, training accuracy 0.91\n",
      "f : 9794.83886719, q : 93332.0, p : 84146.140625, l : 674.568237305\n",
      "batch 185, ep 150, training accuracy 0.91\n",
      "f : 9637.16015625, q : 93292.859375, p : 84262.5703125, l : 674.281860352\n",
      "valid accuracy 0.8979\n",
      "batch 186, ep 0, training accuracy 0.865\n",
      "f : 10024.9902344, q : 93381.8125, p : 84554.359375, l : 1233.25866699\n",
      "batch 186, ep 50, training accuracy 0.875\n",
      "f : 10533.6787109, q : 93259.015625, p : 83851.921875, l : 1060.73571777\n",
      "batch 186, ep 100, training accuracy 0.875\n",
      "f : 10207.1015625, q : 93299.8203125, p : 84204.7734375, l : 1062.12158203\n",
      "batch 186, ep 150, training accuracy 0.87\n",
      "f : 10027.6279297, q : 93267.84375, p : 84362.015625, l : 1071.00512695\n",
      "valid accuracy 0.8998\n",
      "batch 187, ep 0, training accuracy 0.81\n",
      "f : 10241.9453125, q : 93324.3515625, p : 84491.4296875, l : 1451.82861328\n",
      "batch 187, ep 50, training accuracy 0.83\n",
      "f : 11658.8710938, q : 93274.03125, p : 82686.8515625, l : 1036.46630859\n",
      "batch 187, ep 100, training accuracy 0.855\n",
      "f : 10513.7832031, q : 93306.78125, p : 83778.2109375, l : 1013.79022217\n",
      "batch 187, ep 150, training accuracy 0.855\n",
      "f : 10038.7529297, q : 93214.4765625, p : 84283.7109375, l : 1016.33630371\n",
      "valid accuracy 0.8937\n",
      "batch 188, ep 0, training accuracy 0.875\n",
      "f : 9670.62011719, q : 93272.875, p : 84432.546875, l : 883.152648926\n",
      "batch 188, ep 50, training accuracy 0.885\n",
      "f : 10205.9570312, q : 93231.5625, p : 83791.046875, l : 750.038757324\n",
      "batch 188, ep 100, training accuracy 0.89\n",
      "f : 9859.02050781, q : 93273.328125, p : 84041.078125, l : 756.878112793\n",
      "batch 188, ep 150, training accuracy 0.885\n",
      "f : 9725.66699219, q : 93251.8203125, p : 84295.6953125, l : 751.951965332\n",
      "valid accuracy 0.8968\n",
      "batch 189, ep 0, training accuracy 0.895\n",
      "f : 9584.33886719, q : 93275.015625, p : 84426.828125, l : 782.720703125\n",
      "batch 189, ep 50, training accuracy 0.915\n",
      "f : 10116.2402344, q : 93191.3203125, p : 83732.1640625, l : 705.506652832\n",
      "batch 189, ep 100, training accuracy 0.915\n",
      "f : 9796.41992188, q : 93277.0859375, p : 84199.859375, l : 700.639160156\n",
      "batch 189, ep 150, training accuracy 0.915\n",
      "f : 9667.99804688, q : 93282.3125, p : 84191.25, l : 705.69921875\n",
      "valid accuracy 0.8974\n",
      "batch 190, ep 0, training accuracy 0.88\n",
      "f : 9516.7421875, q : 93203.9375, p : 84380.1171875, l : 726.604492188\n",
      "batch 190, ep 50, training accuracy 0.895\n",
      "f : 10032.9169922, q : 93260.265625, p : 83676.9453125, l : 591.434692383\n",
      "batch 190, ep 100, training accuracy 0.89\n",
      "f : 9708.12988281, q : 93196.875, p : 84094.1484375, l : 592.515136719\n",
      "batch 190, ep 150, training accuracy 0.895\n",
      "f : 9552.46191406, q : 93224.53125, p : 84179.9375, l : 594.314575195\n",
      "valid accuracy 0.8971\n",
      "batch 191, ep 0, training accuracy 0.88\n",
      "f : 9518.4921875, q : 93179.6015625, p : 84360.015625, l : 716.935913086\n",
      "batch 191, ep 50, training accuracy 0.9\n",
      "f : 10062.0117188, q : 93212.7421875, p : 83700.65625, l : 631.612121582\n",
      "batch 191, ep 100, training accuracy 0.9\n",
      "f : 9736.36328125, q : 93124.2890625, p : 84061.046875, l : 632.496582031\n",
      "batch 191, ep 150, training accuracy 0.905\n",
      "f : 9568.78710938, q : 93172.5859375, p : 84220.921875, l : 628.820678711\n",
      "valid accuracy 0.8976\n",
      "batch 192, ep 0, training accuracy 0.89\n",
      "f : 9641.41113281, q : 93154.4453125, p : 84429.8359375, l : 840.854614258\n",
      "batch 192, ep 50, training accuracy 0.91\n",
      "f : 10159.5078125, q : 93111.9140625, p : 83695.5, l : 734.375915527\n",
      "batch 192, ep 100, training accuracy 0.91\n",
      "f : 9834.51757812, q : 93142.8671875, p : 84087.03125, l : 736.582397461\n",
      "batch 192, ep 150, training accuracy 0.915\n",
      "f : 9698.64453125, q : 93120.171875, p : 84143.1328125, l : 742.737976074\n",
      "valid accuracy 0.8962\n",
      "batch 193, ep 0, training accuracy 0.855\n",
      "f : 9858.8828125, q : 93127.734375, p : 84290.84375, l : 1053.51574707\n",
      "batch 193, ep 50, training accuracy 0.86\n",
      "f : 10359.7666016, q : 93085.765625, p : 83637.21875, l : 913.244750977\n",
      "batch 193, ep 100, training accuracy 0.865\n",
      "f : 10040.7148438, q : 93074.03125, p : 83953.640625, l : 906.821289062\n",
      "batch 193, ep 150, training accuracy 0.865\n",
      "f : 9908.08984375, q : 93094.3984375, p : 84132.765625, l : 905.179199219\n",
      "valid accuracy 0.8998\n",
      "batch 194, ep 0, training accuracy 0.93\n",
      "f : 9233.52929688, q : 93021.0546875, p : 84363.0234375, l : 439.714172363\n",
      "batch 194, ep 50, training accuracy 0.94\n",
      "f : 9786.43066406, q : 93102.1875, p : 83648.421875, l : 371.376708984\n",
      "batch 194, ep 100, training accuracy 0.945\n",
      "f : 9448.25292969, q : 93054.0859375, p : 83987.9921875, l : 376.673156738\n",
      "batch 194, ep 150, training accuracy 0.94\n",
      "f : 9310.31542969, q : 93114.5703125, p : 84089.8203125, l : 380.283203125\n",
      "valid accuracy 0.9002\n",
      "batch 195, ep 0, training accuracy 0.91\n",
      "f : 9591.99804688, q : 93145.71875, p : 84272.984375, l : 792.754150391\n",
      "batch 195, ep 50, training accuracy 0.915\n",
      "f : 10143.7646484, q : 92987.7421875, p : 83512.578125, l : 699.543701172\n",
      "batch 195, ep 100, training accuracy 0.91\n",
      "f : 9791.81445312, q : 93043.4453125, p : 83992.578125, l : 708.380981445\n",
      "batch 195, ep 150, training accuracy 0.91\n",
      "f : 9648.25292969, q : 93029.46875, p : 84115.6953125, l : 705.209838867\n",
      "valid accuracy 0.9014\n",
      "batch 196, ep 0, training accuracy 0.855\n",
      "f : 10023.2529297, q : 93076.4140625, p : 84233.9609375, l : 1224.19592285\n",
      "batch 196, ep 50, training accuracy 0.865\n",
      "f : 10528.7529297, q : 93017.390625, p : 83530.9296875, l : 1089.53833008\n",
      "batch 196, ep 100, training accuracy 0.865\n",
      "f : 10203.6044922, q : 93041.6796875, p : 83973.5703125, l : 1089.60803223\n",
      "batch 196, ep 150, training accuracy 0.87\n",
      "f : 10030.9111328, q : 93009.265625, p : 84017.8984375, l : 1090.90808105\n",
      "valid accuracy 0.8991\n",
      "batch 197, ep 0, training accuracy 0.89\n",
      "f : 9782.16992188, q : 93056.0625, p : 84204.0546875, l : 986.369262695\n",
      "batch 197, ep 50, training accuracy 0.905\n",
      "f : 10595.84375, q : 92975.9375, p : 83228.390625, l : 810.682189941\n",
      "batch 197, ep 100, training accuracy 0.905\n",
      "f : 9948.51269531, q : 93008.5078125, p : 83851.375, l : 815.181884766\n",
      "batch 197, ep 150, training accuracy 0.9\n",
      "f : 9819.43847656, q : 92961.6640625, p : 84054.2890625, l : 813.981201172\n",
      "valid accuracy 0.8981\n",
      "batch 198, ep 0, training accuracy 0.88\n",
      "f : 9670.21191406, q : 93003.3125, p : 84173.3359375, l : 881.426879883\n",
      "batch 198, ep 50, training accuracy 0.905\n",
      "f : 10161.5908203, q : 92886.171875, p : 83460.75, l : 734.499328613\n",
      "batch 198, ep 100, training accuracy 0.905\n",
      "f : 9853.76269531, q : 92900.2109375, p : 83786.140625, l : 734.988769531\n",
      "batch 198, ep 150, training accuracy 0.905\n",
      "f : 9706.76171875, q : 93026.8359375, p : 84010.2890625, l : 742.162719727\n",
      "valid accuracy 0.9013\n",
      "batch 199, ep 0, training accuracy 0.855\n",
      "f : 9853.58105469, q : 92904.96875, p : 84133.375, l : 1057.77856445\n",
      "batch 199, ep 50, training accuracy 0.895\n",
      "f : 10323.7998047, q : 92947.0546875, p : 83510.6484375, l : 904.037353516\n",
      "batch 199, ep 100, training accuracy 0.895\n",
      "f : 10032.1962891, q : 92929.8203125, p : 83774.9609375, l : 903.027099609\n",
      "batch 199, ep 150, training accuracy 0.895\n",
      "f : 9880.71191406, q : 92874.71875, p : 83952.9453125, l : 904.339355469\n",
      "valid accuracy 0.9007\n",
      "batch 200, ep 0, training accuracy 0.905\n",
      "f : 9335.27539062, q : 92971.3125, p : 84094.625, l : 545.90625\n",
      "batch 200, ep 50, training accuracy 0.925\n",
      "f : 9877.7578125, q : 92833.421875, p : 83408.859375, l : 465.998809814\n",
      "batch 200, ep 100, training accuracy 0.92\n",
      "f : 9543.95605469, q : 92955.3125, p : 83882.484375, l : 464.676940918\n",
      "batch 200, ep 150, training accuracy 0.925\n",
      "f : 9412.04492188, q : 92963.9921875, p : 83981.96875, l : 462.928771973\n",
      "valid accuracy 0.9013\n",
      "batch 201, ep 0, training accuracy 0.925\n",
      "f : 9407.32226562, q : 92882.9609375, p : 84064.1875, l : 602.735656738\n",
      "batch 201, ep 50, training accuracy 0.92\n",
      "f : 9954.26855469, q : 92840.484375, p : 83434.75, l : 505.467376709\n",
      "batch 201, ep 100, training accuracy 0.92\n",
      "f : 9597.47460938, q : 92846.1015625, p : 83768.6796875, l : 504.873291016\n",
      "batch 201, ep 150, training accuracy 0.92\n",
      "f : 9422.92578125, q : 92810.59375, p : 83952.1171875, l : 506.660003662\n",
      "valid accuracy 0.9026\n",
      "batch 202, ep 0, training accuracy 0.91\n",
      "f : 9422.24609375, q : 92888.8203125, p : 84101.015625, l : 618.681030273\n",
      "batch 202, ep 50, training accuracy 0.925\n",
      "f : 9919.17578125, q : 92791.828125, p : 83388.515625, l : 530.120056152\n",
      "batch 202, ep 100, training accuracy 0.93\n",
      "f : 9614.85644531, q : 92823.5703125, p : 83802.2109375, l : 529.970458984\n",
      "batch 202, ep 150, training accuracy 0.925\n",
      "f : 9455.26757812, q : 92817.7265625, p : 84021.3984375, l : 531.187561035\n",
      "valid accuracy 0.9017\n",
      "batch 203, ep 0, training accuracy 0.92\n",
      "f : 9320.02148438, q : 92789.671875, p : 84103.59375, l : 525.976196289\n",
      "batch 203, ep 50, training accuracy 0.915\n",
      "f : 9866.25195312, q : 92852.5625, p : 83539.7421875, l : 470.396636963\n",
      "batch 203, ep 100, training accuracy 0.925\n",
      "f : 9546.34375, q : 92865.5703125, p : 83856.265625, l : 470.295776367\n",
      "batch 203, ep 150, training accuracy 0.925\n",
      "f : 9404.2109375, q : 92786.0546875, p : 83850.7109375, l : 464.866210938\n",
      "valid accuracy 0.9022\n",
      "batch 204, ep 0, training accuracy 0.895\n",
      "f : 9389.72167969, q : 92837.6015625, p : 83967.28125, l : 591.102783203\n",
      "batch 204, ep 50, training accuracy 0.9\n",
      "f : 9933.20019531, q : 92804.4140625, p : 83322.515625, l : 497.665618896\n",
      "batch 204, ep 100, training accuracy 0.905\n",
      "f : 9580.19238281, q : 92767.8359375, p : 83712.703125, l : 502.240661621\n",
      "batch 204, ep 150, training accuracy 0.9\n",
      "f : 9449.00097656, q : 92760.2734375, p : 83776.2890625, l : 500.008178711\n",
      "valid accuracy 0.9026\n",
      "batch 205, ep 0, training accuracy 0.93\n",
      "f : 9461.17578125, q : 92764.3046875, p : 84001.171875, l : 665.117553711\n",
      "batch 205, ep 50, training accuracy 0.94\n",
      "f : 9990.68652344, q : 92718.4453125, p : 83271.328125, l : 564.686279297\n",
      "batch 205, ep 100, training accuracy 0.94\n",
      "f : 9662.94433594, q : 92786.2265625, p : 83699.7421875, l : 567.55090332\n",
      "batch 205, ep 150, training accuracy 0.945\n",
      "f : 9530.62988281, q : 92708.46875, p : 83834.5, l : 564.483642578\n",
      "valid accuracy 0.9011\n",
      "batch 206, ep 0, training accuracy 0.835\n",
      "f : 10035.8671875, q : 92741.5, p : 83930.1640625, l : 1231.13305664\n",
      "batch 206, ep 50, training accuracy 0.875\n",
      "f : 10495.96875, q : 92762.8125, p : 83262.5, l : 1002.70849609\n",
      "batch 206, ep 100, training accuracy 0.865\n",
      "f : 10135.1552734, q : 92755.125, p : 83686.6875, l : 1006.69555664\n",
      "batch 206, ep 150, training accuracy 0.87\n",
      "f : 10024.6640625, q : 92725.6484375, p : 83756.796875, l : 1021.12658691\n",
      "valid accuracy 0.9031\n",
      "batch 207, ep 0, training accuracy 0.85\n",
      "f : 9891.95507812, q : 92770.609375, p : 84044.484375, l : 1107.50708008\n",
      "batch 207, ep 50, training accuracy 0.865\n",
      "f : 10396.8623047, q : 92685.0234375, p : 83175.984375, l : 932.709411621\n",
      "batch 207, ep 100, training accuracy 0.865\n",
      "f : 10054.2490234, q : 92677.2265625, p : 83624.2734375, l : 931.470214844\n",
      "batch 207, ep 150, training accuracy 0.86\n",
      "f : 9933.74707031, q : 92778.1796875, p : 83822.1171875, l : 927.34387207\n",
      "valid accuracy 0.9029\n",
      "batch 208, ep 0, training accuracy 0.92\n",
      "f : 9208.11035156, q : 92639.46875, p : 83889.6640625, l : 415.240844727\n",
      "batch 208, ep 50, training accuracy 0.93\n",
      "f : 9755.71875, q : 92739.40625, p : 83212.5234375, l : 355.628723145\n",
      "batch 208, ep 100, training accuracy 0.925\n",
      "f : 9436.4296875, q : 92642.5625, p : 83658.2734375, l : 353.912231445\n",
      "batch 208, ep 150, training accuracy 0.93\n",
      "f : 9306.73242188, q : 92648.6015625, p : 83812.5546875, l : 359.002166748\n",
      "valid accuracy 0.9008\n",
      "batch 209, ep 0, training accuracy 0.89\n",
      "f : 9548.75195312, q : 92654.875, p : 83963.2890625, l : 750.240600586\n",
      "batch 209, ep 50, training accuracy 0.91\n",
      "f : 10070.8984375, q : 92715.671875, p : 83230.25, l : 644.789123535\n",
      "batch 209, ep 100, training accuracy 0.91\n",
      "f : 9749.95996094, q : 92768.8125, p : 83525.8828125, l : 640.361206055\n",
      "batch 209, ep 150, training accuracy 0.905\n",
      "f : 9607.26660156, q : 92709.6328125, p : 83645.203125, l : 641.586669922\n",
      "valid accuracy 0.8999\n",
      "batch 210, ep 0, training accuracy 0.9\n",
      "f : 9673.5859375, q : 92732.8125, p : 83812.234375, l : 882.455627441\n",
      "batch 210, ep 50, training accuracy 0.905\n",
      "f : 10165.8476562, q : 92699.4609375, p : 83247.8515625, l : 716.800964355\n",
      "batch 210, ep 100, training accuracy 0.905\n",
      "f : 9826.4609375, q : 92631.921875, p : 83514.6875, l : 719.532531738\n",
      "batch 210, ep 150, training accuracy 0.905\n",
      "f : 9680.46484375, q : 92674.34375, p : 83685.5625, l : 711.393676758\n",
      "valid accuracy 0.9021\n",
      "batch 211, ep 0, training accuracy 0.855\n",
      "f : 9702.98828125, q : 92538.140625, p : 83848.046875, l : 905.291870117\n",
      "batch 211, ep 50, training accuracy 0.87\n",
      "f : 10209.3994141, q : 92663.421875, p : 83142.21875, l : 786.632080078\n",
      "batch 211, ep 100, training accuracy 0.87\n",
      "f : 9887.46679688, q : 92599.953125, p : 83480.8828125, l : 797.291137695\n",
      "batch 211, ep 150, training accuracy 0.87\n",
      "f : 9734.63085938, q : 92617.546875, p : 83664.96875, l : 784.98651123\n",
      "valid accuracy 0.9026\n",
      "batch 212, ep 0, training accuracy 0.87\n",
      "f : 9983.04980469, q : 92683.8359375, p : 83883.2265625, l : 1188.71398926\n",
      "batch 212, ep 50, training accuracy 0.885\n",
      "f : 10453.8134766, q : 92562.671875, p : 83217.75, l : 992.96697998\n",
      "batch 212, ep 100, training accuracy 0.885\n",
      "f : 10116.5332031, q : 92571.21875, p : 83421.140625, l : 993.359436035\n",
      "batch 212, ep 150, training accuracy 0.885\n",
      "f : 9986.37792969, q : 92642.15625, p : 83625.0078125, l : 989.243530273\n",
      "valid accuracy 0.9044\n",
      "batch 213, ep 0, training accuracy 0.9\n",
      "f : 9595.13671875, q : 92637.1484375, p : 83781.53125, l : 794.114135742\n",
      "batch 213, ep 50, training accuracy 0.9\n",
      "f : 11139.859375, q : 92591.9453125, p : 82057.671875, l : 704.587158203\n",
      "batch 213, ep 100, training accuracy 0.895\n",
      "f : 9784.36132812, q : 92547.9296875, p : 83445.046875, l : 703.141052246\n",
      "batch 213, ep 150, training accuracy 0.9\n",
      "f : 9659.28613281, q : 92545.5546875, p : 83626.8515625, l : 700.657958984\n",
      "valid accuracy 0.9047\n",
      "batch 214, ep 0, training accuracy 0.855\n",
      "f : 10037.0839844, q : 92478.9765625, p : 83807.0625, l : 1251.83764648\n",
      "batch 214, ep 50, training accuracy 0.875\n",
      "f : 10539.8056641, q : 92490.2265625, p : 83181.1484375, l : 1107.91577148\n",
      "batch 214, ep 100, training accuracy 0.875\n",
      "f : 10206.8916016, q : 92415.90625, p : 83474.8046875, l : 1119.80725098\n",
      "batch 214, ep 150, training accuracy 0.87\n",
      "f : 10086.4775391, q : 92500.6953125, p : 83624.5, l : 1110.33056641\n",
      "valid accuracy 0.9056\n",
      "batch 215, ep 0, training accuracy 0.88\n",
      "f : 9501.42675781, q : 92585.6328125, p : 83753.03125, l : 704.474731445\n",
      "batch 215, ep 50, training accuracy 0.91\n",
      "f : 9978.09472656, q : 92592.703125, p : 83135.15625, l : 574.466918945\n",
      "batch 215, ep 100, training accuracy 0.905\n",
      "f : 9684.40039062, q : 92604.2578125, p : 83376.375, l : 569.966918945\n",
      "batch 215, ep 150, training accuracy 0.91\n",
      "f : 9527.5546875, q : 92479.765625, p : 83583.21875, l : 569.171142578\n",
      "valid accuracy 0.9026\n",
      "batch 216, ep 0, training accuracy 0.92\n",
      "f : 9267.11816406, q : 92594.359375, p : 83749.734375, l : 470.878662109\n",
      "batch 216, ep 50, training accuracy 0.93\n",
      "f : 9822.15917969, q : 92504.5703125, p : 83130.6171875, l : 417.504058838\n",
      "batch 216, ep 100, training accuracy 0.93\n",
      "f : 9491.34863281, q : 92472.421875, p : 83386.609375, l : 425.902038574\n",
      "batch 216, ep 150, training accuracy 0.93\n",
      "f : 9348.01171875, q : 92472.5859375, p : 83611.2578125, l : 416.348175049\n",
      "valid accuracy 0.9036\n",
      "batch 217, ep 0, training accuracy 0.92\n",
      "f : 9219.62890625, q : 92484.0859375, p : 83738.8828125, l : 422.16607666\n",
      "batch 217, ep 50, training accuracy 0.92\n",
      "f : 9756.97949219, q : 92517.4453125, p : 83123.0703125, l : 372.990264893\n",
      "batch 217, ep 100, training accuracy 0.925\n",
      "f : 9438.66992188, q : 92419.71875, p : 83386.4921875, l : 371.952056885\n",
      "batch 217, ep 150, training accuracy 0.92\n",
      "f : 9276.84082031, q : 92436.9375, p : 83517.0625, l : 368.935180664\n",
      "valid accuracy 0.9048\n",
      "batch 218, ep 0, training accuracy 0.915\n",
      "f : 9391.01367188, q : 92473.4921875, p : 83714.453125, l : 597.797912598\n",
      "batch 218, ep 50, training accuracy 0.915\n",
      "f : 9906.41796875, q : 92458.8671875, p : 83099.2890625, l : 505.384765625\n",
      "batch 218, ep 100, training accuracy 0.925\n",
      "f : 9582.05175781, q : 92467.5625, p : 83357.8515625, l : 498.866027832\n",
      "batch 218, ep 150, training accuracy 0.91\n",
      "f : 9459.05859375, q : 92407.390625, p : 83518.234375, l : 505.643737793\n",
      "valid accuracy 0.904\n",
      "batch 219, ep 0, training accuracy 0.88\n",
      "f : 9602.33203125, q : 92463.84375, p : 83620.0390625, l : 813.928344727\n",
      "batch 219, ep 50, training accuracy 0.885\n",
      "f : 10114.8535156, q : 92358.7890625, p : 83056.40625, l : 704.002441406\n",
      "batch 219, ep 100, training accuracy 0.885\n",
      "f : 9794.02148438, q : 92486.0546875, p : 83350.375, l : 712.486938477\n",
      "batch 219, ep 150, training accuracy 0.885\n",
      "f : 9659.08886719, q : 92443.3515625, p : 83439.015625, l : 705.520080566\n",
      "valid accuracy 0.9047\n",
      "batch 220, ep 0, training accuracy 0.885\n",
      "f : 9501.77539062, q : 92417.625, p : 83554.390625, l : 705.430297852\n",
      "batch 220, ep 50, training accuracy 0.88\n",
      "f : 10020.7021484, q : 92428.203125, p : 82962.75, l : 599.483764648\n",
      "batch 220, ep 100, training accuracy 0.9\n",
      "f : 9709.9375, q : 92434.7265625, p : 83249.21875, l : 601.789428711\n",
      "batch 220, ep 150, training accuracy 0.885\n",
      "f : 9548.18847656, q : 92375.2578125, p : 83412.3046875, l : 595.691650391\n",
      "valid accuracy 0.9032\n",
      "batch 221, ep 0, training accuracy 0.87\n",
      "f : 9881.41992188, q : 92373.7734375, p : 83458.359375, l : 1079.76513672\n",
      "batch 221, ep 50, training accuracy 0.895\n",
      "f : 10365.6816406, q : 92370.4921875, p : 82993.859375, l : 931.004394531\n",
      "batch 221, ep 100, training accuracy 0.895\n",
      "f : 10045.4609375, q : 92427.21875, p : 83251.859375, l : 937.867004395\n",
      "batch 221, ep 150, training accuracy 0.895\n",
      "f : 9881.60546875, q : 92379.40625, p : 83417.703125, l : 931.575805664\n",
      "valid accuracy 0.9033\n",
      "batch 222, ep 0, training accuracy 0.915\n",
      "f : 9497.37890625, q : 92336.375, p : 83533.1484375, l : 702.645446777\n",
      "batch 222, ep 50, training accuracy 0.92\n",
      "f : 10017.8515625, q : 92326.109375, p : 82992.609375, l : 611.18737793\n",
      "batch 222, ep 100, training accuracy 0.92\n",
      "f : 9703.53613281, q : 92296.6875, p : 83287.46875, l : 620.955322266\n",
      "batch 222, ep 150, training accuracy 0.92\n",
      "f : 9539.86328125, q : 92363.4140625, p : 83419.265625, l : 625.075683594\n",
      "valid accuracy 0.9044\n",
      "batch 223, ep 0, training accuracy 0.92\n",
      "f : 9320.83984375, q : 92240.59375, p : 83560.015625, l : 530.195678711\n",
      "batch 223, ep 50, training accuracy 0.93\n",
      "f : 9833.38769531, q : 92328.78125, p : 83001.1015625, l : 445.721282959\n",
      "batch 223, ep 100, training accuracy 0.935\n",
      "f : 9524.34863281, q : 92339.7421875, p : 83175.703125, l : 443.182617188\n",
      "batch 223, ep 150, training accuracy 0.93\n",
      "f : 9391.17089844, q : 92331.96875, p : 83362.703125, l : 447.951843262\n",
      "valid accuracy 0.9049\n",
      "batch 224, ep 0, training accuracy 0.835\n",
      "f : 9929.76367188, q : 92234.1015625, p : 83558.7578125, l : 1130.57678223\n",
      "batch 224, ep 50, training accuracy 0.85\n",
      "f : 10395.4824219, q : 92368.40625, p : 82891.5703125, l : 972.881469727\n",
      "batch 224, ep 100, training accuracy 0.855\n",
      "f : 10085.8408203, q : 92226.3203125, p : 83187.3828125, l : 986.817199707\n",
      "batch 224, ep 150, training accuracy 0.85\n",
      "f : 9958.66894531, q : 92222.6640625, p : 83230.1875, l : 982.561096191\n",
      "valid accuracy 0.9041\n",
      "batch 225, ep 0, training accuracy 0.86\n",
      "f : 9759.0625, q : 92308.625, p : 83467.4140625, l : 959.536743164\n",
      "batch 225, ep 50, training accuracy 0.89\n",
      "f : 10209.0458984, q : 92252.8203125, p : 82888.1953125, l : 807.671875\n",
      "batch 225, ep 100, training accuracy 0.88\n",
      "f : 9920.140625, q : 92320.3828125, p : 83168.3828125, l : 813.325073242\n",
      "batch 225, ep 150, training accuracy 0.89\n",
      "f : 9750.90527344, q : 92330.34375, p : 83375.8984375, l : 820.577880859\n",
      "valid accuracy 0.9025\n",
      "batch 226, ep 0, training accuracy 0.905\n",
      "f : 9319.19238281, q : 92239.6328125, p : 83422.640625, l : 520.329223633\n",
      "batch 226, ep 50, training accuracy 0.915\n",
      "f : 9830.64257812, q : 92192.5546875, p : 82922.4296875, l : 443.024475098\n",
      "batch 226, ep 100, training accuracy 0.92\n",
      "f : 9513.45800781, q : 92286.40625, p : 83192.3828125, l : 444.196868896\n",
      "batch 226, ep 150, training accuracy 0.915\n",
      "f : 9391.29980469, q : 92288.5, p : 83356.890625, l : 450.531188965\n",
      "valid accuracy 0.9017\n",
      "batch 227, ep 0, training accuracy 0.84\n",
      "f : 9928.72558594, q : 92202.2734375, p : 83468.765625, l : 1138.67456055\n",
      "batch 227, ep 50, training accuracy 0.855\n",
      "f : 10405.8027344, q : 92313.640625, p : 82848.296875, l : 985.052185059\n",
      "batch 227, ep 100, training accuracy 0.85\n",
      "f : 10100.1083984, q : 92236.1015625, p : 83237.25, l : 982.301452637\n",
      "batch 227, ep 150, training accuracy 0.855\n",
      "f : 9966.45703125, q : 92212.578125, p : 83158.0234375, l : 992.542236328\n",
      "valid accuracy 0.9046\n",
      "batch 228, ep 0, training accuracy 0.89\n",
      "f : 9538.05664062, q : 92196.3359375, p : 83457.9765625, l : 751.927307129\n",
      "batch 228, ep 50, training accuracy 0.89\n",
      "f : 10048.4726562, q : 92173.4375, p : 82760.8359375, l : 648.621948242\n",
      "batch 228, ep 100, training accuracy 0.89\n",
      "f : 9733.16210938, q : 92171.84375, p : 83112.0390625, l : 640.18157959\n",
      "batch 228, ep 150, training accuracy 0.89\n",
      "f : 9598.00390625, q : 92165.9453125, p : 83183.3125, l : 652.597961426\n",
      "valid accuracy 0.9035\n",
      "batch 229, ep 0, training accuracy 0.86\n",
      "f : 9706.81542969, q : 92211.7265625, p : 83444.3671875, l : 909.562927246\n",
      "batch 229, ep 50, training accuracy 0.87\n",
      "f : 10192.9794922, q : 92206.1328125, p : 82869.890625, l : 812.635009766\n",
      "batch 229, ep 100, training accuracy 0.875\n",
      "f : 9899.08398438, q : 92234.8359375, p : 83013.859375, l : 818.725952148\n",
      "batch 229, ep 150, training accuracy 0.87\n",
      "f : 9753.95800781, q : 92233.3828125, p : 83280.5078125, l : 814.039794922\n",
      "valid accuracy 0.9041\n",
      "batch 230, ep 0, training accuracy 0.85\n",
      "f : 9892.02148438, q : 92229.6484375, p : 83424.75, l : 1094.44213867\n",
      "batch 230, ep 50, training accuracy 0.855\n",
      "f : 10339.4277344, q : 92215.375, p : 82688.65625, l : 929.234619141\n",
      "batch 230, ep 100, training accuracy 0.855\n",
      "f : 10034.5488281, q : 92254.3046875, p : 83019.6171875, l : 932.676025391\n",
      "batch 230, ep 150, training accuracy 0.855\n",
      "f : 9901.20800781, q : 92184.21875, p : 83194.0859375, l : 929.352600098\n",
      "valid accuracy 0.9063\n",
      "batch 231, ep 0, training accuracy 0.84\n",
      "f : 9955.57910156, q : 92173.6953125, p : 83366.796875, l : 1155.73193359\n",
      "batch 231, ep 50, training accuracy 0.86\n",
      "f : 10444.4921875, q : 92107.4765625, p : 82670.53125, l : 1038.86877441\n",
      "batch 231, ep 100, training accuracy 0.86\n",
      "f : 10124.9951172, q : 92216.125, p : 83027.703125, l : 1039.0279541\n",
      "batch 231, ep 150, training accuracy 0.86\n",
      "f : 10003.5322266, q : 92047.265625, p : 83205.609375, l : 1039.38171387\n",
      "valid accuracy 0.9047\n",
      "batch 232, ep 0, training accuracy 0.9\n",
      "f : 9407.03417969, q : 92095.8359375, p : 83294.28125, l : 614.008850098\n",
      "batch 232, ep 50, training accuracy 0.91\n",
      "f : 9903.93945312, q : 92149.7890625, p : 82700.71875, l : 538.293457031\n",
      "batch 232, ep 100, training accuracy 0.905\n",
      "f : 9620.05371094, q : 92121.546875, p : 83124.0625, l : 535.450927734\n",
      "batch 232, ep 150, training accuracy 0.905\n",
      "f : 9473.64941406, q : 92214.46875, p : 83135.8046875, l : 538.241821289\n",
      "valid accuracy 0.904\n",
      "batch 233, ep 0, training accuracy 0.93\n",
      "f : 9298.68847656, q : 92041.8359375, p : 83314.921875, l : 505.092163086\n",
      "batch 233, ep 50, training accuracy 0.94\n",
      "f : 9819.03808594, q : 92046.5546875, p : 82715.0078125, l : 440.029510498\n",
      "batch 233, ep 100, training accuracy 0.94\n",
      "f : 9513.21679688, q : 92177.671875, p : 82936.359375, l : 438.920715332\n",
      "batch 233, ep 150, training accuracy 0.94\n",
      "f : 9339.03808594, q : 92084.3046875, p : 83125.421875, l : 437.704345703\n",
      "valid accuracy 0.9045\n",
      "batch 234, ep 0, training accuracy 0.92\n",
      "f : 9311.27636719, q : 92079.140625, p : 83195.6796875, l : 518.886474609\n",
      "batch 234, ep 50, training accuracy 0.925\n",
      "f : 9831.63476562, q : 92070.5546875, p : 82628.359375, l : 442.100158691\n",
      "batch 234, ep 100, training accuracy 0.925\n",
      "f : 9509.18652344, q : 92093.015625, p : 83007.3515625, l : 440.010253906\n",
      "batch 234, ep 150, training accuracy 0.925\n",
      "f : 9358.45898438, q : 91993.65625, p : 83147.515625, l : 444.847717285\n",
      "valid accuracy 0.9061\n",
      "batch 235, ep 0, training accuracy 0.89\n",
      "f : 9566.75585938, q : 92051.3515625, p : 83296.171875, l : 775.082946777\n",
      "batch 235, ep 50, training accuracy 0.92\n",
      "f : 10059.9365234, q : 92038.859375, p : 82682.234375, l : 670.396118164\n",
      "batch 235, ep 100, training accuracy 0.92\n",
      "f : 9760.18261719, q : 92047.140625, p : 82948.09375, l : 663.217834473\n",
      "batch 235, ep 150, training accuracy 0.92\n",
      "f : 9618.54101562, q : 92037.109375, p : 83052.3671875, l : 663.369506836\n",
      "valid accuracy 0.9044\n",
      "batch 236, ep 0, training accuracy 0.845\n",
      "f : 10049.5, q : 92097.734375, p : 83240.5078125, l : 1261.65649414\n",
      "batch 236, ep 50, training accuracy 0.87\n",
      "f : 10502.8203125, q : 92017.4921875, p : 82567.453125, l : 1061.59277344\n",
      "batch 236, ep 100, training accuracy 0.87\n",
      "f : 10190.4003906, q : 91969.3359375, p : 82908.125, l : 1067.51464844\n",
      "batch 236, ep 150, training accuracy 0.865\n",
      "f : 10027.6191406, q : 91950.953125, p : 83097.546875, l : 1072.39355469\n",
      "valid accuracy 0.9042\n",
      "batch 237, ep 0, training accuracy 0.865\n",
      "f : 9776.28027344, q : 92005.8125, p : 83142.5546875, l : 974.451721191\n",
      "batch 237, ep 50, training accuracy 0.88\n",
      "f : 10229.8564453, q : 91933.1953125, p : 82634.5234375, l : 829.258056641\n",
      "batch 237, ep 100, training accuracy 0.88\n",
      "f : 9920.11425781, q : 92066.0546875, p : 82851.0625, l : 827.089233398\n",
      "batch 237, ep 150, training accuracy 0.88\n",
      "f : 9810.64160156, q : 91976.2578125, p : 82883.453125, l : 821.465698242\n",
      "valid accuracy 0.903\n",
      "batch 238, ep 0, training accuracy 0.865\n",
      "f : 9765.88867188, q : 91950.109375, p : 83163.9140625, l : 976.403076172\n",
      "batch 238, ep 50, training accuracy 0.875\n",
      "f : 10198.2197266, q : 91963.75, p : 82495.25, l : 801.298706055\n",
      "batch 238, ep 100, training accuracy 0.865\n",
      "f : 9899.94238281, q : 91974.1328125, p : 82849.2421875, l : 798.470031738\n",
      "batch 238, ep 150, training accuracy 0.88\n",
      "f : 9787.43652344, q : 92046.6484375, p : 82889.5390625, l : 789.479553223\n",
      "valid accuracy 0.9048\n",
      "batch 239, ep 0, training accuracy 0.915\n",
      "f : 9503.63476562, q : 91973.65625, p : 83196.5, l : 704.580688477\n",
      "batch 239, ep 50, training accuracy 0.92\n",
      "f : 9946.47265625, q : 91931.1015625, p : 82494.703125, l : 579.963806152\n",
      "batch 239, ep 100, training accuracy 0.92\n",
      "f : 9655.53027344, q : 91941.0703125, p : 82788.9921875, l : 570.730712891\n",
      "batch 239, ep 150, training accuracy 0.92\n",
      "f : 9522.72851562, q : 91936.265625, p : 83044.171875, l : 569.850158691\n",
      "valid accuracy 0.9047\n",
      "batch 240, ep 0, training accuracy 0.92\n",
      "f : 9266.11523438, q : 91916.5, p : 83144.7734375, l : 470.748901367\n",
      "batch 240, ep 50, training accuracy 0.93\n",
      "f : 9754.05957031, q : 91934.796875, p : 82542.5546875, l : 379.020507812\n",
      "batch 240, ep 100, training accuracy 0.935\n",
      "f : 9441.95019531, q : 91960.765625, p : 82925.46875, l : 376.480895996\n",
      "batch 240, ep 150, training accuracy 0.935\n",
      "f : 9288.56738281, q : 91893.390625, p : 82982.828125, l : 377.352966309\n",
      "valid accuracy 0.9048\n",
      "batch 241, ep 0, training accuracy 0.89\n",
      "f : 9601.54589844, q : 91909.9609375, p : 83025.2734375, l : 809.982666016\n",
      "batch 241, ep 50, training accuracy 0.89\n",
      "f : 10077.5722656, q : 91871.2734375, p : 82502.4609375, l : 693.14630127\n",
      "batch 241, ep 100, training accuracy 0.885\n",
      "f : 9768.07226562, q : 91969.984375, p : 82775.5078125, l : 694.323303223\n",
      "batch 241, ep 150, training accuracy 0.89\n",
      "f : 9645.57128906, q : 91928.203125, p : 82899.5625, l : 696.343261719\n",
      "valid accuracy 0.905\n",
      "batch 242, ep 0, training accuracy 0.925\n",
      "f : 9240.34472656, q : 91968.3359375, p : 83146.9375, l : 456.243041992\n",
      "batch 242, ep 50, training accuracy 0.94\n",
      "f : 9759.73730469, q : 91798.6953125, p : 82491.6875, l : 387.696075439\n",
      "batch 242, ep 100, training accuracy 0.935\n",
      "f : 9455.67089844, q : 91886.453125, p : 82816.1953125, l : 390.292694092\n",
      "batch 242, ep 150, training accuracy 0.94\n",
      "f : 9310.02929688, q : 91874.5546875, p : 82905.6328125, l : 393.291473389\n",
      "valid accuracy 0.9044\n",
      "batch 243, ep 0, training accuracy 0.92\n",
      "f : 9195.42285156, q : 91873.5078125, p : 83063.9921875, l : 399.619110107\n",
      "batch 243, ep 50, training accuracy 0.95\n",
      "f : 9677.44726562, q : 91874.125, p : 82484.5390625, l : 327.438537598\n",
      "batch 243, ep 100, training accuracy 0.945\n",
      "f : 9398.01660156, q : 91950.0, p : 82740.375, l : 328.129882812\n",
      "batch 243, ep 150, training accuracy 0.95\n",
      "f : 9259.92578125, q : 91876.734375, p : 82826.328125, l : 329.703613281\n",
      "valid accuracy 0.9055\n",
      "batch 244, ep 0, training accuracy 0.88\n",
      "f : 9656.00195312, q : 91821.984375, p : 83125.2890625, l : 867.692687988\n",
      "batch 244, ep 50, training accuracy 0.89\n",
      "f : 10137.6630859, q : 91807.9296875, p : 82419.2265625, l : 733.48828125\n",
      "batch 244, ep 100, training accuracy 0.885\n",
      "f : 9822.88574219, q : 91765.21875, p : 82750.6875, l : 735.436096191\n",
      "batch 244, ep 150, training accuracy 0.885\n",
      "f : 9671.50292969, q : 91741.9375, p : 82937.7578125, l : 728.070800781\n",
      "valid accuracy 0.9037\n",
      "batch 245, ep 0, training accuracy 0.865\n",
      "f : 9776.484375, q : 91807.2265625, p : 83027.5703125, l : 983.934814453\n",
      "batch 245, ep 50, training accuracy 0.88\n",
      "f : 10248.7392578, q : 91763.1484375, p : 82346.5703125, l : 852.520385742\n",
      "batch 245, ep 100, training accuracy 0.875\n",
      "f : 9952.75976562, q : 91791.328125, p : 82712.046875, l : 845.676635742\n",
      "batch 245, ep 150, training accuracy 0.88\n",
      "f : 9776.125, q : 91784.640625, p : 82941.96875, l : 845.563110352\n",
      "valid accuracy 0.9054\n",
      "batch 246, ep 0, training accuracy 0.89\n",
      "f : 9481.73632812, q : 91816.2421875, p : 83066.578125, l : 683.892211914\n",
      "batch 246, ep 50, training accuracy 0.925\n",
      "f : 9967.26269531, q : 91711.390625, p : 82340.453125, l : 565.16796875\n",
      "batch 246, ep 100, training accuracy 0.92\n",
      "f : 9646.03125, q : 91766.328125, p : 82667.671875, l : 570.608581543\n",
      "batch 246, ep 150, training accuracy 0.915\n",
      "f : 9519.66796875, q : 91743.890625, p : 82819.046875, l : 564.99798584\n",
      "valid accuracy 0.9056\n",
      "batch 247, ep 0, training accuracy 0.795\n",
      "f : 10232.3769531, q : 91747.4375, p : 82916.078125, l : 1450.40344238\n",
      "batch 247, ep 50, training accuracy 0.825\n",
      "f : 10609.9326172, q : 91777.109375, p : 82309.3359375, l : 1168.61914062\n",
      "batch 247, ep 100, training accuracy 0.82\n",
      "f : 10339.2822266, q : 91633.1171875, p : 82707.34375, l : 1163.56030273\n",
      "batch 247, ep 150, training accuracy 0.825\n",
      "f : 10200.9453125, q : 91796.515625, p : 82736.5, l : 1166.94873047\n",
      "valid accuracy 0.9023\n",
      "batch 248, ep 0, training accuracy 0.88\n",
      "f : 9723.40429688, q : 91830.2265625, p : 82917.6328125, l : 917.332214355\n",
      "batch 248, ep 50, training accuracy 0.9\n",
      "f : 10167.8398438, q : 91729.3515625, p : 82351.375, l : 777.300842285\n",
      "batch 248, ep 100, training accuracy 0.885\n",
      "f : 9877.90039062, q : 91685.375, p : 82624.2578125, l : 773.311828613\n",
      "batch 248, ep 150, training accuracy 0.89\n",
      "f : 9706.85644531, q : 91699.9609375, p : 82787.7734375, l : 780.577392578\n",
      "valid accuracy 0.9057\n",
      "batch 249, ep 0, training accuracy 0.865\n",
      "f : 9953.60351562, q : 91747.109375, p : 82891.4921875, l : 1151.50732422\n",
      "batch 249, ep 50, training accuracy 0.885\n",
      "f : 10338.8964844, q : 91742.8359375, p : 82185.6328125, l : 884.469787598\n",
      "batch 249, ep 100, training accuracy 0.885\n",
      "f : 10034.1826172, q : 91677.4296875, p : 82571.859375, l : 881.055541992\n",
      "batch 249, ep 150, training accuracy 0.885\n",
      "f : 9894.85839844, q : 91704.734375, p : 82708.625, l : 881.246032715\n",
      "valid accuracy 0.9055\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for i in range(n_batches):\n",
    "    \n",
    "    bnn.reset_lr()\n",
    "    \n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        feed = {bnn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "        \n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "        #if ep > 5 and np.mean(fs[-25:]) < np.mean(fs[-15:]):\n",
    "        if ep > 5 and np.mean(fs[-25:]) < v_f:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "                \n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "            \n",
    "            \n",
    "#             print (\"--- learning rate decayed ---\")\n",
    "#             print bnn.get_lr()\n",
    "\n",
    "        if ep % 50 == 0:\n",
    "            train_accuracy = bnn.validate(feed)\n",
    "\n",
    "            print(\"batch %d, ep %d, training accuracy %g\"%(i, ep, train_accuracy))\n",
    "            print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        bnn.train(feed)\n",
    "        \n",
    "    vacc = bnn.validate({bnn.x: x_valid, bnn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict ={bnn.x: x_valid, bnn.t: t_valid})\n",
    "    test_writer.add_summary(summary, i)\n",
    "    \n",
    "#     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "#         bnn.decay_lr()\n",
    "    \n",
    "    bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEACAYAAAD4NNLwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff39deda910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB72ZWeYc9GZmmfsVdRBVAhFdO1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3d6e84dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
