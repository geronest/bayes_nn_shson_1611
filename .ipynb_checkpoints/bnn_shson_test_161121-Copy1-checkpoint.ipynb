{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os, sys, time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from bnn_shson import *\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n",
      "(10,)\n",
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_batch = batch_size, mu = 0.02, rho = -1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.16\n",
      "f : 142400.0625, q : -395973.1875, p : -537571.375, l : -564.619140625\n",
      "step 100, training accuracy 0.06\n",
      "f : 66343.3515625, q : -288410.1875, p : -354096.25, l : -289.918151855\n",
      "step 200, training accuracy 0.04\n",
      "f : 41820.6796875, q : -218279.0, p : -260914.78125, l : -196.624679565\n",
      "step 300, training accuracy 0.1\n",
      "f : 35280.9101562, q : -191772.0, p : -227226.078125, l : -158.304229736\n",
      "step 400, training accuracy 0.08\n",
      "f : 34104.2109375, q : -183626.0625, p : -217776.984375, l : -163.641784668\n",
      "step 500, training accuracy 0.12\n",
      "f : 34020.9726562, q : -182613.5, p : -216417.5625, l : -168.396606445\n",
      "step 600, training accuracy 0.1\n",
      "f : 34033.0078125, q : -182234.28125, p : -216307.515625, l : -160.089996338\n",
      "step 700, training accuracy 0.16\n",
      "f : 34242.34375, q : -182245.09375, p : -216321.78125, l : -150.134277344\n",
      "step 800, training accuracy 0.1\n",
      "f : 34254.7421875, q : -181326.34375, p : -215828.125, l : -195.285003662\n",
      "step 900, training accuracy 0.16\n",
      "f : 34277.8203125, q : -182404.9375, p : -216751.03125, l : -177.108978271\n",
      "step 1000, training accuracy 0.08\n",
      "f : 34110.0234375, q : -181695.0625, p : -215965.6875, l : -165.926483154\n",
      "step 1100, training accuracy 0.02\n",
      "f : 34038.5039062, q : -181742.375, p : -215720.6875, l : -180.006637573\n",
      "step 1200, training accuracy 0.08\n",
      "f : 33974.5234375, q : -182355.1875, p : -216100.34375, l : -167.556060791\n",
      "step 1300, training accuracy 0.06\n",
      "f : 33968.4257812, q : -181849.46875, p : -216185.578125, l : -190.788543701\n",
      "step 1400, training accuracy 0.18\n",
      "f : 33880.4492188, q : -182470.21875, p : -216012.125, l : -156.991119385\n",
      "step 1500, training accuracy 0.18\n",
      "f : 34141.2734375, q : -182316.203125, p : -215809.15625, l : -220.872406006\n",
      "step 1600, training accuracy 0.1\n",
      "f : 33940.5195312, q : -182123.9375, p : -215999.0, l : -200.404876709\n",
      "step 1700, training accuracy 0.12\n",
      "f : 34057.0273438, q : -182599.375, p : -216645.9375, l : -158.388458252\n",
      "step 1800, training accuracy 0.16\n",
      "f : 34228.5039062, q : -182493.8125, p : -216509.171875, l : -184.53704834\n",
      "step 1900, training accuracy 0.14\n",
      "f : 34026.84375, q : -182448.0, p : -216033.859375, l : -160.2159729\n",
      "step 2000, training accuracy 0.16\n",
      "f : 34023.6328125, q : -182504.03125, p : -215993.4375, l : -210.458709717\n",
      "step 2100, training accuracy 0.12\n",
      "f : 34214.8515625, q : -182315.96875, p : -216308.21875, l : -182.933685303\n",
      "step 2200, training accuracy 0.2\n",
      "f : 34130.3046875, q : -181702.71875, p : -216319.640625, l : -182.091552734\n",
      "step 2300, training accuracy 0.2\n",
      "f : 34172.4804688, q : -181355.296875, p : -216200.28125, l : -174.509979248\n",
      "step 2400, training accuracy 0.08\n",
      "f : 33941.4921875, q : -181098.34375, p : -216345.65625, l : -164.724960327\n",
      "step 2500, training accuracy 0.1\n",
      "f : 34023.3671875, q : -181966.375, p : -216601.84375, l : -227.562194824\n",
      "step 2600, training accuracy 0.1\n",
      "f : 34367.15625, q : -181756.421875, p : -216673.484375, l : -146.12197876\n",
      "step 2700, training accuracy 0.16\n",
      "f : 33959.9296875, q : -181536.546875, p : -216227.734375, l : -179.848144531\n",
      "step 2800, training accuracy 0.12\n",
      "f : 33876.6875, q : -182217.1875, p : -216383.46875, l : -174.007965088\n",
      "step 2900, training accuracy 0.12\n",
      "f : 34347.5703125, q : -181994.375, p : -216143.9375, l : -146.031524658\n",
      "step 3000, training accuracy 0.04\n",
      "f : 34161.140625, q : -181958.8125, p : -215970.09375, l : -172.319869995\n",
      "step 3100, training accuracy 0.12\n",
      "f : 34020.9179688, q : -182353.953125, p : -216157.9375, l : -149.136245728\n",
      "step 3200, training accuracy 0.14\n",
      "f : 34014.609375, q : -181973.84375, p : -215842.265625, l : -130.236557007\n",
      "step 3300, training accuracy 0.08\n",
      "f : 34116.6171875, q : -182019.6875, p : -215990.1875, l : -188.376403809\n",
      "step 3400, training accuracy 0.14\n",
      "f : 33891.25, q : -182120.546875, p : -216083.375, l : -151.497497559\n",
      "step 3500, training accuracy 0.14\n",
      "f : 34190.890625, q : -182303.90625, p : -215512.953125, l : -176.241119385\n",
      "step 3600, training accuracy 0.1\n",
      "f : 33863.8515625, q : -181777.25, p : -216097.6875, l : -210.687026978\n",
      "step 3700, training accuracy 0.08\n",
      "f : 34133.71875, q : -182785.5625, p : -216040.0, l : -180.237884521\n",
      "step 3800, training accuracy 0.12\n",
      "f : 34042.1171875, q : -182362.09375, p : -216650.609375, l : -161.301193237\n",
      "step 3900, training accuracy 0.18\n",
      "f : 34002.6757812, q : -183178.515625, p : -216514.96875, l : -169.590118408\n",
      "step 4000, training accuracy 0.12\n",
      "f : 33992.09375, q : -182476.875, p : -216706.703125, l : -147.727706909\n",
      "step 4100, training accuracy 0.14\n",
      "f : 34146.7070312, q : -182489.40625, p : -215770.890625, l : -166.368743896\n",
      "step 4200, training accuracy 0.1\n",
      "f : 34109.3320312, q : -182366.234375, p : -216889.28125, l : -152.246490479\n",
      "step 4300, training accuracy 0.06\n",
      "f : 34270.09375, q : -182629.1875, p : -216107.125, l : -163.141387939\n",
      "step 4400, training accuracy 0.08\n",
      "f : 34311.7304688, q : -182685.46875, p : -216016.890625, l : -168.687042236\n",
      "step 4500, training accuracy 0.1\n",
      "f : 34134.3710938, q : -182019.21875, p : -215897.78125, l : -152.698776245\n",
      "step 4600, training accuracy 0.08\n",
      "f : 33973.1484375, q : -182014.375, p : -215727.84375, l : -176.934112549\n",
      "step 4700, training accuracy 0.14\n",
      "f : 34115.6523438, q : -182095.5, p : -216333.09375, l : -148.966827393\n",
      "step 4800, training accuracy 0.14\n",
      "f : 34141.9414062, q : -181378.984375, p : -216685.5625, l : -162.727935791\n",
      "step 4900, training accuracy 0.06\n",
      "f : 34250.7109375, q : -182226.8125, p : -216328.3125, l : -193.322982788\n",
      "step 5000, training accuracy 0.12\n",
      "f : 34022.3359375, q : -182779.90625, p : -216472.59375, l : -196.571716309\n",
      "step 5100, training accuracy 0.1\n",
      "f : 33846.1054688, q : -182023.90625, p : -216633.09375, l : -165.688537598\n",
      "step 5200, training accuracy 0.04\n",
      "f : 34100.6640625, q : -182461.09375, p : -215882.28125, l : -174.752716064\n",
      "step 5300, training accuracy 0.08\n",
      "f : 34056.5703125, q : -182046.09375, p : -215914.125, l : -182.976715088\n",
      "step 5400, training accuracy 0.16\n",
      "f : 34231.3359375, q : -182525.71875, p : -215283.15625, l : -207.968353271\n",
      "step 5500, training accuracy 0.06\n",
      "f : 34242.3671875, q : -181974.734375, p : -216335.3125, l : -184.936035156\n",
      "step 5600, training accuracy 0.02\n",
      "f : 33889.9453125, q : -181847.09375, p : -215530.109375, l : -168.519561768\n",
      "step 5700, training accuracy 0.14\n",
      "f : 33965.0, q : -182270.421875, p : -217064.625, l : -245.634979248\n",
      "step 5800, training accuracy 0.04\n",
      "f : 34142.9570312, q : -182032.171875, p : -216150.4375, l : -161.631378174\n",
      "step 5900, training accuracy 0.1\n",
      "f : 34154.1328125, q : -182505.15625, p : -216264.28125, l : -180.787719727\n",
      "step 6000, training accuracy 0.08\n",
      "f : 34025.5742188, q : -182182.15625, p : -216853.84375, l : -208.03805542\n",
      "step 6100, training accuracy 0.12\n",
      "f : 34229.7539062, q : -182196.390625, p : -216177.828125, l : -164.701904297\n",
      "step 6200, training accuracy 0.12\n",
      "f : 34322.265625, q : -181501.96875, p : -215837.78125, l : -136.067306519\n",
      "step 6300, training accuracy 0.12\n",
      "f : 34290.6523438, q : -182470.6875, p : -216194.0625, l : -161.874664307\n",
      "step 6400, training accuracy 0.14\n",
      "f : 34178.6210938, q : -182462.328125, p : -215896.53125, l : -206.409057617\n",
      "step 6500, training accuracy 0.12\n",
      "f : 33988.6015625, q : -182063.359375, p : -216925.09375, l : -197.375793457\n",
      "step 6600, training accuracy 0.12\n",
      "f : 34336.25, q : -183256.578125, p : -216998.9375, l : -184.114715576\n",
      "step 6700, training accuracy 0.12\n",
      "f : 34298.484375, q : -181610.4375, p : -215345.640625, l : -214.381317139\n",
      "step 6800, training accuracy 0.14\n",
      "f : 34282.109375, q : -181996.375, p : -216624.21875, l : -154.953155518\n",
      "step 6900, training accuracy 0.12\n",
      "f : 33824.109375, q : -182931.015625, p : -215757.890625, l : -142.946472168\n",
      "step 7000, training accuracy 0.16\n",
      "f : 34150.6054688, q : -182826.96875, p : -215085.34375, l : -174.467437744\n",
      "step 7100, training accuracy 0.08\n",
      "f : 33857.3164062, q : -181470.3125, p : -215790.84375, l : -145.325775146\n",
      "step 7200, training accuracy 0.1\n",
      "f : 33830.3203125, q : -182978.90625, p : -216629.09375, l : -289.031829834\n",
      "step 7300, training accuracy 0.08\n",
      "f : 34040.5703125, q : -182167.8125, p : -215441.6875, l : -172.675292969\n",
      "step 7400, training accuracy 0.04\n",
      "f : 34216.8125, q : -182605.71875, p : -216244.84375, l : -169.041824341\n",
      "step 7500, training accuracy 0.14\n",
      "f : 34159.6289062, q : -181657.5625, p : -214655.9375, l : -211.921508789\n",
      "step 7600, training accuracy 0.12\n",
      "f : 34085.1367188, q : -181041.625, p : -215459.109375, l : -131.842529297\n",
      "step 7700, training accuracy 0.08\n",
      "f : 34370.5976562, q : -182146.875, p : -215127.0625, l : -165.939147949\n",
      "step 7800, training accuracy 0.24\n",
      "f : 34134.3242188, q : -182262.9375, p : -215848.9375, l : -165.241821289\n",
      "step 7900, training accuracy 0.12\n",
      "f : 34247.7421875, q : -181704.75, p : -215720.671875, l : -154.1040802\n",
      "step 8000, training accuracy 0.04\n",
      "f : 34289.7890625, q : -181403.625, p : -216149.890625, l : -173.203399658\n",
      "step 8100, training accuracy 0.04\n",
      "f : 33928.5078125, q : -182533.09375, p : -215822.703125, l : -147.71182251\n",
      "step 8200, training accuracy 0.12\n",
      "f : 33939.65625, q : -182615.5625, p : -215848.65625, l : -149.414321899\n",
      "step 8300, training accuracy 0.14\n",
      "f : 34266.5429688, q : -182090.109375, p : -216342.625, l : -158.226104736\n",
      "step 8400, training accuracy 0.08\n",
      "f : 33961.7734375, q : -182025.46875, p : -216213.8125, l : -189.381011963\n",
      "step 8500, training accuracy 0.02\n",
      "f : 34189.3828125, q : -181427.859375, p : -216541.34375, l : -218.272979736\n",
      "step 8600, training accuracy 0.2\n",
      "f : 34157.890625, q : -182069.0625, p : -216111.625, l : -148.552764893\n",
      "step 8700, training accuracy 0.06\n",
      "f : 34065.4375, q : -182161.71875, p : -215076.53125, l : -189.166351318\n",
      "step 8800, training accuracy 0.1\n",
      "f : 34027.9375, q : -181783.796875, p : -216133.5625, l : -184.077072144\n",
      "step 8900, training accuracy 0.1\n",
      "f : 34218.3945312, q : -182051.984375, p : -215344.703125, l : -170.264648438\n",
      "step 9000, training accuracy 0.1\n",
      "f : 34247.6953125, q : -182293.53125, p : -216238.28125, l : -144.208267212\n",
      "step 9100, training accuracy 0.06\n",
      "f : 33934.9960938, q : -181351.890625, p : -215582.3125, l : -216.494262695\n",
      "step 9200, training accuracy 0.04\n",
      "f : 34025.1875, q : -182220.25, p : -216270.5, l : -216.404510498\n",
      "step 9300, training accuracy 0.16\n",
      "f : 34145.5273438, q : -181772.453125, p : -216543.4375, l : -174.650848389\n",
      "step 9400, training accuracy 0.1\n",
      "f : 34086.1601562, q : -182305.890625, p : -215899.84375, l : -219.278747559\n",
      "step 9500, training accuracy 0.12\n",
      "f : 34023.9921875, q : -182014.9375, p : -216537.3125, l : -211.905731201\n",
      "step 9600, training accuracy 0.18\n",
      "f : 34355.1953125, q : -182185.21875, p : -217081.515625, l : -179.171508789\n",
      "step 9700, training accuracy 0.1\n",
      "f : 34074.1015625, q : -181874.90625, p : -216183.375, l : -189.420806885\n",
      "step 9800, training accuracy 0.08\n",
      "f : 34249.2148438, q : -181623.4375, p : -216652.65625, l : -161.845611572\n",
      "step 9900, training accuracy 0.08\n",
      "f : 34011.3515625, q : -181920.765625, p : -215939.03125, l : -157.652023315\n",
      "step 10000, training accuracy 0.06\n",
      "f : 33874.0351562, q : -182430.578125, p : -216755.546875, l : -194.586273193\n",
      "step 10100, training accuracy 0.12\n",
      "f : 34161.5820312, q : -181714.71875, p : -216847.21875, l : -216.127593994\n",
      "step 10200, training accuracy 0.18\n",
      "f : 33988.3554688, q : -181944.234375, p : -215024.46875, l : -156.235549927\n",
      "step 10300, training accuracy 0.24\n",
      "f : 34060.5429688, q : -182182.1875, p : -215193.703125, l : -159.763275146\n",
      "step 10400, training accuracy 0.12\n",
      "f : 34038.0039062, q : -182381.4375, p : -215946.09375, l : -147.578948975\n",
      "step 10500, training accuracy 0.04\n",
      "f : 34293.3671875, q : -182443.578125, p : -215907.53125, l : -155.02053833\n",
      "step 10600, training accuracy 0.14\n",
      "f : 33882.6367188, q : -181948.21875, p : -215670.671875, l : -178.772888184\n",
      "step 10700, training accuracy 0.14\n",
      "f : 33972.6640625, q : -181983.15625, p : -215678.765625, l : -132.926589966\n",
      "step 10800, training accuracy 0.1\n",
      "f : 33988.4101562, q : -182437.203125, p : -216655.796875, l : -152.547485352\n",
      "step 10900, training accuracy 0.04\n",
      "f : 33858.78125, q : -181580.90625, p : -215700.421875, l : -179.089904785\n",
      "step 11000, training accuracy 0.12\n",
      "f : 33953.9375, q : -181641.84375, p : -215517.0, l : -155.891571045\n",
      "step 11100, training accuracy 0.02\n",
      "f : 34138.0039062, q : -181936.125, p : -216179.90625, l : -153.968399048\n",
      "step 11200, training accuracy 0.02\n",
      "f : 34209.8125, q : -182262.890625, p : -216245.375, l : -193.57043457\n",
      "step 11300, training accuracy 0.12\n",
      "f : 34099.4257812, q : -181598.59375, p : -216604.5, l : -170.497360229\n",
      "step 11400, training accuracy 0.14\n",
      "f : 33959.6679688, q : -182122.015625, p : -215742.8125, l : -202.985290527\n",
      "step 11500, training accuracy 0.06\n",
      "f : 34045.2578125, q : -182288.203125, p : -216069.609375, l : -167.602478027\n",
      "step 11600, training accuracy 0.08\n",
      "f : 34298.6875, q : -181100.453125, p : -216353.375, l : -225.316131592\n",
      "step 11700, training accuracy 0.08\n",
      "f : 34147.0273438, q : -182397.765625, p : -216652.1875, l : -163.792541504\n",
      "step 11800, training accuracy 0.16\n",
      "f : 34304.3828125, q : -182342.609375, p : -215700.15625, l : -156.02432251\n",
      "step 11900, training accuracy 0.1\n",
      "f : 34140.7226562, q : -182398.953125, p : -216225.40625, l : -154.270812988\n",
      "step 12000, training accuracy 0.1\n",
      "f : 34203.4179688, q : -181998.9375, p : -216505.109375, l : -150.65032959\n",
      "step 12100, training accuracy 0.16\n",
      "f : 34300.7109375, q : -182333.96875, p : -215979.921875, l : -164.655944824\n",
      "step 12200, training accuracy 0.14\n",
      "f : 34181.8476562, q : -182426.90625, p : -215516.34375, l : -163.514404297\n",
      "step 12300, training accuracy 0.06\n",
      "f : 34182.875, q : -181897.359375, p : -216314.453125, l : -210.443939209\n",
      "step 12400, training accuracy 0.14\n",
      "f : 34082.1171875, q : -181698.265625, p : -217121.78125, l : -167.133178711\n",
      "step 12500, training accuracy 0.02\n",
      "f : 34163.4882812, q : -182246.984375, p : -216083.0, l : -193.587402344\n",
      "step 12600, training accuracy 0.06\n",
      "f : 34172.3671875, q : -182858.9375, p : -216369.6875, l : -157.533599854\n",
      "step 12700, training accuracy 0.14\n",
      "f : 33866.9492188, q : -181645.125, p : -215666.21875, l : -194.479904175\n",
      "step 12800, training accuracy 0.16\n",
      "f : 34146.2304688, q : -182896.140625, p : -215146.9375, l : -195.052978516\n",
      "step 12900, training accuracy 0.1\n",
      "f : 34088.0429688, q : -182394.71875, p : -215591.5625, l : -148.176467896\n",
      "step 13000, training accuracy 0.1\n",
      "f : 33715.8203125, q : -182234.625, p : -215630.75, l : -198.556854248\n",
      "step 13100, training accuracy 0.08\n",
      "f : 34132.5546875, q : -181915.6875, p : -215787.96875, l : -176.367706299\n",
      "step 13200, training accuracy 0.14\n",
      "f : 34325.046875, q : -182266.609375, p : -216309.015625, l : -184.491729736\n",
      "step 13300, training accuracy 0.12\n",
      "f : 34085.75, q : -182839.78125, p : -216574.125, l : -160.599609375\n",
      "step 13400, training accuracy 0.18\n",
      "f : 33838.7617188, q : -182645.453125, p : -215495.8125, l : -150.378189087\n",
      "step 13500, training accuracy 0.12\n",
      "f : 34069.5898438, q : -182033.96875, p : -216160.71875, l : -197.340011597\n",
      "step 13600, training accuracy 0.06\n",
      "f : 34126.1484375, q : -183381.625, p : -216200.875, l : -161.679351807\n",
      "step 13700, training accuracy 0.22\n",
      "f : 33715.0585938, q : -182069.84375, p : -215673.65625, l : -187.128814697\n",
      "step 13800, training accuracy 0.06\n",
      "f : 34105.3476562, q : -182520.9375, p : -215934.5, l : -198.586334229\n",
      "step 13900, training accuracy 0.1\n",
      "f : 34166.7070312, q : -182088.578125, p : -215160.296875, l : -192.175521851\n",
      "step 14000, training accuracy 0.1\n",
      "f : 34383.09375, q : -181993.96875, p : -215616.0, l : -213.390731812\n",
      "step 14100, training accuracy 0.08\n",
      "f : 33899.484375, q : -181625.625, p : -215152.65625, l : -197.258239746\n",
      "step 14200, training accuracy 0.12\n",
      "f : 34061.578125, q : -182268.53125, p : -215574.03125, l : -162.488128662\n",
      "step 14300, training accuracy 0.08\n",
      "f : 33985.2695312, q : -181999.0, p : -216264.46875, l : -168.639892578\n",
      "step 14400, training accuracy 0.08\n",
      "f : 34149.0898438, q : -181441.25, p : -215311.375, l : -205.532745361\n",
      "step 14500, training accuracy 0.1\n",
      "f : 34109.4648438, q : -182116.640625, p : -215336.90625, l : -163.756469727\n",
      "step 14600, training accuracy 0.06\n",
      "f : 34274.6289062, q : -182208.71875, p : -215197.5625, l : -162.35067749\n",
      "step 14700, training accuracy 0.16\n",
      "f : 34162.359375, q : -181924.0625, p : -217003.5, l : -163.679992676\n",
      "step 14800, training accuracy 0.26\n",
      "f : 34102.1953125, q : -182031.0, p : -215997.84375, l : -153.507003784\n",
      "step 14900, training accuracy 0.1\n",
      "f : 34136.2460938, q : -182615.75, p : -216579.625, l : -153.325256348\n",
      "step 15000, training accuracy 0.08\n",
      "f : 34268.640625, q : -182979.75, p : -216603.34375, l : -131.587432861\n",
      "step 15100, training accuracy 0.04\n",
      "f : 33950.0390625, q : -182237.875, p : -215816.921875, l : -137.740722656\n",
      "step 15200, training accuracy 0.14\n",
      "f : 33978.2148438, q : -181244.984375, p : -216475.6875, l : -140.810531616\n",
      "step 15300, training accuracy 0.08\n",
      "f : 34035.2929688, q : -182493.34375, p : -216245.046875, l : -154.321487427\n",
      "step 15400, training accuracy 0.04\n",
      "f : 34064.4921875, q : -182139.0, p : -216431.328125, l : -163.483398438\n",
      "step 15500, training accuracy 0\n",
      "f : 33977.3671875, q : -182660.03125, p : -216137.96875, l : -180.853149414\n",
      "step 15600, training accuracy 0.18\n",
      "f : 33884.796875, q : -182073.296875, p : -215695.75, l : -147.712463379\n",
      "step 15700, training accuracy 0.16\n",
      "f : 34243.671875, q : -181799.6875, p : -216170.4375, l : -236.689224243\n",
      "step 15800, training accuracy 0.1\n",
      "f : 33788.0976562, q : -182146.5625, p : -216493.96875, l : -249.95703125\n",
      "step 15900, training accuracy 0\n",
      "f : 33872.5195312, q : -181711.6875, p : -215268.734375, l : -150.760299683\n",
      "step 16000, training accuracy 0.12\n",
      "f : 34154.953125, q : -182569.125, p : -216959.546875, l : -159.40020752\n",
      "step 16100, training accuracy 0.06\n",
      "f : 34280.7421875, q : -181294.6875, p : -216428.203125, l : -182.885467529\n",
      "step 16200, training accuracy 0.08\n",
      "f : 33969.1210938, q : -182388.390625, p : -215801.1875, l : -181.683258057\n",
      "step 16300, training accuracy 0.16\n",
      "f : 34172.7617188, q : -181889.5, p : -215937.453125, l : -213.717544556\n",
      "step 16400, training accuracy 0.16\n",
      "f : 34030.4101562, q : -181813.28125, p : -216323.375, l : -140.887664795\n",
      "step 16500, training accuracy 0.04\n",
      "f : 34209.375, q : -182073.03125, p : -216114.90625, l : -177.458526611\n",
      "step 16600, training accuracy 0.2\n",
      "f : 34065.4804688, q : -181717.875, p : -216301.0625, l : -204.577606201\n",
      "step 16700, training accuracy 0.08\n",
      "f : 34031.8046875, q : -182416.5, p : -215762.625, l : -152.447128296\n",
      "step 16800, training accuracy 0.08\n",
      "f : 33922.8320312, q : -181710.046875, p : -215823.0625, l : -260.162536621\n",
      "step 16900, training accuracy 0.06\n",
      "f : 34162.7304688, q : -181582.453125, p : -215140.328125, l : -157.25177002\n",
      "step 17000, training accuracy 0.16\n",
      "f : 33994.6328125, q : -181197.53125, p : -216705.140625, l : -135.050384521\n",
      "step 17100, training accuracy 0.1\n",
      "f : 34104.4414062, q : -181544.53125, p : -216197.09375, l : -198.020553589\n",
      "step 17200, training accuracy 0.1\n",
      "f : 34168.984375, q : -182058.53125, p : -216496.15625, l : -163.914916992\n",
      "step 17300, training accuracy 0.1\n",
      "f : 34238.7421875, q : -182481.4375, p : -215406.671875, l : -186.550216675\n",
      "step 17400, training accuracy 0.12\n",
      "f : 34342.9882812, q : -182326.578125, p : -215247.8125, l : -151.688613892\n",
      "step 17500, training accuracy 0.06\n",
      "f : 34166.8125, q : -181597.1875, p : -216645.109375, l : -152.793716431\n",
      "step 17600, training accuracy 0.02\n",
      "f : 34039.515625, q : -182279.5, p : -215748.4375, l : -181.171112061\n",
      "step 17700, training accuracy 0.24\n",
      "f : 34048.2734375, q : -181633.328125, p : -215099.515625, l : -171.033630371\n",
      "step 17800, training accuracy 0.1\n",
      "f : 34168.7851562, q : -182006.515625, p : -216123.0625, l : -154.661773682\n",
      "step 17900, training accuracy 0.14\n",
      "f : 34262.0820312, q : -182318.0625, p : -216424.59375, l : -216.562347412\n",
      "step 18000, training accuracy 0.08\n",
      "f : 34164.7382812, q : -181825.40625, p : -216036.84375, l : -174.454162598\n",
      "step 18100, training accuracy 0.12\n",
      "f : 34077.4101562, q : -182548.921875, p : -216398.109375, l : -147.065063477\n",
      "step 18200, training accuracy 0.22\n",
      "f : 34158.796875, q : -182605.71875, p : -215760.1875, l : -201.786895752\n",
      "step 18300, training accuracy 0.14\n",
      "f : 33938.8789062, q : -182259.984375, p : -216430.25, l : -120.675857544\n",
      "step 18400, training accuracy 0.06\n",
      "f : 34040.7890625, q : -182189.0, p : -215807.78125, l : -177.240509033\n",
      "step 18500, training accuracy 0.04\n",
      "f : 34243.2617188, q : -182467.453125, p : -216098.875, l : -194.457015991\n",
      "step 18600, training accuracy 0.06\n",
      "f : 34110.5078125, q : -182219.78125, p : -216255.5625, l : -130.80847168\n",
      "step 18700, training accuracy 0.1\n",
      "f : 33935.2304688, q : -181680.8125, p : -217174.8125, l : -156.209899902\n",
      "step 18800, training accuracy 0.04\n",
      "f : 33968.28125, q : -181438.03125, p : -216070.578125, l : -215.138793945\n",
      "step 18900, training accuracy 0.12\n",
      "f : 33966.6953125, q : -183079.875, p : -215726.125, l : -222.910415649\n",
      "step 19000, training accuracy 0.04\n",
      "f : 34404.421875, q : -182789.171875, p : -216583.65625, l : -205.725006104\n",
      "step 19100, training accuracy 0.14\n",
      "f : 34267.8476562, q : -182439.578125, p : -215504.65625, l : -142.327682495\n",
      "step 19200, training accuracy 0.1\n",
      "f : 34126.8359375, q : -181865.328125, p : -216309.375, l : -160.858581543\n",
      "step 19300, training accuracy 0.04\n",
      "f : 34071.2578125, q : -182407.9375, p : -215420.34375, l : -187.449005127\n",
      "step 19400, training accuracy 0\n",
      "f : 34150.5546875, q : -181864.25, p : -216281.75, l : -175.571868896\n",
      "step 19500, training accuracy 0.14\n",
      "f : 34207.1367188, q : -181851.796875, p : -216128.21875, l : -229.594696045\n",
      "step 19600, training accuracy 0.08\n",
      "f : 34184.890625, q : -182264.71875, p : -216852.125, l : -237.389648438\n",
      "step 19700, training accuracy 0.06\n",
      "f : 33985.4140625, q : -182100.65625, p : -216013.015625, l : -151.988555908\n",
      "step 19800, training accuracy 0.14\n",
      "f : 34195.0546875, q : -182721.34375, p : -216113.46875, l : -197.285583496\n",
      "step 19900, training accuracy 0.28\n",
      "f : 34121.71875, q : -181913.5625, p : -216123.890625, l : -153.023025513\n",
      "test accuracy 0.1012\n"
     ]
    }
   ],
   "source": [
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    feed = {bnn.x: batch[0], bnn.t: batch[1]}\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_accuracy = bnn.validate(feed)\n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "        \n",
    "    \n",
    "    bnn.train(feed)\n",
    "\n",
    "print(\"test accuracy %g\"%bnn.validate({bnn.x: mnist.test.images, bnn.t: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEACAYAAABhzAtFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f94a35a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.range(300)\n",
    "aa = tf.reshape(a, [30, 10])\n",
    "aaa = tf.tile(tf.expand_dims(aa, 0), [10, 1, 1])\n",
    "\n",
    "b = tf.truncated_normal([30, 10], stddev = 0.2)\n",
    "\n",
    "argmaxbs = tf.argmax(b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(30), Dimension(10)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2, ..., 297, 298, 299], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(aaa, [-1]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298   5  11  27  32  43  57\n",
      "  63  76  84  97 105 118 123 138 142 158 164 172 182 193 201 215 227 237\n",
      " 248 258 261 271 281 298   5  11  27  32  43  57  63  76  84  97 105 118\n",
      " 123 138 142 158 164 172 182 193 201 215 227 237 248 258 261 271 281 298\n",
      "   5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298   5  11  27  32  43  57\n",
      "  63  76  84  97 105 118 123 138 142 158 164 172 182 193 201 215 227 237\n",
      " 248 258 261 271 281 298   5  11  27  32  43  57  63  76  84  97 105 118\n",
      " 123 138 142 158 164 172 182 193 201 215 227 237 248 258 261 271 281 298\n",
      "   5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298   5  11  27  32  43  57\n",
      "  63  76  84  97 105 118 123 138 142 158 164 172 182 193 201 215 227 237\n",
      " 248 258 261 271 281 298   5  11  27  32  43  57  63  76  84  97 105 118\n",
      " 123 138 142 158 164 172 182 193 201 215 227 237 248 258 261 271 281 298\n",
      "   5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298]\n",
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2, 5, 3, 8, 6, 1, 0, 7, 0, 3, 7, 8, 0, 4, 5, 8, 8, 0, 2, 6, 7, 7,\n",
       "       0, 3, 7, 8, 3, 8, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = tf.range(30).eval()\n",
    "br = ar * 10 + argmaxbs.eval()\n",
    "cr = tf.tile(br, [10])\n",
    "\n",
    "result = tf.gather(tf.reshape(aaa, [-1]), cr).eval()\n",
    "print result\n",
    "print result.shape\n",
    "argmaxbs.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 35], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(aa, [[0, 1], [3, 5]]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test =  mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.Variable(tf.truncated_normal([2, 3], stddev = 0.1))\n",
    "b = tf.Variable(tf.constant(-1.0, shape = [2, 3]))\n",
    "c = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1,) and () are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-50d057430d73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36marg_max\u001b[1;34m(input, dimension, name)\u001b[0m\n\u001b[0;32m    162\u001b[0m   \"\"\"\n\u001b[0;32m    163\u001b[0m   result = _op_def_lib.apply_op(\"ArgMax\", input=input, dimension=dimension,\n\u001b[1;32m--> 164\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m    165\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                            op_def=op_def)\n\u001b[0m\u001b[0;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2317\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2319\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2320\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2321\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1709\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[0;32m   1710\u001b[0m                          % op.type)\n\u001b[1;32m-> 1711\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1712\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36m_ArgOpShape\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1858\u001b[0m   \u001b[1;34m\"\"\"Common shape function for arg-reduction ops.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m   \u001b[0mdimension_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m   \u001b[0mdimension_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1861\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    739\u001b[0m     \"\"\"\n\u001b[0;32m    740\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (1,) and () are incompatible"
     ]
    }
   ],
   "source": [
    "tf.argmax(c, [1]).eval(feed_dict = {c: [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [15, 14, 13, 12, 11, 10, 10, 10, 10, 10]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(a).eval()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519]]\n",
      "[[-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]]\n",
      "[[[-0.04836457  0.11699509 -0.10365508]\n",
      "  [-0.11315618 -0.14960578 -0.13785519]]\n",
      "\n",
      " [[-0.04836457  0.11699509 -0.10365508]\n",
      "  [-0.11315618 -0.14960578 -0.13785519]]]\n",
      "[[ 0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519]]\n",
      "[[ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]]\n",
      "[[ 0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519]]\n",
      "[[ 0.04836457  0.11315618]\n",
      " [-0.11699509  0.14960578]\n",
      " [ 0.10365508  0.13785519]]\n"
     ]
    }
   ],
   "source": [
    "with sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print a.eval()\n",
    "    print tf.tile(a, [6, 3]).eval()\n",
    "    print tf.tile(tf.expand_dims(a, 0), [2, 1, 1]).eval()\n",
    "    a = a * b\n",
    "    print a.eval()\n",
    "    print tf.tile(a, [6, 3]).eval()\n",
    "    print tf.transpose(a, [0, 1]).eval()\n",
    "    print tf.transpose(a, [1, 0]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "arr = [1, 2, 3, 4, 5]\n",
    "print arr[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 15\n",
    "\n",
    "\n",
    "fc8_n_param   = [4096, n_features]\n",
    "\n",
    "images = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "labels = tf.placeholder(tf.float32, [None, n_features])\n",
    "\n",
    "fc7 = net.layers['fc7']\n",
    "\n",
    "\n",
    "W_fc8 = weight_variable(fc8_n_param)\n",
    "b_fc8 = bias_variable([fc8_n_param[-1]])\n",
    "\n",
    "fc8_pred = tf.matmul(fc7, W_fc8) + b_fc8\n",
    "\n",
    "mse_loss = tf.reduce_mean(tf.square(labels - fc8_pred))\n",
    "learning_rate = 1e-4\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(mse_loss)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
