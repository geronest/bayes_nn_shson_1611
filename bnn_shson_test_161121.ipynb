{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys, time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from bnn_shson import *\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_to_onehot(nums, n_labels):\n",
    "    results = list()\n",
    "    for i in range(len(nums)):\n",
    "        res = np.zeros([n_labels])\n",
    "        res[nums[i]] = 1\n",
    "        results.append(res)\n",
    "    return np.asarray(results, dtype = 'float32')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = h5py.File('mnist.hdf5', 'r')\n",
    "\n",
    "x_train = mnist['train_data'][()]\n",
    "t_train = num_to_onehot(mnist['train_label'][()], 10)\n",
    "x_valid = mnist['valid_data'][()]\n",
    "t_valid = num_to_onehot(mnist['valid_label'][()], 10)\n",
    "x_test = mnist['test_data'][()]\n",
    "t_test = num_to_onehot(mnist['test_label'][()], 10)\n",
    "\n",
    "mnist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blundell version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n"
     ]
    }
   ],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rho = -1, n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, step 0, training accuracy 0.12\n",
      "f : 158433.5, q : -395675.8125, p : -681588.875, l : 14897.1064453\n",
      "ep 0, step 50, training accuracy 0.14\n",
      "f : 5204.37011719, q : -393143.875, p : -684969.0, l : 5361.90478516\n",
      "ep 0, step 100, training accuracy 0.22\n",
      "f : 4744.19335938, q : -392972.125, p : -687887.0, l : 4748.96484375\n",
      "ep 0, step 150, training accuracy 0.365\n",
      "f : 4236.07666016, q : -393928.59375, p : -691311.375, l : 4316.70117188\n",
      "ep 0, step 200, training accuracy 0.485\n",
      "f : 3603.91210938, q : -392260.75, p : -691830.3125, l : 3807.90917969\n",
      "valid accuracy 0.4544\n",
      "ep 1, step 0, training accuracy 0.47\n",
      "f : 155175.84375, q : -392200.5, p : -695550.1875, l : 3339.85424805\n",
      "ep 1, step 50, training accuracy 0.555\n",
      "f : 3110.14355469, q : -390537.625, p : -693399.625, l : 3121.4765625\n",
      "ep 1, step 100, training accuracy 0.585\n",
      "f : 3002.48388672, q : -390206.8125, p : -695945.5625, l : 3048.96533203\n",
      "ep 1, step 150, training accuracy 0.58\n",
      "f : 3105.33666992, q : -390380.6875, p : -696804.375, l : 2978.86132812\n",
      "ep 1, step 200, training accuracy 0.735\n",
      "f : 2229.04199219, q : -389305.6875, p : -697991.5, l : 2185.16894531\n",
      "valid accuracy 0.7544\n",
      "ep 2, step 0, training accuracy 0.74\n",
      "f : 157162.96875, q : -389888.125, p : -702368.75, l : 2162.8269043\n",
      "ep 2, step 50, training accuracy 0.775\n",
      "f : 2134.3684082, q : -388876.125, p : -697036.3125, l : 2112.34033203\n",
      "ep 2, step 100, training accuracy 0.72\n",
      "f : 2146.37304688, q : -387945.71875, p : -699923.0, l : 2204.78491211\n",
      "ep 2, step 150, training accuracy 0.73\n",
      "f : 2351.05053711, q : -388028.34375, p : -700253.75, l : 2250.20019531\n",
      "ep 2, step 200, training accuracy 0.795\n",
      "f : 1658.99450684, q : -387666.5625, p : -701294.375, l : 1599.83666992\n",
      "valid accuracy 0.8154\n",
      "ep 3, step 0, training accuracy 0.815\n",
      "f : 159220.796875, q : -387654.375, p : -703627.125, l : 1854.55810547\n",
      "ep 3, step 50, training accuracy 0.825\n",
      "f : 1804.50170898, q : -386835.5625, p : -698129.375, l : 1774.19335938\n",
      "ep 3, step 100, training accuracy 0.775\n",
      "f : 1804.53063965, q : -386212.3125, p : -698115.125, l : 1888.6418457\n",
      "ep 3, step 150, training accuracy 0.77\n",
      "f : 1942.60510254, q : -386071.375, p : -699621.375, l : 1967.39416504\n",
      "ep 3, step 200, training accuracy 0.835\n",
      "f : 1469.99279785, q : -385914.65625, p : -702420.25, l : 1449.80773926\n",
      "valid accuracy 0.8421\n",
      "ep 4, step 0, training accuracy 0.81\n",
      "f : 159189.703125, q : -386288.375, p : -703019.5, l : 1617.88256836\n",
      "ep 4, step 50, training accuracy 0.85\n",
      "f : 1422.4732666, q : -385038.625, p : -698951.25, l : 1468.46826172\n",
      "ep 4, step 100, training accuracy 0.815\n",
      "f : 1724.69311523, q : -383694.96875, p : -698990.875, l : 1620.28369141\n",
      "ep 4, step 150, training accuracy 0.795\n",
      "f : 1756.51916504, q : -384982.1875, p : -697350.625, l : 1862.09179688\n",
      "ep 4, step 200, training accuracy 0.865\n",
      "f : 1261.02062988, q : -384514.78125, p : -699492.625, l : 1196.00830078\n",
      "valid accuracy 0.8604\n",
      "ep 5, step 0, training accuracy 0.855\n",
      "f : 159178.234375, q : -384362.875, p : -702013.5, l : 1472.39355469\n",
      "ep 5, step 50, training accuracy 0.845\n",
      "f : 1320.61108398, q : -383390.65625, p : -697197.625, l : 1290.4128418\n",
      "ep 5, step 100, training accuracy 0.8\n",
      "f : 1488.48571777, q : -384458.375, p : -697762.5, l : 1508.46362305\n",
      "ep 5, step 150, training accuracy 0.835\n",
      "f : 1629.77709961, q : -382978.25, p : -698256.75, l : 1593.83654785\n",
      "ep 5, step 200, training accuracy 0.875\n",
      "f : 1118.36035156, q : -382391.1875, p : -699741.0, l : 1138.82714844\n",
      "valid accuracy 0.8809\n",
      "ep 6, step 0, training accuracy 0.865\n",
      "f : 159589.0625, q : -382596.15625, p : -698751.625, l : 1347.09265137\n",
      "ep 6, step 50, training accuracy 0.845\n",
      "f : 1199.7902832, q : -382103.3125, p : -694680.875, l : 1142.48144531\n",
      "ep 6, step 100, training accuracy 0.845\n",
      "f : 1379.37060547, q : -381404.03125, p : -695860.6875, l : 1346.98693848\n",
      "ep 6, step 150, training accuracy 0.825\n",
      "f : 1439.11499023, q : -381514.8125, p : -697100.4375, l : 1434.04882812\n",
      "ep 6, step 200, training accuracy 0.885\n",
      "f : 960.376708984, q : -380756.84375, p : -698806.9375, l : 1056.70825195\n",
      "valid accuracy 0.8905\n",
      "ep 7, step 0, training accuracy 0.885\n",
      "f : 160125.03125, q : -381358.5625, p : -700957.875, l : 1196.06274414\n",
      "ep 7, step 50, training accuracy 0.86\n",
      "f : 1112.04248047, q : -380269.3125, p : -695050.6875, l : 1100.99755859\n",
      "ep 7, step 100, training accuracy 0.865\n",
      "f : 1339.54711914, q : -380289.3125, p : -694093.625, l : 1363.56262207\n",
      "ep 7, step 150, training accuracy 0.875\n",
      "f : 1360.36462402, q : -380497.875, p : -696276.8125, l : 1398.37072754\n",
      "ep 7, step 200, training accuracy 0.875\n",
      "f : 916.862792969, q : -379636.875, p : -696647.875, l : 918.394042969\n",
      "valid accuracy 0.8995\n",
      "ep 8, step 0, training accuracy 0.865\n",
      "f : 160036.859375, q : -380279.9375, p : -696325.5, l : 1163.44604492\n",
      "ep 8, step 50, training accuracy 0.88\n",
      "f : 1045.53662109, q : -378655.71875, p : -691151.125, l : 1076.11157227\n",
      "ep 8, step 100, training accuracy 0.86\n",
      "f : 1204.72192383, q : -378215.6875, p : -692140.1875, l : 1218.09570312\n",
      "ep 8, step 150, training accuracy 0.885\n",
      "f : 1301.41809082, q : -378496.96875, p : -693885.0, l : 1286.57714844\n",
      "ep 8, step 200, training accuracy 0.895\n",
      "f : 868.66809082, q : -378500.875, p : -695748.75, l : 896.965698242\n",
      "valid accuracy 0.9011\n",
      "ep 9, step 0, training accuracy 0.875\n",
      "f : 158998.515625, q : -377939.5, p : -694533.25, l : 1034.2800293\n",
      "ep 9, step 50, training accuracy 0.87\n",
      "f : 992.190551758, q : -376181.25, p : -690501.25, l : 1086.39501953\n",
      "ep 9, step 100, training accuracy 0.88\n",
      "f : 1142.4909668, q : -376800.9375, p : -692761.125, l : 1242.56982422\n",
      "ep 9, step 150, training accuracy 0.885\n",
      "f : 1180.34143066, q : -376135.5, p : -690745.1875, l : 1185.28894043\n",
      "ep 9, step 200, training accuracy 0.905\n",
      "f : 845.851501465, q : -375999.78125, p : -691389.4375, l : 888.087280273\n",
      "valid accuracy 0.9115\n",
      "ep 10, step 0, training accuracy 0.895\n",
      "f : 158758.265625, q : -376154.59375, p : -692340.375, l : 1014.81164551\n",
      "ep 10, step 50, training accuracy 0.895\n",
      "f : 974.376159668, q : -375976.59375, p : -687222.375, l : 1013.60638428\n",
      "ep 10, step 100, training accuracy 0.88\n",
      "f : 1123.6105957, q : -375596.8125, p : -687682.0, l : 1140.66699219\n",
      "ep 10, step 150, training accuracy 0.875\n",
      "f : 1141.77844238, q : -375128.5625, p : -689648.875, l : 1158.71411133\n",
      "ep 10, step 200, training accuracy 0.915\n",
      "f : 795.792175293, q : -374999.71875, p : -688892.875, l : 795.262084961\n",
      "valid accuracy 0.9084\n",
      "ep 11, step 0, training accuracy 0.895\n",
      "f : 158948.375, q : -374696.5, p : -689076.875, l : 961.38104248\n",
      "ep 11, step 50, training accuracy 0.88\n",
      "f : 1058.94567871, q : -374030.75, p : -685200.125, l : 1001.8961792\n",
      "ep 11, step 100, training accuracy 0.89\n",
      "f : 1121.64355469, q : -374820.0, p : -685776.375, l : 1144.67749023\n",
      "ep 11, step 150, training accuracy 0.875\n",
      "f : 1152.36682129, q : -374568.0, p : -688325.625, l : 1131.97607422\n",
      "ep 11, step 200, training accuracy 0.9\n",
      "f : 757.528015137, q : -373690.3125, p : -687815.625, l : 797.991088867\n",
      "valid accuracy 0.9132\n",
      "ep 12, step 0, training accuracy 0.9\n",
      "f : 157857.3125, q : -372892.625, p : -687781.875, l : 1000.30633545\n",
      "ep 12, step 50, training accuracy 0.9\n",
      "f : 897.275634766, q : -372744.5625, p : -683723.375, l : 979.764160156\n",
      "ep 12, step 100, training accuracy 0.87\n",
      "f : 1118.19030762, q : -372332.4375, p : -684144.0625, l : 1093.43212891\n",
      "ep 12, step 150, training accuracy 0.88\n",
      "f : 1189.20446777, q : -371943.1875, p : -685160.75, l : 1045.78100586\n",
      "ep 12, step 200, training accuracy 0.93\n",
      "f : 729.809326172, q : -371705.3125, p : -684918.75, l : 753.172912598\n",
      "valid accuracy 0.9165\n",
      "ep 13, step 0, training accuracy 0.905\n",
      "f : 158316.15625, q : -372300.1875, p : -685818.6875, l : 944.322143555\n",
      "ep 13, step 50, training accuracy 0.9\n",
      "f : 898.898071289, q : -370980.3125, p : -682027.1875, l : 887.847290039\n",
      "ep 13, step 100, training accuracy 0.895\n",
      "f : 1078.9498291, q : -371174.65625, p : -682060.5, l : 1112.89831543\n",
      "ep 13, step 150, training accuracy 0.88\n",
      "f : 1084.58996582, q : -371282.21875, p : -682546.375, l : 1109.87316895\n",
      "ep 13, step 200, training accuracy 0.925\n",
      "f : 725.459106445, q : -370600.25, p : -682672.4375, l : 743.46887207\n",
      "valid accuracy 0.9176\n",
      "ep 14, step 0, training accuracy 0.905\n",
      "f : 157504.5, q : -370647.375, p : -683018.4375, l : 912.251586914\n",
      "ep 14, step 50, training accuracy 0.905\n",
      "f : 925.661437988, q : -370276.09375, p : -679810.25, l : 842.885009766\n",
      "ep 14, step 100, training accuracy 0.9\n",
      "f : 1022.76623535, q : -369721.125, p : -679331.8125, l : 1019.65350342\n",
      "ep 14, step 150, training accuracy 0.895\n",
      "f : 1055.77160645, q : -370029.0, p : -679357.75, l : 1058.79992676\n",
      "ep 14, step 200, training accuracy 0.93\n",
      "f : 736.815307617, q : -370017.125, p : -678732.375, l : 712.008239746\n",
      "valid accuracy 0.9203\n",
      "ep 15, step 0, training accuracy 0.91\n",
      "f : 155698.546875, q : -369824.03125, p : -682114.0, l : 868.079040527\n",
      "ep 15, step 50, training accuracy 0.9\n",
      "f : 840.780883789, q : -368953.375, p : -676353.25, l : 945.630371094\n",
      "ep 15, step 100, training accuracy 0.905\n",
      "f : 1034.66772461, q : -367992.4375, p : -677256.5625, l : 1039.51855469\n",
      "ep 15, step 150, training accuracy 0.91\n",
      "f : 1078.85351562, q : -367981.5, p : -677343.75, l : 1020.95135498\n",
      "ep 15, step 200, training accuracy 0.925\n",
      "f : 668.014831543, q : -367592.625, p : -678091.5625, l : 655.442749023\n",
      "valid accuracy 0.9189\n",
      "ep 16, step 0, training accuracy 0.93\n",
      "f : 155933.46875, q : -367773.0, p : -680019.1875, l : 871.028442383\n",
      "ep 16, step 50, training accuracy 0.9\n",
      "f : 908.219360352, q : -367817.1875, p : -674163.4375, l : 890.799682617\n",
      "ep 16, step 100, training accuracy 0.89\n",
      "f : 988.225036621, q : -366865.875, p : -675487.625, l : 1044.38745117\n",
      "ep 16, step 150, training accuracy 0.905\n",
      "f : 1019.51428223, q : -366901.625, p : -674784.9375, l : 958.469360352\n",
      "ep 16, step 200, training accuracy 0.94\n",
      "f : 656.183654785, q : -366682.40625, p : -675695.5625, l : 689.10736084\n",
      "valid accuracy 0.9207\n",
      "ep 17, step 0, training accuracy 0.905\n",
      "f : 154898.328125, q : -366555.75, p : -676738.8125, l : 862.661987305\n",
      "ep 17, step 50, training accuracy 0.905\n",
      "f : 880.569946289, q : -366737.4375, p : -672289.375, l : 837.331481934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fe93fc865272>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mbnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecay_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#         if (i+1) % 20 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#             print(\"klrw index : %g\"%(bnn.get_klrw()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/bayes_nn_shson/bnn_shson.pyc\u001b[0m in \u001b[0;36mdecay_klrw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecay_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoeff_kl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoeff_kl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \"\"\"\n\u001b[1;32m--> 559\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3654\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3655\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3656\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 710\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    711\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 908\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 958\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    959\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    941\u001b[0m                 run_metadata):\n\u001b[0;32m    942\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    944\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[1;32m--> 992\u001b[1;33m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[0;32m    993\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "n_epochs = 100\n",
    "n_batches = len(t_train) / batch_size\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for ep in range(n_epochs):\n",
    "    bnn.reset_klrw()\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        bnn.decay_klrw()\n",
    "#         if (i+1) % 20 == 0:\n",
    "#             print(\"klrw index : %g\"%(bnn.get_klrw()))\n",
    "        \n",
    "        feed = {bnn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "        \n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "        \n",
    "#         if i > 50 and np.mean(fs[-50:-25]) < np.mean(fs[-25:]):\n",
    "#             bnn.decay_lr()\n",
    "#             print (\"--- learning rate decayed : %g ---\"%(bnn.get_lr()))\n",
    "\n",
    "        if i%50 == 0:\n",
    "            train_accuracy = bnn.validate(feed)\n",
    "\n",
    "            print(\"ep %d, step %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "            print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "            #print v_q - v_p + v_l\n",
    "\n",
    "        bnn.train(feed)\n",
    "    \n",
    "    vacc = bnn.validate({bnn.x: x_valid, bnn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    if ep > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "        bnn.decay_lr()\n",
    "        print (\"--- learning rate decayed : %g ---\"%(bnn.get_lr()))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEACAYAAACUMoD1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f449a7b5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coeff_klrw = 1 / n_batches\n",
    "\n",
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs*coeff_klrw, 'b')\n",
    "plt.plot(ps*coeff_klrw, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VdW5//HPEwaR0UBkEElABkWGAiqithpxQqpiFVGQ\nonSQ1or2SluxV6+odapeW1u14q/oFYpSFRUUVCoaBRlFYkAmZQwgICIJYQgheX5/7BCSkJCTcJIz\n8H2/XueVs89ZZ5+HhHzPytp7r2XujoiIxJeESBcgIiLhp3AXEYlDCncRkTikcBcRiUMKdxGROKRw\nFxGJQxWGu5mNM7OtZpZxhDZ/M7OvzCzdzHqEt0QREamsUHruLwKXlfekmV0OtHf3jsAI4Lkw1SYi\nIlVUYbi7+2zg+yM0GQCML2w7H2hiZi3CU56IiFRFOMbcWwOZxbY3FT4mIiIRogOqIiJxqHYY9rEJ\naFNs++TCxw5jZprIRkSkCtzdKtM+1J67Fd7KMhUYBmBmfYCd7r71CAVG/e2+++6LeA2qU3XGao2q\nM/y3qqiw525mLwOpQDMz2wDcB9QNctqfd/fpZtbfzL4GdgPDq1SJiIiETYXh7u5DQmhzW3jKERGR\ncNAB1TKkpqZGuoSQqM7wioU6Y6FGUJ3RwKo6nlOlNzPzmnw/EZF4YGZ4JQ+ohuNsGRGJYW3btmX9\n+vWRLkOAlJQU1q1bF5Z9qecucowr7BVGugyh/J9FVXruGnMXEYlDCncRkTikcBcRiUMKdxGROKRw\nF5G49utf/5qHHnoo0mXUOJ0tI3KMi/azZdq1a8e4cePo27dvpEupdjpbRkQEyM/Pj3QJUUvhLiJR\na9iwYWzYsIErrriCxo0b8/jjj5OQkMALL7xASkoKF110EQCDBg2iVatWJCYmkpqayrJly4r2MXz4\ncP7nf/4HgI8//pg2bdrw5JNP0qJFC1q3bs3//d//VVjH9OnT6dWrF02aNCElJYX777+/xPOzZ8/m\nvPPOIzExkZSUFMaPHw/Avn37GDVqFG3btiUxMZHzzz+f3NzcMH13jkzhLiIVMgvPrbLGjx9PcnIy\n06ZNIzs7m0GDBgHwySefsGLFCt5//30A+vfvz+rVq9m2bRu9evXixhtvLHefW7ZsYdeuXWzevJl/\n/vOf/OY3vyErK+uIdTRs2JAJEyaQlZXFtGnTeO6555g6dSoA69evp3///txxxx1s376d9PR0evTo\nAcCoUaNYvHgx8+bNY8eOHfz5z38mIaGGYreG5yR2EYku0f572bZtW585c6a7u69bt84TEhJ83bp1\n5bb//vvv3cw8Ozvb3d1vvvlmv/fee93dPS0tzevXr+/5+flF7Zs3b+7z58+vVE2//e1v/c4773R3\n90ceecSvueaaw9oUFBT48ccf70uWLAl5v+X9LAofr1TequcuIjHn5JNPLrpfUFDA6NGj6dChAyec\ncALt2rXDzNi+fXuZr23WrFmJ3nP9+vXJyck54vstWLCAvn370rx5c0444QTGjh1btP/MzEzat29/\n2Gu2b99Obm4up5xySlX+iUdN4S4iUc3KGM8p/tjLL7/M22+/zYcffsjOnTtZt27dUa1gVJYhQ4Zw\n9dVXs2nTJnbu3MmIESOK9t+mTRu+/vrrw16TlJREvXr1WL16ddjqqAyFu4hEtZYtW7JmzRqAMkN7\n165dHHfccSQmJrJ7927uvvvuMj8QjkZOTg6JiYnUqVOHBQsW8PLLLxc9d+ONNzJz5kxef/118vPz\n2bFjB1988QVmxvDhw7nzzjv55ptvKCgoYN68eeTl5YW1tvIo3EUkqo0ePZoHH3yQpk2bMnny5MOC\ne9iwYSQnJ9O6dWu6du3KueeeW6n9h/JB8Oyzz3LvvffSpEkT/vSnP3H99dcXPdemTRumT5/OE088\nQdOmTenZsycZGRkAPPHEE3Tr1o2zzjqLZs2aMXr0aAoKCkKqKz8fFi2Cxx6r1D/n0L8rnH+6VPhm\nuohJJOpE+0VMxxIz47nnnA8+gA8/hBYt4OKL4e9/r/xFTAp3kWOcwj16mBlDhzoXXxyEeuvWhx5X\nuItIpSjcA127dmXDhg1F2+6OmTF27FgGDx5cIzWEc/oBhbvIMU7hHj00t4yIiByRwl1EJA7VjnQB\nIiJSzMyZsG9fyVsVKNxFRKLJQw9BvXolb1WgA6oiMcAdNmyAzEzo2RMaNAjfvnVANXqE84Cqeu4i\nUSYrC5YsCW4ZGYfuN2wIJ50EK1bAGWdQdC70mWdC7Yp+k/ftg2+/hW3bglvx+3Ho448/ZujQoWRm\nZgLBaY7PPvss559/foVt40VI4W5m/YC/EhyAHefuj5V6/gTgBaA9sBf4mbsvO2xHIvFq50744otD\nt/R0WLkSjjsOGjc+/NakCfkNGrM9rzEbsxuzdntjVm1pzNLMxmzKbkzzjk1I6daYbj0ac/2g+nTr\nbjRrFrzV7t0wO+0Ac9/5jsdv+pa8Tdu4oPM2erfdxulJ22h6YBv2bakA37cPTjwRmjc//Banik8r\nsHTp0pDbxosKw93MEoCngYuAzcBCM5vi7iuKNfsjsNjdrzGzU4FngIuro2CRiCoogLVrDwX4wTD/\n7jvo1g1+8APo3Rt++Uvo3BkOHMCzstm+Jps1X2SzaVk2W1dlsWN2Nnu2ZNO6UTZtm26jQ8Nszq2X\nzQntszg+LxvLzoYPs+GtbMjNhUaNgg+FevVosGMHl+3cyWWJidC8Oft7NOeb/OZ89WVzXtx0It/V\nOoPWPZvT6eLm9OrXnKTTmwevLS/A7rqrZr+HUjMqmvAd6AO8W2x7NHBXqTbvAOcV2/4aOLGMfYU8\nab1IxO3e7T5vnvvYse633up+3nnujRq5t2njfsUV7vfc4/7aa+6rVrkXLv6Qk+M+f777P//pfvvt\n7hde6N6sWXC78EL3O+4InluwIGgbkrw89x073NeudV+2zH3rVvcDB8psWlDgvnKl+zPPuF99tfsJ\nJ7h36+Z+553u06eX/Z7R/Hv52GOP+cCBA0s8dscdd/gdd9zhL774onfu3NkbNWrk7du397Fjxxa1\nSUtL8zZt2hRtF1/wY+/evX7TTTd5YmKid+nSxR9//PESbcvz6KOPevv27b1Ro0bepUsXf/PNN0s8\n//zzzxfV06VLF1+8eLG7u2dmZvo111zjJ554oiclJfnIkSPLfY/yfhZUYbGOUIZlWgPFB6M2Ar1L\ntfkCuAb41Mx6A8nAycC3Vfi8Eal+7rB/f9Arzs2FnBxYvrxkj3zDBjj1VOjRI+iRDxwYfG3alPx8\nWLOmcFx84qHx8U2bgpd07x505H/84+Bry5ZVW2YOCAbUExODWwXMoFOn4HbrrXDgQDCz4AcfBLML\nXnddMF5/ySWHxutDEq5hi0oeuL3hhht44IEH2L17Nw0aNKCgoIBXX32Vt956i++++45p06bRrl07\nZs2aRb9+/ejdu3fREnflGTNmDGvXrmXt2rXk5OTQr1+/kGrp0KEDn376KS1atOC1115j6NChrF69\numj7gQceYMqUKfTq1Ys1a9ZQp04dCgoKuOKKK7j44ouZOHEiCQkJfPbZZ5X6HlRVuA6oPgo8ZWaf\nA0uAxYCWJZfwyc2FVauCAF65ErILhyv27TsU0BVtl36uTp1gTPy44+D44+G004LwvuIKuOeeYLtO\nHbZvL3Zwc2LwddkySEo6FOKDBsGDD0LHjsFuo0Xt2nD22cHtv/87GK+fNSsI+xEjgs+vkETobJrk\n5GR69erFm2++ydChQ5k5cyYNGjSgd++S/csf/ehHXHrppcyaNavCcH/ttdd47rnnaNKkCU2aNOH2\n22/nwQcfrLCWa6+9tuj+ddddx8MPP8yCBQu48sorGTduHH/4wx/o1asXQNHqS/PmzeObb74psXZq\nZackrqpQwn0TQU/8oJMLHyvi7ruAnx3cNrO1wJqydjZmzJii+6mpqaSmpoZcrBwDsrKC00GWLy95\ny8yEdu2CcexTTw0ODh4M5nr1Dt0vvX2k50otVJybG7xVRgYsGX/oTJXduw+F+JlnwvDh0LUrNGkS\noe/RUWjQAPr1C24AW7cGf1VEs8GDB/PKK68wdOhQXnnlFYYMGQLAu+++ywMPPMCqVasoKChg7969\ndO/evcL9bd68ucQyfSkpKSHVMX78eP7yl7+wbt06AHbv3l3hUnuZmZmkpKRUelHstLQ00tLSKvWa\n0kIJ94VABzNLAb4BbgBKTJFmZk2APe6eZ2a/BD529zIXJSwe7nKMcoctWw4P8OXLgx75qacGId65\nM9x8c/C1Q4dq6RKvWQMvvwyvvx78QdC+fRDi3bvDyJHB1zZtwjcqEW1atIh0BRW77rrr+N3vfsem\nTZt48803mT9/Pvv372fgwIH861//YsCAASQkJPCTn/wkpPP1W7VqRWZmJp07dwZg/fr1Fb5mw4YN\n3HLLLXz00Uecc845APTs2bPEUntlLafXpk0bNmzYQEFBQaUCvnTH9/777w/5tQdVGO7unm9mtwEz\nOHQq5HIzGxE87c8DnYGXzKwA+BL4eaUrkfhTUADr1gVjGKVDvHbtQwHeuXMwFNK5c5CklezlVNa3\n38Krr8LEifD118E49NNPw1lnBR16iS5JSUlccMEFDB8+nFNOOYVOnTqRk5PD/v37SUpKIiEhgXff\nfZcZM2bQrVu3Cvc3aNAgHnnkEXr37k1OTg5PP/10ha/ZvXs3CQkJJCUlUVBQwEsvvVTi9Mpf/OIX\njBo1ivPOO49evXqxevVq6tatS+/evWnVqhWjR49mzJgx1KpVi0WLFtXI0ExIY+7u/h5waqnHxha7\nP6/083IMcQ+OJC5dCl9+GXxdujQI9aZN4fTTg+A+++xDPfETT6zREnfvhilTgkD/9FPo3z8Yg770\n0ugaI5eyDRkyhJtuuonHH38cgIYNG/K3v/2N6667jv3793PllVcyYMCAcl9f/Dz2++67j1/96le0\na9eO1q1bM3z4cJ566qkjvn/nzp0ZNWoUffr0oVatWgwbNowf/vCHRc8PHDiQHTt2MGTIEDZv3kzb\ntm2ZMGECbdq04e2332bkyJEkJyeTkJDAkCFDaiTcNf2AVM62bSUD/GCg16sXDER36RJ87doVTj+d\n7w40oVEjqFu35ks9cAD+858g0N95B845B268Ea6+OrjaUwKafiB6aLEOqX47dx4K8eJhnpd3KLwP\n3rp0YW+DJJYtK3nJfEZGcILK/v3BWSQHD0oe/Nq6dfjHst1hwQL417+CoZd27YJAv/76uL4Y86go\n3KOHwl3Cb+XK4Mji/PlBiGdlBcMpxQKcrl0paNGK9RuMjIySIb5+ffkBvm8fZQZ/Xl7Jtt27B29V\nlV71qlVBD33iRKhVKwj0IUOC47ByZAr3QGZmJqeffnqJIRwvXGpv2bJlJc6wqS4KdwmP7dth0iSY\nMCE44XnwYOjbN0jY5GS+z0o4bAKrpUuDUwAPhvHBYD711MoPvWzdevgEWcuWQatWh39IdOgQhHZx\nW7YE5U+cCBs3wg03BKF+xhnxe3ZLdVC4Rw+Fu1Tdvn3BAPSECfDxx9C/PweGDGPFyReTsax2UdBm\nZAQjM127Hh60IVwoWWUHDgRnsJTu5W/dGhyH7d49CPq0NFi4EAYMCAK9b9/Dw19Co3CPHgp3qRx3\n+PRTfPwECl57nZ3JP2Bep2G8lXAN85c35quvICXl8N5427bVflZiyHbtCv5qWLIkuMapTx+48srg\nwlI5Ogr36KFwlwrl5MBX735NwUsTSJk1gZwD9XjJh/FW/RtJ6tmmRE/89NMVkseytm3bhnQhj1S/\nlJSUoitgi1O4H4Py84NhjINDGGs+20G7hf/mxzsm0DFhNYs6Dubbfj+lxeW96NbdYuKKRBEpSeF+\njNixA554AmbMCC72TG6Ry7Ck6QzInkDHDTPZe+HlNBjxU2pdrit0ROKBwj3O7dkDTz0FTz4J1/zE\nue3MeZy6YAJ133o1OPL5058G09LG4oxWIlIuraEap/LyYNw4+NMDBdzUeQErr5pM0w8mwyd1g0D/\n7LPg6KeISCGFexQrKIDX/53PW7//lOsSJrMm/w3qftMIzr0W3ngjmHtcJ3SLSBk0LBOFPO8Ai/43\njXX/O5nUnW9yXHJLGt18LVx7bXBqi4gcUzQsE8tyc2HmTL59bjJ135tC3YRT6HTttTQbMxvrqGvo\nRaRy1HOPpL174f334fXXyX97GqvqdGHSgYF0Gn0Ng0Yl60QXEQHUc48NOTkwfXqw9M+MGezr0ovJ\nDOSR2o/z09+34q6RUL9+pIsUkVincK8J2dkwdWoQ6B9+COeey+7LB/JE82f42ysn8stfwqx3qnfO\nFhE5tkTJzCFxatu2YLmfU06Bf/8brrmGPcvX88gF79H2T79gc96JZGTAo48q2EUkvBTu1WHDBrj9\ndjjttOBy0gULyHvjbZ7bM4yOvRNZvDhY6m3s2GC+cxGRcNOwTDitXAmPPRYs1vnznwcrGLVqxbRp\n8F/9gpkXp0yBM8+MdKEiEu8U7uHw+efwyCPB/OgjRwYzeSUmsmcPjPo1vPde0Eu/9NJIFyoixwoN\ny1SVexDml10GV10F550Ha9fCvfdCYjD0csYZwTzk6ekKdhGpWeq5V5Y7TJsW9NS3bYPRo2HoUDju\nOCCYMuDJJ4PRmb/+NVglSESkpincQ3XgALz2WnBqS0IC3H13MB1AsbXdNm2CYcOCi00XLtRcXiIS\nORqWqUhuLjz/fHDmyz/+EYT755/DoEElgn3yZOjVCy68MFjfU8EuIpGknnt5cnKCo6BPPhnMvvji\ni/CjH5XZ7Le/DQJ96lQ4++yaL1VEpDT13EvLyoL77w8uPFqwAN55J5guoIxgX7gQevYMxtkXL1aw\ni0j0UM+9uF274OKLoWNHmD0bOnUqs1l+fnDA9Kmn4Omn4brrarhOEZEKKNwPys2Fq68Ozl/8xz/K\nXQRj/fpg8aNatYIFkNq0qeE6RURCENKwjJn1M7MVZrbKzO4q4/lmZvaumaWb2RIzuznslVan/HwY\nMgSaNYNnnik32CdNgrPOgiuugA8+ULCLSPSqcD53M0sAVgEXAZuBhcAN7r6iWJv7gHrufreZJQEr\ngRbufqDUvqJvPnd3uOWWoEv+9ttF56sXl50dXHg6fz5MnBh07kVEakpV5nMPpefeG/jK3de7ex4w\nCRhQqs0WoFHh/UbAd6WDPWrdfTdkZARrkpYR7HPnBgdNjz8eFi1SsItIbAhlzL01kFlseyNB4Bf3\n/4CZZrYZaAhcH57yqtnjjwfnL86aBQ0blnjqwAF46KFg+H3sWBhQ+uNMRCSKheuA6t3AF+5+oZm1\nB/5jZt3dPad0wzFjxhTdT01NJTU1NUwlVNILLwTj67NnB2PtxaxZE8wo0KhRcIpjq1aRKVFEjk1p\naWmkpaUd1T5CGXPvA4xx936F26MBd/fHirWZDjzk7p8Wbs8E7nL3z0rtKzrG3N96C269NbjyqNTp\njm+/HczW+8c/BlOyJ+hKABGJsOpaQ3Uh0MHMUoBvgBuAwaXaLAcuBj41sxZAJ2BNZQqpMR99FBxA\nfe+9w4L9P/8Jgn3atOCsGBGRWFVhuLt7vpndBswgOAA7zt2Xm9mI4Gl/HngEeNHMvgAM+IO776jO\nwqtk0SK4/np49dVgIphi5s4NzoZ84w0Fu4jEvgqHZcL6ZpEcllm5ElJT4bnnDjs6+sUXwXzrL70E\n/fpFpjwRkfJU16mQsW/jxmBRjYcfPizYv/oKLr88mEZAwS4i8SL+w/2774Ju+ciRMHx4iacyM+GS\nS+DBBzU/jIjEl/gelsnJgYsugr59g5WTitm2Dc4/Pzi2euedNVeSiEhlVWVYJn7DPTcXrrwSUlKC\nxTaKzRezc2ewqMaVV8IDD9RMOSIiVaVwPyg/HwYPDr6++mqJFZP27AmG33v2DKbsLWeOMBGRqKFw\nh2AisF/9ClavDk5YLzZfzP79wfHU5s2DhZV0gZKIxILquogpttxzT7DG6Ycflgj2/PxgSoF69WDc\nOAW7iMS3+Ar3J58MrkKaNSuYGKaQO4wYAd9/H6yaVzu+/tUiIoeJn5h76aVgEH32bEhKKnrYHX73\nO/jyy2B6gTJm9RURiTvxEe5Tp8Lo0cG8MaWWR3rooSDUP/74sFl9RUTiVuyH+8cfwy9+ERw8Pe20\nEk/9/e9Bh37WLEhMjFB9IiIRENvhvmJFcGnpK68cNtvX+PHBWhyzZkHLlhGqT0QkQmI73F97DYYN\nC65CLebNN+Guu4JRmpSUCNUmIhJBsX1CYHo6nHlmiYc++CA4M6aMURoRkWNG7Id7jx5FmwfnZJ88\n+bDp2kVEjimxe4VqVhacdBJkZ0OtWmRkBDM8ak52EYk3x9Z87hkZ0K0b1KqlOdlFREqJ3XAvHJLJ\nzAyma3/gAc3JLiJyUEyHe06HHlxySbAOx89/HumCRESiR0yH+5tre3D22VpsQ0SktNgM97w8WL6c\nd9Z3o3//SBcjIhJ9YjPcV6zAk5P5aEEDzj030sWIiESf2Az3wvH24447bJ4wEREhhsP9q/o9OOec\nSBciIhKdYjbc5+zpoSEZEZFyxF64uxedKaOeu4hI2WIv3DdupKB2Heavb0nPnpEuRkQkOsXelL/p\n6Xyf3IOe9aBu3UgXIyISnULquZtZPzNbYWarzOyuMp7/nZktNrPPzWyJmR0wsxPCXy6Qns6KehqS\nERE5kgrD3cwSgKeBy4AuwGAzKzFTurs/4e493b0XcDeQ5u47q6Ng0tOZtUsHU0VEjiSUnntv4Ct3\nX+/uecAkYMAR2g8GXglHcWXx9HTeWKOeu4jIkYQS7q2BzGLbGwsfO4yZHQ/0AyYffWllyMrCv9nC\n90kdadGiWt5BRCQuhPuA6pXA7CMNyYwZM6bofmpqKqmpqaHvPSOD7a260efcWlWvUEQkyqWlpZGW\nlnZU+6hwJSYz6wOMcfd+hdujAXf3x8po+wbwqrtPKmdfR7cS09//TtozX7Ls9ue49daq70ZEJJZU\n10pMC4EOZpZiZnWBG4CpZbx5E+ACYEplCqiU9HQ+ztLBVBGRilQY7u6eD9wGzAC+BCa5+3IzG2Fm\ntxRrejXwvrvvrZ5S4cCidD7J7kHXrtX1DiIi8SF2FsjOyyO/UROu6vMt09IahLcwEZEoFt8LZK9Y\nwY6GyfT6kYJdRKQisRPu6eksraXz20VEQhEz4V7weTppO3vQp0+kKxERiX4xE+6756SzuXkPmjaN\ndCUiItEvNsLdnTpfptPwhz0iXYmISEyIjXDfuJF9+XXoenHLSFciIhITYiPc09PJMB1MFREJVUyE\ne87sdD4v6MFpp1XcVkREYiTcsz9JZ99pPUiIiWpFRCIvJuLyuOXpND5fB1NFREIV/eGelUX9XVs4\n9YqOka5ERCRmRH245y3KYAnd6H2O5nAXEQlV1If75unprE/sQaNGka5ERCR2RH2475qdTt7pGm8X\nEamMqA/3+ivTSbxQ4S4iUhnhXkM1vPLyaJW1HAZ2i3QlIiIxJarDfUvaCnYlJNOhq+ZwFxGpjKge\nllk/JZ0tLXtglVp/REREorrnvmdOOtZN4+0iIpUV1T33hl+nk3SRwl1EpLKidoHsvXucPQ2SqL/m\nS45vp6l+ReTYFVcLZGdM3wi16yjYRUSqIGrDfeM76WxrrSEZEZGqiNpwz52fDj9QuIuIVEVUhrs7\nNF6TzomXKtxFRKoiKsN9zRromq8zZUREqioqw33hB1m0ZAt01BzuIiJVEZXhvundDL4/uRvU0hzu\nIiJVEVK4m1k/M1thZqvM7K5y2qSa2WIzW2pmHx1NUXkL00nopSEZEZGqqnD6ATNLAJ4GLgI2AwvN\nbIq7ryjWpgnwDHCpu28ys6SqFrRrF7Talk6zvmdVdRciIse8UHruvYGv3H29u+cBk4ABpdoMASa7\n+yYAd99e1YIWLIA+x6VT+0z13EVEqiqUcG8NZBbb3lj4WHGdgKZm9pGZLTSzn1a1oHmz8miXuxy6\naQ53EZGqCteskLWBXkBfoAEw18zmuvvXpRuOGTOm6H5qaiqpqaklnt80cwW5LZKp20BzuIvIsSkt\nLY20tLSj2keFE4eZWR9gjLv3K9weDbi7P1aszV1APXe/v3D7n8C77j651L6OOHFYQQHc2mgCf71k\nGvXemlTVf5OISFypronDFgIdzCzFzOoCNwBTS7WZAvzQzGqZWX3gbGB5ZQoBWLECzqyTTr0+Gm8X\nETkaFQ7LuHu+md0GzCD4MBjn7svNbETwtD/v7ivM7H0gA8gHnnf3ZZUtZu5cOKdeOvT4fWVfKiIi\nxUTVfO4//5nzzKtJ1Pv6S2ipqX5FRCAO5nNfO2sjterVUbCLiBylqAn3HTsgaVM6tc7QeLuIyNGK\nmnCfNw8ub5lOQk+Fu4jI0YqacJ87F3rXTYceCncRkaMVNeE+Zw60zVK4i4iEQ1ScLXPgALRNzCKz\n4CQsO1tT/YqIFFOVs2XCNf3AUVm6FFKbZmCtNIe7iEg4REW4z50Ll5+kBbFFRMIlKsbc58yBM2tp\nvF1EJFyiJtyTv1e4i4iES8SHZbZuhezv8qi3X3O4i4iES8TDfe5cGNh1BbY9GTSHu4hIWERFuF/W\nIh1O1pCMiEi4RHzMfc4c6GkabxcRCaeIhvv+/bB4MbT+VuEuIhJOEQ339HTo0N6pvVThLiISThEN\n9zlzoH/3jVBHc7iLiIRTRMN97ly45ET12kVEwi3iPffuBQp3EZFwi1i4Z2ZCbi40zVS4i4iEW8TC\nfe5cOPdcsHSFu4hIuEUs3OfMgQt6ZgfzD3TsGKkyRETiUkR77n2TMqBrV83hLiISZhEJ9717gwU6\nOudqSEZEpDpEJNw/+wy6dIG6yxTuIiLVISLhfvBgKjqYKiJSLSIS7nPmwLln5cGyZZrDXUSkGtR4\nuLsHPffzW6yEZM3hLiJSHUIKdzPrZ2YrzGyVmd1VxvMXmNlOM/u88HZPeftas6ZwKpktGpIREaku\nFS7WYWYJwNPARcBmYKGZTXH3FaWafuLuV1W0vzlzNN4uIlLdQum59wa+cvf17p4HTAIGlNHOQnlD\nHUwVEamLfqCiAAAHAElEQVR+oYR7ayCz2PbGwsdKO8fM0s1smpmdXt7O5syBc/q4wl1EpBqFaw3V\nRUCyu+8xs8uBt4BOZTX8+mvo2XwT1K6tOdxFRKpJKOG+CUgutn1y4WNF3D2n2P13zexZM2vq7jtK\n76xp0zE8fM8qaNiQ1LQ0UlNTq1i6iEh8SktLIy0t7aj2Ye5+5AZmtYCVBAdUvwEWAIPdfXmxNi3c\nfWvh/d7Aq+7etox9+e9/7/y58Z8gJwceffSoihcRORaYGe4e0nHNgyocc3f3fOA2YAbwJTDJ3Zeb\n2Qgzu6Ww2UAzW2pmi4G/AteXtz8dTBURqX4V9tzD+mZmvmWL0+K8DvDOO3DaaTX23iIisaoqPfca\nD3fPyoKTToKsLE31KyISgmoZlgm7DM3hLiJS3Wo+3DXeLiJS7RTuIiJxSOEuIhKHav6A6vHHw7ff\naqpfEZEQxcYBVc3hLiJS7Wo+3DUkIyJS7RTuIiJxSOEuIhKHFO4iInGo5s+WqcH3ExGJB7FxtoyI\niFQ7hbuISBxSuIuIxCGFu4hIHFK4i4jEIYW7iEgcUriLiMQhhbuISBxSuIuIxCGFu4hIHFK4i4jE\nIYW7iEgcUriLiMQhhbuISBxSuIuIxCGFu4hIHAop3M2sn5mtMLNVZnbXEdqdZWZ5ZnZN+EoUEZHK\nqjDczSwBeBq4DOgCDDaz08pp9yjwfriLrGlpaWmRLiEkqjO8YqHOWKgRVGc0CKXn3hv4yt3Xu3se\nMAkYUEa7kcDrwLYw1hcRsfIDV53hFQt1xkKNoDqjQSjh3hrILLa9sfCxImZ2EnC1u/8DqNQ6fyIi\nEn7hOqD6V6D4WLwCXkQkgszdj9zArA8wxt37FW6PBtzdHyvWZs3Bu0ASsBu4xd2nltrXkd9MRETK\n5O6V6jSHEu61gJXARcA3wAJgsLsvL6f9i8Db7v5GZQoREZHwqV1RA3fPN7PbgBkEwzjj3H25mY0I\nnvbnS7+kGuoUEZFKqLDnLiIisafGrlAN9UKoSDKzk83sQzP70syWmNntka6pPGaWYGafm9nUiltH\nhpk1MbPXzGx54ff07EjXVBYzu7uwvgwzm2hmdSNdE4CZjTOzrWaWUeyxRDObYWYrzex9M2sSyRoL\nayqrzj8X/tzTzWyymTWOZI2FNR1WZ7HnRplZgZk1jURtpWops04zG1n4PV1iZo9WtJ8aCfdQL4SK\nAgeAO929C3AO8JsorRPgDmBZpIuowFPAdHfvDPwAKPM4TSSZWQrwS6Cnu3cnGKq8IbJVFXmR4Hem\nuNHAB+5+KvAhcHeNV3W4suqcAXRx9x7AV0RvnZjZycAlwPoar6hsh9VpZqnAlUA3d+8GPFHRTmqq\n5x7qhVAR5e5b3D298H4OQRi1PvKral7hf8b+wD8jXUt5CntqP3L3FwHc/YC7Z0e4rLJkA/uBBmZW\nG6gPbI5sSQF3nw18X+rhAcBLhfdfAq6u0aLKUFad7v6BuxcUbs4DTq7xwkop5/sJ8Bfg9zVcTrnK\nqfPXwKPufqCwzfaK9lNT4V7hhVDRxszaAj2A+ZGtpEwH/zNG8wGTdsB2M3uxcPjoeTM7PtJFlebu\n3wP/C2wANgE73f2DyFZ1RM3dfSsEnRGgeYTrCcXPgHcjXURZzOwqINPdl0S6lgp0As43s3lm9pGZ\nnVnRCzQrZBnMrCHBVAp3FPbgo4aZ/RjYWvgXhhG9F4zVBnoBz7h7L2APwZBCVDGzU4D/AlKAk4CG\nZjYkslVVSjR/wGNm/w3kufvLka6ltMLOxh+B+4o/HKFyKlIbSHT3PsAfgFcrekFNhfsmILnY9smF\nj0Wdwj/NXwcmuPuUSNdThvOAqwovHHsFuNDMxke4prJsJOgRfVa4/TpB2EebM4FP3X2Hu+cDbwDn\nRrimI9lqZi0AzKwlUTyXk5ndTDB8GK0flu2BtsAXZraWIJcWmVk0/jWUSfB/E3dfCBSYWbMjvaCm\nwn0h0MHMUgrPRLgBiNazPF4Alrn7U5EupCzu/kd3T3b3Uwi+jx+6+7BI11Va4dBBppl1KnzoIqLz\nAPBKoI+Z1TMzI6gzmg78lv7rbCpwc+H9m4Bo6YCUqNPM+hEMHV7l7rkRq+pwRXW6+1J3b+nup7h7\nO4IOSU93j4YPzNI/97eAvgCFv1N13P27I+2gRsK9sEd08EKoL4FJ5V3hGklmdh5wI9DXzBYXjhX3\ni3RdMex2YKKZpROcLfNwhOs5jLt/AYwHFgFfEPxClb4wLyLM7GVgDtDJzDaY2XCCabUvMbODV41X\neEpcdSunzr8DDYH/FP4ePRvRIim3zuKcKBiWKafOF4BTzGwJ8DJQYYdOFzGJiMQhHVAVEYlDCncR\nkTikcBcRiUMKdxGROKRwFxGJQwp3EZE4pHAXEYlDCncRkTj0/wFGPWgcuymbwgAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f449a7978d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n"
     ]
    }
   ],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rho = -2, n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, ep 0, training accuracy 0.075\n",
      "f : 403935.5, q : -331521.4375, p : -710065.3125, l : 20896.6640625\n",
      "batch 0, ep 50, training accuracy 0.06\n",
      "f : 332692.90625, q : -333337.46875, p : -657624.0, l : 8144.63378906\n",
      "batch 0, ep 100, training accuracy 0.145\n",
      "f : 286573.625, q : -329683.0625, p : -608137.75, l : 6041.01220703\n",
      "batch 0, ep 150, training accuracy 0.105\n",
      "f : 251390.15625, q : -321569.15625, p : -567740.8125, l : 5689.74169922\n",
      "valid accuracy 0.1075\n",
      "batch 1, ep 0, training accuracy 0.14\n",
      "f : 227095.953125, q : -313319.4375, p : -535061.125, l : 5410.35644531\n",
      "batch 1, ep 50, training accuracy 0.165\n",
      "f : 209846.359375, q : -303758.65625, p : -509538.4375, l : 5385.74365234\n",
      "batch 1, ep 100, training accuracy 0.19\n",
      "f : 199473.625, q : -293857.5625, p : -486808.625, l : 5323.47998047\n",
      "batch 1, ep 150, training accuracy 0.075\n",
      "f : 190174.71875, q : -285035.25, p : -471502.4375, l : 5441.43066406\n",
      "valid accuracy 0.1026\n",
      "batch 2, ep 0, training accuracy 0.105\n",
      "f : 183828.328125, q : -275661.15625, p : -454294.3125, l : 5312.2890625\n",
      "batch 2, ep 50, training accuracy 0.135\n",
      "f : 177684.8125, q : -268070.9375, p : -440221.8125, l : 5407.12988281\n",
      "batch 2, ep 100, training accuracy 0.14\n",
      "f : 172588.6875, q : -261032.09375, p : -427956.3125, l : 5563.99707031\n",
      "batch 2, ep 150, training accuracy 0.125\n",
      "f : 168250.8125, q : -254341.171875, p : -417426.6875, l : 5345.48632812\n",
      "valid accuracy 0.1242\n",
      "batch 3, ep 0, training accuracy 0.12\n",
      "f : 164483.0625, q : -248652.0625, p : -408072.75, l : 5350.66894531\n",
      "batch 3, ep 50, training accuracy 0.17\n",
      "f : 160968.0, q : -243812.75, p : -400151.5, l : 5386.34814453\n",
      "batch 3, ep 100, training accuracy 0.13\n",
      "f : 158712.828125, q : -238388.28125, p : -392627.375, l : 5368.50878906\n",
      "batch 3, ep 150, training accuracy 0.125\n",
      "f : 155228.140625, q : -234611.21875, p : -385704.5625, l : 5356.14453125\n",
      "valid accuracy 0.135\n",
      "batch 4, ep 0, training accuracy 0.125\n",
      "f : 153566.890625, q : -231644.4375, p : -380002.5625, l : 5466.92675781\n",
      "batch 4, ep 50, training accuracy 0.135\n",
      "f : 151239.703125, q : -228304.84375, p : -374112.1875, l : 5315.55126953\n",
      "batch 4, ep 100, training accuracy 0.175\n",
      "f : 149146.859375, q : -225418.90625, p : -369767.75, l : 5233.01855469\n",
      "batch 4, ep 150, training accuracy 0.205\n",
      "f : 147596.234375, q : -223524.4375, p : -365457.0, l : 5206.76611328\n",
      "valid accuracy 0.146\n",
      "batch 5, ep 0, training accuracy 0.125\n",
      "f : 146068.46875, q : -220529.34375, p : -361465.6875, l : 5352.41162109\n",
      "batch 5, ep 50, training accuracy 0.195\n",
      "f : 144005.578125, q : -218382.4375, p : -358296.25, l : 5341.91357422\n",
      "batch 5, ep 100, training accuracy 0.235\n",
      "f : 143187.515625, q : -216603.5, p : -355316.4375, l : 5295.39013672\n",
      "batch 5, ep 150, training accuracy 0.125\n",
      "f : 142103.359375, q : -215066.03125, p : -352595.4375, l : 5144.5\n",
      "valid accuracy 0.1917\n",
      "batch 6, ep 0, training accuracy 0.135\n",
      "f : 141105.84375, q : -213726.46875, p : -348370.3125, l : 5221.38916016\n",
      "batch 6, ep 50, training accuracy 0.07\n",
      "f : 139174.375, q : -211683.90625, p : -346090.0625, l : 5371.73779297\n",
      "batch 6, ep 100, training accuracy 0.12\n",
      "f : 138417.609375, q : -210671.796875, p : -343808.875, l : 5266.61083984\n",
      "batch 6, ep 150, training accuracy 0.21\n",
      "f : 137662.890625, q : -209577.640625, p : -341439.125, l : 5267.61572266\n",
      "valid accuracy 0.1177\n",
      "batch 7, ep 0, training accuracy 0.115\n",
      "f : 136730.375, q : -208224.53125, p : -339493.9375, l : 5221.46972656\n",
      "batch 7, ep 50, training accuracy 0.145\n",
      "f : 135515.609375, q : -206746.0, p : -337460.625, l : 5255.00732422\n",
      "batch 7, ep 100, training accuracy 0.115\n",
      "f : 135049.5, q : -205990.015625, p : -335728.6875, l : 5192.54394531\n",
      "batch 7, ep 150, training accuracy 0.12\n",
      "f : 134850.34375, q : -206296.96875, p : -335037.71875, l : 5584.26220703\n",
      "valid accuracy 0.1104\n",
      "batch 8, ep 0, training accuracy 0.14\n",
      "f : 133764.375, q : -204814.625, p : -334077.875, l : 5443.92333984\n",
      "batch 8, ep 50, training accuracy 0.165\n",
      "f : 133056.96875, q : -203840.125, p : -332057.4375, l : 5370.61425781\n",
      "batch 8, ep 100, training accuracy 0.25\n",
      "f : 132352.0625, q : -203323.546875, p : -330610.375, l : 5236.94042969\n",
      "batch 8, ep 150, training accuracy 0.25\n",
      "f : 132081.21875, q : -202327.546875, p : -328742.03125, l : 5298.45361328\n",
      "valid accuracy 0.1888\n",
      "batch 9, ep 0, training accuracy 0.215\n",
      "f : 131819.53125, q : -202024.828125, p : -327741.53125, l : 5138.31005859\n",
      "batch 9, ep 50, training accuracy 0.135\n",
      "f : 131444.953125, q : -201584.09375, p : -326631.75, l : 5092.19824219\n",
      "batch 9, ep 100, training accuracy 0.22\n",
      "f : 130754.546875, q : -200825.71875, p : -326497.4375, l : 5108.83935547\n",
      "batch 9, ep 150, training accuracy 0.18\n",
      "f : 130242.007812, q : -200113.703125, p : -325876.46875, l : 5212.44335938\n",
      "valid accuracy 0.1386\n",
      "batch 10, ep 0, training accuracy 0.165\n",
      "f : 129695.609375, q : -200418.765625, p : -324034.6875, l : 5272.78222656\n",
      "batch 10, ep 50, training accuracy 0.165\n",
      "f : 129212.914062, q : -199254.4375, p : -322883.5, l : 5297.40917969\n",
      "batch 10, ep 100, training accuracy 0.21\n",
      "f : 129001.65625, q : -198616.375, p : -322547.75, l : 4991.05957031\n",
      "batch 10, ep 150, training accuracy 0.35\n",
      "f : 128461.71875, q : -198505.03125, p : -321604.0625, l : 4904.15771484\n",
      "valid accuracy 0.224\n",
      "batch 11, ep 0, training accuracy 0.185\n",
      "f : 128303.601562, q : -198109.328125, p : -321472.09375, l : 5157.00488281\n",
      "batch 11, ep 50, training accuracy 0.15\n",
      "f : 128176.453125, q : -198171.1875, p : -320663.5625, l : 4986.49316406\n",
      "batch 11, ep 100, training accuracy 0.25\n",
      "f : 127934.265625, q : -197789.96875, p : -320357.875, l : 5045.78662109\n",
      "batch 11, ep 150, training accuracy 0.24\n",
      "f : 127468.578125, q : -197579.625, p : -320103.125, l : 5132.90234375\n",
      "valid accuracy 0.1906\n",
      "batch 12, ep 0, training accuracy 0.215\n",
      "f : 128159.554688, q : -196908.21875, p : -320884.90625, l : 5075.85693359\n",
      "batch 12, ep 50, training accuracy 0.295\n",
      "f : 127853.890625, q : -196942.625, p : -319672.15625, l : 5037.49511719\n",
      "batch 12, ep 100, training accuracy 0.285\n",
      "f : 127129.757812, q : -197429.765625, p : -319765.3125, l : 5102.70019531\n",
      "batch 12, ep 150, training accuracy 0.195\n",
      "f : 126375.8125, q : -196865.46875, p : -318296.25, l : 5027.97802734\n",
      "valid accuracy 0.2612\n",
      "batch 13, ep 0, training accuracy 0.265\n",
      "f : 126399.710938, q : -197199.328125, p : -318790.9375, l : 5226.91992188\n",
      "batch 13, ep 50, training accuracy 0.29\n",
      "f : 126165.664062, q : -196453.90625, p : -318409.625, l : 4784.66015625\n",
      "batch 13, ep 100, training accuracy 0.31\n",
      "f : 126536.359375, q : -196607.5625, p : -317973.03125, l : 4804.37792969\n",
      "batch 13, ep 150, training accuracy 0.265\n",
      "f : 125123.03125, q : -195820.421875, p : -316842.4375, l : 4903.70068359\n",
      "valid accuracy 0.2435\n",
      "batch 14, ep 0, training accuracy 0.19\n",
      "f : 125133.53125, q : -196265.75, p : -316702.53125, l : 4661.59619141\n",
      "batch 14, ep 50, training accuracy 0.33\n",
      "f : 125693.867188, q : -196295.59375, p : -317530.59375, l : 4801.671875\n",
      "batch 14, ep 100, training accuracy 0.375\n",
      "f : 125789.257812, q : -196436.09375, p : -315407.875, l : 4619.74707031\n",
      "batch 14, ep 150, training accuracy 0.27\n",
      "f : 125351.484375, q : -195463.953125, p : -315898.5, l : 4700.74902344\n",
      "valid accuracy 0.3529\n",
      "batch 15, ep 0, training accuracy 0.25\n",
      "f : 124954.3125, q : -195916.234375, p : -315527.15625, l : 4950.63574219\n",
      "batch 15, ep 50, training accuracy 0.285\n",
      "f : 124453.953125, q : -196002.296875, p : -316059.90625, l : 4874.17041016\n",
      "batch 15, ep 100, training accuracy 0.315\n",
      "f : 124275.8125, q : -195025.3125, p : -314898.46875, l : 4665.96582031\n",
      "batch 15, ep 150, training accuracy 0.375\n",
      "f : 124157.234375, q : -195285.90625, p : -314492.09375, l : 4418.32910156\n",
      "valid accuracy 0.3308\n",
      "batch 16, ep 0, training accuracy 0.275\n",
      "f : 124360.570312, q : -195184.4375, p : -314655.0, l : 4849.39648438\n",
      "batch 16, ep 50, training accuracy 0.335\n",
      "f : 124440.179688, q : -195394.28125, p : -313628.5625, l : 4454.39355469\n",
      "batch 16, ep 100, training accuracy 0.335\n",
      "f : 123812.851562, q : -194956.015625, p : -314157.125, l : 4402.26806641\n",
      "batch 16, ep 150, training accuracy 0.28\n",
      "f : 122858.8125, q : -194985.03125, p : -313721.0625, l : 4272.33789062\n",
      "valid accuracy 0.2711\n",
      "batch 17, ep 0, training accuracy 0.285\n",
      "f : 123498.273438, q : -195080.390625, p : -312843.0, l : 4499.24072266\n",
      "batch 17, ep 50, training accuracy 0.405\n",
      "f : 124125.304688, q : -193664.1875, p : -314634.3125, l : 4611.72265625\n",
      "batch 17, ep 100, training accuracy 0.36\n",
      "f : 122767.640625, q : -194716.34375, p : -312982.6875, l : 4359.65283203\n",
      "batch 17, ep 150, training accuracy 0.385\n",
      "f : 123348.273438, q : -194660.296875, p : -313563.8125, l : 4377.10009766\n",
      "valid accuracy 0.336\n",
      "batch 18, ep 0, training accuracy 0.405\n",
      "f : 123688.09375, q : -194563.8125, p : -313459.53125, l : 4536.39404297\n",
      "batch 18, ep 50, training accuracy 0.335\n",
      "f : 123939.890625, q : -194176.109375, p : -313938.125, l : 4346.02294922\n",
      "batch 18, ep 100, training accuracy 0.325\n",
      "f : 123040.171875, q : -193876.09375, p : -312522.3125, l : 4409.08886719\n",
      "batch 18, ep 150, training accuracy 0.35\n",
      "f : 122547.21875, q : -195110.5, p : -312048.65625, l : 4414.9765625\n",
      "valid accuracy 0.3143\n",
      "batch 19, ep 0, training accuracy 0.305\n",
      "f : 122701.65625, q : -194404.71875, p : -311915.53125, l : 4447.34179688\n",
      "batch 19, ep 50, training accuracy 0.34\n",
      "f : 123667.359375, q : -194124.96875, p : -312878.375, l : 4330.36669922\n",
      "batch 19, ep 100, training accuracy 0.31\n",
      "f : 122874.492188, q : -194983.65625, p : -313400.0625, l : 4239.02197266\n",
      "batch 19, ep 150, training accuracy 0.335\n",
      "f : 121846.476562, q : -194888.46875, p : -312633.25, l : 4260.47509766\n",
      "valid accuracy 0.291\n",
      "batch 20, ep 0, training accuracy 0.345\n",
      "f : 122599.273438, q : -194643.90625, p : -312498.125, l : 4416.83105469\n",
      "batch 20, ep 50, training accuracy 0.36\n",
      "f : 122375.539062, q : -194097.125, p : -313233.8125, l : 4154.55664062\n",
      "batch 20, ep 100, training accuracy 0.405\n",
      "f : 122972.460938, q : -194469.265625, p : -312830.78125, l : 4053.79858398\n",
      "batch 20, ep 150, training accuracy 0.32\n",
      "f : 122911.125, q : -193890.75, p : -312192.78125, l : 4370.54980469\n",
      "valid accuracy 0.2679\n",
      "batch 21, ep 0, training accuracy 0.335\n",
      "f : 123421.53125, q : -194968.875, p : -313747.5625, l : 4349.68212891\n",
      "batch 21, ep 50, training accuracy 0.39\n",
      "f : 122654.359375, q : -194901.671875, p : -313265.34375, l : 4108.00341797\n",
      "batch 21, ep 100, training accuracy 0.37\n",
      "f : 122629.328125, q : -193739.875, p : -312758.84375, l : 3897.13989258\n",
      "batch 21, ep 150, training accuracy 0.49\n",
      "f : 122523.007812, q : -194538.828125, p : -312623.96875, l : 4132.5859375\n",
      "valid accuracy 0.3301\n",
      "batch 22, ep 0, training accuracy 0.31\n",
      "f : 123204.0625, q : -194536.140625, p : -312779.5625, l : 4349.36083984\n",
      "batch 22, ep 50, training accuracy 0.44\n",
      "f : 122440.625, q : -195148.09375, p : -312760.4375, l : 4020.34106445\n",
      "batch 22, ep 100, training accuracy 0.38\n",
      "f : 121469.742188, q : -195142.859375, p : -312086.4375, l : 4108.45458984\n",
      "batch 22, ep 150, training accuracy 0.4\n",
      "f : 121436.109375, q : -194816.375, p : -311845.09375, l : 3961.91308594\n",
      "valid accuracy 0.3709\n",
      "batch 23, ep 0, training accuracy 0.41\n",
      "f : 121834.859375, q : -194406.25, p : -311999.625, l : 4308.23828125\n",
      "batch 23, ep 50, training accuracy 0.38\n",
      "f : 122436.179688, q : -194061.03125, p : -312931.9375, l : 4161.07470703\n",
      "batch 23, ep 100, training accuracy 0.43\n",
      "f : 122334.703125, q : -194591.109375, p : -312447.4375, l : 4072.14892578\n",
      "batch 23, ep 150, training accuracy 0.4\n",
      "f : 121595.085938, q : -193855.90625, p : -311674.5, l : 4118.36767578\n",
      "valid accuracy 0.3808\n",
      "batch 24, ep 0, training accuracy 0.375\n",
      "f : 121277.101562, q : -194571.5625, p : -312363.625, l : 4083.01098633\n",
      "batch 24, ep 50, training accuracy 0.42\n",
      "f : 121801.304688, q : -194867.71875, p : -312403.6875, l : 4182.48632812\n",
      "batch 24, ep 100, training accuracy 0.46\n",
      "f : 122087.453125, q : -194905.9375, p : -312329.46875, l : 3963.88867188\n",
      "batch 24, ep 150, training accuracy 0.44\n",
      "f : 121895.921875, q : -193985.25, p : -312566.1875, l : 3977.77612305\n",
      "valid accuracy 0.3507\n",
      "batch 25, ep 0, training accuracy 0.385\n",
      "f : 121632.296875, q : -194318.0, p : -311732.125, l : 4506.29980469\n",
      "batch 25, ep 50, training accuracy 0.435\n",
      "f : 122246.46875, q : -193413.984375, p : -313468.3125, l : 3990.27392578\n",
      "batch 25, ep 100, training accuracy 0.385\n",
      "f : 121470.15625, q : -195058.703125, p : -312160.25, l : 4013.89526367\n",
      "batch 25, ep 150, training accuracy 0.45\n",
      "f : 121132.609375, q : -194681.78125, p : -311371.1875, l : 3891.47070312\n",
      "valid accuracy 0.4119\n",
      "batch 26, ep 0, training accuracy 0.39\n",
      "f : 121370.148438, q : -194124.375, p : -311251.1875, l : 4278.80126953\n",
      "batch 26, ep 50, training accuracy 0.44\n",
      "f : 122021.609375, q : -194098.125, p : -312396.875, l : 4113.08984375\n",
      "batch 26, ep 100, training accuracy 0.425\n",
      "f : 121778.351562, q : -194408.09375, p : -311204.5625, l : 4156.07226562\n",
      "batch 26, ep 150, training accuracy 0.46\n",
      "f : 121670.0, q : -194816.90625, p : -311877.71875, l : 3996.80273438\n",
      "valid accuracy 0.3842\n",
      "batch 27, ep 0, training accuracy 0.38\n",
      "f : 121614.03125, q : -194809.0625, p : -312419.9375, l : 4095.9765625\n",
      "batch 27, ep 50, training accuracy 0.34\n",
      "f : 121065.007812, q : -194009.203125, p : -312641.6875, l : 4106.92138672\n",
      "batch 27, ep 100, training accuracy 0.365\n",
      "f : 120694.398438, q : -192903.0625, p : -311337.9375, l : 3928.26049805\n",
      "batch 27, ep 150, training accuracy 0.47\n",
      "f : 120559.117188, q : -194254.84375, p : -311713.78125, l : 3845.76269531\n",
      "valid accuracy 0.3957\n",
      "batch 28, ep 0, training accuracy 0.39\n",
      "f : 121430.117188, q : -195378.46875, p : -311192.4375, l : 4130.6015625\n",
      "batch 28, ep 50, training accuracy 0.37\n",
      "f : 121306.445312, q : -194691.109375, p : -312179.125, l : 3956.95727539\n",
      "batch 28, ep 100, training accuracy 0.4\n",
      "f : 120920.757812, q : -194775.1875, p : -311640.71875, l : 3823.04296875\n",
      "batch 28, ep 150, training accuracy 0.405\n",
      "f : 121386.445312, q : -194885.265625, p : -311715.4375, l : 3790.49829102\n",
      "valid accuracy 0.4126\n",
      "batch 29, ep 0, training accuracy 0.355\n",
      "f : 121342.65625, q : -194756.6875, p : -312993.875, l : 4117.63671875\n",
      "batch 29, ep 50, training accuracy 0.385\n",
      "f : 121179.890625, q : -194848.234375, p : -311232.875, l : 4085.96289062\n",
      "batch 29, ep 100, training accuracy 0.375\n",
      "f : 121434.9375, q : -195230.125, p : -312093.875, l : 3899.66186523\n",
      "batch 29, ep 150, training accuracy 0.43\n",
      "f : 120584.671875, q : -195414.828125, p : -311714.875, l : 3920.76123047\n",
      "valid accuracy 0.3414\n",
      "batch 30, ep 0, training accuracy 0.415\n",
      "f : 120819.929688, q : -195788.90625, p : -310925.0, l : 4041.20654297\n",
      "batch 30, ep 50, training accuracy 0.455\n",
      "f : 121128.359375, q : -194708.875, p : -311552.65625, l : 3972.83691406\n",
      "batch 30, ep 100, training accuracy 0.385\n",
      "f : 120520.046875, q : -195588.25, p : -311225.03125, l : 3757.7890625\n",
      "batch 30, ep 150, training accuracy 0.375\n",
      "f : 120418.085938, q : -194781.890625, p : -311258.4375, l : 3775.30664062\n",
      "valid accuracy 0.4103\n",
      "batch 31, ep 0, training accuracy 0.38\n",
      "f : 120231.96875, q : -194581.25, p : -311745.09375, l : 3846.81884766\n",
      "batch 31, ep 50, training accuracy 0.415\n",
      "f : 120770.882812, q : -195210.0, p : -312029.53125, l : 3809.69433594\n",
      "batch 31, ep 100, training accuracy 0.45\n",
      "f : 120256.539062, q : -195016.75, p : -310901.125, l : 3606.38916016\n",
      "batch 31, ep 150, training accuracy 0.435\n",
      "f : 119688.617188, q : -194652.46875, p : -311276.34375, l : 3696.29223633\n",
      "valid accuracy 0.4193\n",
      "batch 32, ep 0, training accuracy 0.435\n",
      "f : 120718.773438, q : -195466.90625, p : -311293.5625, l : 3999.47119141\n",
      "batch 32, ep 50, training accuracy 0.425\n",
      "f : 120474.84375, q : -194877.28125, p : -310500.1875, l : 3750.87890625\n",
      "batch 32, ep 100, training accuracy 0.4\n",
      "f : 120240.929688, q : -194856.703125, p : -310886.65625, l : 3638.39013672\n",
      "batch 32, ep 150, training accuracy 0.52\n",
      "f : 120217.453125, q : -195298.1875, p : -311564.5625, l : 3804.12573242\n",
      "valid accuracy 0.3734\n",
      "batch 33, ep 0, training accuracy 0.4\n",
      "f : 119972.429688, q : -194116.8125, p : -311165.375, l : 3620.38964844\n",
      "batch 33, ep 50, training accuracy 0.43\n",
      "f : 120174.515625, q : -195235.25, p : -312620.28125, l : 3532.39453125\n",
      "batch 33, ep 100, training accuracy 0.375\n",
      "f : 120374.632812, q : -194487.6875, p : -311581.0625, l : 3440.34667969\n",
      "batch 33, ep 150, training accuracy 0.545"
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for i in range(n_batches):\n",
    "    \n",
    "    bnn.reset_lr()\n",
    "    \n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        feed = {bnn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "        \n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "        if ep > 50 and np.mean(fs[-50:-25]) < np.mean(fs[-25:]):\n",
    "            last_lr = bnn.get_lr()\n",
    "            bnn.decay_lr()\n",
    "            #print(\"=== learning rate decayed ===\")\n",
    "            if bnn.get_lr == last_lr:\n",
    "                print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                break\n",
    "            #print (\"--- learning rate decayed ---\")\n",
    "            #print bnn.get_lr()\n",
    "\n",
    "        if ep % 50 == 0:\n",
    "            train_accuracy = bnn.validate(feed)\n",
    "\n",
    "            print(\"batch %d, ep %d, training accuracy %g\"%(i, ep, train_accuracy))\n",
    "            print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        bnn.train(feed)\n",
    "        \n",
    "    vacc = bnn.validate({bnn.x: x_valid, bnn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "#     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "#         bnn.decay_lr()\n",
    "    \n",
    "    bnn.update_prior()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codes used for testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.range(300)\n",
    "aa = tf.reshape(a, [30, 10])\n",
    "aaa = tf.tile(tf.expand_dims(aa, 0), [10, 1, 1])\n",
    "\n",
    "b = tf.truncated_normal([30, 10], stddev = 0.2)\n",
    "\n",
    "argmaxbs = tf.argmax(b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(30), Dimension(10)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2, ..., 297, 298, 299], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(aaa, [-1]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298   5  11  27  32  43  57\n",
      "  63  76  84  97 105 118 123 138 142 158 164 172 182 193 201 215 227 237\n",
      " 248 258 261 271 281 298   5  11  27  32  43  57  63  76  84  97 105 118\n",
      " 123 138 142 158 164 172 182 193 201 215 227 237 248 258 261 271 281 298\n",
      "   5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298   5  11  27  32  43  57\n",
      "  63  76  84  97 105 118 123 138 142 158 164 172 182 193 201 215 227 237\n",
      " 248 258 261 271 281 298   5  11  27  32  43  57  63  76  84  97 105 118\n",
      " 123 138 142 158 164 172 182 193 201 215 227 237 248 258 261 271 281 298\n",
      "   5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298   5  11  27  32  43  57\n",
      "  63  76  84  97 105 118 123 138 142 158 164 172 182 193 201 215 227 237\n",
      " 248 258 261 271 281 298   5  11  27  32  43  57  63  76  84  97 105 118\n",
      " 123 138 142 158 164 172 182 193 201 215 227 237 248 258 261 271 281 298\n",
      "   5  11  27  32  43  57  63  76  84  97 105 118 123 138 142 158 164 172\n",
      " 182 193 201 215 227 237 248 258 261 271 281 298]\n",
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2, 5, 3, 8, 6, 1, 0, 7, 0, 3, 7, 8, 0, 4, 5, 8, 8, 0, 2, 6, 7, 7,\n",
       "       0, 3, 7, 8, 3, 8, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = tf.range(30).eval()\n",
    "br = ar * 10 + argmaxbs.eval()\n",
    "cr = tf.tile(br, [10])\n",
    "\n",
    "result = tf.gather(tf.reshape(aaa, [-1]), cr).eval()\n",
    "print result\n",
    "print result.shape\n",
    "argmaxbs.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(a).eval()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519]]\n",
      "[[-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]\n",
      " [-0.04836457  0.11699509 -0.10365508 -0.04836457  0.11699509 -0.10365508\n",
      "  -0.04836457  0.11699509 -0.10365508]\n",
      " [-0.11315618 -0.14960578 -0.13785519 -0.11315618 -0.14960578 -0.13785519\n",
      "  -0.11315618 -0.14960578 -0.13785519]]\n",
      "[[[-0.04836457  0.11699509 -0.10365508]\n",
      "  [-0.11315618 -0.14960578 -0.13785519]]\n",
      "\n",
      " [[-0.04836457  0.11699509 -0.10365508]\n",
      "  [-0.11315618 -0.14960578 -0.13785519]]]\n",
      "[[ 0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519]]\n",
      "[[ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]\n",
      " [ 0.04836457 -0.11699509  0.10365508  0.04836457 -0.11699509  0.10365508\n",
      "   0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519  0.11315618  0.14960578  0.13785519\n",
      "   0.11315618  0.14960578  0.13785519]]\n",
      "[[ 0.04836457 -0.11699509  0.10365508]\n",
      " [ 0.11315618  0.14960578  0.13785519]]\n",
      "[[ 0.04836457  0.11315618]\n",
      " [-0.11699509  0.14960578]\n",
      " [ 0.10365508  0.13785519]]\n"
     ]
    }
   ],
   "source": [
    "with sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print a.eval()\n",
    "    print tf.tile(a, [6, 3]).eval()\n",
    "    print tf.tile(tf.expand_dims(a, 0), [2, 1, 1]).eval()\n",
    "    a = a * b\n",
    "    print a.eval()\n",
    "    print tf.tile(a, [6, 3]).eval()\n",
    "    print tf.transpose(a, [0, 1]).eval()\n",
    "    print tf.transpose(a, [1, 0]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.11307557  2.01307557]\n",
      "[ 2.11307557  2.01307557]\n"
     ]
    }
   ],
   "source": [
    "t1 = np.array([[0.1, 0.2, 0.3, 0.4, 0., 0., 0., 0., 0., 0.], [0.1, 0.2, 0.3, 0.4, 0., 0., 0., 0., 0., 0.]])\n",
    "t2 = np.array([[0., 0., 1, 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 1, 0., 0., 0., 0., 0., 0.]])\n",
    "print tf.nn.softmax_cross_entropy_with_logits(t1, t2).eval()\n",
    "print tf.nn.softmax_cross_entropy_with_logits(t1, t2).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2039728"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.log(0.3).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]]]\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "t3 = tf.tile(tf.expand_dims(np.array([[1], [2], [3], [4], [5]]), 0), [10, 1, 1])\n",
    "print t3.eval()\n",
    "t4 = tf.reshape(t3, [-1, 1])\n",
    "print t4.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976630367\n"
     ]
    }
   ],
   "source": [
    "tsh = tf.shape(t3)\n",
    "tf.shape(t3).eval()\n",
    "print tsh[-1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
