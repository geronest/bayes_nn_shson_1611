{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bnn_shson_rhograd import *\n",
    "import nn_shson\n",
    "from shson_exp_manager import *\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_to_onehot(nums, n_labels):\n",
    "    results = list()\n",
    "    for i in range(len(nums)):\n",
    "        res = np.zeros([n_labels])\n",
    "        res[nums[i]] = 1\n",
    "        results.append(res)\n",
    "    return np.asarray(results, dtype = 'float32')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = h5py.File('mnist.hdf5', 'r')\n",
    "\n",
    "x_train = mnist['train_data'][()]\n",
    "t_train = num_to_onehot(mnist['train_label'][()], 10)\n",
    "x_valid = mnist['valid_data'][()]\n",
    "t_valid = num_to_onehot(mnist['valid_label'][()], 10)\n",
    "x_test = mnist['test_data'][()]\n",
    "t_test = num_to_onehot(mnist['test_label'][()], 10)\n",
    "\n",
    "mnist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blundell version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-9-b30b093fd381>:7 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b30b093fd381>:7 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b30b093fd381>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b30b093fd381>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    }
   ],
   "source": [
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-1.0, 5.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = True, train_rho = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(savedir + 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, step 0, training accuracy 0.105\n",
      "f : 53721.7890625, q : -10226.8623047, p : -104833.726562, l : 6629.81591797\n",
      "ep 0, step 50, training accuracy 0.54\n",
      "f : 3417.04711914, q : -10203.8320312, p : -104835.492188, l : 3477.75561523\n",
      "ep 0, step 100, training accuracy 0.71\n",
      "f : 2253.53833008, q : -10198.5859375, p : -104838.351562, l : 2225.73657227\n",
      "ep 0, step 150, training accuracy 0.755\n",
      "f : 1925.98876953, q : -10290.8378906, p : -104840.539062, l : 1966.84912109\n",
      "ep 0, step 200, training accuracy 0.89\n",
      "f : 1115.61767578, q : -10120.9882812, p : -104842.226562, l : 1090.51660156\n",
      "layer0/q_pos/mu:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer0/q_pos/rho:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/mu:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/rho:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "valid accuracy 0.8891\n",
      "ep 1, step 0, training accuracy 0.9\n",
      "f : 48456.2539062, q : -10061.8984375, p : -104843.648438, l : 1121.96435547\n",
      "ep 1, step 50, training accuracy 0.865\n",
      "f : 903.717224121, q : -10093.1738281, p : -104845.179688, l : 931.540466309\n",
      "ep 1, step 100, training accuracy 0.895\n",
      "f : 1129.46533203, q : -10085.8320312, p : -104846.28125, l : 1166.2520752\n",
      "ep 1, step 150, training accuracy 0.865\n",
      "f : 1173.16870117, q : -10052.7460938, p : -104847.101562, l : 1186.31176758\n",
      "ep 1, step 200, training accuracy 0.905\n",
      "f : 737.899414062, q : -10027.1962891, p : -104848.085938, l : 744.65020752\n",
      "layer0/q_pos/mu:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer0/q_pos/rho:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/mu:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/rho:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "valid accuracy 0.9193\n",
      "ep 2, step 0, training accuracy 0.905\n",
      "f : 48284.65625, q : -10017.0048828, p : -104848.882812, l : 893.867248535\n",
      "ep 2, step 50, training accuracy 0.91\n",
      "f : 744.479736328, q : -9921.32324219, p : -104849.84375, l : 680.859375\n",
      "ep 2, step 100, training accuracy 0.885\n",
      "f : 858.75970459, q : -10045.5390625, p : -104850.726562, l : 887.801513672\n",
      "ep 2, step 150, training accuracy 0.915\n",
      "f : 1045.36621094, q : -9949.20507812, p : -104851.445312, l : 1032.52807617\n",
      "ep 2, step 200, training accuracy 0.915\n",
      "f : 590.624084473, q : -9997.11328125, p : -104852.039062, l : 661.438476562\n",
      "layer0/q_pos/mu:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer0/q_pos/rho:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/mu:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/rho:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "valid accuracy 0.93\n",
      "ep 3, step 0, training accuracy 0.945\n",
      "f : 48210.5742188, q : -9968.68261719, p : -104852.695312, l : 682.331298828\n",
      "ep 3, step 50, training accuracy 0.915\n",
      "f : 650.760131836, q : -9933.453125, p : -104853.070312, l : 612.931152344\n",
      "ep 3, step 100, training accuracy 0.92\n",
      "f : 807.178710938, q : -9870.79394531, p : -104853.921875, l : 813.604003906\n",
      "ep 3, step 150, training accuracy 0.905\n",
      "f : 932.148803711, q : -9968.26757812, p : -104854.875, l : 860.770141602\n",
      "ep 3, step 200, training accuracy 0.925\n",
      "f : 569.788391113, q : -9868.859375, p : -104855.265625, l : 598.410217285\n",
      "layer0/q_pos/mu:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer0/q_pos/rho:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/mu:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/rho:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "valid accuracy 0.9361\n",
      "ep 4, step 0, training accuracy 0.935\n",
      "f : 48104.1445312, q : -9952.30566406, p : -104855.6875, l : 616.105834961\n",
      "ep 4, step 50, training accuracy 0.95\n",
      "f : 569.367431641, q : -9866.82519531, p : -104856.140625, l : 551.702880859\n",
      "ep 4, step 100, training accuracy 0.92\n",
      "f : 729.06652832, q : -9876.80859375, p : -104857.109375, l : 775.383544922\n",
      "ep 4, step 150, training accuracy 0.925\n",
      "f : 856.263793945, q : -9866.984375, p : -104857.78125, l : 847.554443359\n",
      "ep 4, step 200, training accuracy 0.945\n",
      "f : 538.030029297, q : -9891.00488281, p : -104858.5625, l : 471.944335938\n",
      "layer0/q_pos/mu:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer0/q_pos/rho:0 (785, 50) (785, 50) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/mu:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "layer1/q_pos/rho:0 (51, 10) (51, 10) <dtype: 'float32_ref'>\n",
      "valid accuracy 0.9401\n",
      "ep 5, step 0, training accuracy 0.945\n",
      "f : 48088.9804688, q : -9838.48046875, p : -104859.007812, l : 581.841369629\n",
      "ep 5, step 50, training accuracy 0.935\n",
      "f : 488.970672607, q : -9931.14550781, p : -104859.21875, l : 474.1796875\n",
      "ep 5, step 100, training accuracy 0.905\n",
      "f : 667.940307617, q : -9873.96289062, p : -104859.625, l : 720.897338867\n",
      "ep 5, step 150, training accuracy 0.925\n",
      "f : 731.027954102, q : -9983.77832031, p : -104860.039062, l : 765.125610352\n",
      "ep 5, step 200, training accuracy 0.955\n",
      "f : 475.960571289, q : -9917.54101562, p : -104861.15625, l : 471.791412354\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6c7653ed2e0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mbnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecay_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m#         if (i+1) % 20 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#             print(\"klrw index : %g\"%(bnn.get_klrw()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/bayes_nn_shson/bnn_shson_rhograd.py\u001b[0m in \u001b[0;36mdecay_klrw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecay_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoeff_kl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoeff_kl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_klrw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3631\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3633\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    997\u001b[0m                 run_metadata):\n\u001b[0;32m    998\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[1;32m-> 1048\u001b[1;33m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[0;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_epochs = 100\n",
    "n_batches = len(t_train) / batch_size\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for ep in range(n_epochs):\n",
    "    bnn.reset_klrw()\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        bnn.decay_klrw()\n",
    "#         if (i+1) % 20 == 0:\n",
    "#             print(\"klrw index : %g\"%(bnn.get_klrw()))\n",
    "        \n",
    "        feed = {bnn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "        \n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "        \n",
    "#         if i > 50 and np.mean(fs[-50:-25]) < np.mean(fs[-25:]):\n",
    "#             bnn.decay_lr()\n",
    "#             print (\"--- learning rate decayed : %g ---\"%(bnn.get_lr()))\n",
    "        \n",
    "            \n",
    "\n",
    "        if i%50 == 0:\n",
    "            train_accuracy = bnn.validate(feed)\n",
    "\n",
    "            print(\"ep %d, step %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "            print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "            #print v_q - v_p + v_l\n",
    "\n",
    "        bnn.train(feed)\n",
    "    \n",
    "    vacc = bnn.validate({bnn.x: x_valid, bnn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict ={bnn.x: x_valid, bnn.t: t_valid})\n",
    "    test_writer.add_summary(summary, ep)\n",
    "    \n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    if ep > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "        bnn.decay_lr()\n",
    "        print (\"--- learning rate decayed : %g ---\"%(bnn.get_lr()))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeff_klrw = 1 / n_batches\n",
    "\n",
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs*coeff_klrw, 'b')\n",
    "plt.plot(ps*coeff_klrw, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VdW5//HPEwaR0UBkEElABkWGAiqithpxQqpiFVGQ\nonSQ1or2SluxV6+odapeW1u14q/oFYpSFRUUVCoaBRlFYkAmZQwgICIJYQgheX5/7BCSkJCTcJIz\n8H2/XueVs89ZZ5+HhHzPytp7r2XujoiIxJeESBcgIiLhp3AXEYlDCncRkTikcBcRiUMKdxGROKRw\nFxGJQxWGu5mNM7OtZpZxhDZ/M7OvzCzdzHqEt0QREamsUHruLwKXlfekmV0OtHf3jsAI4Lkw1SYi\nIlVUYbi7+2zg+yM0GQCML2w7H2hiZi3CU56IiFRFOMbcWwOZxbY3FT4mIiIRogOqIiJxqHYY9rEJ\naFNs++TCxw5jZprIRkSkCtzdKtM+1J67Fd7KMhUYBmBmfYCd7r71CAVG/e2+++6LeA2qU3XGao2q\nM/y3qqiw525mLwOpQDMz2wDcB9QNctqfd/fpZtbfzL4GdgPDq1SJiIiETYXh7u5DQmhzW3jKERGR\ncNAB1TKkpqZGuoSQqM7wioU6Y6FGUJ3RwKo6nlOlNzPzmnw/EZF4YGZ4JQ+ohuNsGRGJYW3btmX9\n+vWRLkOAlJQU1q1bF5Z9qecucowr7BVGugyh/J9FVXruGnMXEYlDCncRkTikcBcRiUMKdxGROKRw\nF5G49utf/5qHHnoo0mXUOJ0tI3KMi/azZdq1a8e4cePo27dvpEupdjpbRkQEyM/Pj3QJUUvhLiJR\na9iwYWzYsIErrriCxo0b8/jjj5OQkMALL7xASkoKF110EQCDBg2iVatWJCYmkpqayrJly4r2MXz4\ncP7nf/4HgI8//pg2bdrw5JNP0qJFC1q3bs3//d//VVjH9OnT6dWrF02aNCElJYX777+/xPOzZ8/m\nvPPOIzExkZSUFMaPHw/Avn37GDVqFG3btiUxMZHzzz+f3NzcMH13jkzhLiIVMgvPrbLGjx9PcnIy\n06ZNIzs7m0GDBgHwySefsGLFCt5//30A+vfvz+rVq9m2bRu9evXixhtvLHefW7ZsYdeuXWzevJl/\n/vOf/OY3vyErK+uIdTRs2JAJEyaQlZXFtGnTeO6555g6dSoA69evp3///txxxx1s376d9PR0evTo\nAcCoUaNYvHgx8+bNY8eOHfz5z38mIaGGYreG5yR2EYku0f572bZtW585c6a7u69bt84TEhJ83bp1\n5bb//vvv3cw8Ozvb3d1vvvlmv/fee93dPS0tzevXr+/5+flF7Zs3b+7z58+vVE2//e1v/c4773R3\n90ceecSvueaaw9oUFBT48ccf70uWLAl5v+X9LAofr1TequcuIjHn5JNPLrpfUFDA6NGj6dChAyec\ncALt2rXDzNi+fXuZr23WrFmJ3nP9+vXJyck54vstWLCAvn370rx5c0444QTGjh1btP/MzEzat29/\n2Gu2b99Obm4up5xySlX+iUdN4S4iUc3KGM8p/tjLL7/M22+/zYcffsjOnTtZt27dUa1gVJYhQ4Zw\n9dVXs2nTJnbu3MmIESOK9t+mTRu+/vrrw16TlJREvXr1WL16ddjqqAyFu4hEtZYtW7JmzRqAMkN7\n165dHHfccSQmJrJ7927uvvvuMj8QjkZOTg6JiYnUqVOHBQsW8PLLLxc9d+ONNzJz5kxef/118vPz\n2bFjB1988QVmxvDhw7nzzjv55ptvKCgoYN68eeTl5YW1tvIo3EUkqo0ePZoHH3yQpk2bMnny5MOC\ne9iwYSQnJ9O6dWu6du3KueeeW6n9h/JB8Oyzz3LvvffSpEkT/vSnP3H99dcXPdemTRumT5/OE088\nQdOmTenZsycZGRkAPPHEE3Tr1o2zzjqLZs2aMXr0aAoKCkKqKz8fFi2Cxx6r1D/n0L8rnH+6VPhm\nuohJJOpE+0VMxxIz47nnnA8+gA8/hBYt4OKL4e9/r/xFTAp3kWOcwj16mBlDhzoXXxyEeuvWhx5X\nuItIpSjcA127dmXDhg1F2+6OmTF27FgGDx5cIzWEc/oBhbvIMU7hHj00t4yIiByRwl1EJA7VjnQB\nIiJSzMyZsG9fyVsVKNxFRKLJQw9BvXolb1WgA6oiMcAdNmyAzEzo2RMaNAjfvnVANXqE84Cqeu4i\nUSYrC5YsCW4ZGYfuN2wIJ50EK1bAGWdQdC70mWdC7Yp+k/ftg2+/hW3bglvx+3Ho448/ZujQoWRm\nZgLBaY7PPvss559/foVt40VI4W5m/YC/EhyAHefuj5V6/gTgBaA9sBf4mbsvO2xHIvFq50744otD\nt/R0WLkSjjsOGjc+/NakCfkNGrM9rzEbsxuzdntjVm1pzNLMxmzKbkzzjk1I6daYbj0ac/2g+nTr\nbjRrFrzV7t0wO+0Ac9/5jsdv+pa8Tdu4oPM2erfdxulJ22h6YBv2bakA37cPTjwRmjc//Banik8r\nsHTp0pDbxosKw93MEoCngYuAzcBCM5vi7iuKNfsjsNjdrzGzU4FngIuro2CRiCoogLVrDwX4wTD/\n7jvo1g1+8APo3Rt++Uvo3BkOHMCzstm+Jps1X2SzaVk2W1dlsWN2Nnu2ZNO6UTZtm26jQ8Nszq2X\nzQntszg+LxvLzoYPs+GtbMjNhUaNgg+FevVosGMHl+3cyWWJidC8Oft7NOeb/OZ89WVzXtx0It/V\nOoPWPZvT6eLm9OrXnKTTmwevLS/A7rqrZr+HUjMqmvAd6AO8W2x7NHBXqTbvAOcV2/4aOLGMfYU8\nab1IxO3e7T5vnvvYse633up+3nnujRq5t2njfsUV7vfc4/7aa+6rVrkXLv6Qk+M+f777P//pfvvt\n7hde6N6sWXC78EL3O+4InluwIGgbkrw89x073NeudV+2zH3rVvcDB8psWlDgvnKl+zPPuF99tfsJ\nJ7h36+Z+553u06eX/Z7R/Hv52GOP+cCBA0s8dscdd/gdd9zhL774onfu3NkbNWrk7du397Fjxxa1\nSUtL8zZt2hRtF1/wY+/evX7TTTd5YmKid+nSxR9//PESbcvz6KOPevv27b1Ro0bepUsXf/PNN0s8\n//zzzxfV06VLF1+8eLG7u2dmZvo111zjJ554oiclJfnIkSPLfY/yfhZUYbGOUIZlWgPFB6M2Ar1L\ntfkCuAb41Mx6A8nAycC3Vfi8Eal+7rB/f9Arzs2FnBxYvrxkj3zDBjj1VOjRI+iRDxwYfG3alPx8\nWLOmcFx84qHx8U2bgpd07x505H/84+Bry5ZVW2YOCAbUExODWwXMoFOn4HbrrXDgQDCz4AcfBLML\nXnddMF5/ySWHxutDEq5hi0oeuL3hhht44IEH2L17Nw0aNKCgoIBXX32Vt956i++++45p06bRrl07\nZs2aRb9+/ejdu3fREnflGTNmDGvXrmXt2rXk5OTQr1+/kGrp0KEDn376KS1atOC1115j6NChrF69\numj7gQceYMqUKfTq1Ys1a9ZQp04dCgoKuOKKK7j44ouZOHEiCQkJfPbZZ5X6HlRVuA6oPgo8ZWaf\nA0uAxYCWJZfwyc2FVauCAF65ErILhyv27TsU0BVtl36uTp1gTPy44+D44+G004LwvuIKuOeeYLtO\nHbZvL3Zwc2LwddkySEo6FOKDBsGDD0LHjsFuo0Xt2nD22cHtv/87GK+fNSsI+xEjgs+vkETobJrk\n5GR69erFm2++ydChQ5k5cyYNGjSgd++S/csf/ehHXHrppcyaNavCcH/ttdd47rnnaNKkCU2aNOH2\n22/nwQcfrLCWa6+9tuj+ddddx8MPP8yCBQu48sorGTduHH/4wx/o1asXQNHqS/PmzeObb74psXZq\nZackrqpQwn0TQU/8oJMLHyvi7ruAnx3cNrO1wJqydjZmzJii+6mpqaSmpoZcrBwDsrKC00GWLy95\ny8yEdu2CcexTTw0ODh4M5nr1Dt0vvX2k50otVJybG7xVRgYsGX/oTJXduw+F+JlnwvDh0LUrNGkS\noe/RUWjQAPr1C24AW7cGf1VEs8GDB/PKK68wdOhQXnnlFYYMGQLAu+++ywMPPMCqVasoKChg7969\ndO/evcL9bd68ucQyfSkpKSHVMX78eP7yl7+wbt06AHbv3l3hUnuZmZmkpKRUelHstLQ00tLSKvWa\n0kIJ94VABzNLAb4BbgBKTJFmZk2APe6eZ2a/BD529zIXJSwe7nKMcoctWw4P8OXLgx75qacGId65\nM9x8c/C1Q4dq6RKvWQMvvwyvvx78QdC+fRDi3bvDyJHB1zZtwjcqEW1atIh0BRW77rrr+N3vfsem\nTZt48803mT9/Pvv372fgwIH861//YsCAASQkJPCTn/wkpPP1W7VqRWZmJp07dwZg/fr1Fb5mw4YN\n3HLLLXz00Uecc845APTs2bPEUntlLafXpk0bNmzYQEFBQaUCvnTH9/777w/5tQdVGO7unm9mtwEz\nOHQq5HIzGxE87c8DnYGXzKwA+BL4eaUrkfhTUADr1gVjGKVDvHbtQwHeuXMwFNK5c5CklezlVNa3\n38Krr8LEifD118E49NNPw1lnBR16iS5JSUlccMEFDB8+nFNOOYVOnTqRk5PD/v37SUpKIiEhgXff\nfZcZM2bQrVu3Cvc3aNAgHnnkEXr37k1OTg5PP/10ha/ZvXs3CQkJJCUlUVBQwEsvvVTi9Mpf/OIX\njBo1ivPOO49evXqxevVq6tatS+/evWnVqhWjR49mzJgx1KpVi0WLFtXI0ExIY+7u/h5waqnHxha7\nP6/083IMcQ+OJC5dCl9+GXxdujQI9aZN4fTTg+A+++xDPfETT6zREnfvhilTgkD/9FPo3z8Yg770\n0ugaI5eyDRkyhJtuuonHH38cgIYNG/K3v/2N6667jv3793PllVcyYMCAcl9f/Dz2++67j1/96le0\na9eO1q1bM3z4cJ566qkjvn/nzp0ZNWoUffr0oVatWgwbNowf/vCHRc8PHDiQHTt2MGTIEDZv3kzb\ntm2ZMGECbdq04e2332bkyJEkJyeTkJDAkCFDaiTcNf2AVM62bSUD/GCg16sXDER36RJ87doVTj+d\n7w40oVEjqFu35ks9cAD+858g0N95B845B268Ea6+OrjaUwKafiB6aLEOqX47dx4K8eJhnpd3KLwP\n3rp0YW+DJJYtK3nJfEZGcILK/v3BWSQHD0oe/Nq6dfjHst1hwQL417+CoZd27YJAv/76uL4Y86go\n3KOHwl3Cb+XK4Mji/PlBiGdlBcMpxQKcrl0paNGK9RuMjIySIb5+ffkBvm8fZQZ/Xl7Jtt27B29V\nlV71qlVBD33iRKhVKwj0IUOC47ByZAr3QGZmJqeffnqJIRwvXGpv2bJlJc6wqS4KdwmP7dth0iSY\nMCE44XnwYOjbN0jY5GS+z0o4bAKrpUuDUwAPhvHBYD711MoPvWzdevgEWcuWQatWh39IdOgQhHZx\nW7YE5U+cCBs3wg03BKF+xhnxe3ZLdVC4Rw+Fu1Tdvn3BAPSECfDxx9C/PweGDGPFyReTsax2UdBm\nZAQjM127Hh60IVwoWWUHDgRnsJTu5W/dGhyH7d49CPq0NFi4EAYMCAK9b9/Dw19Co3CPHgp3qRx3\n+PRTfPwECl57nZ3JP2Bep2G8lXAN85c35quvICXl8N5427bVflZiyHbtCv5qWLIkuMapTx+48srg\nwlI5Ogr36KFwlwrl5MBX735NwUsTSJk1gZwD9XjJh/FW/RtJ6tmmRE/89NMVkseytm3bhnQhj1S/\nlJSUoitgi1O4H4Py84NhjINDGGs+20G7hf/mxzsm0DFhNYs6Dubbfj+lxeW96NbdYuKKRBEpSeF+\njNixA554AmbMCC72TG6Ry7Ck6QzInkDHDTPZe+HlNBjxU2pdrit0ROKBwj3O7dkDTz0FTz4J1/zE\nue3MeZy6YAJ133o1OPL5058G09LG4oxWIlIuraEap/LyYNw4+NMDBdzUeQErr5pM0w8mwyd1g0D/\n7LPg6KeISCGFexQrKIDX/53PW7//lOsSJrMm/w3qftMIzr0W3ngjmHtcJ3SLSBk0LBOFPO8Ai/43\njXX/O5nUnW9yXHJLGt18LVx7bXBqi4gcUzQsE8tyc2HmTL59bjJ135tC3YRT6HTttTQbMxvrqGvo\nRaRy1HOPpL174f334fXXyX97GqvqdGHSgYF0Gn0Ng0Yl60QXEQHUc48NOTkwfXqw9M+MGezr0ovJ\nDOSR2o/z09+34q6RUL9+pIsUkVincK8J2dkwdWoQ6B9+COeey+7LB/JE82f42ysn8stfwqx3qnfO\nFhE5tkTJzCFxatu2YLmfU06Bf/8brrmGPcvX88gF79H2T79gc96JZGTAo48q2EUkvBTu1WHDBrj9\ndjjttOBy0gULyHvjbZ7bM4yOvRNZvDhY6m3s2GC+cxGRcNOwTDitXAmPPRYs1vnznwcrGLVqxbRp\n8F/9gpkXp0yBM8+MdKEiEu8U7uHw+efwyCPB/OgjRwYzeSUmsmcPjPo1vPde0Eu/9NJIFyoixwoN\ny1SVexDml10GV10F550Ha9fCvfdCYjD0csYZwTzk6ekKdhGpWeq5V5Y7TJsW9NS3bYPRo2HoUDju\nOCCYMuDJJ4PRmb/+NVglSESkpincQ3XgALz2WnBqS0IC3H13MB1AsbXdNm2CYcOCi00XLtRcXiIS\nORqWqUhuLjz/fHDmyz/+EYT755/DoEElgn3yZOjVCy68MFjfU8EuIpGknnt5cnKCo6BPPhnMvvji\ni/CjH5XZ7Le/DQJ96lQ4++yaL1VEpDT13EvLyoL77w8uPFqwAN55J5guoIxgX7gQevYMxtkXL1aw\ni0j0UM+9uF274OKLoWNHmD0bOnUqs1l+fnDA9Kmn4Omn4brrarhOEZEKKNwPys2Fq68Ozl/8xz/K\nXQRj/fpg8aNatYIFkNq0qeE6RURCENKwjJn1M7MVZrbKzO4q4/lmZvaumaWb2RIzuznslVan/HwY\nMgSaNYNnnik32CdNgrPOgiuugA8+ULCLSPSqcD53M0sAVgEXAZuBhcAN7r6iWJv7gHrufreZJQEr\ngRbufqDUvqJvPnd3uOWWoEv+9ttF56sXl50dXHg6fz5MnBh07kVEakpV5nMPpefeG/jK3de7ex4w\nCRhQqs0WoFHh/UbAd6WDPWrdfTdkZARrkpYR7HPnBgdNjz8eFi1SsItIbAhlzL01kFlseyNB4Bf3\n/4CZZrYZaAhcH57yqtnjjwfnL86aBQ0blnjqwAF46KFg+H3sWBhQ+uNMRCSKheuA6t3AF+5+oZm1\nB/5jZt3dPad0wzFjxhTdT01NJTU1NUwlVNILLwTj67NnB2PtxaxZE8wo0KhRcIpjq1aRKVFEjk1p\naWmkpaUd1T5CGXPvA4xx936F26MBd/fHirWZDjzk7p8Wbs8E7nL3z0rtKzrG3N96C269NbjyqNTp\njm+/HczW+8c/BlOyJ+hKABGJsOpaQ3Uh0MHMUoBvgBuAwaXaLAcuBj41sxZAJ2BNZQqpMR99FBxA\nfe+9w4L9P/8Jgn3atOCsGBGRWFVhuLt7vpndBswgOAA7zt2Xm9mI4Gl/HngEeNHMvgAM+IO776jO\nwqtk0SK4/np49dVgIphi5s4NzoZ84w0Fu4jEvgqHZcL6ZpEcllm5ElJT4bnnDjs6+sUXwXzrL70E\n/fpFpjwRkfJU16mQsW/jxmBRjYcfPizYv/oKLr88mEZAwS4i8SL+w/2774Ju+ciRMHx4iacyM+GS\nS+DBBzU/jIjEl/gelsnJgYsugr59g5WTitm2Dc4/Pzi2euedNVeSiEhlVWVYJn7DPTcXrrwSUlKC\nxTaKzRezc2ewqMaVV8IDD9RMOSIiVaVwPyg/HwYPDr6++mqJFZP27AmG33v2DKbsLWeOMBGRqKFw\nh2AisF/9ClavDk5YLzZfzP79wfHU5s2DhZV0gZKIxILquogpttxzT7DG6Ycflgj2/PxgSoF69WDc\nOAW7iMS3+Ar3J58MrkKaNSuYGKaQO4wYAd9/H6yaVzu+/tUiIoeJn5h76aVgEH32bEhKKnrYHX73\nO/jyy2B6gTJm9RURiTvxEe5Tp8Lo0cG8MaWWR3rooSDUP/74sFl9RUTiVuyH+8cfwy9+ERw8Pe20\nEk/9/e9Bh37WLEhMjFB9IiIRENvhvmJFcGnpK68cNtvX+PHBWhyzZkHLlhGqT0QkQmI73F97DYYN\nC65CLebNN+Guu4JRmpSUCNUmIhJBsX1CYHo6nHlmiYc++CA4M6aMURoRkWNG7Id7jx5FmwfnZJ88\n+bDp2kVEjimxe4VqVhacdBJkZ0OtWmRkBDM8ak52EYk3x9Z87hkZ0K0b1KqlOdlFREqJ3XAvHJLJ\nzAyma3/gAc3JLiJyUEyHe06HHlxySbAOx89/HumCRESiR0yH+5tre3D22VpsQ0SktNgM97w8WL6c\nd9Z3o3//SBcjIhJ9YjPcV6zAk5P5aEEDzj030sWIiESf2Az3wvH24447bJ4wEREhhsP9q/o9OOec\nSBciIhKdYjbc5+zpoSEZEZFyxF64uxedKaOeu4hI2WIv3DdupKB2Heavb0nPnpEuRkQkOsXelL/p\n6Xyf3IOe9aBu3UgXIyISnULquZtZPzNbYWarzOyuMp7/nZktNrPPzWyJmR0wsxPCXy6Qns6KehqS\nERE5kgrD3cwSgKeBy4AuwGAzKzFTurs/4e493b0XcDeQ5u47q6Ng0tOZtUsHU0VEjiSUnntv4Ct3\nX+/uecAkYMAR2g8GXglHcWXx9HTeWKOeu4jIkYQS7q2BzGLbGwsfO4yZHQ/0AyYffWllyMrCv9nC\n90kdadGiWt5BRCQuhPuA6pXA7CMNyYwZM6bofmpqKqmpqaHvPSOD7a260efcWlWvUEQkyqWlpZGW\nlnZU+6hwJSYz6wOMcfd+hdujAXf3x8po+wbwqrtPKmdfR7cS09//TtozX7Ls9ue49daq70ZEJJZU\n10pMC4EOZpZiZnWBG4CpZbx5E+ACYEplCqiU9HQ+ztLBVBGRilQY7u6eD9wGzAC+BCa5+3IzG2Fm\ntxRrejXwvrvvrZ5S4cCidD7J7kHXrtX1DiIi8SF2FsjOyyO/UROu6vMt09IahLcwEZEoFt8LZK9Y\nwY6GyfT6kYJdRKQisRPu6eksraXz20VEQhEz4V7weTppO3vQp0+kKxERiX4xE+6756SzuXkPmjaN\ndCUiItEvNsLdnTpfptPwhz0iXYmISEyIjXDfuJF9+XXoenHLSFciIhITYiPc09PJMB1MFREJVUyE\ne87sdD4v6MFpp1XcVkREYiTcsz9JZ99pPUiIiWpFRCIvJuLyuOXpND5fB1NFREIV/eGelUX9XVs4\n9YqOka5ERCRmRH245y3KYAnd6H2O5nAXEQlV1If75unprE/sQaNGka5ERCR2RH2475qdTt7pGm8X\nEamMqA/3+ivTSbxQ4S4iUhnhXkM1vPLyaJW1HAZ2i3QlIiIxJarDfUvaCnYlJNOhq+ZwFxGpjKge\nllk/JZ0tLXtglVp/REREorrnvmdOOtZN4+0iIpUV1T33hl+nk3SRwl1EpLKidoHsvXucPQ2SqL/m\nS45vp6l+ReTYFVcLZGdM3wi16yjYRUSqIGrDfeM76WxrrSEZEZGqiNpwz52fDj9QuIuIVEVUhrs7\nNF6TzomXKtxFRKoiKsN9zRromq8zZUREqioqw33hB1m0ZAt01BzuIiJVEZXhvundDL4/uRvU0hzu\nIiJVEVK4m1k/M1thZqvM7K5y2qSa2WIzW2pmHx1NUXkL00nopSEZEZGqqnD6ATNLAJ4GLgI2AwvN\nbIq7ryjWpgnwDHCpu28ys6SqFrRrF7Talk6zvmdVdRciIse8UHruvYGv3H29u+cBk4ABpdoMASa7\n+yYAd99e1YIWLIA+x6VT+0z13EVEqiqUcG8NZBbb3lj4WHGdgKZm9pGZLTSzn1a1oHmz8miXuxy6\naQ53EZGqCteskLWBXkBfoAEw18zmuvvXpRuOGTOm6H5qaiqpqaklnt80cwW5LZKp20BzuIvIsSkt\nLY20tLSj2keFE4eZWR9gjLv3K9weDbi7P1aszV1APXe/v3D7n8C77j651L6OOHFYQQHc2mgCf71k\nGvXemlTVf5OISFypronDFgIdzCzFzOoCNwBTS7WZAvzQzGqZWX3gbGB5ZQoBWLECzqyTTr0+Gm8X\nETkaFQ7LuHu+md0GzCD4MBjn7svNbETwtD/v7ivM7H0gA8gHnnf3ZZUtZu5cOKdeOvT4fWVfKiIi\nxUTVfO4//5nzzKtJ1Pv6S2ipqX5FRCAO5nNfO2sjterVUbCLiBylqAn3HTsgaVM6tc7QeLuIyNGK\nmnCfNw8ub5lOQk+Fu4jI0YqacJ87F3rXTYceCncRkaMVNeE+Zw60zVK4i4iEQ1ScLXPgALRNzCKz\n4CQsO1tT/YqIFFOVs2XCNf3AUVm6FFKbZmCtNIe7iEg4REW4z50Ll5+kBbFFRMIlKsbc58yBM2tp\nvF1EJFyiJtyTv1e4i4iES8SHZbZuhezv8qi3X3O4i4iES8TDfe5cGNh1BbY9GTSHu4hIWERFuF/W\nIh1O1pCMiEi4RHzMfc4c6GkabxcRCaeIhvv+/bB4MbT+VuEuIhJOEQ339HTo0N6pvVThLiISThEN\n9zlzoH/3jVBHc7iLiIRTRMN97ly45ET12kVEwi3iPffuBQp3EZFwi1i4Z2ZCbi40zVS4i4iEW8TC\nfe5cOPdcsHSFu4hIuEUs3OfMgQt6ZgfzD3TsGKkyRETiUkR77n2TMqBrV83hLiISZhEJ9717gwU6\nOudqSEZEpDpEJNw/+wy6dIG6yxTuIiLVISLhfvBgKjqYKiJSLSIS7nPmwLln5cGyZZrDXUSkGtR4\nuLsHPffzW6yEZM3hLiJSHUIKdzPrZ2YrzGyVmd1VxvMXmNlOM/u88HZPeftas6ZwKpktGpIREaku\nFS7WYWYJwNPARcBmYKGZTXH3FaWafuLuV1W0vzlzNN4uIlLdQum59wa+cvf17p4HTAIGlNHOQnlD\nHUwVEamLfqCiAAAHAElEQVR+oYR7ayCz2PbGwsdKO8fM0s1smpmdXt7O5syBc/q4wl1EpBqFaw3V\nRUCyu+8xs8uBt4BOZTX8+mvo2XwT1K6tOdxFRKpJKOG+CUgutn1y4WNF3D2n2P13zexZM2vq7jtK\n76xp0zE8fM8qaNiQ1LQ0UlNTq1i6iEh8SktLIy0t7aj2Ye5+5AZmtYCVBAdUvwEWAIPdfXmxNi3c\nfWvh/d7Aq+7etox9+e9/7/y58Z8gJwceffSoihcRORaYGe4e0nHNgyocc3f3fOA2YAbwJTDJ3Zeb\n2Qgzu6Ww2UAzW2pmi4G/AteXtz8dTBURqX4V9tzD+mZmvmWL0+K8DvDOO3DaaTX23iIisaoqPfca\nD3fPyoKTToKsLE31KyISgmoZlgm7DM3hLiJS3Wo+3DXeLiJS7RTuIiJxSOEuIhKHav6A6vHHw7ff\naqpfEZEQxcYBVc3hLiJS7Wo+3DUkIyJS7RTuIiJxSOEuIhKHFO4iInGo5s+WqcH3ExGJB7FxtoyI\niFQ7hbuISBxSuIuIxCGFu4hIHFK4i4jEIYW7iEgcUriLiMQhhbuISBxSuIuIxCGFu4hIHFK4i4jE\nIYW7iEgcUriLiMQhhbuISBxSuIuIxCGFu4hIHAop3M2sn5mtMLNVZnbXEdqdZWZ5ZnZN+EoUEZHK\nqjDczSwBeBq4DOgCDDaz08pp9yjwfriLrGlpaWmRLiEkqjO8YqHOWKgRVGc0CKXn3hv4yt3Xu3se\nMAkYUEa7kcDrwLYw1hcRsfIDV53hFQt1xkKNoDqjQSjh3hrILLa9sfCxImZ2EnC1u/8DqNQ6fyIi\nEn7hOqD6V6D4WLwCXkQkgszdj9zArA8wxt37FW6PBtzdHyvWZs3Bu0ASsBu4xd2nltrXkd9MRETK\n5O6V6jSHEu61gJXARcA3wAJgsLsvL6f9i8Db7v5GZQoREZHwqV1RA3fPN7PbgBkEwzjj3H25mY0I\nnvbnS7+kGuoUEZFKqLDnLiIisafGrlAN9UKoSDKzk83sQzP70syWmNntka6pPGaWYGafm9nUiltH\nhpk1MbPXzGx54ff07EjXVBYzu7uwvgwzm2hmdSNdE4CZjTOzrWaWUeyxRDObYWYrzex9M2sSyRoL\nayqrzj8X/tzTzWyymTWOZI2FNR1WZ7HnRplZgZk1jURtpWops04zG1n4PV1iZo9WtJ8aCfdQL4SK\nAgeAO929C3AO8JsorRPgDmBZpIuowFPAdHfvDPwAKPM4TSSZWQrwS6Cnu3cnGKq8IbJVFXmR4Hem\nuNHAB+5+KvAhcHeNV3W4suqcAXRx9x7AV0RvnZjZycAlwPoar6hsh9VpZqnAlUA3d+8GPFHRTmqq\n5x7qhVAR5e5b3D298H4OQRi1PvKral7hf8b+wD8jXUt5CntqP3L3FwHc/YC7Z0e4rLJkA/uBBmZW\nG6gPbI5sSQF3nw18X+rhAcBLhfdfAq6u0aLKUFad7v6BuxcUbs4DTq7xwkop5/sJ8Bfg9zVcTrnK\nqfPXwKPufqCwzfaK9lNT4V7hhVDRxszaAj2A+ZGtpEwH/zNG8wGTdsB2M3uxcPjoeTM7PtJFlebu\n3wP/C2wANgE73f2DyFZ1RM3dfSsEnRGgeYTrCcXPgHcjXURZzOwqINPdl0S6lgp0As43s3lm9pGZ\nnVnRCzQrZBnMrCHBVAp3FPbgo4aZ/RjYWvgXhhG9F4zVBnoBz7h7L2APwZBCVDGzU4D/AlKAk4CG\nZjYkslVVSjR/wGNm/w3kufvLka6ltMLOxh+B+4o/HKFyKlIbSHT3PsAfgFcrekFNhfsmILnY9smF\nj0Wdwj/NXwcmuPuUSNdThvOAqwovHHsFuNDMxke4prJsJOgRfVa4/TpB2EebM4FP3X2Hu+cDbwDn\nRrimI9lqZi0AzKwlUTyXk5ndTDB8GK0flu2BtsAXZraWIJcWmVk0/jWUSfB/E3dfCBSYWbMjvaCm\nwn0h0MHMUgrPRLgBiNazPF4Alrn7U5EupCzu/kd3T3b3Uwi+jx+6+7BI11Va4dBBppl1KnzoIqLz\nAPBKoI+Z1TMzI6gzmg78lv7rbCpwc+H9m4Bo6YCUqNPM+hEMHV7l7rkRq+pwRXW6+1J3b+nup7h7\nO4IOSU93j4YPzNI/97eAvgCFv1N13P27I+2gRsK9sEd08EKoL4FJ5V3hGklmdh5wI9DXzBYXjhX3\ni3RdMex2YKKZpROcLfNwhOs5jLt/AYwHFgFfEPxClb4wLyLM7GVgDtDJzDaY2XCCabUvMbODV41X\neEpcdSunzr8DDYH/FP4ePRvRIim3zuKcKBiWKafOF4BTzGwJ8DJQYYdOFzGJiMQhHVAVEYlDCncR\nkTikcBcRiUMKdxGROKRwFxGJQwp3EZE4pHAXEYlDCncRkTj0/wFGPWgcuymbwgAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f449a7978d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:9 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-383b757ba51b>:9 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    }
   ],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-5.0, 1.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False, train_rho = True, only_loglike = False)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, ep 0, training accuracy 0.1\n",
      "f : 202075.15625, q : 142556.53125, p : -54964.1367188, l : 4614.22753906\n",
      "batch 0, ep 50, training accuracy 0.995\n",
      "f : 195851.8125, q : 140581.421875, p : -55005.390625, l : 338.313293457\n",
      "batch 0, ep 100, training accuracy 1\n",
      "f : 193669.015625, q : 138568.765625, p : -55024.6875, l : 83.1640777588\n",
      "batch 0, ep 150, training accuracy 1\n",
      "f : 191672.21875, q : 136465.4375, p : -55032.6953125, l : 45.8235168457\n",
      "valid accuracy 0.7855\n",
      "batch 1, ep 0, training accuracy 0.845\n",
      "f : 9938.27929688, q : 134565.203125, p : 125749.96875, l : 1091.68847656\n",
      "batch 1, ep 50, training accuracy 0.985\n",
      "f : 320976.34375, q : 134166.890625, p : -186605.125, l : 241.655303955\n",
      "batch 1, ep 100, training accuracy 0.99\n",
      "f : 318606.3125, q : 134078.671875, p : -184275.375, l : 215.447280884\n",
      "batch 1, ep 150, training accuracy 0.99\n",
      "f : 316796.90625, q : 134001.4375, p : -182541.484375, l : 194.12878418\n",
      "valid accuracy 0.8274\n",
      "batch 2, ep 0, training accuracy 0.765\n",
      "f : 10223.7861328, q : 133943.203125, p : 125113.328125, l : 1385.89709473\n",
      "batch 2, ep 50, training accuracy 0.995\n",
      "f : 320183.90625, q : 133460.0, p : -186443.109375, l : 273.858032227\n",
      "batch 2, ep 100, training accuracy 0.995\n",
      "f : 318114.34375, q : 133395.3125, p : -184524.90625, l : 243.684143066\n",
      "batch 2, ep 150, training accuracy 0.995\n",
      "f : 316385.09375, q : 133441.8125, p : -182775.5625, l : 219.176864624\n",
      "valid accuracy 0.8407\n",
      "batch 3, ep 0, training accuracy 0.82\n",
      "f : 10132.1914062, q : 133271.015625, p : 124417.929688, l : 1288.88671875\n",
      "batch 3, ep 50, training accuracy 0.975\n",
      "f : 319144.15625, q : 132756.1875, p : -186080.84375, l : 277.915893555\n",
      "batch 3, ep 100, training accuracy 0.99\n",
      "f : 316961.875, q : 132674.828125, p : -184003.234375, l : 246.710540771\n",
      "batch 3, ep 150, training accuracy 0.995\n",
      "f : 315334.84375, q : 132655.09375, p : -182389.703125, l : 220.299377441\n",
      "valid accuracy 0.8357\n",
      "batch 4, ep 0, training accuracy 0.83\n",
      "f : 10053.3212891, q : 132664.40625, p : 123804.546875, l : 1208.97729492\n",
      "batch 4, ep 50, training accuracy 0.995\n",
      "f : 318219.28125, q : 132100.421875, p : -185819.96875, l : 213.613037109\n",
      "batch 4, ep 100, training accuracy 0.995\n",
      "f : 315950.375, q : 132006.296875, p : -183684.59375, l : 190.57119751\n",
      "batch 4, ep 150, training accuracy 0.995\n",
      "f : 314248.0, q : 131921.390625, p : -182109.203125, l : 172.720077515\n",
      "valid accuracy 0.8314\n",
      "batch 5, ep 0, training accuracy 0.76\n",
      "f : 10367.8720703, q : 131921.53125, p : 123121.539062, l : 1520.87133789\n",
      "batch 5, ep 50, training accuracy 0.99\n",
      "f : 317381.09375, q : 131498.015625, p : -185610.46875, l : 256.840759277\n",
      "batch 5, ep 100, training accuracy 1\n",
      "f : 315134.84375, q : 131317.203125, p : -183482.53125, l : 228.857086182\n",
      "batch 5, ep 150, training accuracy 1\n",
      "f : 313155.34375, q : 131387.421875, p : -181689.875, l : 206.55255127\n",
      "valid accuracy 0.8342\n",
      "batch 6, ep 0, training accuracy 0.815\n",
      "f : 10179.8427734, q : 131381.140625, p : 122481.960938, l : 1342.07958984\n",
      "batch 6, ep 50, training accuracy 0.975\n",
      "f : 317614.34375, q : 130779.023438, p : -186578.828125, l : 281.680480957\n",
      "batch 6, ep 100, training accuracy 0.985\n",
      "f : 315543.4375, q : 130743.984375, p : -184570.578125, l : 244.49407959\n",
      "batch 6, ep 150, training accuracy 0.99\n",
      "f : 313926.875, q : 130635.820312, p : -183002.8125, l : 215.796447754\n",
      "valid accuracy 0.8321\n",
      "batch 7, ep 0, training accuracy 0.825\n",
      "f : 10028.3007812, q : 130695.695312, p : 121786.953125, l : 1190.90625\n",
      "batch 7, ep 50, training accuracy 0.995\n",
      "f : 316449.25, q : 130135.96875, p : -186138.578125, l : 210.082000732\n",
      "batch 7, ep 100, training accuracy 1\n",
      "f : 314657.8125, q : 130057.90625, p : -184306.6875, l : 184.380599976\n",
      "batch 7, ep 150, training accuracy 1\n",
      "f : 312773.15625, q : 130012.054688, p : -182638.5, l : 163.592636108\n",
      "valid accuracy 0.8468\n",
      "batch 8, ep 0, training accuracy 0.87\n",
      "f : 9693.1953125, q : 129965.289062, p : 121094.828125, l : 846.125183105\n",
      "batch 8, ep 50, training accuracy 0.995\n",
      "f : 316137.5, q : 129419.65625, p : -186446.703125, l : 146.51776123\n",
      "batch 8, ep 100, training accuracy 0.995\n",
      "f : 313877.125, q : 129415.398438, p : -184393.1875, l : 133.458328247\n",
      "batch 8, ep 150, training accuracy 0.995\n",
      "f : 312318.0625, q : 129319.28125, p : -182890.015625, l : 122.05330658\n",
      "valid accuracy 0.8342\n",
      "batch 9, ep 0, training accuracy 0.78\n",
      "f : 10031.1826172, q : 129320.21875, p : 120445.890625, l : 1188.11889648\n",
      "batch 9, ep 50, training accuracy 0.99\n",
      "f : 314735.1875, q : 128872.523438, p : -185758.1875, l : 185.100006104\n",
      "batch 9, ep 100, training accuracy 0.995\n",
      "f : 312626.09375, q : 128799.828125, p : -183744.5625, l : 163.329040527\n",
      "batch 9, ep 150, training accuracy 0.995\n",
      "f : 310744.84375, q : 128708.632812, p : -181927.34375, l : 145.71824646\n",
      "valid accuracy 0.8511\n",
      "batch 10, ep 0, training accuracy 0.87\n",
      "f : 9713.93847656, q : 128575.953125, p : 119773.632812, l : 872.927062988\n",
      "batch 10, ep 50, training accuracy 0.99\n",
      "f : 313710.0625, q : 128091.851562, p : -185400.234375, l : 172.296005249\n",
      "batch 10, ep 100, training accuracy 0.99\n",
      "f : 311837.0625, q : 128063.679688, p : -183570.734375, l : 152.85043335\n",
      "batch 10, ep 150, training accuracy 0.99\n",
      "f : 310170.0625, q : 127972.6875, p : -181933.3125, l : 137.672607422\n",
      "valid accuracy 0.841\n",
      "batch 11, ep 0, training accuracy 0.82\n",
      "f : 9827.1171875, q : 127914.007812, p : 119067.03125, l : 986.954711914\n",
      "batch 11, ep 50, training accuracy 0.985\n",
      "f : 312863.875, q : 127552.335938, p : -185285.1875, l : 165.64364624\n",
      "batch 11, ep 100, training accuracy 0.99\n",
      "f : 310815.3125, q : 127435.679688, p : -183252.53125, l : 148.995819092\n",
      "batch 11, ep 150, training accuracy 0.99\n",
      "f : 309244.6875, q : 127331.125, p : -181782.640625, l : 134.839904785\n",
      "valid accuracy 0.8279\n",
      "batch 12, ep 0, training accuracy 0.855\n",
      "f : 9829.22363281, q : 127330.351562, p : 118527.625, l : 987.421020508\n",
      "batch 12, ep 50, training accuracy 1\n",
      "f : 311647.8125, q : 126884.546875, p : -184715.53125, l : 155.420227051\n",
      "batch 12, ep 100, training accuracy 1\n",
      "f : 309322.71875, q : 126771.65625, p : -182581.609375, l : 135.985870361\n",
      "batch 12, ep 150, training accuracy 1\n",
      "f : 307903.53125, q : 126649.710938, p : -180989.109375, l : 122.023178101\n",
      "valid accuracy 0.8375\n",
      "batch 13, ep 0, training accuracy 0.825\n",
      "f : 10206.4511719, q : 126641.1875, p : 117822.265625, l : 1368.98706055\n",
      "batch 13, ep 50, training accuracy 0.985\n",
      "f : 310854.34375, q : 126127.179688, p : -184495.28125, l : 264.271057129\n",
      "batch 13, ep 100, training accuracy 0.99\n",
      "f : 308413.90625, q : 126066.257812, p : -182118.53125, l : 230.901031494\n",
      "batch 13, ep 150, training accuracy 0.99\n",
      "f : 306628.1875, q : 126039.40625, p : -180427.375, l : 205.383422852\n",
      "valid accuracy 0.8341\n",
      "batch 14, ep 0, training accuracy 0.85\n",
      "f : 9828.109375, q : 125981.8125, p : 117149.4375, l : 990.622680664\n",
      "batch 14, ep 50, training accuracy 0.995\n",
      "f : 309766.5, q : 125464.117188, p : -184072.0625, l : 177.983291626\n",
      "batch 14, ep 100, training accuracy 0.995\n",
      "f : 307346.40625, q : 125443.148438, p : -181773.09375, l : 158.34979248\n",
      "batch 14, ep 150, training accuracy 0.995\n",
      "f : 305528.875, q : 125323.21875, p : -179950.515625, l : 142.931518555\n",
      "valid accuracy 0.8374\n",
      "batch 15, ep 0, training accuracy 0.83\n",
      "f : 9854.57421875, q : 125289.578125, p : 116479.226562, l : 1018.10870361\n",
      "batch 15, ep 50, training accuracy 1\n",
      "f : 308461.5625, q : 124923.125, p : -183506.484375, l : 140.844650269\n",
      "batch 15, ep 100, training accuracy 1\n",
      "f : 306003.3125, q : 124762.679688, p : -181142.375, l : 122.54901123\n",
      "batch 15, ep 150, training accuracy 1\n",
      "f : 304409.9375, q : 124717.992188, p : -179586.234375, l : 110.833946228\n",
      "valid accuracy 0.8448\n",
      "batch 16, ep 0, training accuracy 0.84\n",
      "f : 9904.02636719, q : 124659.117188, p : 115767.164062, l : 1065.8458252\n",
      "batch 16, ep 50, training accuracy 1\n",
      "f : 306970.1875, q : 124207.585938, p : -182631.84375, l : 153.962860107\n",
      "batch 16, ep 100, training accuracy 1\n",
      "f : 304617.96875, q : 124073.421875, p : -180400.90625, l : 137.279602051\n",
      "batch 16, ep 150, training accuracy 1\n",
      "f : 302685.59375, q : 124044.039062, p : -178496.140625, l : 124.723999023\n",
      "valid accuracy 0.8434\n",
      "batch 17, ep 0, training accuracy 0.845\n",
      "f : 9622.81835938, q : 123953.625, p : 115161.3125, l : 784.401062012\n",
      "batch 17, ep 50, training accuracy 1\n",
      "f : 305479.15625, q : 123561.9375, p : -181839.3125, l : 126.716178894\n",
      "batch 17, ep 100, training accuracy 1\n",
      "f : 302801.40625, q : 123491.40625, p : -179260.9375, l : 110.861778259\n",
      "batch 17, ep 150, training accuracy 1\n",
      "f : 300733.125, q : 123406.453125, p : -177234.8125, l : 99.8332824707\n",
      "valid accuracy 0.8469\n",
      "batch 18, ep 0, training accuracy 0.835\n",
      "f : 10105.4013672, q : 123259.34375, p : 114570.054688, l : 1267.83032227\n",
      "batch 18, ep 50, training accuracy 0.985\n",
      "f : 303305.90625, q : 122812.140625, p : -180355.703125, l : 204.866592407\n",
      "batch 18, ep 100, training accuracy 0.985\n",
      "f : 300696.6875, q : 122826.101562, p : -177725.4375, l : 179.670303345\n",
      "batch 18, ep 150, training accuracy 0.985\n",
      "f : 298498.90625, q : 122754.023438, p : -175593.15625, l : 159.813903809\n",
      "valid accuracy 0.8358\n",
      "batch 19, ep 0, training accuracy 0.85\n",
      "f : 9772.15039062, q : 122728.328125, p : 113856.0625, l : 942.674804688\n",
      "batch 19, ep 50, training accuracy 0.995\n",
      "f : 301491.59375, q : 122203.328125, p : -179182.796875, l : 126.200164795\n",
      "batch 19, ep 100, training accuracy 1\n",
      "f : 298586.25, q : 122198.46875, p : -176403.9375, l : 108.65737915\n",
      "batch 19, ep 150, training accuracy 1\n",
      "f : 296689.3125, q : 122007.953125, p : -174450.125, l : 96.441947937\n",
      "valid accuracy 0.8532\n",
      "batch 20, ep 0, training accuracy 0.835\n",
      "f : 9976.19628906, q : 122057.5, p : 113144.492188, l : 1144.24597168\n",
      "batch 20, ep 50, training accuracy 0.99\n",
      "f : 299170.375, q : 121579.210938, p : -177418.671875, l : 194.382324219\n",
      "batch 20, ep 100, training accuracy 0.995\n",
      "f : 296135.6875, q : 121532.09375, p : -174503.4375, l : 167.824676514\n",
      "batch 20, ep 150, training accuracy 0.995\n",
      "f : 294002.0, q : 121481.015625, p : -172437.8125, l : 150.701675415\n",
      "valid accuracy 0.8449\n",
      "batch 21, ep 0, training accuracy 0.815\n",
      "f : 10079.0761719, q : 121400.164062, p : 112551.960938, l : 1239.91137695\n",
      "batch 21, ep 50, training accuracy 0.985\n",
      "f : 296954.375, q : 120835.632812, p : -175844.609375, l : 183.260986328\n",
      "batch 21, ep 100, training accuracy 0.985\n",
      "f : 293947.21875, q : 120821.585938, p : -172923.21875, l : 164.456817627\n",
      "batch 21, ep 150, training accuracy 0.99\n",
      "f : 291336.1875, q : 120836.601562, p : -170428.015625, l : 150.597747803\n",
      "valid accuracy 0.8429\n",
      "batch 22, ep 0, training accuracy 0.895\n",
      "f : 9572.8515625, q : 120738.976562, p : 111954.40625, l : 739.93963623\n",
      "batch 22, ep 50, training accuracy 1\n",
      "f : 295431.1875, q : 120244.085938, p : -175123.515625, l : 92.5924377441\n",
      "batch 22, ep 100, training accuracy 1\n",
      "f : 292327.40625, q : 120231.898438, p : -172112.703125, l : 82.2629089355\n",
      "batch 22, ep 150, training accuracy 1\n",
      "f : 290088.375, q : 120199.804688, p : -169865.28125, l : 75.1778182983\n",
      "valid accuracy 0.8568\n",
      "batch 23, ep 0, training accuracy 0.82\n",
      "f : 10001.2304688, q : 120128.601562, p : 111242.703125, l : 1165.27734375\n",
      "batch 23, ep 50, training accuracy 0.985\n",
      "f : 292067.40625, q : 119602.023438, p : -172310.4375, l : 167.255477905\n",
      "batch 23, ep 100, training accuracy 0.99\n",
      "f : 288718.8125, q : 119498.078125, p : -169016.859375, l : 145.854370117\n",
      "batch 23, ep 150, training accuracy 0.995\n",
      "f : 286205.0625, q : 119440.007812, p : -166529.296875, l : 128.518859863\n",
      "valid accuracy 0.8492\n",
      "batch 24, ep 0, training accuracy 0.79\n",
      "f : 10147.3769531, q : 119470.578125, p : 110564.59375, l : 1315.00305176\n",
      "batch 24, ep 50, training accuracy 0.99\n",
      "f : 290149.75, q : 119003.695312, p : -171085.3125, l : 146.481887817\n",
      "batch 24, ep 100, training accuracy 0.99\n",
      "f : 286526.875, q : 118870.671875, p : -167526.15625, l : 126.731040955\n",
      "batch 24, ep 150, training accuracy 0.995\n",
      "f : 284051.1875, q : 118863.570312, p : -165038.78125, l : 112.83115387\n",
      "valid accuracy 0.8446\n",
      "batch 25, ep 0, training accuracy 0.785\n",
      "f : 10329.4003906, q : 118803.359375, p : 109996.34375, l : 1495.72900391\n",
      "batch 25, ep 50, training accuracy 0.97\n",
      "f : 287058.875, q : 118369.945312, p : -168495.609375, l : 250.440505981\n",
      "batch 25, ep 100, training accuracy 0.97\n",
      "f : 283326.375, q : 118254.125, p : -164890.28125, l : 219.270263672\n",
      "batch 25, ep 150, training accuracy 0.975\n",
      "f : 280384.125, q : 118258.398438, p : -161938.0625, l : 195.327362061\n",
      "valid accuracy 0.8415\n",
      "batch 26, ep 0, training accuracy 0.84\n",
      "f : 9955.87792969, q : 118155.398438, p : 109375.078125, l : 1127.94494629\n",
      "batch 26, ep 50, training accuracy 0.99\n",
      "f : 283662.46875, q : 117631.554688, p : -165760.671875, l : 168.69380188\n",
      "batch 26, ep 100, training accuracy 0.99\n",
      "f : 279692.09375, q : 117701.171875, p : -161925.75, l : 136.014648438\n",
      "batch 26, ep 150, training accuracy 0.99\n",
      "f : 276463.15625, q : 117519.1875, p : -158765.71875, l : 113.902427673\n",
      "valid accuracy 0.8485\n",
      "batch 27, ep 0, training accuracy 0.85\n",
      "f : 9854.58886719, q : 117474.367188, p : 108733.46875, l : 1023.63879395\n",
      "batch 27, ep 50, training accuracy 1\n",
      "f : 280696.34375, q : 117023.320312, p : -163520.34375, l : 89.8798828125\n",
      "batch 27, ep 100, training accuracy 1\n",
      "f : 276405.40625, q : 117027.414062, p : -159274.953125, l : 78.7478790283\n",
      "batch 27, ep 150, training accuracy 1\n",
      "f : 272925.875, q : 116951.164062, p : -155908.078125, l : 69.6899185181\n",
      "valid accuracy 0.8526\n",
      "batch 28, ep 0, training accuracy 0.81\n",
      "f : 9956.06445312, q : 116935.875, p : 108087.289062, l : 1133.98632812\n",
      "batch 28, ep 50, training accuracy 0.995\n",
      "f : 275920.625, q : 116403.445312, p : -159264.25, l : 142.134887695\n",
      "batch 28, ep 100, training accuracy 0.995\n",
      "f : 270956.25, q : 116430.382812, p : -154462.65625, l : 125.56803894\n",
      "batch 28, ep 150, training accuracy 0.995\n",
      "f : 267080.71875, q : 116305.710938, p : -150623.84375, l : 110.940658569\n",
      "valid accuracy 0.8523\n",
      "batch 29, ep 0, training accuracy 0.91\n",
      "f : 9698.93359375, q : 116262.585938, p : 107489.734375, l : 870.778320312\n",
      "batch 29, ep 50, training accuracy 0.985\n",
      "f : 271261.21875, q : 115704.765625, p : -155292.4375, l : 206.977233887\n",
      "batch 29, ep 100, training accuracy 0.985\n",
      "f : 265753.90625, q : 115747.054688, p : -149829.4375, l : 179.646575928\n",
      "batch 29, ep 150, training accuracy 0.99\n",
      "f : 261357.953125, q : 115680.4375, p : -145479.65625, l : 159.25567627\n",
      "valid accuracy 0.8592\n",
      "batch 30, ep 0, training accuracy 0.92\n",
      "f : 9635.44824219, q : 115674.09375, p : 106891.828125, l : 805.966308594\n",
      "batch 30, ep 50, training accuracy 0.995\n",
      "f : 262704.09375, q : 115111.367188, p : -147558.984375, l : 80.9360198975\n",
      "batch 30, ep 100, training accuracy 1\n",
      "f : 253480.6875, q : 115039.757812, p : -138343.828125, l : 54.1732711792\n",
      "batch 30, ep 150, training accuracy 1\n",
      "f : 246991.859375, q : 114956.554688, p : -132032.09375, l : 43.8620910645\n",
      "valid accuracy 0.8496\n",
      "batch 31, ep 0, training accuracy 0.895\n",
      "f : 9507.27148438, q : 114821.210938, p : 105966.6875, l : 682.372192383\n",
      "batch 31, ep 50, training accuracy 0.99\n",
      "f : 233062.640625, q : 114619.96875, p : -118505.734375, l : 112.607391357\n",
      "batch 31, ep 100, training accuracy 0.995\n",
      "f : 226039.359375, q : 114518.742188, p : -111547.195312, l : 97.1412963867\n",
      "batch 31, ep 150, training accuracy 0.995\n",
      "f : 220552.28125, q : 114478.1875, p : -106099.929688, l : 84.1557617188\n",
      "valid accuracy 0.8505\n",
      "batch 32, ep 0, training accuracy 0.905\n",
      "f : 9510.08105469, q : 114377.3125, p : 105582.734375, l : 684.556396484\n",
      "batch 32, ep 50, training accuracy 0.995\n",
      "f : 236595.03125, q : 114034.0625, p : -122554.734375, l : 89.3507995605\n",
      "batch 32, ep 100, training accuracy 0.995\n",
      "f : 229255.703125, q : 113969.742188, p : -115164.203125, l : 76.8374786377\n",
      "batch 32, ep 150, training accuracy 1\n",
      "f : 222924.109375, q : 113850.78125, p : -108953.664062, l : 66.5896606445\n",
      "valid accuracy 0.8594\n",
      "batch 33, ep 0, training accuracy 0.855\n",
      "f : 9804.76074219, q : 113833.453125, p : 105043.835938, l : 981.753234863\n",
      "batch 33, ep 50, training accuracy 0.99\n",
      "f : 236908.65625, q : 113502.484375, p : -123303.625, l : 122.255256653\n",
      "batch 33, ep 100, training accuracy 0.99\n",
      "f : 228865.828125, q : 113367.820312, p : -115345.96875, l : 108.01398468\n",
      "batch 33, ep 150, training accuracy 0.99\n",
      "f : 222550.34375, q : 113354.671875, p : -109090.039062, l : 96.6392822266\n",
      "valid accuracy 0.8618\n",
      "batch 34, ep 0, training accuracy 0.83\n",
      "f : 10210.5839844, q : 113329.8125, p : 104447.289062, l : 1385.61474609\n",
      "batch 34, ep 50, training accuracy 0.99\n",
      "f : 227402.4375, q : 112866.671875, p : -114476.695312, l : 133.358123779\n",
      "batch 34, ep 100, training accuracy 0.99\n",
      "f : 214103.875, q : 112863.023438, p : -101223.617188, l : 104.866928101\n",
      "batch 34, ep 150, training accuracy 0.995\n",
      "f : 203729.390625, q : 112672.359375, p : -90997.2578125, l : 87.6545715332\n",
      "valid accuracy 0.855\n",
      "batch 35, ep 0, training accuracy 0.855\n",
      "f : 9898.12890625, q : 112542.148438, p : 103714.296875, l : 1072.31066895\n",
      "batch 35, ep 50, training accuracy 0.98\n",
      "f : 185990.578125, q : 112174.726562, p : -73520.15625, l : 255.362823486\n",
      "batch 35, ep 100, training accuracy 0.99\n",
      "f : 165268.984375, q : 111992.265625, p : -53079.671875, l : 202.483917236\n",
      "batch 35, ep 150, training accuracy 0.99\n",
      "f : 152975.65625, q : 111945.9375, p : -40812.59375, l : 170.98046875\n",
      "valid accuracy 0.8571\n",
      "batch 36, ep 0, training accuracy 0.805\n",
      "f : 10285.4882812, q : 111813.304688, p : 102945.34375, l : 1451.50170898\n",
      "batch 36, ep 50, training accuracy 0.99\n",
      "f : 160278.09375, q : 111389.398438, p : -48740.8789062, l : 185.422637939\n",
      "batch 36, ep 100, training accuracy 0.995\n",
      "f : 138387.203125, q : 111156.71875, p : -26971.3671875, l : 129.680892944\n",
      "batch 36, ep 150, training accuracy 0.995\n",
      "f : 126245.445312, q : 111083.125, p : -14993.2050781, l : 104.961021423\n",
      "valid accuracy 0.8694\n",
      "batch 37, ep 0, training accuracy 0.88\n",
      "f : 9674.98535156, q : 111037.664062, p : 102208.710938, l : 849.001525879\n",
      "batch 37, ep 50, training accuracy 0.995\n",
      "f : 137241.546875, q : 110737.453125, p : -26523.6484375, l : 91.911529541\n",
      "batch 37, ep 100, training accuracy 1\n",
      "f : 115568.453125, q : 110503.851562, p : -4858.2734375, l : 71.2910614014\n",
      "batch 37, ep 150, training accuracy 1\n",
      "f : 103262.335938, q : 110481.054688, p : 7205.44189453, l : 60.3767852783\n",
      "valid accuracy 0.8636\n",
      "batch 38, ep 0, training accuracy 0.78\n",
      "f : 10601.9550781, q : 110278.09375, p : 101603.289062, l : 1771.82299805\n",
      "batch 38, ep 50, training accuracy 0.995\n",
      "f : 123366.992188, q : 109945.570312, p : -13236.4082031, l : 146.823028564\n",
      "batch 38, ep 100, training accuracy 0.995\n",
      "f : 101387.226562, q : 109884.835938, p : 8682.76660156, l : 112.119338989\n",
      "batch 38, ep 150, training accuracy 1\n",
      "f : 89737.34375, q : 109743.929688, p : 20203.0859375, l : 93.1372756958\n",
      "valid accuracy 0.8639\n",
      "batch 39, ep 0, training accuracy 0.83\n",
      "f : 10223.5732422, q : 109707.5, p : 100806.703125, l : 1406.13500977\n",
      "batch 39, ep 50, training accuracy 0.995\n",
      "f : 94087.5859375, q : 109209.804688, p : 15298.7783203, l : 114.541488647\n",
      "batch 39, ep 100, training accuracy 1\n",
      "f : 71790.6484375, q : 109119.820312, p : 37326.5, l : 79.8889312744\n",
      "batch 39, ep 150, training accuracy 1\n",
      "f : 62262.2734375, q : 108988.234375, p : 46832.7148438, l : 63.1287994385\n",
      "valid accuracy 0.8679\n",
      "batch 40, ep 0, training accuracy 0.89\n",
      "f : 9624.28222656, q : 108871.953125, p : 100103.296875, l : 808.629882812\n",
      "batch 40, ep 50, training accuracy 0.995\n",
      "f : 58018.1679688, q : 108535.3125, p : 50665.9570312, l : 96.0211181641\n",
      "batch 40, ep 100, training accuracy 1\n",
      "f : 43475.0507812, q : 108457.640625, p : 65093.359375, l : 69.8210754395\n",
      "batch 40, ep 150, training accuracy 1\n",
      "f : 37649.8554688, q : 108498.210938, p : 70807.8984375, l : 57.4604949951\n",
      "valid accuracy 0.8659\n",
      "batch 41, ep 0, training accuracy 0.855\n",
      "f : 10074.3925781, q : 108336.875, p : 99578.71875, l : 1257.77880859\n",
      "batch 41, ep 50, training accuracy 0.965\n",
      "f : 50259.140625, q : 108086.992188, p : 58006.9609375, l : 243.475570679\n",
      "batch 41, ep 100, training accuracy 0.985\n",
      "f : 37875.1992188, q : 108079.71875, p : 70316.5, l : 179.08605957\n",
      "batch 41, ep 150, training accuracy 0.99\n",
      "f : 33028.5507812, q : 107945.882812, p : 75133.9453125, l : 142.777191162\n",
      "valid accuracy 0.8647\n",
      "batch 42, ep 0, training accuracy 0.9\n",
      "f : 9832.76464844, q : 107864.984375, p : 99065.71875, l : 1008.33349609\n",
      "batch 42, ep 50, training accuracy 0.96\n",
      "f : 40405.5195312, q : 107474.828125, p : 67260.5390625, l : 288.700836182\n",
      "batch 42, ep 100, training accuracy 0.975\n",
      "f : 30124.0917969, q : 107429.765625, p : 77662.7421875, l : 229.114044189\n",
      "batch 42, ep 150, training accuracy 0.98\n",
      "f : 26404.3027344, q : 107430.023438, p : 81204.7109375, l : 186.197021484\n",
      "valid accuracy 0.8583\n",
      "batch 43, ep 0, training accuracy 0.76\n",
      "f : 10981.1367188, q : 107296.984375, p : 98593.9921875, l : 2160.40283203\n",
      "batch 43, ep 50, training accuracy 0.915\n",
      "f : 36360.7890625, q : 106953.75, p : 71177.765625, l : 464.507720947\n",
      "batch 43, ep 100, training accuracy 0.965\n",
      "f : 29280.4648438, q : 106972.5625, p : 78003.046875, l : 338.977325439\n",
      "batch 43, ep 150, training accuracy 0.975\n",
      "f : 26907.8457031, q : 106984.179688, p : 80201.046875, l : 267.414428711\n",
      "valid accuracy 0.8458\n",
      "batch 44, ep 0, training accuracy 0.785\n",
      "f : 10681.203125, q : 106920.242188, p : 98038.421875, l : 1869.61376953\n",
      "batch 44, ep 50, training accuracy 0.945\n",
      "f : 38672.5742188, q : 106493.546875, p : 68170.1953125, l : 421.414306641\n",
      "batch 44, ep 100, training accuracy 0.97\n",
      "f : 35333.7304688, q : 106435.34375, p : 71141.609375, l : 216.189666748\n",
      "batch 44, ep 150, training accuracy 0.995\n",
      "f : 34445.7734375, q : 106326.476562, p : 71936.40625, l : 133.136322021\n",
      "valid accuracy 0.8453\n",
      "batch 45, ep 0, training accuracy 0.87\n",
      "f : 9667.05761719, q : 106393.328125, p : 97509.3671875, l : 856.809082031\n",
      "batch 45, ep 50, training accuracy 0.975\n",
      "f : 28390.7871094, q : 105979.976562, p : 77766.234375, l : 195.053436279\n",
      "batch 45, ep 100, training accuracy 0.99\n",
      "f : 26986.6074219, q : 105850.140625, p : 79201.890625, l : 138.893814087\n",
      "batch 45, ep 150, training accuracy 1\n",
      "f : 14572.3535156, q : 105876.554688, p : 91374.1484375, l : 111.226463318\n",
      "valid accuracy 0.8627\n",
      "batch 46, ep 0, training accuracy 0.87\n",
      "f : 9868.36425781, q : 105867.820312, p : 97094.703125, l : 1055.68359375\n",
      "batch 46, ep 50, training accuracy 0.875\n",
      "f : 25806.3828125, q : 105665.78125, p : 80562.140625, l : 752.377380371\n",
      "batch 46, ep 100, training accuracy 0.935\n",
      "f : 13538.3837891, q : 105637.09375, p : 92531.1171875, l : 428.865112305\n",
      "batch 46, ep 150, training accuracy 0.94\n",
      "f : 12442.9960938, q : 105674.828125, p : 93588.3046875, l : 389.378875732\n",
      "valid accuracy 0.8592\n",
      "batch 47, ep 0, training accuracy 0.84\n",
      "f : 10266.4882812, q : 105607.773438, p : 96800.921875, l : 1450.08666992\n",
      "batch 47, ep 50, training accuracy 0.91\n",
      "f : 25653.1210938, q : 105321.195312, p : 80193.6953125, l : 574.355102539\n",
      "batch 47, ep 100, training accuracy 0.95\n",
      "f : 24543.1289062, q : 105235.140625, p : 81067.7734375, l : 305.903900146\n",
      "batch 47, ep 150, training accuracy 0.975\n",
      "f : 14485.1191406, q : 105252.484375, p : 91014.203125, l : 215.161010742\n",
      "valid accuracy 0.8584\n",
      "batch 48, ep 0, training accuracy 0.865\n",
      "f : 9727.07617188, q : 105196.390625, p : 96528.796875, l : 901.010314941\n",
      "batch 48, ep 50, training accuracy 0.94\n",
      "f : 21518.3320312, q : 104916.164062, p : 83894.8671875, l : 445.609344482\n",
      "batch 48, ep 100, training accuracy 0.965\n",
      "f : 12667.0244141, q : 104878.890625, p : 92575.234375, l : 357.852294922\n",
      "batch 48, ep 150, training accuracy 0.97\n",
      "f : 11718.9189453, q : 104893.046875, p : 93518.1953125, l : 334.585662842\n",
      "valid accuracy 0.8502\n",
      "batch 49, ep 0, training accuracy 0.895\n",
      "f : 9649.75, q : 104877.601562, p : 96092.265625, l : 837.806152344\n",
      "batch 49, ep 50, training accuracy 0.95\n",
      "f : 19750.1367188, q : 104671.34375, p : 85295.28125, l : 401.597290039\n",
      "batch 49, ep 100, training accuracy 0.96\n",
      "f : 11856.5644531, q : 104712.34375, p : 93161.6171875, l : 330.17086792\n",
      "batch 49, ep 150, training accuracy 0.96\n",
      "f : 10936.2744141, q : 104574.265625, p : 94071.5703125, l : 305.906707764\n",
      "valid accuracy 0.8611\n",
      "batch 50, ep 0, training accuracy 0.905\n",
      "f : 9693.73242188, q : 104641.101562, p : 95814.5390625, l : 875.309143066\n",
      "batch 50, ep 50, training accuracy 0.92\n",
      "f : 19485.3457031, q : 104445.054688, p : 85409.8046875, l : 478.016845703\n",
      "batch 50, ep 100, training accuracy 0.93\n",
      "f : 11955.2675781, q : 104361.5625, p : 92754.8046875, l : 398.970062256\n",
      "batch 50, ep 150, training accuracy 0.93\n",
      "f : 10778.6416016, q : 104461.890625, p : 93977.609375, l : 379.85144043\n",
      "valid accuracy 0.8598\n",
      "batch 51, ep 0, training accuracy 0.825\n",
      "f : 10203.5673828, q : 104274.1875, p : 95521.9140625, l : 1384.78967285\n",
      "batch 51, ep 50, training accuracy 0.91\n",
      "f : 18949.2578125, q : 104045.304688, p : 85772.953125, l : 495.39666748\n",
      "batch 51, ep 100, training accuracy 0.96\n",
      "f : 11820.6064453, q : 104063.695312, p : 92606.8203125, l : 368.462036133\n",
      "batch 51, ep 150, training accuracy 0.965\n",
      "f : 10941.8837891, q : 104096.132812, p : 93528.3515625, l : 344.321166992\n",
      "valid accuracy 0.8571\n",
      "batch 52, ep 0, training accuracy 0.895\n",
      "f : 9459.79003906, q : 104030.84375, p : 95244.2265625, l : 643.715209961\n",
      "batch 52, ep 50, training accuracy 0.955\n",
      "f : 17119.375, q : 103761.273438, p : 86844.1875, l : 286.981079102\n",
      "batch 52, ep 100, training accuracy 0.95\n",
      "f : 10126.5996094, q : 103763.273438, p : 93826.5078125, l : 256.541931152\n",
      "batch 52, ep 150, training accuracy 0.955\n",
      "f : 9825.44042969, q : 103844.695312, p : 94325.609375, l : 248.450775146\n",
      "valid accuracy 0.8708\n",
      "batch 53, ep 0, training accuracy 0.835\n",
      "f : 10038.8818359, q : 103810.539062, p : 95021.3671875, l : 1224.47045898\n",
      "batch 53, ep 50, training accuracy 0.87\n",
      "f : 17416.6289062, q : 103540.476562, p : 86965.5, l : 869.852294922\n",
      "batch 53, ep 100, training accuracy 0.87\n",
      "f : 10752.0390625, q : 103507.710938, p : 93570.59375, l : 820.435913086\n",
      "batch 53, ep 150, training accuracy 0.88\n",
      "f : 10473.7695312, q : 103455.179688, p : 93890.328125, l : 805.69921875\n",
      "valid accuracy 0.8698\n",
      "batch 54, ep 0, training accuracy 0.89\n",
      "f : 9766.87988281, q : 103479.054688, p : 94748.53125, l : 954.096557617\n",
      "batch 54, ep 50, training accuracy 0.92\n",
      "f : 11407.3134766, q : 103327.328125, p : 92515.609375, l : 622.372558594\n",
      "batch 54, ep 100, training accuracy 0.93\n",
      "f : 10321.1220703, q : 103301.90625, p : 93539.6953125, l : 589.90246582\n",
      "batch 54, ep 150, training accuracy 0.93\n",
      "f : 10043.7568359, q : 103310.65625, p : 93842.578125, l : 580.35546875\n",
      "valid accuracy 0.8747\n",
      "batch 55, ep 0, training accuracy 0.9\n",
      "f : 9493.35644531, q : 103292.46875, p : 94468.40625, l : 673.58770752\n",
      "batch 55, ep 50, training accuracy 0.93\n",
      "f : 10747.5380859, q : 103072.828125, p : 92904.0859375, l : 518.191833496\n",
      "batch 55, ep 100, training accuracy 0.93\n",
      "f : 9965.4609375, q : 103102.8125, p : 93623.1953125, l : 503.534118652\n",
      "batch 55, ep 150, training accuracy 0.93\n",
      "f : 9708.07226562, q : 103077.4375, p : 93893.8359375, l : 503.002502441\n",
      "valid accuracy 0.8752\n",
      "batch 56, ep 0, training accuracy 0.88\n",
      "f : 9838.69335938, q : 103144.679688, p : 94331.90625, l : 1023.4942627\n",
      "batch 56, ep 50, training accuracy 0.885\n",
      "f : 16007.2568359, q : 102884.023438, p : 87841.5546875, l : 886.810974121\n",
      "batch 56, ep 100, training accuracy 0.895\n",
      "f : 10400.6464844, q : 102847.460938, p : 93318.53125, l : 853.512145996\n",
      "batch 56, ep 150, training accuracy 0.895\n",
      "f : 10105.6132812, q : 102854.40625, p : 93631.28125, l : 851.522705078\n",
      "valid accuracy 0.8721\n",
      "batch 57, ep 0, training accuracy 0.845\n",
      "f : 10228.3886719, q : 102866.5625, p : 94027.5859375, l : 1411.61535645\n",
      "batch 57, ep 50, training accuracy 0.875\n",
      "f : 15944.4550781, q : 102614.476562, p : 87641.390625, l : 878.567138672\n",
      "batch 57, ep 100, training accuracy 0.875\n",
      "f : 10513.0986328, q : 102633.140625, p : 92810.6796875, l : 836.318237305\n",
      "batch 57, ep 150, training accuracy 0.88\n",
      "f : 10274.2832031, q : 102506.390625, p : 93144.8046875, l : 826.323730469\n",
      "valid accuracy 0.8724\n",
      "batch 58, ep 0, training accuracy 0.88\n",
      "f : 10086.2578125, q : 102568.703125, p : 93875.984375, l : 1275.43457031\n",
      "batch 58, ep 50, training accuracy 0.885\n",
      "f : 15644.3535156, q : 102406.695312, p : 87748.6640625, l : 1072.18359375\n",
      "batch 58, ep 100, training accuracy 0.89\n",
      "f : 10503.7744141, q : 102357.195312, p : 92835.7421875, l : 1022.95812988\n",
      "batch 58, ep 150, training accuracy 0.89\n",
      "f : 10252.1328125, q : 102417.75, p : 93183.40625, l : 1015.86022949\n",
      "valid accuracy 0.8753\n",
      "batch 59, ep 0, training accuracy 0.89\n",
      "f : 9636.09179688, q : 102317.710938, p : 93511.6953125, l : 825.629150391\n",
      "batch 59, ep 50, training accuracy 0.905\n",
      "f : 10793.0869141, q : 102127.476562, p : 91998.0625, l : 716.514282227\n",
      "batch 59, ep 100, training accuracy 0.91\n",
      "f : 10088.3789062, q : 102118.703125, p : 92869.578125, l : 701.880493164\n",
      "batch 59, ep 150, training accuracy 0.91\n",
      "f : 9801.39355469, q : 102162.96875, p : 93042.4296875, l : 698.624572754\n",
      "valid accuracy 0.8735\n",
      "batch 60, ep 0, training accuracy 0.865\n",
      "f : 9642.53417969, q : 102092.921875, p : 93378.5078125, l : 826.567138672\n",
      "batch 60, ep 50, training accuracy 0.925\n",
      "f : 10757.3359375, q : 101972.578125, p : 91754.3046875, l : 606.606872559\n",
      "batch 60, ep 100, training accuracy 0.925\n",
      "f : 10051.5634766, q : 101944.757812, p : 92515.0546875, l : 585.075622559\n",
      "batch 60, ep 150, training accuracy 0.925\n",
      "f : 9777.87695312, q : 101969.9375, p : 92683.3984375, l : 581.065307617\n",
      "valid accuracy 0.8702\n",
      "batch 61, ep 0, training accuracy 0.855\n",
      "f : 10177.2792969, q : 101908.421875, p : 93064.2734375, l : 1368.26928711\n",
      "batch 61, ep 50, training accuracy 0.87\n",
      "f : 14996.5185547, q : 101718.34375, p : 87741.390625, l : 1052.84924316\n",
      "batch 61, ep 100, training accuracy 0.865\n",
      "f : 10440.8779297, q : 101684.570312, p : 92302.078125, l : 1029.33166504\n",
      "batch 61, ep 150, training accuracy 0.865\n",
      "f : 10205.6269531, q : 101689.46875, p : 92563.109375, l : 1021.14306641\n",
      "valid accuracy 0.8705\n",
      "batch 62, ep 0, training accuracy 0.825\n",
      "f : 10255.0166016, q : 101694.835938, p : 92872.375, l : 1459.20288086\n",
      "batch 62, ep 50, training accuracy 0.835\n",
      "f : 11217.2705078, q : 101583.890625, p : 91482.53125, l : 1138.15454102\n",
      "batch 62, ep 100, training accuracy 0.84\n",
      "f : 10533.0214844, q : 101536.648438, p : 92078.625, l : 1118.58569336\n",
      "batch 62, ep 150, training accuracy 0.835\n",
      "f : 10288.265625, q : 101464.492188, p : 92318.0703125, l : 1107.31542969\n",
      "valid accuracy 0.8786\n",
      "batch 63, ep 0, training accuracy 0.835\n",
      "f : 10211.3447266, q : 101529.132812, p : 92659.3515625, l : 1395.99230957\n",
      "batch 63, ep 50, training accuracy 0.85\n",
      "f : 11149.6826172, q : 101453.484375, p : 91395.3359375, l : 1181.8737793\n",
      "batch 63, ep 100, training accuracy 0.855\n",
      "f : 10496.2236328, q : 101440.46875, p : 92089.9609375, l : 1156.80688477\n",
      "batch 63, ep 150, training accuracy 0.855\n",
      "f : 10256.4199219, q : 101396.789062, p : 92200.6953125, l : 1145.10424805\n",
      "valid accuracy 0.8792\n",
      "batch 64, ep 0, training accuracy 0.83\n",
      "f : 9897.59179688, q : 101325.804688, p : 92522.140625, l : 1093.55932617\n",
      "batch 64, ep 50, training accuracy 0.84\n",
      "f : 14281.9599609, q : 101154.507812, p : 87856.359375, l : 936.829467773\n",
      "batch 64, ep 100, training accuracy 0.84\n",
      "f : 10229.2734375, q : 101192.820312, p : 91929.59375, l : 930.310241699\n",
      "batch 64, ep 150, training accuracy 0.845\n",
      "f : 10006.8544922, q : 101177.109375, p : 92144.7890625, l : 925.199401855\n",
      "valid accuracy 0.8774\n",
      "batch 65, ep 0, training accuracy 0.75\n",
      "f : 10694.7802734, q : 101190.757812, p : 92438.8359375, l : 1892.38110352\n",
      "batch 65, ep 50, training accuracy 0.805\n",
      "f : 14879.6513672, q : 101121.179688, p : 87600.546875, l : 1460.70593262\n",
      "batch 65, ep 100, training accuracy 0.83\n",
      "f : 11542.4365234, q : 100983.390625, p : 91037.3359375, l : 1379.23339844\n",
      "batch 65, ep 150, training accuracy 0.835\n",
      "f : 10847.9199219, q : 101119.585938, p : 91632.4375, l : 1362.30969238\n",
      "valid accuracy 0.8802\n",
      "batch 66, ep 0, training accuracy 0.905\n",
      "f : 9646.21582031, q : 101060.046875, p : 92249.4921875, l : 838.525024414\n",
      "batch 66, ep 50, training accuracy 0.91\n",
      "f : 10660.9951172, q : 100877.460938, p : 90993.46875, l : 763.980163574\n",
      "batch 66, ep 100, training accuracy 0.91\n",
      "f : 10033.8603516, q : 100894.796875, p : 91569.9921875, l : 756.08795166\n",
      "batch 66, ep 150, training accuracy 0.91\n",
      "f : 9811.25488281, q : 100997.085938, p : 91830.2109375, l : 760.272094727\n",
      "valid accuracy 0.8791\n",
      "batch 67, ep 0, training accuracy 0.9\n",
      "f : 9562.84765625, q : 100940.070312, p : 92073.453125, l : 753.702209473\n",
      "batch 67, ep 50, training accuracy 0.905\n",
      "f : 10558.5175781, q : 100752.78125, p : 90895.7890625, l : 676.979003906\n",
      "batch 67, ep 100, training accuracy 0.91\n",
      "f : 9914.89160156, q : 100742.046875, p : 91460.90625, l : 665.870239258\n",
      "batch 67, ep 150, training accuracy 0.905\n",
      "f : 9614.29882812, q : 100634.625, p : 91713.46875, l : 666.919616699\n",
      "valid accuracy 0.8815\n",
      "batch 68, ep 0, training accuracy 0.835\n",
      "f : 10005.5820312, q : 100729.71875, p : 91910.5390625, l : 1198.95629883\n",
      "batch 68, ep 50, training accuracy 0.87\n",
      "f : 10969.4453125, q : 100542.203125, p : 90600.296875, l : 1030.41015625\n",
      "batch 68, ep 100, training accuracy 0.87\n",
      "f : 10305.7324219, q : 100557.3125, p : 91284.984375, l : 1015.12524414\n",
      "batch 68, ep 150, training accuracy 0.87\n",
      "f : 10089.3291016, q : 100485.75, p : 91382.6953125, l : 1005.40863037\n",
      "valid accuracy 0.8777\n",
      "batch 69, ep 0, training accuracy 0.83\n",
      "f : 10027.2050781, q : 100548.195312, p : 91709.1328125, l : 1221.41357422\n",
      "batch 69, ep 50, training accuracy 0.87\n",
      "f : 11273.5439453, q : 100415.351562, p : 90161.7109375, l : 1032.53833008\n",
      "batch 69, ep 100, training accuracy 0.885\n",
      "f : 10307.1044922, q : 100450.132812, p : 91128.8359375, l : 1024.05285645\n",
      "batch 69, ep 150, training accuracy 0.885\n",
      "f : 10109.4677734, q : 100352.429688, p : 91268.21875, l : 1016.00775146\n",
      "valid accuracy 0.8779\n",
      "batch 70, ep 0, training accuracy 0.825\n",
      "f : 10135.7265625, q : 100441.992188, p : 91671.4375, l : 1333.36413574\n",
      "batch 70, ep 50, training accuracy 0.86\n",
      "f : 13825.2060547, q : 100267.757812, p : 87458.84375, l : 984.54498291\n",
      "batch 70, ep 100, training accuracy 0.86\n",
      "f : 10343.5722656, q : 100238.15625, p : 90908.2109375, l : 969.770263672\n",
      "batch 70, ep 150, training accuracy 0.87\n",
      "f : 10102.6103516, q : 100267.078125, p : 91062.28125, l : 962.093322754\n",
      "valid accuracy 0.8752\n",
      "batch 71, ep 0, training accuracy 0.82\n",
      "f : 10284.8789062, q : 100237.382812, p : 91609.53125, l : 1472.20117188\n",
      "batch 71, ep 50, training accuracy 0.835\n",
      "f : 11037.9492188, q : 100182.085938, p : 90244.0625, l : 1111.7121582\n",
      "batch 71, ep 100, training accuracy 0.84\n",
      "f : 10410.7578125, q : 100144.460938, p : 90708.3984375, l : 1093.94592285\n",
      "batch 71, ep 150, training accuracy 0.835\n",
      "f : 10189.8671875, q : 100114.9375, p : 91058.7421875, l : 1080.88256836\n",
      "valid accuracy 0.8756\n",
      "batch 72, ep 0, training accuracy 0.855\n",
      "f : 9646.47070312, q : 100204.804688, p : 91387.703125, l : 856.077880859\n",
      "batch 72, ep 50, training accuracy 0.87\n",
      "f : 10533.3349609, q : 100021.359375, p : 90099.25, l : 624.204711914\n",
      "batch 72, ep 100, training accuracy 0.88\n",
      "f : 9966.54589844, q : 100092.914062, p : 90615.6640625, l : 619.405883789\n",
      "batch 72, ep 150, training accuracy 0.88\n",
      "f : 9691.31640625, q : 100009.484375, p : 90952.9921875, l : 614.689453125\n",
      "valid accuracy 0.8814\n",
      "batch 73, ep 0, training accuracy 0.775\n",
      "f : 10428.6777344, q : 99985.03125, p : 91115.7734375, l : 1623.05310059\n",
      "batch 73, ep 50, training accuracy 0.815\n",
      "f : 11256.1289062, q : 99823.3046875, p : 89901.75, l : 1302.00549316\n",
      "batch 73, ep 100, training accuracy 0.825\n",
      "f : 10626.4628906, q : 99778.0703125, p : 90531.28125, l : 1272.2019043\n",
      "batch 73, ep 150, training accuracy 0.835\n",
      "f : 10404.7958984, q : 99860.890625, p : 90762.6953125, l : 1263.12145996\n",
      "valid accuracy 0.873\n",
      "batch 74, ep 0, training accuracy 0.845\n",
      "f : 9783.27441406, q : 99809.390625, p : 90968.234375, l : 981.671203613\n",
      "batch 74, ep 50, training accuracy 0.91\n",
      "f : 10917.8964844, q : 99642.6484375, p : 89433.6484375, l : 704.669799805\n",
      "batch 74, ep 100, training accuracy 0.91\n",
      "f : 10010.3125, q : 99654.3984375, p : 90380.6796875, l : 697.61541748\n",
      "batch 74, ep 150, training accuracy 0.91\n",
      "f : 9746.86816406, q : 99646.0234375, p : 90600.1640625, l : 695.831542969\n",
      "valid accuracy 0.8816\n",
      "batch 75, ep 0, training accuracy 0.88\n",
      "f : 9719.41113281, q : 99675.7734375, p : 90807.6796875, l : 924.060119629\n",
      "batch 75, ep 50, training accuracy 0.89\n",
      "f : 10635.6132812, q : 99537.28125, p : 89732.4453125, l : 815.453735352\n",
      "batch 75, ep 100, training accuracy 0.89\n",
      "f : 10050.0732422, q : 99460.3125, p : 90302.8515625, l : 820.428710938\n",
      "batch 75, ep 150, training accuracy 0.885\n",
      "f : 9849.27148438, q : 99552.0078125, p : 90378.4375, l : 822.291809082\n",
      "valid accuracy 0.8821\n",
      "batch 76, ep 0, training accuracy 0.89\n",
      "f : 9780.93652344, q : 99561.9296875, p : 90739.5703125, l : 980.202636719\n",
      "batch 76, ep 50, training accuracy 0.905\n",
      "f : 10713.2294922, q : 99318.546875, p : 89567.8203125, l : 888.042663574\n",
      "batch 76, ep 100, training accuracy 0.9\n",
      "f : 10103.6933594, q : 99375.390625, p : 90237.7890625, l : 899.739990234\n",
      "batch 76, ep 150, training accuracy 0.905\n",
      "f : 9911.20410156, q : 99310.609375, p : 90353.0, l : 889.473999023\n",
      "valid accuracy 0.8817\n",
      "batch 77, ep 0, training accuracy 0.885\n",
      "f : 9780.94726562, q : 99279.8125, p : 90531.7109375, l : 977.407104492\n",
      "batch 77, ep 50, training accuracy 0.9\n",
      "f : 10649.7099609, q : 99302.625, p : 89364.8125, l : 874.989440918\n",
      "batch 77, ep 100, training accuracy 0.89\n",
      "f : 10101.6933594, q : 99194.640625, p : 89947.40625, l : 873.12097168\n",
      "batch 77, ep 150, training accuracy 0.89\n",
      "f : 9908.70703125, q : 99225.734375, p : 90170.1875, l : 867.182861328\n",
      "valid accuracy 0.8836\n",
      "batch 78, ep 0, training accuracy 0.835\n",
      "f : 10067.9902344, q : 99223.34375, p : 90462.546875, l : 1253.45544434\n",
      "batch 78, ep 50, training accuracy 0.855\n",
      "f : 10849.2460938, q : 99041.6484375, p : 89316.203125, l : 1079.43188477\n",
      "batch 78, ep 100, training accuracy 0.855\n",
      "f : 10321.1582031, q : 99144.484375, p : 89850.75, l : 1075.00366211\n",
      "batch 78, ep 150, training accuracy 0.855\n",
      "f : 10105.2001953, q : 99053.0625, p : 90090.0, l : 1073.03295898\n",
      "valid accuracy 0.8826\n",
      "batch 79, ep 0, training accuracy 0.82\n",
      "f : 10400.6367188, q : 99066.3046875, p : 90210.2421875, l : 1595.53100586\n",
      "batch 79, ep 50, training accuracy 0.81\n",
      "f : 13448.2226562, q : 98927.6328125, p : 86786.8125, l : 1355.59521484\n",
      "batch 79, ep 100, training accuracy 0.825\n",
      "f : 10624.5869141, q : 98905.1640625, p : 89634.8828125, l : 1350.90405273\n",
      "batch 79, ep 150, training accuracy 0.82\n",
      "f : 10431.3720703, q : 98982.9609375, p : 89909.578125, l : 1338.38378906\n",
      "valid accuracy 0.8762\n",
      "batch 80, ep 0, training accuracy 0.865\n",
      "f : 10006.6005859, q : 98920.3203125, p : 90095.90625, l : 1192.82397461\n",
      "batch 80, ep 50, training accuracy 0.87\n",
      "f : 10827.0615234, q : 98794.375, p : 89021.03125, l : 1015.3180542\n",
      "batch 80, ep 100, training accuracy 0.875\n",
      "f : 10287.8515625, q : 98791.9921875, p : 89482.640625, l : 1011.90795898\n",
      "batch 80, ep 150, training accuracy 0.875\n",
      "f : 10039.9130859, q : 98826.3515625, p : 89781.328125, l : 1008.83935547\n",
      "valid accuracy 0.8804\n",
      "batch 81, ep 0, training accuracy 0.91\n",
      "f : 9500.421875, q : 98798.78125, p : 89983.2109375, l : 690.128417969\n",
      "batch 81, ep 50, training accuracy 0.925\n",
      "f : 10342.1748047, q : 98749.328125, p : 88991.828125, l : 608.895812988\n",
      "batch 81, ep 100, training accuracy 0.915\n",
      "f : 9815.65234375, q : 98704.9375, p : 89483.609375, l : 608.647216797\n",
      "batch 81, ep 150, training accuracy 0.925\n",
      "f : 9607.46679688, q : 98700.0546875, p : 89695.3359375, l : 617.613464355\n",
      "valid accuracy 0.8812\n",
      "batch 82, ep 0, training accuracy 0.88\n",
      "f : 9801.64941406, q : 98726.6328125, p : 89978.5703125, l : 982.553894043\n",
      "batch 82, ep 50, training accuracy 0.88\n",
      "f : 10607.4277344, q : 98545.1796875, p : 88874.375, l : 899.298950195\n",
      "batch 82, ep 100, training accuracy 0.88\n",
      "f : 10096.4384766, q : 98526.171875, p : 89436.9609375, l : 897.85559082\n",
      "batch 82, ep 150, training accuracy 0.88\n",
      "f : 9909.50097656, q : 98544.8671875, p : 89585.6328125, l : 901.556518555\n",
      "valid accuracy 0.8822\n",
      "batch 83, ep 0, training accuracy 0.815\n",
      "f : 9916.16699219, q : 98573.375, p : 89774.3671875, l : 1108.97094727\n",
      "batch 83, ep 50, training accuracy 0.835\n",
      "f : 10661.0761719, q : 98449.2890625, p : 88729.5625, l : 929.033569336\n",
      "batch 83, ep 100, training accuracy 0.84\n",
      "f : 10158.2460938, q : 98516.0234375, p : 89269.0, l : 933.424194336\n",
      "batch 83, ep 150, training accuracy 0.835\n",
      "f : 9923.01855469, q : 98489.4140625, p : 89452.4765625, l : 919.990539551\n",
      "valid accuracy 0.8844\n",
      "batch 84, ep 0, training accuracy 0.83\n",
      "f : 9943.8828125, q : 98422.4921875, p : 89670.265625, l : 1147.64746094\n",
      "batch 84, ep 50, training accuracy 0.87\n",
      "f : 10679.3876953, q : 98360.828125, p : 88538.1953125, l : 845.25793457\n",
      "batch 84, ep 100, training accuracy 0.875\n",
      "f : 10134.0107422, q : 98474.3828125, p : 89023.8671875, l : 817.169311523\n",
      "batch 84, ep 150, training accuracy 0.86\n",
      "f : 9935.69628906, q : 98342.2109375, p : 89208.1328125, l : 813.828857422\n",
      "valid accuracy 0.8823\n",
      "batch 85, ep 0, training accuracy 0.85\n",
      "f : 9878.87695312, q : 98344.515625, p : 89551.0234375, l : 1070.44799805\n",
      "batch 85, ep 50, training accuracy 0.865\n",
      "f : 10646.4794922, q : 98266.390625, p : 88437.734375, l : 948.212280273\n",
      "batch 85, ep 100, training accuracy 0.855\n",
      "f : 10165.3095703, q : 98211.765625, p : 89047.6484375, l : 946.403442383\n",
      "batch 85, ep 150, training accuracy 0.865\n",
      "f : 9966.06835938, q : 98264.15625, p : 89214.0625, l : 935.504150391\n",
      "valid accuracy 0.8851\n",
      "batch 86, ep 0, training accuracy 0.91\n",
      "f : 9485.04492188, q : 98204.609375, p : 89363.2421875, l : 679.169677734\n",
      "batch 86, ep 50, training accuracy 0.925\n",
      "f : 10296.1796875, q : 98108.6953125, p : 88390.109375, l : 610.499267578\n",
      "batch 86, ep 100, training accuracy 0.925\n",
      "f : 9789.80957031, q : 98188.921875, p : 88962.1640625, l : 605.112304688\n",
      "batch 86, ep 150, training accuracy 0.925\n",
      "f : 9541.68652344, q : 98193.0078125, p : 89226.1640625, l : 604.957641602\n",
      "valid accuracy 0.8865\n",
      "batch 87, ep 0, training accuracy 0.83\n",
      "f : 9963.27929688, q : 98223.3828125, p : 89383.8203125, l : 1155.31030273\n",
      "batch 87, ep 50, training accuracy 0.87\n",
      "f : 10712.5498047, q : 97947.375, p : 88271.4140625, l : 958.950927734\n",
      "batch 87, ep 100, training accuracy 0.87\n",
      "f : 10210.3125, q : 98054.7265625, p : 88725.7109375, l : 949.572631836\n",
      "batch 87, ep 150, training accuracy 0.865\n",
      "f : 10022.8652344, q : 98092.8046875, p : 88909.828125, l : 942.089111328\n",
      "valid accuracy 0.887\n",
      "batch 88, ep 0, training accuracy 0.8\n",
      "f : 10074.7050781, q : 98084.0234375, p : 89224.1875, l : 1262.11157227\n",
      "batch 88, ep 50, training accuracy 0.83\n",
      "f : 10787.3398438, q : 97933.9765625, p : 88225.1875, l : 1087.74743652\n",
      "batch 88, ep 100, training accuracy 0.825\n",
      "f : 10295.5087891, q : 97957.296875, p : 88818.046875, l : 1088.21313477\n",
      "batch 88, ep 150, training accuracy 0.835\n",
      "f : 10107.2822266, q : 97927.75, p : 88883.4375, l : 1084.50891113\n",
      "valid accuracy 0.8862\n",
      "batch 89, ep 0, training accuracy 0.865\n",
      "f : 9882.12304688, q : 98035.6875, p : 89122.1875, l : 1077.74353027\n",
      "batch 89, ep 50, training accuracy 0.88\n",
      "f : 10611.4052734, q : 97853.5859375, p : 88203.703125, l : 949.55065918\n",
      "batch 89, ep 100, training accuracy 0.875\n",
      "f : 10148.1796875, q : 97865.1796875, p : 88616.1171875, l : 955.070922852\n",
      "batch 89, ep 150, training accuracy 0.875\n",
      "f : 9937.32617188, q : 97811.3359375, p : 88874.9296875, l : 961.741333008\n",
      "valid accuracy 0.8852\n",
      "batch 90, ep 0, training accuracy 0.905\n",
      "f : 9505.64941406, q : 97927.4453125, p : 89050.3125, l : 700.424438477\n",
      "batch 90, ep 50, training accuracy 0.9\n",
      "f : 12162.0, q : 97833.0390625, p : 86107.0, l : 556.645202637\n",
      "batch 90, ep 100, training accuracy 0.905\n",
      "f : 9758.60644531, q : 97767.578125, p : 88483.046875, l : 540.044921875\n",
      "batch 90, ep 150, training accuracy 0.905\n",
      "f : 9568.41992188, q : 97771.515625, p : 88699.96875, l : 533.30279541\n",
      "valid accuracy 0.8827\n",
      "batch 91, ep 0, training accuracy 0.905\n",
      "f : 9513.98828125, q : 97805.4765625, p : 88951.1328125, l : 708.4609375\n",
      "batch 91, ep 50, training accuracy 0.915\n",
      "f : 10277.4121094, q : 97705.3359375, p : 88027.5625, l : 611.572631836\n",
      "batch 91, ep 100, training accuracy 0.91\n",
      "f : 9773.40039062, q : 97679.078125, p : 88484.8046875, l : 601.196777344\n",
      "batch 91, ep 150, training accuracy 0.915\n",
      "f : 9604.64746094, q : 97611.8046875, p : 88661.5703125, l : 596.140075684\n",
      "valid accuracy 0.8852\n",
      "batch 92, ep 0, training accuracy 0.85\n",
      "f : 10047.4199219, q : 97622.703125, p : 88824.7109375, l : 1244.0612793\n",
      "batch 92, ep 50, training accuracy 0.875\n",
      "f : 10806.1699219, q : 97664.1953125, p : 87829.9453125, l : 1055.20361328\n",
      "batch 92, ep 100, training accuracy 0.875\n",
      "f : 10260.1171875, q : 97549.125, p : 88351.0390625, l : 1043.11645508\n",
      "batch 92, ep 150, training accuracy 0.88\n",
      "f : 10064.4609375, q : 97476.5703125, p : 88587.78125, l : 1038.16174316\n",
      "valid accuracy 0.8879\n",
      "batch 93, ep 0, training accuracy 0.905\n",
      "f : 9583.75585938, q : 97547.6875, p : 88700.4140625, l : 778.371520996\n",
      "batch 93, ep 50, training accuracy 0.91\n",
      "f : 10316.1591797, q : 97565.1171875, p : 87842.5234375, l : 685.44519043\n",
      "batch 93, ep 100, training accuracy 0.915\n",
      "f : 9747.66308594, q : 97612.3671875, p : 88501.9296875, l : 684.846679688\n",
      "batch 93, ep 150, training accuracy 0.915\n",
      "f : 9615.43359375, q : 97582.453125, p : 88509.8984375, l : 679.35559082\n",
      "valid accuracy 0.8893\n",
      "batch 94, ep 0, training accuracy 0.89\n",
      "f : 9475.84570312, q : 97418.1640625, p : 88694.5, l : 676.93371582\n",
      "batch 94, ep 50, training accuracy 0.9\n",
      "f : 10213.2119141, q : 97412.3125, p : 87719.375, l : 550.877380371\n",
      "batch 94, ep 100, training accuracy 0.91\n",
      "f : 9726.72363281, q : 97484.46875, p : 88257.859375, l : 543.004882812\n",
      "batch 94, ep 150, training accuracy 0.91\n",
      "f : 9532.36816406, q : 97447.0, p : 88373.3203125, l : 547.97088623\n",
      "valid accuracy 0.8886\n",
      "batch 95, ep 0, training accuracy 0.85\n",
      "f : 9844.65527344, q : 97464.7421875, p : 88581.84375, l : 1039.90234375\n",
      "batch 95, ep 50, training accuracy 0.865\n",
      "f : 12265.1191406, q : 97331.78125, p : 85818.1015625, l : 764.707885742\n",
      "batch 95, ep 100, training accuracy 0.855\n",
      "f : 9993.24902344, q : 97322.5703125, p : 88042.4921875, l : 753.307678223\n",
      "batch 95, ep 150, training accuracy 0.86\n",
      "f : 9821.68164062, q : 97246.25, p : 88301.328125, l : 745.929260254\n",
      "valid accuracy 0.8873\n",
      "batch 96, ep 0, training accuracy 0.875\n",
      "f : 9707.60839844, q : 97310.21875, p : 88483.2265625, l : 901.891845703\n",
      "batch 96, ep 50, training accuracy 0.915\n",
      "f : 12096.8818359, q : 97343.5234375, p : 85837.2421875, l : 710.55847168\n",
      "batch 96, ep 100, training accuracy 0.91\n",
      "f : 9901.89550781, q : 97287.1875, p : 87988.46875, l : 687.223876953\n",
      "batch 96, ep 150, training accuracy 0.905\n",
      "f : 9709.08984375, q : 97254.9765625, p : 88226.78125, l : 682.774414062\n",
      "valid accuracy 0.8921\n",
      "batch 97, ep 0, training accuracy 0.87\n",
      "f : 9679.83203125, q : 97227.6484375, p : 88436.890625, l : 868.206542969\n",
      "batch 97, ep 50, training accuracy 0.905\n",
      "f : 10369.9970703, q : 97133.96875, p : 87591.4375, l : 714.252807617\n",
      "batch 97, ep 100, training accuracy 0.9\n",
      "f : 9912.39746094, q : 97168.9453125, p : 87943.8828125, l : 712.309875488\n",
      "batch 97, ep 150, training accuracy 0.91\n",
      "f : 9725.27148438, q : 97141.125, p : 88096.2578125, l : 710.984680176\n",
      "valid accuracy 0.8915\n",
      "batch 98, ep 0, training accuracy 0.93\n",
      "f : 9209.83007812, q : 97128.1875, p : 88373.4375, l : 407.10534668\n",
      "batch 98, ep 50, training accuracy 0.95\n",
      "f : 9937.87207031, q : 97145.171875, p : 87568.3828125, l : 350.699401855\n",
      "batch 98, ep 100, training accuracy 0.955\n",
      "f : 9503.23730469, q : 97136.6171875, p : 87984.4609375, l : 355.204589844\n",
      "batch 98, ep 150, training accuracy 0.945\n",
      "f : 9269.03808594, q : 97083.296875, p : 88245.578125, l : 350.511779785\n",
      "valid accuracy 0.892\n",
      "batch 99, ep 0, training accuracy 0.815\n",
      "f : 10001.0585938, q : 97167.2734375, p : 88302.46875, l : 1195.72900391\n",
      "batch 99, ep 50, training accuracy 0.86\n",
      "f : 10609.6318359, q : 97021.390625, p : 87279.2109375, l : 924.745544434\n",
      "batch 99, ep 100, training accuracy 0.855\n",
      "f : 10163.03125, q : 97018.390625, p : 87748.5625, l : 914.887573242\n",
      "batch 99, ep 150, training accuracy 0.86\n",
      "f : 9985.18359375, q : 97077.5703125, p : 87915.1640625, l : 904.795471191\n",
      "valid accuracy 0.8912\n",
      "batch 100, ep 0, training accuracy 0.84\n",
      "f : 9928.47265625, q : 97040.640625, p : 88221.8515625, l : 1119.35546875\n",
      "batch 100, ep 50, training accuracy 0.86\n",
      "f : 10621.6152344, q : 96918.5703125, p : 87329.4765625, l : 906.953491211\n",
      "batch 100, ep 100, training accuracy 0.865\n",
      "f : 10158.7548828, q : 96899.7109375, p : 87725.1328125, l : 900.575683594\n",
      "batch 100, ep 150, training accuracy 0.86\n",
      "f : 9965.53613281, q : 96931.515625, p : 87912.15625, l : 902.248413086\n",
      "valid accuracy 0.894\n",
      "batch 101, ep 0, training accuracy 0.88\n",
      "f : 9534.13476562, q : 96994.359375, p : 88079.7109375, l : 733.635375977\n",
      "batch 101, ep 50, training accuracy 0.915\n",
      "f : 10195.8193359, q : 96907.3359375, p : 87245.40625, l : 590.58404541\n",
      "batch 101, ep 100, training accuracy 0.91\n",
      "f : 9777.0859375, q : 96968.3671875, p : 87751.953125, l : 583.067260742\n",
      "batch 101, ep 150, training accuracy 0.91\n",
      "f : 9589.1640625, q : 96925.6875, p : 87859.1953125, l : 581.213867188\n",
      "valid accuracy 0.8919\n",
      "batch 102, ep 0, training accuracy 0.905\n",
      "f : 9484.92089844, q : 96841.9296875, p : 88123.1875, l : 685.693603516\n",
      "batch 102, ep 50, training accuracy 0.92\n",
      "f : 10196.03125, q : 96823.515625, p : 87287.7734375, l : 625.861999512\n",
      "batch 102, ep 100, training accuracy 0.92\n",
      "f : 9732.24902344, q : 96839.5859375, p : 87707.78125, l : 626.56652832\n",
      "batch 102, ep 150, training accuracy 0.92\n",
      "f : 9533.35839844, q : 96897.0390625, p : 87905.5078125, l : 624.320861816\n",
      "valid accuracy 0.8912\n",
      "batch 103, ep 0, training accuracy 0.875\n",
      "f : 9914.58398438, q : 96827.4921875, p : 88089.9375, l : 1115.45178223\n",
      "batch 103, ep 50, training accuracy 0.875\n",
      "f : 10604.7021484, q : 96730.53125, p : 87116.6640625, l : 956.661804199\n",
      "batch 103, ep 100, training accuracy 0.875\n",
      "f : 10158.3525391, q : 96763.171875, p : 87565.671875, l : 955.512939453\n",
      "batch 103, ep 150, training accuracy 0.87\n",
      "f : 9988.30078125, q : 96821.765625, p : 87689.15625, l : 953.63269043\n",
      "valid accuracy 0.892\n",
      "batch 104, ep 0, training accuracy 0.825\n",
      "f : 9960.60449219, q : 96784.0546875, p : 87976.0234375, l : 1142.21240234\n",
      "batch 104, ep 50, training accuracy 0.86\n",
      "f : 10588.4306641, q : 96773.4609375, p : 86960.0859375, l : 938.585510254\n",
      "batch 104, ep 100, training accuracy 0.865\n",
      "f : 10134.4316406, q : 96732.4375, p : 87540.6953125, l : 931.805908203\n",
      "batch 104, ep 150, training accuracy 0.865\n",
      "f : 9979.43164062, q : 96741.0078125, p : 87713.0625, l : 929.43560791\n",
      "valid accuracy 0.89\n",
      "batch 105, ep 0, training accuracy 0.905\n",
      "f : 9442.50585938, q : 96717.6484375, p : 87951.6328125, l : 647.683410645\n",
      "batch 105, ep 50, training accuracy 0.915\n",
      "f : 10161.8085938, q : 96621.40625, p : 87076.796875, l : 564.897705078\n",
      "batch 105, ep 100, training accuracy 0.915\n",
      "f : 9712.76464844, q : 96654.3671875, p : 87528.6484375, l : 567.224243164\n",
      "batch 105, ep 150, training accuracy 0.915\n",
      "f : 9546.84277344, q : 96602.21875, p : 87645.515625, l : 562.745056152\n",
      "valid accuracy 0.8908\n",
      "batch 106, ep 0, training accuracy 0.88\n",
      "f : 9689.43261719, q : 96719.6484375, p : 87864.359375, l : 889.13848877\n",
      "batch 106, ep 50, training accuracy 0.885\n",
      "f : 10368.34375, q : 96568.65625, p : 86923.15625, l : 752.564086914\n",
      "batch 106, ep 100, training accuracy 0.885\n",
      "f : 9924.7890625, q : 96654.265625, p : 87397.7890625, l : 747.864868164\n",
      "batch 106, ep 150, training accuracy 0.885\n",
      "f : 9754.40136719, q : 96542.1640625, p : 87645.3125, l : 752.350708008\n",
      "valid accuracy 0.8913\n",
      "batch 107, ep 0, training accuracy 0.88\n",
      "f : 9651.31640625, q : 96532.0703125, p : 87719.3046875, l : 849.062072754\n",
      "batch 107, ep 50, training accuracy 0.89\n",
      "f : 11886.4335938, q : 96396.0625, p : 85330.5546875, l : 706.686767578\n",
      "batch 107, ep 100, training accuracy 0.895\n",
      "f : 9870.54980469, q : 96508.140625, p : 87334.4765625, l : 699.030944824\n",
      "batch 107, ep 150, training accuracy 0.89\n",
      "f : 9707.75683594, q : 96466.5703125, p : 87469.453125, l : 704.243164062\n",
      "valid accuracy 0.8892\n",
      "batch 108, ep 0, training accuracy 0.905\n",
      "f : 9465.41894531, q : 96446.8671875, p : 87642.765625, l : 664.720825195\n",
      "batch 108, ep 50, training accuracy 0.92\n",
      "f : 10128.8730469, q : 96375.3046875, p : 86828.8203125, l : 558.038635254\n",
      "batch 108, ep 100, training accuracy 0.92\n",
      "f : 9743.37207031, q : 96344.7734375, p : 87280.7578125, l : 561.840148926\n",
      "batch 108, ep 150, training accuracy 0.92\n",
      "f : 9514.65429688, q : 96342.078125, p : 87531.078125, l : 557.809387207\n",
      "valid accuracy 0.8907\n",
      "batch 109, ep 0, training accuracy 0.895\n",
      "f : 9538.23144531, q : 96455.859375, p : 87669.234375, l : 732.375671387\n",
      "batch 109, ep 50, training accuracy 0.925\n",
      "f : 10218.4277344, q : 96368.4609375, p : 86850.921875, l : 642.065307617\n",
      "batch 109, ep 100, training accuracy 0.925\n",
      "f : 9778.54296875, q : 96367.7109375, p : 87217.875, l : 640.510681152\n",
      "batch 109, ep 150, training accuracy 0.925\n",
      "f : 9604.58203125, q : 96350.1171875, p : 87400.9375, l : 637.344909668\n",
      "valid accuracy 0.8897\n",
      "batch 110, ep 0, training accuracy 0.895\n",
      "f : 9435.57324219, q : 96293.03125, p : 87518.5546875, l : 639.938476562\n",
      "batch 110, ep 50, training accuracy 0.9\n",
      "f : 10124.890625, q : 96385.8671875, p : 86665.609375, l : 540.087219238\n",
      "batch 110, ep 100, training accuracy 0.895\n",
      "f : 9698.33984375, q : 96345.796875, p : 87145.8046875, l : 533.48638916\n",
      "batch 110, ep 150, training accuracy 0.895\n",
      "f : 9478.06347656, q : 96252.5703125, p : 87356.7734375, l : 541.058105469\n",
      "valid accuracy 0.8922\n",
      "batch 111, ep 0, training accuracy 0.895\n",
      "f : 9623.04296875, q : 96228.4921875, p : 87424.5625, l : 810.65625\n",
      "batch 111, ep 50, training accuracy 0.91\n",
      "f : 10266.921875, q : 96276.78125, p : 86665.78125, l : 711.957214355\n",
      "batch 111, ep 100, training accuracy 0.91\n",
      "f : 9871.18164062, q : 96223.0234375, p : 87099.921875, l : 708.630615234\n",
      "batch 111, ep 150, training accuracy 0.905\n",
      "f : 9655.88183594, q : 96228.859375, p : 87229.8671875, l : 710.102416992\n",
      "valid accuracy 0.893\n",
      "batch 112, ep 0, training accuracy 0.825\n",
      "f : 10267.8222656, q : 96243.5078125, p : 87379.96875, l : 1473.85266113\n",
      "batch 112, ep 50, training accuracy 0.825\n",
      "f : 10927.9238281, q : 96131.6640625, p : 86453.7734375, l : 1333.93322754\n",
      "batch 112, ep 100, training accuracy 0.825\n",
      "f : 10518.8896484, q : 96157.78125, p : 87023.40625, l : 1322.65429688\n",
      "batch 112, ep 150, training accuracy 0.83\n",
      "f : 10324.0224609, q : 96250.890625, p : 87139.1953125, l : 1337.63195801\n",
      "valid accuracy 0.8938\n",
      "batch 113, ep 0, training accuracy 0.885\n",
      "f : 9686.29394531, q : 96188.5234375, p : 87412.734375, l : 884.32824707\n",
      "batch 113, ep 50, training accuracy 0.885\n",
      "f : 10403.3652344, q : 96057.421875, p : 86433.90625, l : 784.489318848\n",
      "batch 113, ep 100, training accuracy 0.885\n",
      "f : 9943.71972656, q : 96149.953125, p : 87060.7734375, l : 791.830566406\n",
      "batch 113, ep 150, training accuracy 0.885\n",
      "f : 9778.80761719, q : 96101.2734375, p : 87105.25, l : 791.3828125\n",
      "valid accuracy 0.8927\n",
      "batch 114, ep 0, training accuracy 0.925\n",
      "f : 9192.00976562, q : 96067.0703125, p : 87367.4296875, l : 390.520324707\n",
      "batch 114, ep 50, training accuracy 0.955\n",
      "f : 9889.54785156, q : 96099.984375, p : 86486.5, l : 332.938598633\n",
      "batch 114, ep 100, training accuracy 0.955\n",
      "f : 9461.78125, q : 96079.515625, p : 86908.265625, l : 337.192993164\n",
      "batch 114, ep 150, training accuracy 0.95\n",
      "f : 9302.02441406, q : 96074.7734375, p : 87032.0625, l : 334.599975586\n",
      "valid accuracy 0.8914\n",
      "batch 115, ep 0, training accuracy 0.88\n",
      "f : 9614.81347656, q : 96109.84375, p : 87158.40625, l : 802.989624023\n",
      "batch 115, ep 50, training accuracy 0.9\n",
      "f : 10321.2382812, q : 95992.1328125, p : 86353.9921875, l : 663.635131836\n",
      "batch 115, ep 100, training accuracy 0.89\n",
      "f : 9814.68164062, q : 95909.8125, p : 86825.6953125, l : 653.117980957\n",
      "batch 115, ep 150, training accuracy 0.9\n",
      "f : 9638.17773438, q : 96000.84375, p : 86967.7421875, l : 653.04699707\n",
      "valid accuracy 0.891\n",
      "batch 116, ep 0, training accuracy 0.9\n",
      "f : 9549.81152344, q : 95973.21875, p : 87175.59375, l : 746.053100586\n",
      "batch 116, ep 50, training accuracy 0.925\n",
      "f : 10221.84375, q : 95937.65625, p : 86369.5859375, l : 647.290710449\n",
      "batch 116, ep 100, training accuracy 0.93\n",
      "f : 9788.89941406, q : 95937.5625, p : 86876.484375, l : 648.498657227\n",
      "batch 116, ep 150, training accuracy 0.93\n",
      "f : 9594.43359375, q : 95941.6953125, p : 86982.03125, l : 649.592773438\n",
      "valid accuracy 0.8919\n",
      "batch 117, ep 0, training accuracy 0.865\n",
      "f : 9720.13378906, q : 95880.1875, p : 87068.6171875, l : 915.258056641\n",
      "batch 117, ep 50, training accuracy 0.895\n",
      "f : 10358.3671875, q : 95887.375, p : 86356.4453125, l : 778.620300293\n",
      "batch 117, ep 100, training accuracy 0.9\n",
      "f : 9938.9921875, q : 95884.0390625, p : 86710.796875, l : 779.216796875\n",
      "batch 117, ep 150, training accuracy 0.895\n",
      "f : 9768.53515625, q : 95871.8125, p : 86985.7734375, l : 777.54510498\n",
      "valid accuracy 0.8931\n",
      "batch 118, ep 0, training accuracy 0.89\n",
      "f : 9611.37695312, q : 95859.109375, p : 87052.3046875, l : 811.624145508\n",
      "batch 118, ep 50, training accuracy 0.91\n",
      "f : 10281.2929688, q : 95815.5546875, p : 86202.3359375, l : 728.636901855\n",
      "batch 118, ep 100, training accuracy 0.91\n",
      "f : 9882.86621094, q : 95755.3984375, p : 86682.5390625, l : 736.328613281\n",
      "batch 118, ep 150, training accuracy 0.905\n",
      "f : 9672.88671875, q : 95746.5078125, p : 86824.421875, l : 733.987304688\n",
      "valid accuracy 0.8933\n",
      "batch 119, ep 0, training accuracy 0.905\n",
      "f : 9660.75195312, q : 95855.9609375, p : 87037.5390625, l : 863.270996094\n",
      "batch 119, ep 50, training accuracy 0.92\n",
      "f : 10379.9072266, q : 95717.40625, p : 86091.484375, l : 716.270141602\n",
      "batch 119, ep 100, training accuracy 0.92\n",
      "f : 9872.91601562, q : 95724.4140625, p : 86495.5546875, l : 707.365234375\n",
      "batch 119, ep 150, training accuracy 0.92\n",
      "f : 9722.52246094, q : 95861.734375, p : 86734.1796875, l : 708.774841309\n",
      "valid accuracy 0.8917\n",
      "batch 120, ep 0, training accuracy 0.9\n",
      "f : 9474.64648438, q : 95717.3359375, p : 87006.3984375, l : 678.475891113\n",
      "batch 120, ep 50, training accuracy 0.91\n",
      "f : 10114.5214844, q : 95731.7734375, p : 86155.0703125, l : 610.888977051\n",
      "batch 120, ep 100, training accuracy 0.91\n",
      "f : 9729.62597656, q : 95749.0390625, p : 86596.296875, l : 605.657409668\n",
      "batch 120, ep 150, training accuracy 0.91\n",
      "f : 9530.70898438, q : 95724.7265625, p : 86795.421875, l : 610.800537109\n",
      "valid accuracy 0.8923\n",
      "batch 121, ep 0, training accuracy 0.895\n",
      "f : 9676.75683594, q : 95761.0234375, p : 86937.4765625, l : 869.450378418\n",
      "batch 121, ep 50, training accuracy 0.9\n",
      "f : 10343.8818359, q : 95694.0703125, p : 86191.96875, l : 787.663208008\n",
      "batch 121, ep 100, training accuracy 0.905\n",
      "f : 9909.89453125, q : 95719.28125, p : 86519.9921875, l : 789.42755127\n",
      "batch 121, ep 150, training accuracy 0.905\n",
      "f : 9717.97460938, q : 95654.09375, p : 86681.1796875, l : 789.344055176\n",
      "valid accuracy 0.8923\n",
      "batch 122, ep 0, training accuracy 0.885\n",
      "f : 9789.34375, q : 95609.59375, p : 86830.8671875, l : 997.608520508\n",
      "batch 122, ep 50, training accuracy 0.885\n",
      "f : 10394.1640625, q : 95577.9609375, p : 85931.09375, l : 808.284362793\n",
      "batch 122, ep 100, training accuracy 0.885\n",
      "f : 10005.6074219, q : 95586.65625, p : 86364.21875, l : 799.507324219\n",
      "batch 122, ep 150, training accuracy 0.875\n",
      "f : 9850.83007812, q : 95595.015625, p : 86553.6640625, l : 801.19708252\n",
      "valid accuracy 0.8914\n",
      "batch 123, ep 0, training accuracy 0.85\n",
      "f : 10189.2705078, q : 95649.296875, p : 86816.9375, l : 1388.10705566\n",
      "batch 123, ep 50, training accuracy 0.855\n",
      "f : 10775.4550781, q : 95563.53125, p : 85874.5546875, l : 1145.99975586\n",
      "batch 123, ep 100, training accuracy 0.86\n",
      "f : 10330.4111328, q : 95577.828125, p : 86357.546875, l : 1138.51696777\n",
      "batch 123, ep 150, training accuracy 0.86\n",
      "f : 10162.5234375, q : 95504.84375, p : 86538.1875, l : 1144.63598633\n",
      "valid accuracy 0.8905\n",
      "batch 124, ep 0, training accuracy 0.85\n",
      "f : 9836.05175781, q : 95521.3984375, p : 86786.9921875, l : 1028.32214355\n",
      "batch 124, ep 50, training accuracy 0.87\n",
      "f : 10454.2158203, q : 95526.375, p : 85915.7578125, l : 882.963012695\n",
      "batch 124, ep 100, training accuracy 0.875\n",
      "f : 10032.2314453, q : 95497.40625, p : 86351.7421875, l : 871.729553223\n",
      "batch 124, ep 150, training accuracy 0.875\n",
      "f : 9882.74121094, q : 95551.8671875, p : 86461.9921875, l : 872.414916992\n",
      "valid accuracy 0.8903\n",
      "batch 125, ep 0, training accuracy 0.91\n",
      "f : 9462.75683594, q : 95544.03125, p : 86699.6796875, l : 652.514282227\n",
      "batch 125, ep 50, training accuracy 0.92\n",
      "f : 10086.2441406, q : 95484.6640625, p : 85879.703125, l : 569.139831543\n",
      "batch 125, ep 100, training accuracy 0.92\n",
      "f : 9709.31738281, q : 95404.28125, p : 86349.1328125, l : 571.667785645\n",
      "batch 125, ep 150, training accuracy 0.92\n",
      "f : 9548.40722656, q : 95522.515625, p : 86437.953125, l : 575.895446777\n",
      "valid accuracy 0.8905\n",
      "batch 126, ep 0, training accuracy 0.875\n",
      "f : 9519.68554688, q : 95433.2421875, p : 86749.8046875, l : 722.284484863\n",
      "batch 126, ep 50, training accuracy 0.88\n",
      "f : 10146.1103516, q : 95504.390625, p : 85862.7734375, l : 626.239624023\n",
      "batch 126, ep 100, training accuracy 0.88\n",
      "f : 9761.88867188, q : 95416.21875, p : 86241.390625, l : 629.314880371\n",
      "batch 126, ep 150, training accuracy 0.88\n",
      "f : 9595.48242188, q : 95438.5, p : 86459.5859375, l : 622.188903809\n",
      "valid accuracy 0.8889\n",
      "batch 127, ep 0, training accuracy 0.92\n",
      "f : 9520.66601562, q : 95388.203125, p : 86708.953125, l : 714.249145508\n",
      "batch 127, ep 50, training accuracy 0.92\n",
      "f : 10160.7558594, q : 95277.7578125, p : 85815.9375, l : 631.18762207\n",
      "batch 127, ep 100, training accuracy 0.92\n",
      "f : 9779.5703125, q : 95449.3671875, p : 86230.5703125, l : 629.122924805\n",
      "batch 127, ep 150, training accuracy 0.92\n",
      "f : 9616.7421875, q : 95252.171875, p : 86478.1640625, l : 629.664367676\n",
      "valid accuracy 0.8914\n",
      "batch 128, ep 0, training accuracy 0.895\n",
      "f : 9468.40527344, q : 95348.5546875, p : 86593.265625, l : 670.278808594\n",
      "batch 128, ep 50, training accuracy 0.9\n",
      "f : 10205.6884766, q : 95349.8359375, p : 85642.1015625, l : 602.718383789\n",
      "batch 128, ep 100, training accuracy 0.9\n",
      "f : 9714.96289062, q : 95315.859375, p : 86208.2578125, l : 597.665222168\n",
      "batch 128, ep 150, training accuracy 0.9\n",
      "f : 9571.54492188, q : 95349.609375, p : 86377.0625, l : 598.91027832\n",
      "valid accuracy 0.8927\n",
      "batch 129, ep 0, training accuracy 0.895\n",
      "f : 9574.7109375, q : 95308.40625, p : 86485.3203125, l : 771.445617676\n",
      "batch 129, ep 50, training accuracy 0.91\n",
      "f : 10208.2880859, q : 95364.2734375, p : 85777.34375, l : 685.072631836\n",
      "batch 129, ep 100, training accuracy 0.91\n",
      "f : 9813.33789062, q : 95275.609375, p : 86089.9140625, l : 686.847290039\n",
      "batch 129, ep 150, training accuracy 0.91\n",
      "f : 9661.9296875, q : 95248.578125, p : 86303.4609375, l : 686.724853516\n",
      "valid accuracy 0.8953\n",
      "batch 130, ep 0, training accuracy 0.93\n",
      "f : 9388.61816406, q : 95263.7578125, p : 86423.1640625, l : 593.398620605\n",
      "batch 130, ep 50, training accuracy 0.93\n",
      "f : 10004.9580078, q : 95198.5859375, p : 85734.578125, l : 496.57913208\n",
      "batch 130, ep 100, training accuracy 0.935\n",
      "f : 9623.53125, q : 95247.21875, p : 86125.9921875, l : 505.270141602\n",
      "batch 130, ep 150, training accuracy 0.94\n",
      "f : 9437.38964844, q : 95245.703125, p : 86189.609375, l : 500.888366699\n",
      "valid accuracy 0.8939\n",
      "batch 131, ep 0, training accuracy 0.895\n",
      "f : 9683.12402344, q : 95232.25, p : 86410.4453125, l : 885.000305176\n",
      "batch 131, ep 50, training accuracy 0.91\n",
      "f : 10317.9199219, q : 95192.1875, p : 85647.2578125, l : 787.80065918\n",
      "batch 131, ep 100, training accuracy 0.91\n",
      "f : 9925.94921875, q : 95079.7578125, p : 86088.859375, l : 786.730651855\n",
      "batch 131, ep 150, training accuracy 0.915\n",
      "f : 9763.61230469, q : 95169.90625, p : 86171.84375, l : 786.2890625\n",
      "valid accuracy 0.8953\n",
      "batch 132, ep 0, training accuracy 0.865\n",
      "f : 9679.78417969, q : 95222.203125, p : 86328.03125, l : 884.133544922\n",
      "batch 132, ep 50, training accuracy 0.87\n",
      "f : 10275.375, q : 95219.9375, p : 85674.96875, l : 764.775146484\n",
      "batch 132, ep 100, training accuracy 0.87\n",
      "f : 9911.51660156, q : 95188.1640625, p : 85938.625, l : 767.79699707\n",
      "batch 132, ep 150, training accuracy 0.87\n",
      "f : 9705.65039062, q : 95192.421875, p : 86296.34375, l : 758.283203125\n",
      "valid accuracy 0.8945\n",
      "batch 133, ep 0, training accuracy 0.825\n",
      "f : 10181.4980469, q : 95165.1328125, p : 86333.1328125, l : 1386.74487305\n",
      "batch 133, ep 50, training accuracy 0.84\n",
      "f : 10775.9970703, q : 95092.6015625, p : 85645.4921875, l : 1238.17993164\n",
      "batch 133, ep 100, training accuracy 0.84\n",
      "f : 10382.8085938, q : 95155.6796875, p : 86036.5625, l : 1234.59570312\n",
      "batch 133, ep 150, training accuracy 0.84\n",
      "f : 10196.3125, q : 95110.1875, p : 86168.6484375, l : 1230.57971191\n",
      "valid accuracy 0.896\n",
      "batch 134, ep 0, training accuracy 0.885\n",
      "f : 9812.27734375, q : 95166.5234375, p : 86333.28125, l : 1010.94299316\n",
      "batch 134, ep 50, training accuracy 0.895\n",
      "f : 10406.7910156, q : 95211.796875, p : 85545.6640625, l : 873.213867188\n",
      "batch 134, ep 100, training accuracy 0.895\n",
      "f : 10031.671875, q : 95088.015625, p : 85899.859375, l : 870.507446289\n",
      "batch 134, ep 150, training accuracy 0.895\n",
      "f : 9883.875, q : 95097.7421875, p : 85976.4140625, l : 872.761230469\n",
      "valid accuracy 0.8955\n",
      "batch 135, ep 0, training accuracy 0.86\n",
      "f : 9771.86621094, q : 95054.96875, p : 86305.359375, l : 960.045654297\n",
      "batch 135, ep 50, training accuracy 0.875\n",
      "f : 10349.703125, q : 95056.21875, p : 85507.5546875, l : 814.319641113\n",
      "batch 135, ep 100, training accuracy 0.88\n",
      "f : 9976.39160156, q : 95057.7421875, p : 85913.375, l : 823.424560547\n",
      "batch 135, ep 150, training accuracy 0.885\n",
      "f : 9826.39648438, q : 95126.84375, p : 85991.0625, l : 822.23248291\n",
      "valid accuracy 0.8941\n",
      "batch 136, ep 0, training accuracy 0.87\n",
      "f : 9663.29492188, q : 95070.0390625, p : 86276.3125, l : 861.824584961\n",
      "batch 136, ep 50, training accuracy 0.9\n",
      "f : 10246.7988281, q : 95007.828125, p : 85373.3203125, l : 697.228515625\n",
      "batch 136, ep 100, training accuracy 0.895\n",
      "f : 9884.47851562, q : 94982.078125, p : 85752.171875, l : 688.036743164\n",
      "batch 136, ep 150, training accuracy 0.895\n",
      "f : 9701.49414062, q : 95022.4765625, p : 85952.0546875, l : 692.527099609\n",
      "valid accuracy 0.8933\n",
      "batch 137, ep 0, training accuracy 0.85\n",
      "f : 9812.67871094, q : 94881.984375, p : 86202.390625, l : 1004.86132812\n",
      "batch 137, ep 50, training accuracy 0.86\n",
      "f : 10406.5332031, q : 94975.046875, p : 85417.5234375, l : 888.965820312\n",
      "batch 137, ep 100, training accuracy 0.86\n",
      "f : 10021.3173828, q : 95029.9140625, p : 85746.7890625, l : 881.922607422\n",
      "batch 137, ep 150, training accuracy 0.865\n",
      "f : 9885.3671875, q : 94991.3515625, p : 85905.734375, l : 889.570556641\n",
      "valid accuracy 0.8942\n",
      "batch 138, ep 0, training accuracy 0.85\n",
      "f : 9946.66601562, q : 94877.375, p : 86181.6796875, l : 1148.15148926\n",
      "batch 138, ep 50, training accuracy 0.875\n",
      "f : 11779.2148438, q : 94983.78125, p : 83990.265625, l : 920.102478027\n",
      "batch 138, ep 100, training accuracy 0.875\n",
      "f : 10057.3808594, q : 94974.203125, p : 85751.0625, l : 892.122009277\n",
      "batch 138, ep 150, training accuracy 0.875\n",
      "f : 9897.07617188, q : 94933.0546875, p : 85856.1875, l : 894.804931641\n",
      "valid accuracy 0.8947\n",
      "batch 139, ep 0, training accuracy 0.87\n",
      "f : 9666.61328125, q : 94859.4921875, p : 86079.4453125, l : 867.770996094\n",
      "batch 139, ep 50, training accuracy 0.895\n",
      "f : 10270.8408203, q : 94851.4140625, p : 85285.03125, l : 750.428466797\n",
      "batch 139, ep 100, training accuracy 0.89\n",
      "f : 9882.29199219, q : 94896.8671875, p : 85750.2890625, l : 753.181213379\n",
      "batch 139, ep 150, training accuracy 0.895\n",
      "f : 9737.30273438, q : 94819.4921875, p : 85803.640625, l : 756.399047852\n",
      "valid accuracy 0.8948\n",
      "batch 140, ep 0, training accuracy 0.925\n",
      "f : 9452.95019531, q : 94832.3046875, p : 86023.703125, l : 647.365722656\n",
      "batch 140, ep 50, training accuracy 0.925\n",
      "f : 10088.4960938, q : 94822.78125, p : 85288.671875, l : 605.905212402\n",
      "batch 140, ep 100, training accuracy 0.925\n",
      "f : 9706.44433594, q : 94796.7265625, p : 85710.8125, l : 603.242248535\n",
      "batch 140, ep 150, training accuracy 0.925\n",
      "f : 9533.39648438, q : 94851.765625, p : 85934.7421875, l : 605.128967285\n",
      "valid accuracy 0.895\n",
      "batch 141, ep 0, training accuracy 0.87\n",
      "f : 9700.76171875, q : 94812.9453125, p : 86048.234375, l : 897.367126465\n",
      "batch 141, ep 50, training accuracy 0.88\n",
      "f : 10288.6289062, q : 94810.5625, p : 85179.6953125, l : 768.626464844\n",
      "batch 141, ep 100, training accuracy 0.89\n",
      "f : 9917.85839844, q : 94855.046875, p : 85672.8125, l : 770.64074707\n",
      "batch 141, ep 150, training accuracy 0.89\n",
      "f : 9722.47753906, q : 94807.390625, p : 85692.3125, l : 766.130126953\n",
      "valid accuracy 0.8945\n",
      "batch 142, ep 0, training accuracy 0.895\n",
      "f : 9666.68945312, q : 94771.671875, p : 85923.7578125, l : 860.589599609\n",
      "batch 142, ep 50, training accuracy 0.895\n",
      "f : 10272.5878906, q : 94693.2109375, p : 85240.9296875, l : 788.379272461\n",
      "batch 142, ep 100, training accuracy 0.895\n",
      "f : 9903.81640625, q : 94747.5546875, p : 85549.703125, l : 781.842895508\n",
      "batch 142, ep 150, training accuracy 0.895\n",
      "f : 9732.20996094, q : 94792.6875, p : 85770.0625, l : 781.531494141\n",
      "valid accuracy 0.8935\n",
      "batch 143, ep 0, training accuracy 0.89\n",
      "f : 9888.44824219, q : 94697.3671875, p : 85928.2890625, l : 1089.85058594\n",
      "batch 143, ep 50, training accuracy 0.9\n",
      "f : 10451.6396484, q : 94765.7265625, p : 85215.546875, l : 961.416503906\n",
      "batch 143, ep 100, training accuracy 0.905\n",
      "f : 10090.3789062, q : 94698.3671875, p : 85526.421875, l : 960.41003418\n",
      "batch 143, ep 150, training accuracy 0.905\n",
      "f : 9941.78515625, q : 94651.421875, p : 85674.328125, l : 959.980957031\n",
      "valid accuracy 0.8969\n",
      "batch 144, ep 0, training accuracy 0.875\n",
      "f : 9585.92382812, q : 94762.5234375, p : 85925.421875, l : 789.815002441\n",
      "batch 144, ep 50, training accuracy 0.91\n",
      "f : 10192.4980469, q : 94673.28125, p : 85180.8359375, l : 667.58581543\n",
      "batch 144, ep 100, training accuracy 0.91\n",
      "f : 9808.90527344, q : 94689.578125, p : 85490.046875, l : 664.744262695\n",
      "batch 144, ep 150, training accuracy 0.905\n",
      "f : 9631.16015625, q : 94574.4296875, p : 85643.9453125, l : 672.772277832\n",
      "valid accuracy 0.8966\n",
      "batch 145, ep 0, training accuracy 0.86\n",
      "f : 9760.73632812, q : 94664.3203125, p : 85821.3359375, l : 972.903381348\n",
      "batch 145, ep 50, training accuracy 0.875\n",
      "f : 10347.2587891, q : 94609.1953125, p : 85088.2265625, l : 822.104431152\n",
      "batch 145, ep 100, training accuracy 0.88\n",
      "f : 9965.58496094, q : 94643.484375, p : 85475.2578125, l : 825.948364258\n",
      "batch 145, ep 150, training accuracy 0.875\n",
      "f : 9777.98632812, q : 94601.6484375, p : 85678.2109375, l : 822.111755371\n",
      "valid accuracy 0.8973\n",
      "batch 146, ep 0, training accuracy 0.85\n",
      "f : 9814.68164062, q : 94591.46875, p : 85794.6015625, l : 1017.86450195\n",
      "batch 146, ep 50, training accuracy 0.87\n",
      "f : 10377.8056641, q : 94596.9765625, p : 85047.46875, l : 898.618408203\n",
      "batch 146, ep 100, training accuracy 0.865\n",
      "f : 10026.4042969, q : 94593.015625, p : 85516.53125, l : 891.865661621\n",
      "batch 146, ep 150, training accuracy 0.87\n",
      "f : 9873.40917969, q : 94661.890625, p : 85608.2890625, l : 899.849182129\n",
      "valid accuracy 0.8994\n",
      "batch 147, ep 0, training accuracy 0.9\n",
      "f : 9487.3359375, q : 94537.765625, p : 85751.8203125, l : 690.964477539\n",
      "batch 147, ep 50, training accuracy 0.91\n",
      "f : 10078.0136719, q : 94612.0703125, p : 85042.9296875, l : 585.171569824\n",
      "batch 147, ep 100, training accuracy 0.91\n",
      "f : 9701.22167969, q : 94593.765625, p : 85408.7109375, l : 589.315063477\n",
      "batch 147, ep 150, training accuracy 0.91\n",
      "f : 9550.71875, q : 94501.5625, p : 85551.9453125, l : 586.392456055\n",
      "valid accuracy 0.8991\n",
      "batch 148, ep 0, training accuracy 0.925\n",
      "f : 9361.71289062, q : 94595.40625, p : 85808.7890625, l : 561.526611328\n",
      "batch 148, ep 50, training accuracy 0.93\n",
      "f : 9967.28320312, q : 94539.203125, p : 84988.0625, l : 485.864227295\n",
      "batch 148, ep 100, training accuracy 0.935\n",
      "f : 9591.54199219, q : 94440.09375, p : 85550.6015625, l : 485.512634277\n",
      "batch 148, ep 150, training accuracy 0.93\n",
      "f : 9445.57617188, q : 94476.5625, p : 85528.96875, l : 484.754577637\n",
      "valid accuracy 0.8983\n",
      "batch 149, ep 0, training accuracy 0.825\n",
      "f : 10218.4794922, q : 94484.0546875, p : 85689.7578125, l : 1425.30859375\n",
      "batch 149, ep 50, training accuracy 0.84\n",
      "f : 10759.9423828, q : 94502.796875, p : 84980.1875, l : 1229.77209473\n",
      "batch 149, ep 100, training accuracy 0.84\n",
      "f : 10376.6494141, q : 94441.640625, p : 85326.234375, l : 1222.80957031\n",
      "batch 149, ep 150, training accuracy 0.84\n",
      "f : 10188.53125, q : 94437.7109375, p : 85527.9140625, l : 1226.06005859\n",
      "valid accuracy 0.8962\n",
      "batch 150, ep 0, training accuracy 0.825\n",
      "f : 9858.52441406, q : 94460.796875, p : 85697.953125, l : 1060.26464844\n",
      "batch 150, ep 50, training accuracy 0.87\n",
      "f : 10375.2441406, q : 94462.7421875, p : 84895.2578125, l : 854.272094727\n",
      "batch 150, ep 100, training accuracy 0.875\n",
      "f : 10002.6835938, q : 94454.0625, p : 85337.8359375, l : 853.474731445\n",
      "batch 150, ep 150, training accuracy 0.88\n",
      "f : 9860.84375, q : 94458.84375, p : 85447.0546875, l : 851.993713379\n",
      "valid accuracy 0.8958\n",
      "batch 151, ep 0, training accuracy 0.91\n",
      "f : 9423.07617188, q : 94384.3203125, p : 85589.5078125, l : 622.197875977\n",
      "batch 151, ep 50, training accuracy 0.92\n",
      "f : 9996.69335938, q : 94409.9453125, p : 84920.046875, l : 523.891601562\n",
      "batch 151, ep 100, training accuracy 0.92\n",
      "f : 9633.40332031, q : 94288.75, p : 85341.28125, l : 526.587524414\n",
      "batch 151, ep 150, training accuracy 0.92\n",
      "f : 9494.17675781, q : 94448.34375, p : 85334.9140625, l : 524.789306641\n",
      "valid accuracy 0.8987\n",
      "batch 152, ep 0, training accuracy 0.85\n",
      "f : 9772.16113281, q : 94385.28125, p : 85637.171875, l : 973.555480957\n",
      "batch 152, ep 50, training accuracy 0.875\n",
      "f : 10309.2558594, q : 94373.859375, p : 84918.421875, l : 794.694458008\n",
      "batch 152, ep 100, training accuracy 0.87\n",
      "f : 9941.50976562, q : 94395.953125, p : 85218.7890625, l : 790.977172852\n",
      "batch 152, ep 150, training accuracy 0.875\n",
      "f : 9784.34472656, q : 94384.3515625, p : 85409.3515625, l : 794.226806641\n",
      "valid accuracy 0.8975\n",
      "batch 153, ep 0, training accuracy 0.865\n",
      "f : 9731.96582031, q : 94393.296875, p : 85574.5546875, l : 939.568115234\n",
      "batch 153, ep 50, training accuracy 0.9\n",
      "f : 10292.3886719, q : 94323.5078125, p : 84807.0390625, l : 791.961303711\n",
      "batch 153, ep 100, training accuracy 0.895\n",
      "f : 9928.546875, q : 94301.0078125, p : 85201.3046875, l : 789.29095459\n",
      "batch 153, ep 150, training accuracy 0.895\n",
      "f : 9744.35058594, q : 94250.875, p : 85344.1015625, l : 788.878051758\n",
      "valid accuracy 0.8887\n",
      "batch 154, ep 0, training accuracy 0.9\n",
      "f : 9805.65625, q : 94300.6171875, p : 85476.4765625, l : 1001.62823486\n",
      "batch 154, ep 50, training accuracy 0.92\n",
      "f : 10352.0625, q : 94271.890625, p : 84866.6171875, l : 841.931762695\n",
      "batch 154, ep 100, training accuracy 0.92\n",
      "f : 9976.5234375, q : 94315.7578125, p : 85137.15625, l : 838.851745605\n",
      "batch 154, ep 150, training accuracy 0.92\n",
      "f : 9818.98339844, q : 94280.34375, p : 85374.6015625, l : 841.806884766\n",
      "valid accuracy 0.8922\n",
      "batch 155, ep 0, training accuracy 0.87\n",
      "f : 10031.6416016, q : 94212.5703125, p : 85455.2421875, l : 1235.81738281\n",
      "batch 155, ep 50, training accuracy 0.89\n",
      "f : 10594.4570312, q : 94189.9453125, p : 84788.90625, l : 1111.77026367\n",
      "batch 155, ep 100, training accuracy 0.89\n",
      "f : 10233.5087891, q : 94219.1484375, p : 85136.7578125, l : 1110.77587891\n",
      "batch 155, ep 150, training accuracy 0.89\n",
      "f : 10089.8105469, q : 94217.25, p : 85271.4765625, l : 1097.00305176\n",
      "valid accuracy 0.8949\n",
      "batch 156, ep 0, training accuracy 0.825\n",
      "f : 10123.8271484, q : 94195.8671875, p : 85397.4921875, l : 1327.33483887\n",
      "batch 156, ep 50, training accuracy 0.84\n",
      "f : 10642.7431641, q : 94170.9140625, p : 84646.328125, l : 1131.32580566\n",
      "batch 156, ep 100, training accuracy 0.835\n",
      "f : 10271.7050781, q : 94206.3203125, p : 85076.578125, l : 1119.09875488\n",
      "batch 156, ep 150, training accuracy 0.835\n",
      "f : 10119.4082031, q : 94197.6640625, p : 85148.0078125, l : 1114.05322266\n",
      "valid accuracy 0.8984\n",
      "batch 157, ep 0, training accuracy 0.89\n",
      "f : 9795.46777344, q : 94246.625, p : 85457.234375, l : 997.845092773\n",
      "batch 157, ep 50, training accuracy 0.89\n",
      "f : 10371.7890625, q : 94227.0234375, p : 84691.2265625, l : 866.020202637\n",
      "batch 157, ep 100, training accuracy 0.89\n",
      "f : 9994.08105469, q : 94149.2421875, p : 85000.6796875, l : 871.793579102\n",
      "batch 157, ep 150, training accuracy 0.89\n",
      "f : 9830.73925781, q : 94192.9375, p : 85184.3515625, l : 867.039428711\n",
      "valid accuracy 0.8979\n",
      "batch 158, ep 0, training accuracy 0.825\n",
      "f : 10037.6816406, q : 94181.7734375, p : 85336.2109375, l : 1245.63842773\n",
      "batch 158, ep 50, training accuracy 0.845\n",
      "f : 10593.0019531, q : 94146.1953125, p : 84570.140625, l : 1071.93640137\n",
      "batch 158, ep 100, training accuracy 0.85\n",
      "f : 10232.3417969, q : 94102.5859375, p : 84911.8984375, l : 1081.87902832\n",
      "batch 158, ep 150, training accuracy 0.84\n",
      "f : 10074.8994141, q : 94211.015625, p : 85099.3515625, l : 1088.89477539\n",
      "valid accuracy 0.8977\n",
      "batch 159, ep 0, training accuracy 0.86\n",
      "f : 9665.15332031, q : 94209.265625, p : 85337.765625, l : 867.805419922\n",
      "batch 159, ep 50, training accuracy 0.885\n",
      "f : 11408.5957031, q : 94082.4453125, p : 83496.6640625, l : 691.275512695\n",
      "batch 159, ep 100, training accuracy 0.89\n",
      "f : 9814.40625, q : 94137.421875, p : 85045.1953125, l : 677.804199219\n",
      "batch 159, ep 150, training accuracy 0.89\n",
      "f : 9663.45214844, q : 94107.8984375, p : 85116.2109375, l : 679.94519043\n",
      "valid accuracy 0.8943\n",
      "batch 160, ep 0, training accuracy 0.875\n",
      "f : 9755.81640625, q : 94125.6171875, p : 85336.1484375, l : 956.710876465\n",
      "batch 160, ep 50, training accuracy 0.89\n",
      "f : 10303.2597656, q : 94062.6875, p : 84660.28125, l : 823.798095703\n",
      "batch 160, ep 100, training accuracy 0.89\n",
      "f : 9941.63769531, q : 94064.40625, p : 84968.6796875, l : 820.202941895\n",
      "batch 160, ep 150, training accuracy 0.89\n",
      "f : 9771.19726562, q : 94099.625, p : 85111.8671875, l : 819.032958984\n",
      "valid accuracy 0.8959\n",
      "batch 161, ep 0, training accuracy 0.845\n",
      "f : 9886.26660156, q : 94130.4453125, p : 85256.5546875, l : 1096.48046875\n",
      "batch 161, ep 50, training accuracy 0.865\n",
      "f : 10435.3779297, q : 94131.0546875, p : 84623.34375, l : 937.816650391\n",
      "batch 161, ep 100, training accuracy 0.855\n",
      "f : 10077.5068359, q : 94047.859375, p : 84898.8828125, l : 931.133728027\n",
      "batch 161, ep 150, training accuracy 0.855\n",
      "f : 9891.67480469, q : 94100.2734375, p : 85109.3671875, l : 925.555053711\n",
      "valid accuracy 0.896\n",
      "batch 162, ep 0, training accuracy 0.84\n",
      "f : 9917.16113281, q : 94113.7578125, p : 85323.0546875, l : 1113.60791016\n",
      "batch 162, ep 50, training accuracy 0.87\n",
      "f : 10425.7910156, q : 94047.3828125, p : 84515.703125, l : 944.803222656\n",
      "batch 162, ep 100, training accuracy 0.87\n",
      "f : 10101.7568359, q : 94105.5546875, p : 84875.0546875, l : 948.794311523\n",
      "batch 162, ep 150, training accuracy 0.87\n",
      "f : 9949.78222656, q : 93946.9453125, p : 85051.140625, l : 948.364990234\n",
      "valid accuracy 0.8983\n",
      "batch 163, ep 0, training accuracy 0.9\n",
      "f : 9675.88183594, q : 94034.0625, p : 85175.328125, l : 865.990661621\n",
      "batch 163, ep 50, training accuracy 0.92\n",
      "f : 10237.0185547, q : 93935.1875, p : 84511.703125, l : 753.80078125\n",
      "batch 163, ep 100, training accuracy 0.92\n",
      "f : 9872.72265625, q : 94009.3828125, p : 84907.0234375, l : 756.032470703\n",
      "batch 163, ep 150, training accuracy 0.92\n",
      "f : 9728.24316406, q : 93961.8671875, p : 85008.4375, l : 759.12109375\n",
      "valid accuracy 0.8997\n",
      "batch 164, ep 0, training accuracy 0.91\n",
      "f : 9422.37695312, q : 93998.078125, p : 85235.171875, l : 622.926269531\n",
      "batch 164, ep 50, training accuracy 0.92\n",
      "f : 10000.8535156, q : 93973.203125, p : 84528.4921875, l : 519.516296387\n",
      "batch 164, ep 100, training accuracy 0.925\n",
      "f : 9630.75488281, q : 93906.3359375, p : 84821.125, l : 510.902587891\n",
      "batch 164, ep 150, training accuracy 0.925\n",
      "f : 9485.58398438, q : 93971.84375, p : 84900.734375, l : 512.77532959\n",
      "valid accuracy 0.8981\n",
      "batch 165, ep 0, training accuracy 0.9\n",
      "f : 9462.44238281, q : 93954.046875, p : 85140.5703125, l : 667.283569336\n",
      "batch 165, ep 50, training accuracy 0.93\n",
      "f : 10032.9169922, q : 93907.015625, p : 84406.015625, l : 547.204956055\n",
      "batch 165, ep 100, training accuracy 0.93\n",
      "f : 9670.67480469, q : 93823.7734375, p : 84773.34375, l : 547.063720703\n",
      "batch 165, ep 150, training accuracy 0.93\n",
      "f : 9499.59960938, q : 93967.015625, p : 84957.1171875, l : 556.753723145\n",
      "valid accuracy 0.8978\n",
      "batch 166, ep 0, training accuracy 0.865\n",
      "f : 9662.55859375, q : 93904.1484375, p : 85115.40625, l : 859.426025391\n",
      "batch 166, ep 50, training accuracy 0.895\n",
      "f : 10201.7460938, q : 93845.40625, p : 84539.84375, l : 729.874267578\n",
      "batch 166, ep 100, training accuracy 0.895\n",
      "f : 9849.75683594, q : 93850.5859375, p : 84794.3203125, l : 736.69519043\n",
      "batch 166, ep 150, training accuracy 0.89\n",
      "f : 9707.83984375, q : 93998.3515625, p : 84931.875, l : 724.989990234\n",
      "valid accuracy 0.8997\n",
      "batch 167, ep 0, training accuracy 0.905\n",
      "f : 9554.94335938, q : 93908.296875, p : 85149.234375, l : 757.528503418\n",
      "batch 167, ep 50, training accuracy 0.92\n",
      "f : 10112.9228516, q : 93827.484375, p : 84396.4453125, l : 664.981994629\n",
      "batch 167, ep 100, training accuracy 0.92\n",
      "f : 9772.30859375, q : 93834.2734375, p : 84769.4453125, l : 672.134277344\n",
      "batch 167, ep 150, training accuracy 0.915\n",
      "f : 9630.70898438, q : 93869.1015625, p : 84899.9296875, l : 664.426025391\n",
      "valid accuracy 0.8986\n",
      "batch 168, ep 0, training accuracy 0.91\n",
      "f : 9359.37011719, q : 93767.8125, p : 85046.796875, l : 559.318115234\n",
      "batch 168, ep 50, training accuracy 0.915\n",
      "f : 9955.05273438, q : 93843.40625, p : 84431.375, l : 509.644042969\n",
      "batch 168, ep 100, training accuracy 0.92\n",
      "f : 9613.43457031, q : 93832.4140625, p : 84725.6328125, l : 506.97833252\n",
      "batch 168, ep 150, training accuracy 0.92\n",
      "f : 9465.0078125, q : 93742.875, p : 84929.84375, l : 508.644104004\n",
      "valid accuracy 0.8998\n",
      "batch 169, ep 0, training accuracy 0.94\n",
      "f : 9119.77734375, q : 93801.8515625, p : 85057.6953125, l : 325.651672363\n",
      "batch 169, ep 50, training accuracy 0.95\n",
      "f : 9714.99902344, q : 93818.90625, p : 84423.328125, l : 294.145843506\n",
      "batch 169, ep 100, training accuracy 0.95\n",
      "f : 9381.15527344, q : 93759.21875, p : 84743.59375, l : 295.73248291\n",
      "batch 169, ep 150, training accuracy 0.945\n",
      "f : 9214.71386719, q : 93841.703125, p : 84865.453125, l : 294.20993042\n",
      "valid accuracy 0.9007\n",
      "batch 170, ep 0, training accuracy 0.88\n",
      "f : 9483.93164062, q : 93774.234375, p : 85051.453125, l : 683.321228027\n",
      "batch 170, ep 50, training accuracy 0.89\n",
      "f : 10057.0605469, q : 93778.6796875, p : 84292.078125, l : 604.153442383\n",
      "batch 170, ep 100, training accuracy 0.89\n",
      "f : 9703.90039062, q : 93823.921875, p : 84676.578125, l : 608.805480957\n",
      "batch 170, ep 150, training accuracy 0.89\n",
      "f : 9568.265625, q : 93777.9296875, p : 84831.6015625, l : 609.481872559\n",
      "valid accuracy 0.9002\n",
      "batch 171, ep 0, training accuracy 0.94\n",
      "f : 9228.44335938, q : 93815.6953125, p : 85017.3828125, l : 429.900787354\n",
      "batch 171, ep 50, training accuracy 0.945\n",
      "f : 9806.33105469, q : 93761.8203125, p : 84291.1640625, l : 373.15234375\n",
      "batch 171, ep 100, training accuracy 0.945\n",
      "f : 9456.93554688, q : 93751.03125, p : 84726.296875, l : 372.787841797\n",
      "batch 171, ep 150, training accuracy 0.945\n",
      "f : 9291.80859375, q : 93695.515625, p : 84771.75, l : 372.289794922\n",
      "valid accuracy 0.9007\n",
      "batch 172, ep 0, training accuracy 0.86\n",
      "f : 9699.6953125, q : 93706.3515625, p : 84860.984375, l : 896.319824219\n",
      "batch 172, ep 50, training accuracy 0.88\n",
      "f : 10295.9052734, q : 93660.7265625, p : 84154.0390625, l : 791.157409668\n",
      "batch 172, ep 100, training accuracy 0.87\n",
      "f : 9902.46289062, q : 93740.8828125, p : 84587.359375, l : 784.160522461\n",
      "batch 172, ep 150, training accuracy 0.875\n",
      "f : 9762.40136719, q : 93637.9375, p : 84675.671875, l : 784.512817383\n",
      "valid accuracy 0.9001\n",
      "batch 173, ep 0, training accuracy 0.865\n",
      "f : 9728.75488281, q : 93658.296875, p : 84764.53125, l : 935.453613281\n",
      "batch 173, ep 50, training accuracy 0.895\n",
      "f : 10361.1865234, q : 93637.25, p : 84111.0625, l : 818.19128418\n",
      "batch 173, ep 100, training accuracy 0.895\n",
      "f : 9916.36132812, q : 93607.71875, p : 84576.390625, l : 817.408874512\n",
      "batch 173, ep 150, training accuracy 0.9\n",
      "f : 9793.24121094, q : 93583.7734375, p : 84661.7265625, l : 817.831787109\n",
      "valid accuracy 0.8982\n",
      "batch 174, ep 0, training accuracy 0.875\n",
      "f : 9751.54296875, q : 93617.546875, p : 84902.3359375, l : 946.501342773\n",
      "batch 174, ep 50, training accuracy 0.89\n",
      "f : 10290.8300781, q : 93605.0546875, p : 84135.53125, l : 824.607543945\n",
      "batch 174, ep 100, training accuracy 0.89\n",
      "f : 9948.53515625, q : 93699.5, p : 84452.515625, l : 827.022155762\n",
      "batch 174, ep 150, training accuracy 0.89\n",
      "f : 9811.51953125, q : 93599.046875, p : 84708.8125, l : 820.063354492\n",
      "valid accuracy 0.8999\n",
      "batch 175, ep 0, training accuracy 0.9\n",
      "f : 9405.73535156, q : 93664.5859375, p : 84886.2109375, l : 598.995056152\n",
      "batch 175, ep 50, training accuracy 0.91\n",
      "f : 9961.5, q : 93622.265625, p : 84174.8828125, l : 523.613952637\n",
      "batch 175, ep 100, training accuracy 0.915\n",
      "f : 9609.88378906, q : 93598.34375, p : 84435.1875, l : 524.649108887\n",
      "batch 175, ep 150, training accuracy 0.915\n",
      "f : 9479.89160156, q : 93647.8203125, p : 84624.703125, l : 520.305175781\n",
      "valid accuracy 0.9002\n",
      "batch 176, ep 0, training accuracy 0.92\n",
      "f : 9397.41113281, q : 93585.1640625, p : 84867.3984375, l : 603.971008301\n",
      "batch 176, ep 50, training accuracy 0.935\n",
      "f : 9958.21679688, q : 93594.9921875, p : 84162.0, l : 532.244262695\n",
      "batch 176, ep 100, training accuracy 0.93\n",
      "f : 9630.09960938, q : 93584.2109375, p : 84482.6015625, l : 535.46484375\n",
      "batch 176, ep 150, training accuracy 0.925\n",
      "f : 9441.59765625, q : 93528.8515625, p : 84630.4453125, l : 532.200439453\n",
      "valid accuracy 0.9017\n",
      "batch 177, ep 0, training accuracy 0.865\n",
      "f : 9880.80078125, q : 93587.5859375, p : 84747.8671875, l : 1079.70959473\n",
      "batch 177, ep 50, training accuracy 0.88\n",
      "f : 10441.984375, q : 93501.65625, p : 84066.0234375, l : 951.11730957\n",
      "batch 177, ep 100, training accuracy 0.88\n",
      "f : 10075.5771484, q : 93507.4140625, p : 84395.6015625, l : 961.405517578\n",
      "batch 177, ep 150, training accuracy 0.885\n",
      "f : 9911.16308594, q : 93612.84375, p : 84586.90625, l : 955.419311523\n",
      "valid accuracy 0.9007\n",
      "batch 178, ep 0, training accuracy 0.9\n",
      "f : 9384.52734375, q : 93565.3203125, p : 84782.71875, l : 587.855529785\n",
      "batch 178, ep 50, training accuracy 0.915\n",
      "f : 9944.1640625, q : 93549.796875, p : 84139.9765625, l : 498.214874268\n",
      "batch 178, ep 100, training accuracy 0.92\n",
      "f : 9602.05957031, q : 93488.6015625, p : 84470.1640625, l : 505.059997559\n",
      "batch 178, ep 150, training accuracy 0.925\n",
      "f : 9406.60449219, q : 93605.0, p : 84628.421875, l : 497.321258545\n",
      "valid accuracy 0.8995\n",
      "batch 179, ep 0, training accuracy 0.9\n",
      "f : 9357.02734375, q : 93577.015625, p : 84674.9453125, l : 571.133056641\n",
      "batch 179, ep 50, training accuracy 0.905\n",
      "f : 9919.30371094, q : 93505.46875, p : 84063.3203125, l : 491.111633301\n",
      "batch 179, ep 100, training accuracy 0.91\n",
      "f : 9589.68652344, q : 93528.7421875, p : 84419.609375, l : 493.372924805\n",
      "batch 179, ep 150, training accuracy 0.9\n",
      "f : 9402.1796875, q : 93491.375, p : 84613.0859375, l : 491.664367676\n",
      "valid accuracy 0.8991\n",
      "batch 180, ep 0, training accuracy 0.88\n",
      "f : 9750.67871094, q : 93504.7578125, p : 84693.28125, l : 954.348449707\n",
      "batch 180, ep 50, training accuracy 0.885\n",
      "f : 10285.0234375, q : 93448.453125, p : 84003.6796875, l : 849.807250977\n",
      "batch 180, ep 100, training accuracy 0.89\n",
      "f : 9959.9296875, q : 93326.7265625, p : 84392.859375, l : 842.219970703\n",
      "batch 180, ep 150, training accuracy 0.89\n",
      "f : 9825.15820312, q : 93411.703125, p : 84491.625, l : 844.296386719\n",
      "valid accuracy 0.8988\n",
      "batch 181, ep 0, training accuracy 0.89\n",
      "f : 9428.88769531, q : 93471.3125, p : 84678.7890625, l : 628.826293945\n",
      "batch 181, ep 50, training accuracy 0.895\n",
      "f : 9969.44335938, q : 93428.8125, p : 83982.6953125, l : 532.782836914\n",
      "batch 181, ep 100, training accuracy 0.905\n",
      "f : 9629.45703125, q : 93339.8125, p : 84330.1953125, l : 536.239013672\n",
      "batch 181, ep 150, training accuracy 0.91\n",
      "f : 9477.875, q : 93445.796875, p : 84530.765625, l : 535.564941406\n",
      "valid accuracy 0.9001\n",
      "batch 182, ep 0, training accuracy 0.865\n",
      "f : 9709.36523438, q : 93338.2890625, p : 84533.875, l : 908.416687012\n",
      "batch 182, ep 50, training accuracy 0.88\n",
      "f : 10239.6601562, q : 93376.7421875, p : 83985.109375, l : 756.628356934\n",
      "batch 182, ep 100, training accuracy 0.88\n",
      "f : 9894.96386719, q : 93399.25, p : 84298.453125, l : 763.402954102\n",
      "batch 182, ep 150, training accuracy 0.88\n",
      "f : 9735.07128906, q : 93370.9765625, p : 84364.78125, l : 760.424194336\n",
      "valid accuracy 0.8995\n",
      "batch 183, ep 0, training accuracy 0.92\n",
      "f : 9405.26757812, q : 93433.109375, p : 84648.9609375, l : 601.01550293\n",
      "batch 183, ep 50, training accuracy 0.93\n",
      "f : 9954.92285156, q : 93514.2421875, p : 83928.8515625, l : 522.152587891\n",
      "batch 183, ep 100, training accuracy 0.925\n",
      "f : 9623.75878906, q : 93288.2265625, p : 84418.5546875, l : 527.10736084\n",
      "batch 183, ep 150, training accuracy 0.925\n",
      "f : 9479.56445312, q : 93405.0234375, p : 84449.4921875, l : 522.775634766\n",
      "valid accuracy 0.8985\n",
      "batch 184, ep 0, training accuracy 0.915\n",
      "f : 9390.04296875, q : 93372.125, p : 84632.9609375, l : 600.916015625\n",
      "batch 184, ep 50, training accuracy 0.92\n",
      "f : 9958.72167969, q : 93442.390625, p : 83900.15625, l : 505.764648438\n",
      "batch 184, ep 100, training accuracy 0.92\n",
      "f : 9615.10253906, q : 93361.6015625, p : 84237.6328125, l : 507.294647217\n",
      "batch 184, ep 150, training accuracy 0.92\n",
      "f : 9444.64453125, q : 93268.890625, p : 84346.2265625, l : 507.273376465\n",
      "valid accuracy 0.8998\n",
      "batch 185, ep 0, training accuracy 0.89\n",
      "f : 9583.97460938, q : 93337.765625, p : 84515.984375, l : 785.075195312\n",
      "batch 185, ep 50, training accuracy 0.91\n",
      "f : 10146.3759766, q : 93316.3359375, p : 83838.0078125, l : 673.999206543\n",
      "batch 185, ep 100, training accuracy 0.91\n",
      "f : 9794.83886719, q : 93332.0, p : 84146.140625, l : 674.568237305\n",
      "batch 185, ep 150, training accuracy 0.91\n",
      "f : 9637.16015625, q : 93292.859375, p : 84262.5703125, l : 674.281860352\n",
      "valid accuracy 0.8979\n",
      "batch 186, ep 0, training accuracy 0.865\n",
      "f : 10024.9902344, q : 93381.8125, p : 84554.359375, l : 1233.25866699\n",
      "batch 186, ep 50, training accuracy 0.875\n",
      "f : 10533.6787109, q : 93259.015625, p : 83851.921875, l : 1060.73571777\n",
      "batch 186, ep 100, training accuracy 0.875\n",
      "f : 10207.1015625, q : 93299.8203125, p : 84204.7734375, l : 1062.12158203\n",
      "batch 186, ep 150, training accuracy 0.87\n",
      "f : 10027.6279297, q : 93267.84375, p : 84362.015625, l : 1071.00512695\n",
      "valid accuracy 0.8998\n",
      "batch 187, ep 0, training accuracy 0.81\n",
      "f : 10241.9453125, q : 93324.3515625, p : 84491.4296875, l : 1451.82861328\n",
      "batch 187, ep 50, training accuracy 0.83\n",
      "f : 11658.8710938, q : 93274.03125, p : 82686.8515625, l : 1036.46630859\n",
      "batch 187, ep 100, training accuracy 0.855\n",
      "f : 10513.7832031, q : 93306.78125, p : 83778.2109375, l : 1013.79022217\n",
      "batch 187, ep 150, training accuracy 0.855\n",
      "f : 10038.7529297, q : 93214.4765625, p : 84283.7109375, l : 1016.33630371\n",
      "valid accuracy 0.8937\n",
      "batch 188, ep 0, training accuracy 0.875\n",
      "f : 9670.62011719, q : 93272.875, p : 84432.546875, l : 883.152648926\n",
      "batch 188, ep 50, training accuracy 0.885\n",
      "f : 10205.9570312, q : 93231.5625, p : 83791.046875, l : 750.038757324\n",
      "batch 188, ep 100, training accuracy 0.89\n",
      "f : 9859.02050781, q : 93273.328125, p : 84041.078125, l : 756.878112793\n",
      "batch 188, ep 150, training accuracy 0.885\n",
      "f : 9725.66699219, q : 93251.8203125, p : 84295.6953125, l : 751.951965332\n",
      "valid accuracy 0.8968\n",
      "batch 189, ep 0, training accuracy 0.895\n",
      "f : 9584.33886719, q : 93275.015625, p : 84426.828125, l : 782.720703125\n",
      "batch 189, ep 50, training accuracy 0.915\n",
      "f : 10116.2402344, q : 93191.3203125, p : 83732.1640625, l : 705.506652832\n",
      "batch 189, ep 100, training accuracy 0.915\n",
      "f : 9796.41992188, q : 93277.0859375, p : 84199.859375, l : 700.639160156\n",
      "batch 189, ep 150, training accuracy 0.915\n",
      "f : 9667.99804688, q : 93282.3125, p : 84191.25, l : 705.69921875\n",
      "valid accuracy 0.8974\n",
      "batch 190, ep 0, training accuracy 0.88\n",
      "f : 9516.7421875, q : 93203.9375, p : 84380.1171875, l : 726.604492188\n",
      "batch 190, ep 50, training accuracy 0.895\n",
      "f : 10032.9169922, q : 93260.265625, p : 83676.9453125, l : 591.434692383\n",
      "batch 190, ep 100, training accuracy 0.89\n",
      "f : 9708.12988281, q : 93196.875, p : 84094.1484375, l : 592.515136719\n",
      "batch 190, ep 150, training accuracy 0.895\n",
      "f : 9552.46191406, q : 93224.53125, p : 84179.9375, l : 594.314575195\n",
      "valid accuracy 0.8971\n",
      "batch 191, ep 0, training accuracy 0.88\n",
      "f : 9518.4921875, q : 93179.6015625, p : 84360.015625, l : 716.935913086\n",
      "batch 191, ep 50, training accuracy 0.9\n",
      "f : 10062.0117188, q : 93212.7421875, p : 83700.65625, l : 631.612121582\n",
      "batch 191, ep 100, training accuracy 0.9\n",
      "f : 9736.36328125, q : 93124.2890625, p : 84061.046875, l : 632.496582031\n",
      "batch 191, ep 150, training accuracy 0.905\n",
      "f : 9568.78710938, q : 93172.5859375, p : 84220.921875, l : 628.820678711\n",
      "valid accuracy 0.8976\n",
      "batch 192, ep 0, training accuracy 0.89\n",
      "f : 9641.41113281, q : 93154.4453125, p : 84429.8359375, l : 840.854614258\n",
      "batch 192, ep 50, training accuracy 0.91\n",
      "f : 10159.5078125, q : 93111.9140625, p : 83695.5, l : 734.375915527\n",
      "batch 192, ep 100, training accuracy 0.91\n",
      "f : 9834.51757812, q : 93142.8671875, p : 84087.03125, l : 736.582397461\n",
      "batch 192, ep 150, training accuracy 0.915\n",
      "f : 9698.64453125, q : 93120.171875, p : 84143.1328125, l : 742.737976074\n",
      "valid accuracy 0.8962\n",
      "batch 193, ep 0, training accuracy 0.855\n",
      "f : 9858.8828125, q : 93127.734375, p : 84290.84375, l : 1053.51574707\n",
      "batch 193, ep 50, training accuracy 0.86\n",
      "f : 10359.7666016, q : 93085.765625, p : 83637.21875, l : 913.244750977\n",
      "batch 193, ep 100, training accuracy 0.865\n",
      "f : 10040.7148438, q : 93074.03125, p : 83953.640625, l : 906.821289062\n",
      "batch 193, ep 150, training accuracy 0.865\n",
      "f : 9908.08984375, q : 93094.3984375, p : 84132.765625, l : 905.179199219\n",
      "valid accuracy 0.8998\n",
      "batch 194, ep 0, training accuracy 0.93\n",
      "f : 9233.52929688, q : 93021.0546875, p : 84363.0234375, l : 439.714172363\n",
      "batch 194, ep 50, training accuracy 0.94\n",
      "f : 9786.43066406, q : 93102.1875, p : 83648.421875, l : 371.376708984\n",
      "batch 194, ep 100, training accuracy 0.945\n",
      "f : 9448.25292969, q : 93054.0859375, p : 83987.9921875, l : 376.673156738\n",
      "batch 194, ep 150, training accuracy 0.94\n",
      "f : 9310.31542969, q : 93114.5703125, p : 84089.8203125, l : 380.283203125\n",
      "valid accuracy 0.9002\n",
      "batch 195, ep 0, training accuracy 0.91\n",
      "f : 9591.99804688, q : 93145.71875, p : 84272.984375, l : 792.754150391\n",
      "batch 195, ep 50, training accuracy 0.915\n",
      "f : 10143.7646484, q : 92987.7421875, p : 83512.578125, l : 699.543701172\n",
      "batch 195, ep 100, training accuracy 0.91\n",
      "f : 9791.81445312, q : 93043.4453125, p : 83992.578125, l : 708.380981445\n",
      "batch 195, ep 150, training accuracy 0.91\n",
      "f : 9648.25292969, q : 93029.46875, p : 84115.6953125, l : 705.209838867\n",
      "valid accuracy 0.9014\n",
      "batch 196, ep 0, training accuracy 0.855\n",
      "f : 10023.2529297, q : 93076.4140625, p : 84233.9609375, l : 1224.19592285\n",
      "batch 196, ep 50, training accuracy 0.865\n",
      "f : 10528.7529297, q : 93017.390625, p : 83530.9296875, l : 1089.53833008\n",
      "batch 196, ep 100, training accuracy 0.865\n",
      "f : 10203.6044922, q : 93041.6796875, p : 83973.5703125, l : 1089.60803223\n",
      "batch 196, ep 150, training accuracy 0.87\n",
      "f : 10030.9111328, q : 93009.265625, p : 84017.8984375, l : 1090.90808105\n",
      "valid accuracy 0.8991\n",
      "batch 197, ep 0, training accuracy 0.89\n",
      "f : 9782.16992188, q : 93056.0625, p : 84204.0546875, l : 986.369262695\n",
      "batch 197, ep 50, training accuracy 0.905\n",
      "f : 10595.84375, q : 92975.9375, p : 83228.390625, l : 810.682189941\n",
      "batch 197, ep 100, training accuracy 0.905\n",
      "f : 9948.51269531, q : 93008.5078125, p : 83851.375, l : 815.181884766\n",
      "batch 197, ep 150, training accuracy 0.9\n",
      "f : 9819.43847656, q : 92961.6640625, p : 84054.2890625, l : 813.981201172\n",
      "valid accuracy 0.8981\n",
      "batch 198, ep 0, training accuracy 0.88\n",
      "f : 9670.21191406, q : 93003.3125, p : 84173.3359375, l : 881.426879883\n",
      "batch 198, ep 50, training accuracy 0.905\n",
      "f : 10161.5908203, q : 92886.171875, p : 83460.75, l : 734.499328613\n",
      "batch 198, ep 100, training accuracy 0.905\n",
      "f : 9853.76269531, q : 92900.2109375, p : 83786.140625, l : 734.988769531\n",
      "batch 198, ep 150, training accuracy 0.905\n",
      "f : 9706.76171875, q : 93026.8359375, p : 84010.2890625, l : 742.162719727\n",
      "valid accuracy 0.9013\n",
      "batch 199, ep 0, training accuracy 0.855\n",
      "f : 9853.58105469, q : 92904.96875, p : 84133.375, l : 1057.77856445\n",
      "batch 199, ep 50, training accuracy 0.895\n",
      "f : 10323.7998047, q : 92947.0546875, p : 83510.6484375, l : 904.037353516\n",
      "batch 199, ep 100, training accuracy 0.895\n",
      "f : 10032.1962891, q : 92929.8203125, p : 83774.9609375, l : 903.027099609\n",
      "batch 199, ep 150, training accuracy 0.895\n",
      "f : 9880.71191406, q : 92874.71875, p : 83952.9453125, l : 904.339355469\n",
      "valid accuracy 0.9007\n",
      "batch 200, ep 0, training accuracy 0.905\n",
      "f : 9335.27539062, q : 92971.3125, p : 84094.625, l : 545.90625\n",
      "batch 200, ep 50, training accuracy 0.925\n",
      "f : 9877.7578125, q : 92833.421875, p : 83408.859375, l : 465.998809814\n",
      "batch 200, ep 100, training accuracy 0.92\n",
      "f : 9543.95605469, q : 92955.3125, p : 83882.484375, l : 464.676940918\n",
      "batch 200, ep 150, training accuracy 0.925\n",
      "f : 9412.04492188, q : 92963.9921875, p : 83981.96875, l : 462.928771973\n",
      "valid accuracy 0.9013\n",
      "batch 201, ep 0, training accuracy 0.925\n",
      "f : 9407.32226562, q : 92882.9609375, p : 84064.1875, l : 602.735656738\n",
      "batch 201, ep 50, training accuracy 0.92\n",
      "f : 9954.26855469, q : 92840.484375, p : 83434.75, l : 505.467376709\n",
      "batch 201, ep 100, training accuracy 0.92\n",
      "f : 9597.47460938, q : 92846.1015625, p : 83768.6796875, l : 504.873291016\n",
      "batch 201, ep 150, training accuracy 0.92\n",
      "f : 9422.92578125, q : 92810.59375, p : 83952.1171875, l : 506.660003662\n",
      "valid accuracy 0.9026\n",
      "batch 202, ep 0, training accuracy 0.91\n",
      "f : 9422.24609375, q : 92888.8203125, p : 84101.015625, l : 618.681030273\n",
      "batch 202, ep 50, training accuracy 0.925\n",
      "f : 9919.17578125, q : 92791.828125, p : 83388.515625, l : 530.120056152\n",
      "batch 202, ep 100, training accuracy 0.93\n",
      "f : 9614.85644531, q : 92823.5703125, p : 83802.2109375, l : 529.970458984\n",
      "batch 202, ep 150, training accuracy 0.925\n",
      "f : 9455.26757812, q : 92817.7265625, p : 84021.3984375, l : 531.187561035\n",
      "valid accuracy 0.9017\n",
      "batch 203, ep 0, training accuracy 0.92\n",
      "f : 9320.02148438, q : 92789.671875, p : 84103.59375, l : 525.976196289\n",
      "batch 203, ep 50, training accuracy 0.915\n",
      "f : 9866.25195312, q : 92852.5625, p : 83539.7421875, l : 470.396636963\n",
      "batch 203, ep 100, training accuracy 0.925\n",
      "f : 9546.34375, q : 92865.5703125, p : 83856.265625, l : 470.295776367\n",
      "batch 203, ep 150, training accuracy 0.925\n",
      "f : 9404.2109375, q : 92786.0546875, p : 83850.7109375, l : 464.866210938\n",
      "valid accuracy 0.9022\n",
      "batch 204, ep 0, training accuracy 0.895\n",
      "f : 9389.72167969, q : 92837.6015625, p : 83967.28125, l : 591.102783203\n",
      "batch 204, ep 50, training accuracy 0.9\n",
      "f : 9933.20019531, q : 92804.4140625, p : 83322.515625, l : 497.665618896\n",
      "batch 204, ep 100, training accuracy 0.905\n",
      "f : 9580.19238281, q : 92767.8359375, p : 83712.703125, l : 502.240661621\n",
      "batch 204, ep 150, training accuracy 0.9\n",
      "f : 9449.00097656, q : 92760.2734375, p : 83776.2890625, l : 500.008178711\n",
      "valid accuracy 0.9026\n",
      "batch 205, ep 0, training accuracy 0.93\n",
      "f : 9461.17578125, q : 92764.3046875, p : 84001.171875, l : 665.117553711\n",
      "batch 205, ep 50, training accuracy 0.94\n",
      "f : 9990.68652344, q : 92718.4453125, p : 83271.328125, l : 564.686279297\n",
      "batch 205, ep 100, training accuracy 0.94\n",
      "f : 9662.94433594, q : 92786.2265625, p : 83699.7421875, l : 567.55090332\n",
      "batch 205, ep 150, training accuracy 0.945\n",
      "f : 9530.62988281, q : 92708.46875, p : 83834.5, l : 564.483642578\n",
      "valid accuracy 0.9011\n",
      "batch 206, ep 0, training accuracy 0.835\n",
      "f : 10035.8671875, q : 92741.5, p : 83930.1640625, l : 1231.13305664\n",
      "batch 206, ep 50, training accuracy 0.875\n",
      "f : 10495.96875, q : 92762.8125, p : 83262.5, l : 1002.70849609\n",
      "batch 206, ep 100, training accuracy 0.865\n",
      "f : 10135.1552734, q : 92755.125, p : 83686.6875, l : 1006.69555664\n",
      "batch 206, ep 150, training accuracy 0.87\n",
      "f : 10024.6640625, q : 92725.6484375, p : 83756.796875, l : 1021.12658691\n",
      "valid accuracy 0.9031\n",
      "batch 207, ep 0, training accuracy 0.85\n",
      "f : 9891.95507812, q : 92770.609375, p : 84044.484375, l : 1107.50708008\n",
      "batch 207, ep 50, training accuracy 0.865\n",
      "f : 10396.8623047, q : 92685.0234375, p : 83175.984375, l : 932.709411621\n",
      "batch 207, ep 100, training accuracy 0.865\n",
      "f : 10054.2490234, q : 92677.2265625, p : 83624.2734375, l : 931.470214844\n",
      "batch 207, ep 150, training accuracy 0.86\n",
      "f : 9933.74707031, q : 92778.1796875, p : 83822.1171875, l : 927.34387207\n",
      "valid accuracy 0.9029\n",
      "batch 208, ep 0, training accuracy 0.92\n",
      "f : 9208.11035156, q : 92639.46875, p : 83889.6640625, l : 415.240844727\n",
      "batch 208, ep 50, training accuracy 0.93\n",
      "f : 9755.71875, q : 92739.40625, p : 83212.5234375, l : 355.628723145\n",
      "batch 208, ep 100, training accuracy 0.925\n",
      "f : 9436.4296875, q : 92642.5625, p : 83658.2734375, l : 353.912231445\n",
      "batch 208, ep 150, training accuracy 0.93\n",
      "f : 9306.73242188, q : 92648.6015625, p : 83812.5546875, l : 359.002166748\n",
      "valid accuracy 0.9008\n",
      "batch 209, ep 0, training accuracy 0.89\n",
      "f : 9548.75195312, q : 92654.875, p : 83963.2890625, l : 750.240600586\n",
      "batch 209, ep 50, training accuracy 0.91\n",
      "f : 10070.8984375, q : 92715.671875, p : 83230.25, l : 644.789123535\n",
      "batch 209, ep 100, training accuracy 0.91\n",
      "f : 9749.95996094, q : 92768.8125, p : 83525.8828125, l : 640.361206055\n",
      "batch 209, ep 150, training accuracy 0.905\n",
      "f : 9607.26660156, q : 92709.6328125, p : 83645.203125, l : 641.586669922\n",
      "valid accuracy 0.8999\n",
      "batch 210, ep 0, training accuracy 0.9\n",
      "f : 9673.5859375, q : 92732.8125, p : 83812.234375, l : 882.455627441\n",
      "batch 210, ep 50, training accuracy 0.905\n",
      "f : 10165.8476562, q : 92699.4609375, p : 83247.8515625, l : 716.800964355\n",
      "batch 210, ep 100, training accuracy 0.905\n",
      "f : 9826.4609375, q : 92631.921875, p : 83514.6875, l : 719.532531738\n",
      "batch 210, ep 150, training accuracy 0.905\n",
      "f : 9680.46484375, q : 92674.34375, p : 83685.5625, l : 711.393676758\n",
      "valid accuracy 0.9021\n",
      "batch 211, ep 0, training accuracy 0.855\n",
      "f : 9702.98828125, q : 92538.140625, p : 83848.046875, l : 905.291870117\n",
      "batch 211, ep 50, training accuracy 0.87\n",
      "f : 10209.3994141, q : 92663.421875, p : 83142.21875, l : 786.632080078\n",
      "batch 211, ep 100, training accuracy 0.87\n",
      "f : 9887.46679688, q : 92599.953125, p : 83480.8828125, l : 797.291137695\n",
      "batch 211, ep 150, training accuracy 0.87\n",
      "f : 9734.63085938, q : 92617.546875, p : 83664.96875, l : 784.98651123\n",
      "valid accuracy 0.9026\n",
      "batch 212, ep 0, training accuracy 0.87\n",
      "f : 9983.04980469, q : 92683.8359375, p : 83883.2265625, l : 1188.71398926\n",
      "batch 212, ep 50, training accuracy 0.885\n",
      "f : 10453.8134766, q : 92562.671875, p : 83217.75, l : 992.96697998\n",
      "batch 212, ep 100, training accuracy 0.885\n",
      "f : 10116.5332031, q : 92571.21875, p : 83421.140625, l : 993.359436035\n",
      "batch 212, ep 150, training accuracy 0.885\n",
      "f : 9986.37792969, q : 92642.15625, p : 83625.0078125, l : 989.243530273\n",
      "valid accuracy 0.9044\n",
      "batch 213, ep 0, training accuracy 0.9\n",
      "f : 9595.13671875, q : 92637.1484375, p : 83781.53125, l : 794.114135742\n",
      "batch 213, ep 50, training accuracy 0.9\n",
      "f : 11139.859375, q : 92591.9453125, p : 82057.671875, l : 704.587158203\n",
      "batch 213, ep 100, training accuracy 0.895\n",
      "f : 9784.36132812, q : 92547.9296875, p : 83445.046875, l : 703.141052246\n",
      "batch 213, ep 150, training accuracy 0.9\n",
      "f : 9659.28613281, q : 92545.5546875, p : 83626.8515625, l : 700.657958984\n",
      "valid accuracy 0.9047\n",
      "batch 214, ep 0, training accuracy 0.855\n",
      "f : 10037.0839844, q : 92478.9765625, p : 83807.0625, l : 1251.83764648\n",
      "batch 214, ep 50, training accuracy 0.875\n",
      "f : 10539.8056641, q : 92490.2265625, p : 83181.1484375, l : 1107.91577148\n",
      "batch 214, ep 100, training accuracy 0.875\n",
      "f : 10206.8916016, q : 92415.90625, p : 83474.8046875, l : 1119.80725098\n",
      "batch 214, ep 150, training accuracy 0.87\n",
      "f : 10086.4775391, q : 92500.6953125, p : 83624.5, l : 1110.33056641\n",
      "valid accuracy 0.9056\n",
      "batch 215, ep 0, training accuracy 0.88\n",
      "f : 9501.42675781, q : 92585.6328125, p : 83753.03125, l : 704.474731445\n",
      "batch 215, ep 50, training accuracy 0.91\n",
      "f : 9978.09472656, q : 92592.703125, p : 83135.15625, l : 574.466918945\n",
      "batch 215, ep 100, training accuracy 0.905\n",
      "f : 9684.40039062, q : 92604.2578125, p : 83376.375, l : 569.966918945\n",
      "batch 215, ep 150, training accuracy 0.91\n",
      "f : 9527.5546875, q : 92479.765625, p : 83583.21875, l : 569.171142578\n",
      "valid accuracy 0.9026\n",
      "batch 216, ep 0, training accuracy 0.92\n",
      "f : 9267.11816406, q : 92594.359375, p : 83749.734375, l : 470.878662109\n",
      "batch 216, ep 50, training accuracy 0.93\n",
      "f : 9822.15917969, q : 92504.5703125, p : 83130.6171875, l : 417.504058838\n",
      "batch 216, ep 100, training accuracy 0.93\n",
      "f : 9491.34863281, q : 92472.421875, p : 83386.609375, l : 425.902038574\n",
      "batch 216, ep 150, training accuracy 0.93\n",
      "f : 9348.01171875, q : 92472.5859375, p : 83611.2578125, l : 416.348175049\n",
      "valid accuracy 0.9036\n",
      "batch 217, ep 0, training accuracy 0.92\n",
      "f : 9219.62890625, q : 92484.0859375, p : 83738.8828125, l : 422.16607666\n",
      "batch 217, ep 50, training accuracy 0.92\n",
      "f : 9756.97949219, q : 92517.4453125, p : 83123.0703125, l : 372.990264893\n",
      "batch 217, ep 100, training accuracy 0.925\n",
      "f : 9438.66992188, q : 92419.71875, p : 83386.4921875, l : 371.952056885\n",
      "batch 217, ep 150, training accuracy 0.92\n",
      "f : 9276.84082031, q : 92436.9375, p : 83517.0625, l : 368.935180664\n",
      "valid accuracy 0.9048\n",
      "batch 218, ep 0, training accuracy 0.915\n",
      "f : 9391.01367188, q : 92473.4921875, p : 83714.453125, l : 597.797912598\n",
      "batch 218, ep 50, training accuracy 0.915\n",
      "f : 9906.41796875, q : 92458.8671875, p : 83099.2890625, l : 505.384765625\n",
      "batch 218, ep 100, training accuracy 0.925\n",
      "f : 9582.05175781, q : 92467.5625, p : 83357.8515625, l : 498.866027832\n",
      "batch 218, ep 150, training accuracy 0.91\n",
      "f : 9459.05859375, q : 92407.390625, p : 83518.234375, l : 505.643737793\n",
      "valid accuracy 0.904\n",
      "batch 219, ep 0, training accuracy 0.88\n",
      "f : 9602.33203125, q : 92463.84375, p : 83620.0390625, l : 813.928344727\n",
      "batch 219, ep 50, training accuracy 0.885\n",
      "f : 10114.8535156, q : 92358.7890625, p : 83056.40625, l : 704.002441406\n",
      "batch 219, ep 100, training accuracy 0.885\n",
      "f : 9794.02148438, q : 92486.0546875, p : 83350.375, l : 712.486938477\n",
      "batch 219, ep 150, training accuracy 0.885\n",
      "f : 9659.08886719, q : 92443.3515625, p : 83439.015625, l : 705.520080566\n",
      "valid accuracy 0.9047\n",
      "batch 220, ep 0, training accuracy 0.885\n",
      "f : 9501.77539062, q : 92417.625, p : 83554.390625, l : 705.430297852\n",
      "batch 220, ep 50, training accuracy 0.88\n",
      "f : 10020.7021484, q : 92428.203125, p : 82962.75, l : 599.483764648\n",
      "batch 220, ep 100, training accuracy 0.9\n",
      "f : 9709.9375, q : 92434.7265625, p : 83249.21875, l : 601.789428711\n",
      "batch 220, ep 150, training accuracy 0.885\n",
      "f : 9548.18847656, q : 92375.2578125, p : 83412.3046875, l : 595.691650391\n",
      "valid accuracy 0.9032\n",
      "batch 221, ep 0, training accuracy 0.87\n",
      "f : 9881.41992188, q : 92373.7734375, p : 83458.359375, l : 1079.76513672\n",
      "batch 221, ep 50, training accuracy 0.895\n",
      "f : 10365.6816406, q : 92370.4921875, p : 82993.859375, l : 931.004394531\n",
      "batch 221, ep 100, training accuracy 0.895\n",
      "f : 10045.4609375, q : 92427.21875, p : 83251.859375, l : 937.867004395\n",
      "batch 221, ep 150, training accuracy 0.895\n",
      "f : 9881.60546875, q : 92379.40625, p : 83417.703125, l : 931.575805664\n",
      "valid accuracy 0.9033\n",
      "batch 222, ep 0, training accuracy 0.915\n",
      "f : 9497.37890625, q : 92336.375, p : 83533.1484375, l : 702.645446777\n",
      "batch 222, ep 50, training accuracy 0.92\n",
      "f : 10017.8515625, q : 92326.109375, p : 82992.609375, l : 611.18737793\n",
      "batch 222, ep 100, training accuracy 0.92\n",
      "f : 9703.53613281, q : 92296.6875, p : 83287.46875, l : 620.955322266\n",
      "batch 222, ep 150, training accuracy 0.92\n",
      "f : 9539.86328125, q : 92363.4140625, p : 83419.265625, l : 625.075683594\n",
      "valid accuracy 0.9044\n",
      "batch 223, ep 0, training accuracy 0.92\n",
      "f : 9320.83984375, q : 92240.59375, p : 83560.015625, l : 530.195678711\n",
      "batch 223, ep 50, training accuracy 0.93\n",
      "f : 9833.38769531, q : 92328.78125, p : 83001.1015625, l : 445.721282959\n",
      "batch 223, ep 100, training accuracy 0.935\n",
      "f : 9524.34863281, q : 92339.7421875, p : 83175.703125, l : 443.182617188\n",
      "batch 223, ep 150, training accuracy 0.93\n",
      "f : 9391.17089844, q : 92331.96875, p : 83362.703125, l : 447.951843262\n",
      "valid accuracy 0.9049\n",
      "batch 224, ep 0, training accuracy 0.835\n",
      "f : 9929.76367188, q : 92234.1015625, p : 83558.7578125, l : 1130.57678223\n",
      "batch 224, ep 50, training accuracy 0.85\n",
      "f : 10395.4824219, q : 92368.40625, p : 82891.5703125, l : 972.881469727\n",
      "batch 224, ep 100, training accuracy 0.855\n",
      "f : 10085.8408203, q : 92226.3203125, p : 83187.3828125, l : 986.817199707\n",
      "batch 224, ep 150, training accuracy 0.85\n",
      "f : 9958.66894531, q : 92222.6640625, p : 83230.1875, l : 982.561096191\n",
      "valid accuracy 0.9041\n",
      "batch 225, ep 0, training accuracy 0.86\n",
      "f : 9759.0625, q : 92308.625, p : 83467.4140625, l : 959.536743164\n",
      "batch 225, ep 50, training accuracy 0.89\n",
      "f : 10209.0458984, q : 92252.8203125, p : 82888.1953125, l : 807.671875\n",
      "batch 225, ep 100, training accuracy 0.88\n",
      "f : 9920.140625, q : 92320.3828125, p : 83168.3828125, l : 813.325073242\n",
      "batch 225, ep 150, training accuracy 0.89\n",
      "f : 9750.90527344, q : 92330.34375, p : 83375.8984375, l : 820.577880859\n",
      "valid accuracy 0.9025\n",
      "batch 226, ep 0, training accuracy 0.905\n",
      "f : 9319.19238281, q : 92239.6328125, p : 83422.640625, l : 520.329223633\n",
      "batch 226, ep 50, training accuracy 0.915\n",
      "f : 9830.64257812, q : 92192.5546875, p : 82922.4296875, l : 443.024475098\n",
      "batch 226, ep 100, training accuracy 0.92\n",
      "f : 9513.45800781, q : 92286.40625, p : 83192.3828125, l : 444.196868896\n",
      "batch 226, ep 150, training accuracy 0.915\n",
      "f : 9391.29980469, q : 92288.5, p : 83356.890625, l : 450.531188965\n",
      "valid accuracy 0.9017\n",
      "batch 227, ep 0, training accuracy 0.84\n",
      "f : 9928.72558594, q : 92202.2734375, p : 83468.765625, l : 1138.67456055\n",
      "batch 227, ep 50, training accuracy 0.855\n",
      "f : 10405.8027344, q : 92313.640625, p : 82848.296875, l : 985.052185059\n",
      "batch 227, ep 100, training accuracy 0.85\n",
      "f : 10100.1083984, q : 92236.1015625, p : 83237.25, l : 982.301452637\n",
      "batch 227, ep 150, training accuracy 0.855\n",
      "f : 9966.45703125, q : 92212.578125, p : 83158.0234375, l : 992.542236328\n",
      "valid accuracy 0.9046\n",
      "batch 228, ep 0, training accuracy 0.89\n",
      "f : 9538.05664062, q : 92196.3359375, p : 83457.9765625, l : 751.927307129\n",
      "batch 228, ep 50, training accuracy 0.89\n",
      "f : 10048.4726562, q : 92173.4375, p : 82760.8359375, l : 648.621948242\n",
      "batch 228, ep 100, training accuracy 0.89\n",
      "f : 9733.16210938, q : 92171.84375, p : 83112.0390625, l : 640.18157959\n",
      "batch 228, ep 150, training accuracy 0.89\n",
      "f : 9598.00390625, q : 92165.9453125, p : 83183.3125, l : 652.597961426\n",
      "valid accuracy 0.9035\n",
      "batch 229, ep 0, training accuracy 0.86\n",
      "f : 9706.81542969, q : 92211.7265625, p : 83444.3671875, l : 909.562927246\n",
      "batch 229, ep 50, training accuracy 0.87\n",
      "f : 10192.9794922, q : 92206.1328125, p : 82869.890625, l : 812.635009766\n",
      "batch 229, ep 100, training accuracy 0.875\n",
      "f : 9899.08398438, q : 92234.8359375, p : 83013.859375, l : 818.725952148\n",
      "batch 229, ep 150, training accuracy 0.87\n",
      "f : 9753.95800781, q : 92233.3828125, p : 83280.5078125, l : 814.039794922\n",
      "valid accuracy 0.9041\n",
      "batch 230, ep 0, training accuracy 0.85\n",
      "f : 9892.02148438, q : 92229.6484375, p : 83424.75, l : 1094.44213867\n",
      "batch 230, ep 50, training accuracy 0.855\n",
      "f : 10339.4277344, q : 92215.375, p : 82688.65625, l : 929.234619141\n",
      "batch 230, ep 100, training accuracy 0.855\n",
      "f : 10034.5488281, q : 92254.3046875, p : 83019.6171875, l : 932.676025391\n",
      "batch 230, ep 150, training accuracy 0.855\n",
      "f : 9901.20800781, q : 92184.21875, p : 83194.0859375, l : 929.352600098\n",
      "valid accuracy 0.9063\n",
      "batch 231, ep 0, training accuracy 0.84\n",
      "f : 9955.57910156, q : 92173.6953125, p : 83366.796875, l : 1155.73193359\n",
      "batch 231, ep 50, training accuracy 0.86\n",
      "f : 10444.4921875, q : 92107.4765625, p : 82670.53125, l : 1038.86877441\n",
      "batch 231, ep 100, training accuracy 0.86\n",
      "f : 10124.9951172, q : 92216.125, p : 83027.703125, l : 1039.0279541\n",
      "batch 231, ep 150, training accuracy 0.86\n",
      "f : 10003.5322266, q : 92047.265625, p : 83205.609375, l : 1039.38171387\n",
      "valid accuracy 0.9047\n",
      "batch 232, ep 0, training accuracy 0.9\n",
      "f : 9407.03417969, q : 92095.8359375, p : 83294.28125, l : 614.008850098\n",
      "batch 232, ep 50, training accuracy 0.91\n",
      "f : 9903.93945312, q : 92149.7890625, p : 82700.71875, l : 538.293457031\n",
      "batch 232, ep 100, training accuracy 0.905\n",
      "f : 9620.05371094, q : 92121.546875, p : 83124.0625, l : 535.450927734\n",
      "batch 232, ep 150, training accuracy 0.905\n",
      "f : 9473.64941406, q : 92214.46875, p : 83135.8046875, l : 538.241821289\n",
      "valid accuracy 0.904\n",
      "batch 233, ep 0, training accuracy 0.93\n",
      "f : 9298.68847656, q : 92041.8359375, p : 83314.921875, l : 505.092163086\n",
      "batch 233, ep 50, training accuracy 0.94\n",
      "f : 9819.03808594, q : 92046.5546875, p : 82715.0078125, l : 440.029510498\n",
      "batch 233, ep 100, training accuracy 0.94\n",
      "f : 9513.21679688, q : 92177.671875, p : 82936.359375, l : 438.920715332\n",
      "batch 233, ep 150, training accuracy 0.94\n",
      "f : 9339.03808594, q : 92084.3046875, p : 83125.421875, l : 437.704345703\n",
      "valid accuracy 0.9045\n",
      "batch 234, ep 0, training accuracy 0.92\n",
      "f : 9311.27636719, q : 92079.140625, p : 83195.6796875, l : 518.886474609\n",
      "batch 234, ep 50, training accuracy 0.925\n",
      "f : 9831.63476562, q : 92070.5546875, p : 82628.359375, l : 442.100158691\n",
      "batch 234, ep 100, training accuracy 0.925\n",
      "f : 9509.18652344, q : 92093.015625, p : 83007.3515625, l : 440.010253906\n",
      "batch 234, ep 150, training accuracy 0.925\n",
      "f : 9358.45898438, q : 91993.65625, p : 83147.515625, l : 444.847717285\n",
      "valid accuracy 0.9061\n",
      "batch 235, ep 0, training accuracy 0.89\n",
      "f : 9566.75585938, q : 92051.3515625, p : 83296.171875, l : 775.082946777\n",
      "batch 235, ep 50, training accuracy 0.92\n",
      "f : 10059.9365234, q : 92038.859375, p : 82682.234375, l : 670.396118164\n",
      "batch 235, ep 100, training accuracy 0.92\n",
      "f : 9760.18261719, q : 92047.140625, p : 82948.09375, l : 663.217834473\n",
      "batch 235, ep 150, training accuracy 0.92\n",
      "f : 9618.54101562, q : 92037.109375, p : 83052.3671875, l : 663.369506836\n",
      "valid accuracy 0.9044\n",
      "batch 236, ep 0, training accuracy 0.845\n",
      "f : 10049.5, q : 92097.734375, p : 83240.5078125, l : 1261.65649414\n",
      "batch 236, ep 50, training accuracy 0.87\n",
      "f : 10502.8203125, q : 92017.4921875, p : 82567.453125, l : 1061.59277344\n",
      "batch 236, ep 100, training accuracy 0.87\n",
      "f : 10190.4003906, q : 91969.3359375, p : 82908.125, l : 1067.51464844\n",
      "batch 236, ep 150, training accuracy 0.865\n",
      "f : 10027.6191406, q : 91950.953125, p : 83097.546875, l : 1072.39355469\n",
      "valid accuracy 0.9042\n",
      "batch 237, ep 0, training accuracy 0.865\n",
      "f : 9776.28027344, q : 92005.8125, p : 83142.5546875, l : 974.451721191\n",
      "batch 237, ep 50, training accuracy 0.88\n",
      "f : 10229.8564453, q : 91933.1953125, p : 82634.5234375, l : 829.258056641\n",
      "batch 237, ep 100, training accuracy 0.88\n",
      "f : 9920.11425781, q : 92066.0546875, p : 82851.0625, l : 827.089233398\n",
      "batch 237, ep 150, training accuracy 0.88\n",
      "f : 9810.64160156, q : 91976.2578125, p : 82883.453125, l : 821.465698242\n",
      "valid accuracy 0.903\n",
      "batch 238, ep 0, training accuracy 0.865\n",
      "f : 9765.88867188, q : 91950.109375, p : 83163.9140625, l : 976.403076172\n",
      "batch 238, ep 50, training accuracy 0.875\n",
      "f : 10198.2197266, q : 91963.75, p : 82495.25, l : 801.298706055\n",
      "batch 238, ep 100, training accuracy 0.865\n",
      "f : 9899.94238281, q : 91974.1328125, p : 82849.2421875, l : 798.470031738\n",
      "batch 238, ep 150, training accuracy 0.88\n",
      "f : 9787.43652344, q : 92046.6484375, p : 82889.5390625, l : 789.479553223\n",
      "valid accuracy 0.9048\n",
      "batch 239, ep 0, training accuracy 0.915\n",
      "f : 9503.63476562, q : 91973.65625, p : 83196.5, l : 704.580688477\n",
      "batch 239, ep 50, training accuracy 0.92\n",
      "f : 9946.47265625, q : 91931.1015625, p : 82494.703125, l : 579.963806152\n",
      "batch 239, ep 100, training accuracy 0.92\n",
      "f : 9655.53027344, q : 91941.0703125, p : 82788.9921875, l : 570.730712891\n",
      "batch 239, ep 150, training accuracy 0.92\n",
      "f : 9522.72851562, q : 91936.265625, p : 83044.171875, l : 569.850158691\n",
      "valid accuracy 0.9047\n",
      "batch 240, ep 0, training accuracy 0.92\n",
      "f : 9266.11523438, q : 91916.5, p : 83144.7734375, l : 470.748901367\n",
      "batch 240, ep 50, training accuracy 0.93\n",
      "f : 9754.05957031, q : 91934.796875, p : 82542.5546875, l : 379.020507812\n",
      "batch 240, ep 100, training accuracy 0.935\n",
      "f : 9441.95019531, q : 91960.765625, p : 82925.46875, l : 376.480895996\n",
      "batch 240, ep 150, training accuracy 0.935\n",
      "f : 9288.56738281, q : 91893.390625, p : 82982.828125, l : 377.352966309\n",
      "valid accuracy 0.9048\n",
      "batch 241, ep 0, training accuracy 0.89\n",
      "f : 9601.54589844, q : 91909.9609375, p : 83025.2734375, l : 809.982666016\n",
      "batch 241, ep 50, training accuracy 0.89\n",
      "f : 10077.5722656, q : 91871.2734375, p : 82502.4609375, l : 693.14630127\n",
      "batch 241, ep 100, training accuracy 0.885\n",
      "f : 9768.07226562, q : 91969.984375, p : 82775.5078125, l : 694.323303223\n",
      "batch 241, ep 150, training accuracy 0.89\n",
      "f : 9645.57128906, q : 91928.203125, p : 82899.5625, l : 696.343261719\n",
      "valid accuracy 0.905\n",
      "batch 242, ep 0, training accuracy 0.925\n",
      "f : 9240.34472656, q : 91968.3359375, p : 83146.9375, l : 456.243041992\n",
      "batch 242, ep 50, training accuracy 0.94\n",
      "f : 9759.73730469, q : 91798.6953125, p : 82491.6875, l : 387.696075439\n",
      "batch 242, ep 100, training accuracy 0.935\n",
      "f : 9455.67089844, q : 91886.453125, p : 82816.1953125, l : 390.292694092\n",
      "batch 242, ep 150, training accuracy 0.94\n",
      "f : 9310.02929688, q : 91874.5546875, p : 82905.6328125, l : 393.291473389\n",
      "valid accuracy 0.9044\n",
      "batch 243, ep 0, training accuracy 0.92\n",
      "f : 9195.42285156, q : 91873.5078125, p : 83063.9921875, l : 399.619110107\n",
      "batch 243, ep 50, training accuracy 0.95\n",
      "f : 9677.44726562, q : 91874.125, p : 82484.5390625, l : 327.438537598\n",
      "batch 243, ep 100, training accuracy 0.945\n",
      "f : 9398.01660156, q : 91950.0, p : 82740.375, l : 328.129882812\n",
      "batch 243, ep 150, training accuracy 0.95\n",
      "f : 9259.92578125, q : 91876.734375, p : 82826.328125, l : 329.703613281\n",
      "valid accuracy 0.9055\n",
      "batch 244, ep 0, training accuracy 0.88\n",
      "f : 9656.00195312, q : 91821.984375, p : 83125.2890625, l : 867.692687988\n",
      "batch 244, ep 50, training accuracy 0.89\n",
      "f : 10137.6630859, q : 91807.9296875, p : 82419.2265625, l : 733.48828125\n",
      "batch 244, ep 100, training accuracy 0.885\n",
      "f : 9822.88574219, q : 91765.21875, p : 82750.6875, l : 735.436096191\n",
      "batch 244, ep 150, training accuracy 0.885\n",
      "f : 9671.50292969, q : 91741.9375, p : 82937.7578125, l : 728.070800781\n",
      "valid accuracy 0.9037\n",
      "batch 245, ep 0, training accuracy 0.865\n",
      "f : 9776.484375, q : 91807.2265625, p : 83027.5703125, l : 983.934814453\n",
      "batch 245, ep 50, training accuracy 0.88\n",
      "f : 10248.7392578, q : 91763.1484375, p : 82346.5703125, l : 852.520385742\n",
      "batch 245, ep 100, training accuracy 0.875\n",
      "f : 9952.75976562, q : 91791.328125, p : 82712.046875, l : 845.676635742\n",
      "batch 245, ep 150, training accuracy 0.88\n",
      "f : 9776.125, q : 91784.640625, p : 82941.96875, l : 845.563110352\n",
      "valid accuracy 0.9054\n",
      "batch 246, ep 0, training accuracy 0.89\n",
      "f : 9481.73632812, q : 91816.2421875, p : 83066.578125, l : 683.892211914\n",
      "batch 246, ep 50, training accuracy 0.925\n",
      "f : 9967.26269531, q : 91711.390625, p : 82340.453125, l : 565.16796875\n",
      "batch 246, ep 100, training accuracy 0.92\n",
      "f : 9646.03125, q : 91766.328125, p : 82667.671875, l : 570.608581543\n",
      "batch 246, ep 150, training accuracy 0.915\n",
      "f : 9519.66796875, q : 91743.890625, p : 82819.046875, l : 564.99798584\n",
      "valid accuracy 0.9056\n",
      "batch 247, ep 0, training accuracy 0.795\n",
      "f : 10232.3769531, q : 91747.4375, p : 82916.078125, l : 1450.40344238\n",
      "batch 247, ep 50, training accuracy 0.825\n",
      "f : 10609.9326172, q : 91777.109375, p : 82309.3359375, l : 1168.61914062\n",
      "batch 247, ep 100, training accuracy 0.82\n",
      "f : 10339.2822266, q : 91633.1171875, p : 82707.34375, l : 1163.56030273\n",
      "batch 247, ep 150, training accuracy 0.825\n",
      "f : 10200.9453125, q : 91796.515625, p : 82736.5, l : 1166.94873047\n",
      "valid accuracy 0.9023\n",
      "batch 248, ep 0, training accuracy 0.88\n",
      "f : 9723.40429688, q : 91830.2265625, p : 82917.6328125, l : 917.332214355\n",
      "batch 248, ep 50, training accuracy 0.9\n",
      "f : 10167.8398438, q : 91729.3515625, p : 82351.375, l : 777.300842285\n",
      "batch 248, ep 100, training accuracy 0.885\n",
      "f : 9877.90039062, q : 91685.375, p : 82624.2578125, l : 773.311828613\n",
      "batch 248, ep 150, training accuracy 0.89\n",
      "f : 9706.85644531, q : 91699.9609375, p : 82787.7734375, l : 780.577392578\n",
      "valid accuracy 0.9057\n",
      "batch 249, ep 0, training accuracy 0.865\n",
      "f : 9953.60351562, q : 91747.109375, p : 82891.4921875, l : 1151.50732422\n",
      "batch 249, ep 50, training accuracy 0.885\n",
      "f : 10338.8964844, q : 91742.8359375, p : 82185.6328125, l : 884.469787598\n",
      "batch 249, ep 100, training accuracy 0.885\n",
      "f : 10034.1826172, q : 91677.4296875, p : 82571.859375, l : 881.055541992\n",
      "batch 249, ep 150, training accuracy 0.885\n",
      "f : 9894.85839844, q : 91704.734375, p : 82708.625, l : 881.246032715\n",
      "valid accuracy 0.9055\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for i in range(n_batches):\n",
    "    \n",
    "    bnn.reset_lr()\n",
    "    \n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        feed = {bnn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "        \n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "        #if ep > 5 and np.mean(fs[-25:]) < np.mean(fs[-15:]):\n",
    "        if ep > 5 and np.mean(fs[-25:]) < v_f:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "                \n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "            \n",
    "            \n",
    "#             print (\"--- learning rate decayed ---\")\n",
    "#             print bnn.get_lr()\n",
    "\n",
    "        if ep % 50 == 0:\n",
    "            train_accuracy = bnn.validate(feed)\n",
    "\n",
    "            print(\"batch %d, ep %d, training accuracy %g\"%(i, ep, train_accuracy))\n",
    "            print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        bnn.train(feed)\n",
    "        \n",
    "    vacc = bnn.validate({bnn.x: x_valid, bnn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict ={bnn.x: x_valid, bnn.t: t_valid})\n",
    "    test_writer.add_summary(summary, i)\n",
    "    \n",
    "#     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "#         bnn.decay_lr()\n",
    "    \n",
    "    bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEACAYAAAD4NNLwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff39deda910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB72ZWeYc9GZmmfsVdRBVAhFdO1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3d6e84dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Online version + EWC with rho_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer done\n",
      "layer done\n",
      "(10, ?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-6-521779afb03f>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-521779afb03f>:8 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-521779afb03f>:9 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-521779afb03f>:9 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n"
     ]
    }
   ],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-5.0, 1.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False, train_rho = True, only_loglike = False, ewc = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, ep 0, training accuracy 0.13\n",
      "f : 202074.671875, q : 142556.53125, p : -54964.109375, l : 4613.77050781\n",
      "batch 0, ep 50, training accuracy 0.74\n",
      "f : 197856.96875, q : 140581.453125, p : -54972.4726562, l : 2377.52807617\n",
      "batch 0, ep 100, training accuracy 0.945\n",
      "f : 194393.984375, q : 138568.890625, p : -54990.0898438, l : 843.247314453\n",
      "batch 0, ep 150, training accuracy 0.99\n",
      "f : 191964.390625, q : 136465.609375, p : -55002.8164062, l : 367.646057129\n",
      "layer0/q_pos/mu:0\n",
      "max: 0.574779093266, min: -0.607787549496, mean: 0.000433833221905, std: 0.0849701985717\n",
      "layer0/q_pos/rho:0\n",
      "max: -0.983308315277, min: -1.00497055054, mean: -0.995843231678, std: 0.000728058745153\n",
      "layer1/q_pos/mu:0\n",
      "max: 2.10006117821, min: -2.11797761917, mean: 8.38649066282e-05, std: 0.771158874035\n",
      "layer1/q_pos/rho:0\n",
      "max: -0.960147321224, min: -1.02143192291, mean: -0.995382487774, std: 0.00712784193456\n",
      "valid accuracy 0.7811\n",
      "batch 1, ep 0, training accuracy 0.825\n",
      "f : 9982.43066406, q : 134689.5, p : 125735.742188, l : 1140.55151367\n",
      "batch 1, ep 50, training accuracy 0.94\n",
      "f : 194007.046875, q : 134120.25, p : -59354.0273438, l : 552.10925293\n",
      "batch 1, ep 100, training accuracy 0.97\n",
      "f : 168429.015625, q : 133940.078125, p : -33986.1953125, l : 470.452026367\n",
      "batch 1, ep 150, training accuracy 0.975\n",
      "f : 152558.421875, q : 133854.15625, p : -18287.5410156, l : 420.223754883\n",
      "layer0/q_pos/mu:0\n",
      "max: 102.462173462, min: -96.7948913574, mean: -0.125466957688, std: 11.465294838\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.09610652924, min: -3.69348192215, mean: -0.408622205257, std: 0.621213853359\n",
      "layer1/q_pos/mu:0\n",
      "max: 49.0307426453, min: -90.8923797607, mean: -0.205567240715, std: 11.5995883942\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.36199975014, min: -2.10150027275, mean: -0.400654107332, std: 0.599153220654\n",
      "valid accuracy 0.8331\n",
      "batch 2, ep 0, training accuracy 0.82\n",
      "f : 10028.3320312, q : 133815.796875, p : 124888.953125, l : 1184.80371094\n",
      "batch 2, ep 50, training accuracy 0.94\n",
      "f : 153123.734375, q : 133349.6875, p : -19221.9902344, l : 573.483642578\n",
      "batch 2, ep 100, training accuracy 0.97\n",
      "f : 127822.835938, q : 133200.703125, p : 5819.41699219, l : 497.971069336\n",
      "batch 2, ep 150, training accuracy 0.97\n",
      "f : 113670.203125, q : 133143.796875, p : 20002.5898438, l : 455.128875732\n",
      "layer0/q_pos/mu:0\n",
      "max: 102.132484436, min: -102.835739136, mean: 0.0329499430954, std: 11.8996419907\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.46535181999, min: -3.61740708351, mean: -0.289555847645, std: 0.609050154686\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.9037246704, min: -46.7674102783, mean: 0.816919565201, std: 11.1447372437\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.05701518059, min: -1.2998752594, mean: -0.383168667555, std: 0.61103540659\n",
      "valid accuracy 0.8648\n",
      "batch 3, ep 0, training accuracy 0.845\n",
      "f : 9867.09863281, q : 133046.46875, p : 124249.601562, l : 1027.72546387\n",
      "batch 3, ep 50, training accuracy 0.95\n",
      "f : 116983.085938, q : 132451.921875, p : 16074.6591797, l : 495.987304688\n",
      "batch 3, ep 100, training accuracy 0.96\n",
      "f : 90595.84375, q : 132371.421875, p : 42088.5859375, l : 420.383300781\n",
      "batch 3, ep 150, training accuracy 0.965\n",
      "f : 78553.765625, q : 132252.84375, p : 53974.1640625, l : 377.399230957\n",
      "layer0/q_pos/mu:0\n",
      "max: 102.626678467, min: -92.1684265137, mean: 0.00157592457253, std: 15.2968702316\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.72063422203, min: -3.11150169373, mean: -0.172230869532, std: 0.581970572472\n",
      "layer1/q_pos/mu:0\n",
      "max: 72.5650634766, min: -52.5647201538, mean: 0.218062669039, std: 15.18364048\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.58946871758, min: -2.53057050705, mean: -0.301069110632, std: 0.633058667183\n",
      "valid accuracy 0.8701\n",
      "batch 4, ep 0, training accuracy 0.85\n",
      "f : 9940.28515625, q : 132156.828125, p : 123311.914062, l : 1098.60534668\n",
      "batch 4, ep 50, training accuracy 0.925\n",
      "f : 66185.8203125, q : 131739.765625, p : 66298.015625, l : 648.036132812\n",
      "batch 4, ep 100, training accuracy 0.94\n",
      "f : 50500.6328125, q : 131755.0625, p : 81861.7734375, l : 588.38092041\n",
      "batch 4, ep 150, training accuracy 0.95\n",
      "f : 44060.6992188, q : 131695.96875, p : 88177.3125, l : 545.139038086\n",
      "layer0/q_pos/mu:0\n",
      "max: 76.9003143311, min: -97.1084671021, mean: -0.0276262313128, std: 15.3242387772\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.81368374825, min: -3.07498478889, mean: -0.0811492279172, std: 0.525385379791\n",
      "layer1/q_pos/mu:0\n",
      "max: 46.5813026428, min: -47.9479560852, mean: -0.242818072438, std: 14.3624954224\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.63647902012, min: -1.03225791454, mean: -0.177469238639, std: 0.547353565693\n",
      "valid accuracy 0.8643\n",
      "batch 5, ep 0, training accuracy 0.825\n",
      "f : 9977.97558594, q : 131652.328125, p : 122826.59375, l : 1136.75268555\n",
      "batch 5, ep 50, training accuracy 0.94\n",
      "f : 59037.0273438, q : 131363.9375, p : 72936.9140625, l : 674.258911133\n",
      "batch 5, ep 100, training accuracy 0.945\n",
      "f : 44475.9921875, q : 131231.203125, p : 87395.46875, l : 622.128723145\n",
      "batch 5, ep 150, training accuracy 0.95\n",
      "f : 39006.171875, q : 131261.015625, p : 92782.4296875, l : 582.553222656\n",
      "layer0/q_pos/mu:0\n",
      "max: 75.5383605957, min: -90.0540237427, mean: 0.0247566532344, std: 15.095913887\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.07804489136, min: -2.76016902924, mean: -0.0668360441923, std: 0.514000058174\n",
      "layer1/q_pos/mu:0\n",
      "max: 38.2004852295, min: -48.9605865479, mean: -0.219386309385, std: 14.4261760712\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.50616562366, min: -1.03991639614, mean: -0.184115543962, std: 0.570629239082\n",
      "valid accuracy 0.8762\n",
      "batch 6, ep 0, training accuracy 0.845\n",
      "f : 9868.79101562, q : 131134.953125, p : 122248.929688, l : 1025.14306641\n",
      "batch 6, ep 50, training accuracy 0.92\n",
      "f : 46343.9921875, q : 130807.398438, p : 85055.4453125, l : 623.125610352\n",
      "batch 6, ep 100, training accuracy 0.935\n",
      "f : 35068.734375, q : 130738.101562, p : 96241.25, l : 579.821044922\n",
      "batch 6, ep 150, training accuracy 0.94\n",
      "f : 30625.9082031, q : 130727.40625, p : 100645.007812, l : 548.391357422\n",
      "layer0/q_pos/mu:0\n",
      "max: 75.259185791, min: -70.642829895, mean: -0.0791335701942, std: 14.9041318893\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.75611495972, min: -2.53093576431, mean: -0.0465851873159, std: 0.497792363167\n",
      "layer1/q_pos/mu:0\n",
      "max: 42.9454307556, min: -47.0057945251, mean: -0.302761614323, std: 13.30265522\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.32380199432, min: -1.03861391544, mean: -0.133760869503, std: 0.558353722095\n",
      "valid accuracy 0.878\n",
      "batch 7, ep 0, training accuracy 0.85\n",
      "f : 9718.90722656, q : 130713.546875, p : 121839.9375, l : 875.71484375\n",
      "batch 7, ep 50, training accuracy 0.945\n",
      "f : 38743.7148438, q : 130273.460938, p : 92179.5, l : 556.553833008\n",
      "batch 7, ep 100, training accuracy 0.945\n",
      "f : 29280.1992188, q : 130296.820312, p : 101558.34375, l : 522.225952148\n",
      "batch 7, ep 150, training accuracy 0.95\n",
      "f : 25897.7070312, q : 130272.15625, p : 104854.28125, l : 496.632141113\n",
      "layer0/q_pos/mu:0\n",
      "max: 70.3620300293, min: -71.3693161011, mean: -0.118209049106, std: 14.6554355621\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.65554666519, min: -3.38270568848, mean: -0.0348802693188, std: 0.486063569784\n",
      "layer1/q_pos/mu:0\n",
      "max: 48.4705123901, min: -39.5432434082, mean: -0.265268951654, std: 14.519903183\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.34412062168, min: -1.0251057148, mean: -0.0719348713756, std: 0.509295701981\n",
      "valid accuracy 0.8835\n",
      "batch 8, ep 0, training accuracy 0.895\n",
      "f : 9534.24414062, q : 130300.03125, p : 121432.117188, l : 693.49597168\n",
      "batch 8, ep 50, training accuracy 0.95\n",
      "f : 43234.5625, q : 129889.976562, p : 86978.0703125, l : 372.894012451\n",
      "batch 8, ep 100, training accuracy 0.97\n",
      "f : 22027.6699219, q : 129766.5, p : 108038.59375, l : 314.763336182\n",
      "batch 8, ep 150, training accuracy 0.965\n",
      "f : 20842.6289062, q : 129800.796875, p : 109265.109375, l : 298.018890381\n",
      "layer0/q_pos/mu:0\n",
      "max: 64.1190490723, min: -62.0189094543, mean: -0.075378485024, std: 14.4014720917\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.16212129593, min: -2.9802172184, mean: -0.017219632864, std: 0.478321015835\n",
      "layer1/q_pos/mu:0\n",
      "max: 39.2990989685, min: -48.2164039612, mean: -0.103704899549, std: 12.4411039352\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.86712956429, min: -2.06620121002, mean: -0.142758458853, std: 0.538804888725\n",
      "valid accuracy 0.873\n",
      "batch 9, ep 0, training accuracy 0.88\n",
      "f : 9555.81933594, q : 129734.140625, p : 121008.242188, l : 716.823242188\n",
      "batch 9, ep 50, training accuracy 0.94\n",
      "f : 33957.5195312, q : 129430.570312, p : 95918.1953125, l : 475.168334961\n",
      "batch 9, ep 100, training accuracy 0.945\n",
      "f : 17702.5976562, q : 129357.820312, p : 112150.585938, l : 431.790374756\n",
      "batch 9, ep 150, training accuracy 0.95\n",
      "f : 16904.6914062, q : 129271.507812, p : 112898.914062, l : 415.101837158\n",
      "layer0/q_pos/mu:0\n",
      "max: 61.9065437317, min: -64.4631195068, mean: -0.0857365727425, std: 14.1765375137\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.7777659893, min: -2.54210662842, mean: -0.00639279698953, std: 0.465996980667\n",
      "layer1/q_pos/mu:0\n",
      "max: 44.5031661987, min: -35.6816253662, mean: -0.0803719013929, std: 13.0628948212\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.50890684128, min: -1.03138768673, mean: -0.104272477329, std: 0.498335272074\n",
      "valid accuracy 0.8929\n",
      "batch 10, ep 0, training accuracy 0.91\n",
      "f : 9501.09667969, q : 129407.140625, p : 120500.882812, l : 660.981811523\n",
      "batch 10, ep 50, training accuracy 0.92\n",
      "f : 28096.1914062, q : 128974.085938, p : 101345.007812, l : 521.059875488\n",
      "batch 10, ep 100, training accuracy 0.93\n",
      "f : 26375.6894531, q : 128967.585938, p : 103079.875, l : 486.22644043\n",
      "batch 10, ep 150, training accuracy 0.93\n",
      "f : 14094.0136719, q : 128844.796875, p : 115156.09375, l : 461.264312744\n",
      "layer0/q_pos/mu:0\n",
      "max: 59.5630989075, min: -57.9991798401, mean: -0.0842042267323, std: 13.9986104965\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.62330794334, min: -1.51653468609, mean: 0.000556823913939, std: 0.458634108305\n",
      "layer1/q_pos/mu:0\n",
      "max: 42.959728241, min: -42.2131996155, mean: -1.27835023403, std: 12.7281980515\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.50592303276, min: -1.01919972897, mean: -0.0494860447943, std: 0.534359455109\n",
      "valid accuracy 0.8929\n",
      "batch 11, ep 0, training accuracy 0.925\n",
      "f : 9381.890625, q : 128983.1875, p : 120086.664062, l : 542.581726074\n",
      "batch 11, ep 50, training accuracy 0.94\n",
      "f : 23237.1191406, q : 128702.421875, p : 105789.078125, l : 459.062286377\n",
      "batch 11, ep 100, training accuracy 0.95\n",
      "f : 12571.7949219, q : 128690.5625, p : 116643.257812, l : 439.629119873\n",
      "batch 11, ep 150, training accuracy 0.95\n",
      "f : 12383.9121094, q : 128699.3125, p : 116696.265625, l : 432.088897705\n",
      "layer0/q_pos/mu:0\n",
      "max: 64.0196151733, min: -50.3396186829, mean: 0.0153675172478, std: 11.6929178238\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.79310655594, min: -1.90559351444, mean: 0.00146953389049, std: 0.448838800192\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.3228111267, min: -31.5223941803, mean: 0.217930212617, std: 11.2259435654\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.02588820457, min: -1.01724040508, mean: -0.0242563318461, std: 0.427861481905\n",
      "valid accuracy 0.8925\n",
      "batch 12, ep 0, training accuracy 0.94\n",
      "f : 9361.12402344, q : 128710.835938, p : 119826.296875, l : 521.549255371\n",
      "batch 12, ep 50, training accuracy 0.95\n",
      "f : 22380.546875, q : 128257.632812, p : 106300.585938, l : 429.202270508\n",
      "batch 12, ep 100, training accuracy 0.955\n",
      "f : 12339.8232422, q : 128314.1875, p : 116299.359375, l : 414.647888184\n",
      "batch 12, ep 150, training accuracy 0.95\n",
      "f : 12181.8105469, q : 128310.921875, p : 116551.09375, l : 405.936126709\n",
      "layer0/q_pos/mu:0\n",
      "max: 50.2643547058, min: -51.806098938, mean: 0.0557834655046, std: 11.6831655502\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.72245573997, min: -2.21441030502, mean: 0.0106261381879, std: 0.447655230761\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.6480960846, min: -38.0411148071, mean: -0.720079660416, std: 10.8730344772\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.76632535458, min: -1.06972825527, mean: -0.0299447663128, std: 0.469202131033\n",
      "valid accuracy 0.8895\n",
      "batch 13, ep 0, training accuracy 0.86\n",
      "f : 9739.91992188, q : 128327.265625, p : 119504.296875, l : 907.919433594\n",
      "batch 13, ep 50, training accuracy 0.865\n",
      "f : 22541.2519531, q : 127948.921875, p : 106384.289062, l : 993.536560059\n",
      "batch 13, ep 100, training accuracy 0.915\n",
      "f : 12799.3769531, q : 127997.140625, p : 115951.0625, l : 673.743041992\n",
      "batch 13, ep 150, training accuracy 0.915\n",
      "f : 11838.1464844, q : 128023.335938, p : 116822.515625, l : 661.908813477\n",
      "layer0/q_pos/mu:0\n",
      "max: 41.7140464783, min: -80.7811584473, mean: 0.098031014204, std: 10.811920166\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.9982278347, min: -1.0675110817, mean: 0.00533553678542, std: 0.448827087879\n",
      "layer1/q_pos/mu:0\n",
      "max: 30.5263519287, min: -30.6274147034, mean: 0.293648958206, std: 10.2274589539\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.10025143623, min: -1.01770019531, mean: -0.0499885678291, std: 0.498294264078\n",
      "valid accuracy 0.8913\n",
      "batch 14, ep 0, training accuracy 0.9\n",
      "f : 9529.390625, q : 127949.007812, p : 119120.4375, l : 689.100341797\n",
      "batch 14, ep 50, training accuracy 0.905\n",
      "f : 19545.125, q : 127654.664062, p : 108830.984375, l : 618.495361328\n",
      "batch 14, ep 100, training accuracy 0.905\n",
      "f : 11667.6894531, q : 127671.40625, p : 116667.828125, l : 607.865783691\n",
      "batch 14, ep 150, training accuracy 0.905\n",
      "f : 10747.3554688, q : 127675.765625, p : 117589.40625, l : 604.312927246\n",
      "layer0/q_pos/mu:0\n",
      "max: 42.0360221863, min: -43.2722969055, mean: 0.0176180191338, std: 10.453669548\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.68251824379, min: -2.33815908432, mean: 0.00657176505774, std: 0.446771174669\n",
      "layer1/q_pos/mu:0\n",
      "max: 34.8891563416, min: -30.5397548676, mean: 0.301278948784, std: 10.175693512\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.76977932453, min: -1.03883945942, mean: -8.38859414216e-05, std: 0.449158251286\n",
      "valid accuracy 0.8934\n",
      "batch 15, ep 0, training accuracy 0.905\n",
      "f : 9512.55273438, q : 127761.609375, p : 118857.65625, l : 677.28527832\n",
      "batch 15, ep 50, training accuracy 0.91\n",
      "f : 11381.4121094, q : 127510.78125, p : 116733.59375, l : 637.280029297\n",
      "batch 15, ep 100, training accuracy 0.905\n",
      "f : 10456.0976562, q : 127384.054688, p : 117578.125, l : 635.593383789\n",
      "batch 15, ep 150, training accuracy 0.9\n",
      "f : 10411.4814453, q : 127401.109375, p : 117653.9375, l : 633.388305664\n",
      "layer0/q_pos/mu:0\n",
      "max: 45.8002433777, min: -44.0260505676, mean: 0.0828637182713, std: 10.3248090744\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.43623495102, min: -1.08818411827, mean: 0.0105315363035, std: 0.444018781185\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.241437912, min: -30.7558555603, mean: 0.505243659019, std: 10.1361103058\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.99377691746, min: -1.00557339191, mean: -0.0138246184215, std: 0.466705709696\n",
      "valid accuracy 0.8933\n",
      "batch 16, ep 0, training accuracy 0.885\n",
      "f : 9543.86425781, q : 127428.460938, p : 118559.21875, l : 700.867858887\n",
      "batch 16, ep 50, training accuracy 0.915\n",
      "f : 17859.8652344, q : 127172.976562, p : 109773.195312, l : 574.931335449\n",
      "batch 16, ep 100, training accuracy 0.92\n",
      "f : 10497.2910156, q : 127093.75, p : 117233.929688, l : 559.803222656\n",
      "batch 16, ep 150, training accuracy 0.92\n",
      "f : 10202.0400391, q : 127226.679688, p : 117538.929688, l : 550.450073242\n",
      "layer0/q_pos/mu:0\n",
      "max: 41.1541748047, min: -41.2497673035, mean: -0.0493801273406, std: 10.2387714386\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.08989953995, min: -1.03089177608, mean: 0.00682251621038, std: 0.44224268198\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.9828605652, min: -34.8231925964, mean: -0.8225517869, std: 9.93493747711\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.69143724442, min: -1.10528326035, mean: -0.0347314067185, std: 0.485401332378\n",
      "valid accuracy 0.896\n",
      "batch 17, ep 0, training accuracy 0.935\n",
      "f : 9357.46386719, q : 127186.726562, p : 118285.078125, l : 521.899719238\n",
      "batch 17, ep 50, training accuracy 0.945\n",
      "f : 16915.4121094, q : 126857.609375, p : 110407.601562, l : 486.867370605\n",
      "batch 17, ep 100, training accuracy 0.935\n",
      "f : 10056.4042969, q : 126850.40625, p : 117258.859375, l : 485.253295898\n",
      "batch 17, ep 150, training accuracy 0.935\n",
      "f : 9773.39257812, q : 126877.757812, p : 117624.195312, l : 485.329284668\n",
      "layer0/q_pos/mu:0\n",
      "max: 54.6819152832, min: -38.8965034485, mean: 0.0258082151413, std: 10.2049446106\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.79937887192, min: -1.02191472054, mean: 0.00565326679498, std: 0.441855102777\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.821931839, min: -27.2490444183, mean: -0.122867748141, std: 9.8304271698\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.90496385098, min: -1.02000331879, mean: -3.35945806e-05, std: 0.451673388481\n",
      "valid accuracy 0.8972\n",
      "batch 18, ep 0, training accuracy 0.895\n",
      "f : 9667.63964844, q : 126938.585938, p : 117986.804688, l : 829.159301758\n",
      "batch 18, ep 50, training accuracy 0.895\n",
      "f : 16582.9296875, q : 126620.90625, p : 110845.046875, l : 789.744506836\n",
      "batch 18, ep 100, training accuracy 0.9\n",
      "f : 10236.9365234, q : 126664.875, p : 117127.828125, l : 787.026062012\n",
      "batch 18, ep 150, training accuracy 0.9\n",
      "f : 9982.23242188, q : 126689.898438, p : 117496.640625, l : 786.861938477\n",
      "layer0/q_pos/mu:0\n",
      "max: 44.4126243591, min: -41.6943054199, mean: 0.0474784597754, std: 10.1185016632\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.50087094307, min: -1.02360868454, mean: 0.00490320986137, std: 0.440356016159\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.0617980957, min: -29.4641895294, mean: -0.666665732861, std: 9.92427921295\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.58245670795, min: -1.01959109306, mean: -0.00657837977633, std: 0.484061717987\n",
      "valid accuracy 0.8986\n",
      "batch 19, ep 0, training accuracy 0.93\n",
      "f : 9385.61425781, q : 126621.140625, p : 117820.0625, l : 543.424438477\n",
      "batch 19, ep 50, training accuracy 0.93\n",
      "f : 10719.3457031, q : 126431.828125, p : 116149.023438, l : 528.165039062\n",
      "batch 19, ep 100, training accuracy 0.93\n",
      "f : 9936.41308594, q : 126431.632812, p : 117005.4375, l : 524.993225098\n",
      "batch 19, ep 150, training accuracy 0.93\n",
      "f : 9659.65039062, q : 126374.273438, p : 117235.054688, l : 528.232116699\n",
      "layer0/q_pos/mu:0\n",
      "max: 45.9674377441, min: -44.111995697, mean: 0.0578838326037, std: 10.0045986176\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.56362819672, min: -1.02042293549, mean: 0.00298962811939, std: 0.441679149866\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.6735877991, min: -25.534204483, mean: 0.065341770649, std: 10.3215637207\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.83150351048, min: -0.984256029129, mean: 0.00967808347195, std: 0.448742359877\n",
      "valid accuracy 0.8997\n",
      "batch 20, ep 0, training accuracy 0.895\n",
      "f : 9733.8671875, q : 126379.195312, p : 117497.328125, l : 897.085571289\n",
      "batch 20, ep 50, training accuracy 0.895\n",
      "f : 10992.0273438, q : 126149.703125, p : 115963.65625, l : 847.60546875\n",
      "batch 20, ep 100, training accuracy 0.895\n",
      "f : 10240.59375, q : 126150.585938, p : 116729.789062, l : 841.401062012\n",
      "batch 20, ep 150, training accuracy 0.895\n",
      "f : 9970.19140625, q : 126189.585938, p : 117009.03125, l : 839.444824219\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.6813316345, min: -39.5659790039, mean: -0.0578064359725, std: 9.96443939209\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.00065112114, min: -1.01844632626, mean: 0.00447220588103, std: 0.440090000629\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.514497757, min: -25.7660446167, mean: 0.223612710834, std: 9.86855602264\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.72406637669, min: -1.00894868374, mean: 0.0048686270602, std: 0.441177010536\n",
      "valid accuracy 0.8995\n",
      "batch 21, ep 0, training accuracy 0.925\n",
      "f : 9478.69335938, q : 126165.632812, p : 117323.804688, l : 643.229064941\n",
      "batch 21, ep 50, training accuracy 0.925\n",
      "f : 15442.6835938, q : 125939.25, p : 111129.257812, l : 620.205810547\n",
      "batch 21, ep 100, training accuracy 0.93\n",
      "f : 9960.72070312, q : 125962.117188, p : 116639.203125, l : 617.754760742\n",
      "batch 21, ep 150, training accuracy 0.93\n",
      "f : 9705.24511719, q : 125928.96875, p : 116838.734375, l : 619.78125\n",
      "layer0/q_pos/mu:0\n",
      "max: 41.2219772339, min: -39.516292572, mean: -0.105919972062, std: 9.87871074677\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.59468340874, min: -1.0373789072, mean: 0.00347709748894, std: 0.440053373575\n",
      "layer1/q_pos/mu:0\n",
      "max: 31.4383945465, min: -31.0679168701, mean: 0.0080621605739, std: 9.70446777344\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.1318526268, min: -1.00827682018, mean: -0.00401898892596, std: 0.46066364646\n",
      "valid accuracy 0.9018\n",
      "batch 22, ep 0, training accuracy 0.915\n",
      "f : 9402.72753906, q : 125902.15625, p : 117093.6875, l : 565.948364258\n",
      "batch 22, ep 50, training accuracy 0.92\n",
      "f : 10589.1181641, q : 125683.828125, p : 115641.5, l : 544.365600586\n",
      "batch 22, ep 100, training accuracy 0.915\n",
      "f : 9887.85253906, q : 125669.59375, p : 116434.273438, l : 547.262145996\n",
      "batch 22, ep 150, training accuracy 0.92\n",
      "f : 9600.51953125, q : 125731.414062, p : 116676.296875, l : 546.767822266\n",
      "layer0/q_pos/mu:0\n",
      "max: 38.383026123, min: -40.2305259705, mean: 0.0217134710401, std: 9.82535266876\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.71781945229, min: -0.936898827553, mean: 0.00956079550087, std: 0.442576885223\n",
      "layer1/q_pos/mu:0\n",
      "max: 31.8857460022, min: -27.9583358765, mean: 0.131506830454, std: 9.15718841553\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.83649003506, min: -1.0192438364, mean: 0.00780459772795, std: 0.429744273424\n",
      "valid accuracy 0.9024\n",
      "batch 23, ep 0, training accuracy 0.89\n",
      "f : 9561.45703125, q : 125728.15625, p : 116900.257812, l : 721.602233887\n",
      "batch 23, ep 50, training accuracy 0.89\n",
      "f : 10704.421875, q : 125522.40625, p : 115516.632812, l : 675.353881836\n",
      "batch 23, ep 100, training accuracy 0.895\n",
      "f : 9987.5625, q : 125516.640625, p : 116197.945312, l : 675.966918945\n",
      "batch 23, ep 150, training accuracy 0.895\n",
      "f : 9655.62695312, q : 125560.195312, p : 116600.414062, l : 670.177368164\n",
      "layer0/q_pos/mu:0\n",
      "max: 43.4783210754, min: -40.6784286499, mean: -0.099102884531, std: 9.69459342957\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.44557952881, min: -0.968623816967, mean: 0.0024629808031, std: 0.441409349442\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.3790206909, min: -23.7605018616, mean: 0.430122286081, std: 9.16478157043\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.65310418606, min: -1.03151464462, mean: 0.00049432303058, std: 0.425410509109\n",
      "valid accuracy 0.9027\n",
      "batch 24, ep 0, training accuracy 0.91\n",
      "f : 9539.7109375, q : 125511.945312, p : 116685.8125, l : 704.001708984\n",
      "batch 24, ep 50, training accuracy 0.905\n",
      "f : 14786.3125, q : 125285.609375, p : 111293.757812, l : 682.968688965\n",
      "batch 24, ep 100, training accuracy 0.91\n",
      "f : 9993.20410156, q : 125267.40625, p : 116003.796875, l : 682.337768555\n",
      "batch 24, ep 150, training accuracy 0.91\n",
      "f : 9726.74804688, q : 125334.203125, p : 116313.695312, l : 681.031066895\n",
      "layer0/q_pos/mu:0\n",
      "max: 43.0822486877, min: -43.3098068237, mean: -0.0242012031376, std: 9.70761871338\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.24058222771, min: -0.939994931221, mean: 0.0044483076781, std: 0.439891904593\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.2225456238, min: -31.7573776245, mean: 0.942090570927, std: 9.43095397949\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.82278072834, min: -0.871696472168, mean: 0.0062723075971, std: 0.421129196882\n",
      "valid accuracy 0.9017\n",
      "batch 25, ep 0, training accuracy 0.865\n",
      "f : 9752.48535156, q : 125302.5625, p : 116470.132812, l : 917.2421875\n",
      "batch 25, ep 50, training accuracy 0.865\n",
      "f : 10860.6210938, q : 125151.257812, p : 115187.65625, l : 875.260314941\n",
      "batch 25, ep 100, training accuracy 0.865\n",
      "f : 10192.4121094, q : 125126.898438, p : 115725.132812, l : 875.728820801\n",
      "batch 25, ep 150, training accuracy 0.865\n",
      "f : 9926.65917969, q : 125200.679688, p : 116154.226562, l : 872.517089844\n",
      "layer0/q_pos/mu:0\n",
      "max: 38.768283844, min: -45.4113616943, mean: -0.00491092121229, std: 9.64497756958\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.65349268913, min: -0.912823796272, mean: -1.67477119248e-05, std: 0.44211012125\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.182888031, min: -27.2356376648, mean: -0.47904214263, std: 9.52474212646\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.66442000866, min: -0.998067438602, mean: 0.0307879466563, std: 0.453158348799\n",
      "valid accuracy 0.9005\n",
      "batch 26, ep 0, training accuracy 0.9\n",
      "f : 9569.4453125, q : 125138.90625, p : 116344.054688, l : 725.715393066\n",
      "batch 26, ep 50, training accuracy 0.9\n",
      "f : 10692.6425781, q : 124951.953125, p : 114910.75, l : 697.771606445\n",
      "batch 26, ep 100, training accuracy 0.905\n",
      "f : 9982.96972656, q : 124919.039062, p : 115683.921875, l : 697.99609375\n",
      "batch 26, ep 150, training accuracy 0.91\n",
      "f : 9746.7109375, q : 124996.523438, p : 115882.554688, l : 695.115600586\n",
      "layer0/q_pos/mu:0\n",
      "max: 39.5937690735, min: -40.1930732727, mean: 0.0572704598308, std: 9.62319660187\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.96661829948, min: -0.934088349342, mean: 0.00589359831065, std: 0.437147706747\n",
      "layer1/q_pos/mu:0\n",
      "max: 30.1325969696, min: -33.3588409424, mean: -0.685514688492, std: 9.7520236969\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.62066912651, min: -0.893858671188, mean: -0.00492711551487, std: 0.418855786324\n",
      "valid accuracy 0.9019\n",
      "batch 27, ep 0, training accuracy 0.92\n",
      "f : 9370.23242188, q : 125005.148438, p : 116209.65625, l : 533.184204102\n",
      "batch 27, ep 50, training accuracy 0.925\n",
      "f : 10469.1083984, q : 124785.796875, p : 114767.960938, l : 504.73260498\n",
      "batch 27, ep 100, training accuracy 0.925\n",
      "f : 9798.44726562, q : 124725.9375, p : 115433.398438, l : 504.553253174\n",
      "batch 27, ep 150, training accuracy 0.93\n",
      "f : 9468.6015625, q : 124816.210938, p : 115837.53125, l : 504.36114502\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.8568229675, min: -44.3673057556, mean: 0.0160570237786, std: 9.56046485901\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.58745455742, min: -1.01327776909, mean: 0.00512959668413, std: 0.440981060266\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.7155151367, min: -40.3440361023, mean: -0.250981837511, std: 8.87306880951\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.5439620018, min: -1.03592026234, mean: 0.0111061902717, std: 0.456505417824\n",
      "valid accuracy 0.9001\n",
      "batch 28, ep 0, training accuracy 0.895\n",
      "f : 9542.99316406, q : 124796.789062, p : 115936.546875, l : 708.826660156\n",
      "batch 28, ep 50, training accuracy 0.91\n",
      "f : 10603.1181641, q : 124563.625, p : 114607.3125, l : 685.067932129\n",
      "batch 28, ep 100, training accuracy 0.91\n",
      "f : 9969.91308594, q : 124646.164062, p : 115364.164062, l : 687.893432617\n",
      "batch 28, ep 150, training accuracy 0.91\n",
      "f : 9715.8046875, q : 124578.6875, p : 115560.859375, l : 688.308349609\n",
      "layer0/q_pos/mu:0\n",
      "max: 38.6797065735, min: -39.6593017578, mean: 0.0273054409772, std: 9.58030223846\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.67138504982, min: -0.944236576557, mean: 0.00355140632018, std: 0.441305816174\n",
      "layer1/q_pos/mu:0\n",
      "max: 29.1722793579, min: -27.1999568939, mean: 0.185899317265, std: 9.41036987305\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.95672285557, min: -0.873918712139, mean: -0.0066317836754, std: 0.435955107212\n",
      "valid accuracy 0.9016\n",
      "batch 29, ep 0, training accuracy 0.92\n",
      "f : 9576.47851562, q : 124578.734375, p : 115741.15625, l : 740.315917969\n",
      "batch 29, ep 50, training accuracy 0.92\n",
      "f : 10617.4707031, q : 124390.335938, p : 114446.8125, l : 719.80847168\n",
      "batch 29, ep 100, training accuracy 0.915\n",
      "f : 9990.66992188, q : 124362.664062, p : 115189.859375, l : 718.649536133\n",
      "batch 29, ep 150, training accuracy 0.915\n",
      "f : 9734.59667969, q : 124307.375, p : 115353.625, l : 715.759887695\n",
      "layer0/q_pos/mu:0\n",
      "max: 45.5923423767, min: -41.3012619019, mean: 0.0809543952346, std: 9.47399520874\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.09610414505, min: -0.924762368202, mean: 0.00857528112829, std: 0.440890222788\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.1058235168, min: -32.3778190613, mean: 0.116474807262, std: 9.19334125519\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.60085308552, min: -0.868199050426, mean: 0.0214239452034, std: 0.406354278326\n",
      "valid accuracy 0.9014\n",
      "batch 30, ep 0, training accuracy 0.94\n",
      "f : 9369.34960938, q : 124352.226562, p : 115504.804688, l : 532.913879395\n",
      "batch 30, ep 50, training accuracy 0.94\n",
      "f : 10405.7431641, q : 124138.75, p : 114343.578125, l : 516.470581055\n",
      "batch 30, ep 100, training accuracy 0.94\n",
      "f : 9784.84570312, q : 124131.375, p : 114941.148438, l : 519.755493164\n",
      "batch 30, ep 150, training accuracy 0.94\n",
      "f : 9455.53515625, q : 124275.8125, p : 115308.210938, l : 517.571166992\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.2996482849, min: -47.0342712402, mean: -0.0551533028483, std: 9.37525844574\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.1730928421, min: -0.918088138103, mean: 0.00503028417006, std: 0.439925432205\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.3487758636, min: -33.8032302856, mean: 0.0527561344206, std: 8.83111858368\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.93235528469, min: -0.817813515663, mean: 0.0486616529524, std: 0.406200528145\n",
      "valid accuracy 0.9016\n",
      "batch 31, ep 0, training accuracy 0.915\n",
      "f : 9336.62792969, q : 124191.335938, p : 115343.210938, l : 504.457061768\n",
      "batch 31, ep 50, training accuracy 0.94\n",
      "f : 10448.9785156, q : 124018.382812, p : 114060.804688, l : 429.798156738\n",
      "batch 31, ep 100, training accuracy 0.94\n",
      "f : 9791.11132812, q : 123969.664062, p : 114669.742188, l : 425.868408203\n",
      "batch 31, ep 150, training accuracy 0.94\n",
      "f : 9560.19726562, q : 124016.796875, p : 114886.375, l : 426.30859375\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.8593025208, min: -45.5418510437, mean: -0.0159570798278, std: 9.47606182098\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.86219644547, min: -0.914433777332, mean: 0.00501335645095, std: 0.44047421217\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.1625366211, min: -25.4859352112, mean: 0.57032340765, std: 9.7179479599\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.5091830492, min: -1.09566617012, mean: -0.00318063842133, std: 0.468043357134\n",
      "valid accuracy 0.8981\n",
      "batch 32, ep 0, training accuracy 0.93\n",
      "f : 9394.94335938, q : 124098.484375, p : 115213.96875, l : 561.263305664\n",
      "batch 32, ep 50, training accuracy 0.93\n",
      "f : 10380.7128906, q : 123949.40625, p : 114099.734375, l : 543.151855469\n",
      "batch 32, ep 100, training accuracy 0.92\n",
      "f : 9777.83984375, q : 123910.460938, p : 114684.578125, l : 545.017333984\n",
      "batch 32, ep 150, training accuracy 0.92\n",
      "f : 9490.20214844, q : 123865.78125, p : 114936.390625, l : 543.679443359\n",
      "layer0/q_pos/mu:0\n",
      "max: 38.6028900146, min: -40.5902175903, mean: -0.0245551671833, std: 9.27510070801\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.08329844475, min: -0.950741350651, mean: -0.00289609003812, std: 0.439560830593\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.0320281982, min: -30.3814373016, mean: 0.32562533021, std: 9.01702404022\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.99741292, min: -0.852324306965, mean: -0.0404495820403, std: 0.423319250345\n",
      "valid accuracy 0.8991\n",
      "batch 33, ep 0, training accuracy 0.905\n",
      "f : 9441.97558594, q : 124014.195312, p : 115034.351562, l : 601.737487793\n",
      "batch 33, ep 50, training accuracy 0.915\n",
      "f : 10445.5166016, q : 123721.695312, p : 113787.320312, l : 588.201049805\n",
      "batch 33, ep 100, training accuracy 0.915\n",
      "f : 9842.13085938, q : 123797.265625, p : 114528.039062, l : 588.499084473\n",
      "batch 33, ep 150, training accuracy 0.915\n",
      "f : 9616.44628906, q : 123703.0625, p : 114650.53125, l : 589.212219238\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.941368103, min: -38.9118537903, mean: 0.00654267007485, std: 9.34151649475\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.83811330795, min: -0.944934368134, mean: 0.00853432901204, std: 0.441163182259\n",
      "layer1/q_pos/mu:0\n",
      "max: 30.1257133484, min: -22.012386322, mean: 0.492430925369, std: 8.99757480621\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.35554075241, min: -0.797552764416, mean: -0.0194238368422, std: 0.446626633406\n",
      "valid accuracy 0.8996\n",
      "batch 34, ep 0, training accuracy 0.85\n",
      "f : 9733.99316406, q : 123746.140625, p : 114849.28125, l : 900.926513672\n",
      "batch 34, ep 50, training accuracy 0.865\n",
      "f : 10714.2958984, q : 123595.039062, p : 113716.507812, l : 855.869628906\n",
      "batch 34, ep 100, training accuracy 0.865\n",
      "f : 10117.4814453, q : 123513.695312, p : 114324.265625, l : 858.48626709\n",
      "batch 34, ep 150, training accuracy 0.87\n",
      "f : 9834.1015625, q : 123556.640625, p : 114458.648438, l : 857.41796875\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.8224449158, min: -40.1987495422, mean: 0.136268317699, std: 9.24561595917\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.63108658791, min: -0.958463072777, mean: 0.00468789087608, std: 0.439676970243\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.9973583221, min: -26.3214893341, mean: -0.306462734938, std: 8.84778785706\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.46651697159, min: -1.04342269897, mean: 0.0239349026233, std: 0.424693614244\n",
      "valid accuracy 0.9021\n",
      "batch 35, ep 0, training accuracy 0.92\n",
      "f : 9545.56445312, q : 123557.671875, p : 114744.84375, l : 710.013549805\n",
      "batch 35, ep 50, training accuracy 0.92\n",
      "f : 10545.9902344, q : 123365.953125, p : 113523.070312, l : 685.524047852\n",
      "batch 35, ep 100, training accuracy 0.92\n",
      "f : 9921.07226562, q : 123402.015625, p : 114025.648438, l : 687.000732422\n",
      "batch 35, ep 150, training accuracy 0.92\n",
      "f : 9628.71875, q : 123342.46875, p : 114399.78125, l : 685.912231445\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.6562728882, min: -35.6988601685, mean: -0.0633384883404, std: 9.23578453064\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.57582139969, min: -0.971538484097, mean: 0.00182586512528, std: 0.438780128956\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.6301879883, min: -22.5850467682, mean: -1.02914917469, std: 8.82742214203\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.75934100151, min: -0.880705654621, mean: 0.00812368001789, std: 0.46273714304\n",
      "valid accuracy 0.902\n",
      "batch 36, ep 0, training accuracy 0.845\n",
      "f : 9819.78613281, q : 123367.46875, p : 114494.703125, l : 980.049926758\n",
      "batch 36, ep 50, training accuracy 0.85\n",
      "f : 13540.9433594, q : 123191.765625, p : 110509.5625, l : 933.923583984\n",
      "batch 36, ep 100, training accuracy 0.85\n",
      "f : 10183.828125, q : 123174.0625, p : 113891.84375, l : 937.40234375\n",
      "batch 36, ep 150, training accuracy 0.85\n",
      "f : 9967.61914062, q : 123192.554688, p : 114206.273438, l : 930.814941406\n",
      "layer0/q_pos/mu:0\n",
      "max: 42.3553009033, min: -40.3623771667, mean: -0.0244643948972, std: 9.24743080139\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.20770835876, min: -0.926324665546, mean: 0.00753696030006, std: 0.437006562948\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.4020709991, min: -25.5780353546, mean: -0.231739625335, std: 9.13302612305\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.62252449989, min: -0.989863932133, mean: -0.0221774447709, std: 0.433446913958\n",
      "valid accuracy 0.9026\n",
      "batch 37, ep 0, training accuracy 0.94\n",
      "f : 9419.8671875, q : 123151.351562, p : 114409.90625, l : 580.097839355\n",
      "batch 37, ep 50, training accuracy 0.945\n",
      "f : 10338.0996094, q : 123042.789062, p : 113238.234375, l : 557.899719238\n",
      "batch 37, ep 100, training accuracy 0.945\n",
      "f : 9807.15722656, q : 123060.835938, p : 113710.359375, l : 554.387084961\n",
      "batch 37, ep 150, training accuracy 0.945\n",
      "f : 9499.45605469, q : 123093.203125, p : 113986.789062, l : 554.622131348\n",
      "layer0/q_pos/mu:0\n",
      "max: 41.5112800598, min: -38.2184677124, mean: 0.076587587595, std: 9.19791984558\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.80400943756, min: -0.921693444252, mean: -0.000356892007403, std: 0.439332902431\n",
      "layer1/q_pos/mu:0\n",
      "max: 29.7956447601, min: -24.0767059326, mean: -0.21313084662, std: 8.5975484848\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.51486229897, min: -0.892190873623, mean: 0.0187155902386, std: 0.452632397413\n",
      "valid accuracy 0.9029\n",
      "batch 38, ep 0, training accuracy 0.89\n",
      "f : 9566.38085938, q : 123064.46875, p : 114118.445312, l : 733.785827637\n",
      "batch 38, ep 50, training accuracy 0.905\n",
      "f : 10511.171875, q : 122854.492188, p : 113050.796875, l : 690.637329102\n",
      "batch 38, ep 100, training accuracy 0.905\n",
      "f : 9959.59667969, q : 122923.304688, p : 113617.859375, l : 683.511108398\n",
      "batch 38, ep 150, training accuracy 0.905\n",
      "f : 9738.03515625, q : 122855.046875, p : 113906.328125, l : 685.771179199\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.9600219727, min: -38.5965766907, mean: 0.032672483474, std: 9.19222545624\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.3009622097, min: -0.93038803339, mean: 0.00496454164386, std: 0.440592736006\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.177312851, min: -28.3453502655, mean: -0.337016969919, std: 8.8414850235\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.78931796551, min: -1.04687845707, mean: -0.0158331431448, std: 0.440939486027\n",
      "valid accuracy 0.9009\n",
      "batch 39, ep 0, training accuracy 0.86\n",
      "f : 9650.22949219, q : 122799.28125, p : 114009.664062, l : 815.275390625\n",
      "batch 39, ep 50, training accuracy 0.87\n",
      "f : 10576.6855469, q : 122637.453125, p : 112901.1875, l : 769.841796875\n",
      "batch 39, ep 100, training accuracy 0.87\n",
      "f : 10013.65625, q : 122744.070312, p : 113514.765625, l : 766.475341797\n",
      "batch 39, ep 150, training accuracy 0.87\n",
      "f : 9805.52246094, q : 122707.476562, p : 113786.5, l : 764.328125\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.2460975647, min: -38.3874130249, mean: -0.0538287833333, std: 9.05779838562\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.18132758141, min: -0.902881085873, mean: -0.00076197803719, std: 0.43780040741\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.6938381195, min: -25.4710712433, mean: 0.0459493286908, std: 9.05401325226\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.02555704117, min: -0.93026393652, mean: 0.0127457361668, std: 0.436848849058\n",
      "valid accuracy 0.9022\n",
      "batch 40, ep 0, training accuracy 0.91\n",
      "f : 9403.57519531, q : 122678.242188, p : 113864.835938, l : 575.390136719\n",
      "batch 40, ep 50, training accuracy 0.91\n",
      "f : 10323.1494141, q : 122615.070312, p : 112798.007812, l : 547.626525879\n",
      "batch 40, ep 100, training accuracy 0.91\n",
      "f : 9764.609375, q : 122592.40625, p : 113378.640625, l : 550.41217041\n",
      "batch 40, ep 150, training accuracy 0.91\n",
      "f : 9545.86035156, q : 122484.328125, p : 113485.804688, l : 550.113342285\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.4087028503, min: -40.2344894409, mean: 0.0363382585347, std: 9.01777458191\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.87039780617, min: -0.929995059967, mean: 0.000686107145157, std: 0.43722447753\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.6775913239, min: -29.9722595215, mean: -0.430024832487, std: 8.81158542633\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.8309071064, min: -0.825912296772, mean: 0.0163353011012, std: 0.443932324648\n",
      "valid accuracy 0.9016\n",
      "batch 41, ep 0, training accuracy 0.92\n",
      "f : 9606.10449219, q : 122684.554688, p : 113788.304688, l : 770.706298828\n",
      "batch 41, ep 50, training accuracy 0.915\n",
      "f : 10511.1826172, q : 122438.226562, p : 112682.90625, l : 748.422668457\n",
      "batch 41, ep 100, training accuracy 0.92\n",
      "f : 9959.96972656, q : 122416.117188, p : 113150.515625, l : 747.164550781\n",
      "batch 41, ep 150, training accuracy 0.915\n",
      "f : 9754.17382812, q : 122371.28125, p : 113490.382812, l : 747.84387207\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.0346336365, min: -42.9009170532, mean: -0.0598323531449, std: 8.94885444641\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.54918694496, min: -0.920154809952, mean: 0.00291375839151, std: 0.439833909273\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.1350269318, min: -24.0440769196, mean: 0.241478428245, std: 9.15889072418\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.86868190765, min: -0.863533914089, mean: 0.026599066332, std: 0.419495254755\n",
      "valid accuracy 0.9029\n",
      "batch 42, ep 0, training accuracy 0.9\n",
      "f : 9515.02441406, q : 122440.789062, p : 113585.578125, l : 679.710083008\n",
      "batch 42, ep 50, training accuracy 0.91\n",
      "f : 10411.4013672, q : 122288.1875, p : 112618.015625, l : 663.926879883\n",
      "batch 42, ep 100, training accuracy 0.905\n",
      "f : 9870.53710938, q : 122351.71875, p : 113073.375, l : 663.985717773\n",
      "batch 42, ep 150, training accuracy 0.91\n",
      "f : 9680.0703125, q : 122378.789062, p : 113312.015625, l : 665.66418457\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.4294052124, min: -37.0655479431, mean: -0.0705390498042, std: 9.03196811676\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.89128565788, min: -0.925641179085, mean: -2.88727387669e-05, std: 0.440721273422\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.8384342194, min: -32.6793365479, mean: -0.127049297094, std: 9.31007099152\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.39018344879, min: -0.791291475296, mean: 0.0349178873003, std: 0.431140691042\n",
      "valid accuracy 0.902\n",
      "batch 43, ep 0, training accuracy 0.8\n",
      "f : 10094.8876953, q : 122280.546875, p : 113464.953125, l : 1260.58227539\n",
      "batch 43, ep 50, training accuracy 0.81\n",
      "f : 10958.0830078, q : 122330.53125, p : 112425.320312, l : 1202.9017334\n",
      "batch 43, ep 100, training accuracy 0.815\n",
      "f : 10434.9472656, q : 122201.34375, p : 113070.78125, l : 1200.80212402\n",
      "batch 43, ep 150, training accuracy 0.815\n",
      "f : 10227.8144531, q : 122189.195312, p : 113274.359375, l : 1198.28491211\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.1248168945, min: -34.3310546875, mean: -0.0488790236413, std: 8.9537191391\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.67518353462, min: -0.918953716755, mean: 0.00145016086753, std: 0.43740722537\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.6069450378, min: -23.7205448151, mean: -0.555964112282, std: 8.90787315369\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.70143318176, min: -0.852771639824, mean: 0.00112496502697, std: 0.441957086325\n",
      "valid accuracy 0.9024\n",
      "batch 44, ep 0, training accuracy 0.835\n",
      "f : 9847.02734375, q : 122193.929688, p : 113347.546875, l : 1013.83544922\n",
      "batch 44, ep 50, training accuracy 0.845\n",
      "f : 10687.0488281, q : 122046.640625, p : 112348.242188, l : 920.482666016\n",
      "batch 44, ep 100, training accuracy 0.845\n",
      "f : 10150.8017578, q : 122017.085938, p : 112781.164062, l : 910.91809082\n",
      "batch 44, ep 150, training accuracy 0.84\n",
      "f : 9942.44140625, q : 122087.71875, p : 113005.0625, l : 902.797241211\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.5808944702, min: -36.5765609741, mean: -0.081105902791, std: 8.98676681519\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.47193455696, min: -0.948088943958, mean: -0.000662790436763, std: 0.438019871712\n",
      "layer1/q_pos/mu:0\n",
      "max: 31.2766475677, min: -27.9708347321, mean: -0.201230481267, std: 8.78240776062\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.55183398724, min: -1.08172476292, mean: -0.0385921001434, std: 0.412096768618\n",
      "valid accuracy 0.8996\n",
      "batch 45, ep 0, training accuracy 0.925\n",
      "f : 9441.46972656, q : 122037.992188, p : 113190.953125, l : 606.229614258\n",
      "batch 45, ep 50, training accuracy 0.93\n",
      "f : 10328.4824219, q : 122004.265625, p : 112169.726562, l : 576.261108398\n",
      "batch 45, ep 100, training accuracy 0.93\n",
      "f : 9799.86035156, q : 121961.890625, p : 112696.421875, l : 571.658874512\n",
      "batch 45, ep 150, training accuracy 0.93\n",
      "f : 9592.90234375, q : 121997.789062, p : 112954.835938, l : 572.171936035\n",
      "layer0/q_pos/mu:0\n",
      "max: 40.6795845032, min: -34.1227302551, mean: -0.0108219170943, std: 8.90724277496\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.63252043724, min: -0.937952041626, mean: 0.0012274403125, std: 0.435716450214\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.4574985504, min: -29.0928115845, mean: -0.574917376041, std: 8.81690311432\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.79880571365, min: -0.891903340816, mean: 0.00709211966023, std: 0.413269430399\n",
      "valid accuracy 0.9006\n",
      "batch 46, ep 0, training accuracy 0.875\n",
      "f : 9574.75878906, q : 121930.210938, p : 113148.359375, l : 737.892028809\n",
      "batch 46, ep 50, training accuracy 0.87\n",
      "f : 10418.2880859, q : 121763.929688, p : 112086.46875, l : 719.850402832\n",
      "batch 46, ep 100, training accuracy 0.875\n",
      "f : 9930.26367188, q : 121856.65625, p : 112611.890625, l : 718.991577148\n",
      "batch 46, ep 150, training accuracy 0.875\n",
      "f : 9652.38378906, q : 121922.789062, p : 112886.757812, l : 716.372070312\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.828994751, min: -34.8935966492, mean: -0.100831456482, std: 8.8163022995\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.6113986969, min: -0.933840572834, mean: 0.000467229867354, std: 0.43884575367\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.9470691681, min: -28.0915164948, mean: 0.759975850582, std: 9.14972877502\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.81649112701, min: -0.879872262478, mean: -0.000360084988642, std: 0.415964484215\n",
      "valid accuracy 0.9031\n",
      "batch 47, ep 0, training accuracy 0.925\n",
      "f : 9541.05078125, q : 121859.570312, p : 113019.265625, l : 705.429077148\n",
      "batch 47, ep 50, training accuracy 0.92\n",
      "f : 10371.1787109, q : 121746.21875, p : 112037.382812, l : 674.248779297\n",
      "batch 47, ep 100, training accuracy 0.92\n",
      "f : 9883.53417969, q : 121715.210938, p : 112542.6875, l : 678.190368652\n",
      "batch 47, ep 150, training accuracy 0.925\n",
      "f : 9633.4921875, q : 121717.554688, p : 112802.65625, l : 674.199707031\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.0638275146, min: -37.2725982666, mean: 0.0201081074774, std: 8.89381694794\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.91743063927, min: -0.913492679596, mean: 0.000966093619354, std: 0.440582424402\n",
      "layer1/q_pos/mu:0\n",
      "max: 29.5787220001, min: -29.9019813538, mean: -0.0565210990608, std: 8.99289798737\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.6636660099, min: -0.842611312866, mean: -0.016428316012, std: 0.457310259342\n",
      "valid accuracy 0.9025\n",
      "batch 48, ep 0, training accuracy 0.905\n",
      "f : 9603.23144531, q : 121739.945312, p : 112913.023438, l : 767.860656738\n",
      "batch 48, ep 50, training accuracy 0.9\n",
      "f : 10441.4414062, q : 121633.929688, p : 111891.125, l : 681.640136719\n",
      "batch 48, ep 100, training accuracy 0.91\n",
      "f : 9902.56933594, q : 121595.671875, p : 112440.0625, l : 679.400512695\n",
      "batch 48, ep 150, training accuracy 0.905\n",
      "f : 9716.25390625, q : 121540.851562, p : 112521.257812, l : 672.234375\n",
      "layer0/q_pos/mu:0\n",
      "max: 38.3855476379, min: -38.0283622742, mean: -0.0367421172559, std: 8.84276485443\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.5664229393, min: -0.934950768948, mean: -5.21283000126e-05, std: 0.436455965042\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.1649360657, min: -26.4213790894, mean: -0.354541927576, std: 8.60825252533\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.90122747421, min: -1.0013897419, mean: -0.00336419744417, std: 0.458948820829\n",
      "valid accuracy 0.8976\n",
      "batch 49, ep 0, training accuracy 0.95\n",
      "f : 9349.6796875, q : 121619.867188, p : 112728.375, l : 513.351074219\n",
      "batch 49, ep 50, training accuracy 0.95\n",
      "f : 10208.5439453, q : 121562.585938, p : 111728.867188, l : 497.402954102\n",
      "batch 49, ep 100, training accuracy 0.95\n",
      "f : 9693.77246094, q : 121486.414062, p : 112338.53125, l : 496.714508057\n",
      "batch 49, ep 150, training accuracy 0.95\n",
      "f : 9429.55175781, q : 121470.59375, p : 112617.382812, l : 499.921508789\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.7511672974, min: -35.381942749, mean: -0.0162809863687, std: 8.74781036377\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.60774993896, min: -0.933732748032, mean: 0.00161697657313, std: 0.4407967031\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.6366043091, min: -23.9949302673, mean: -0.0562916025519, std: 8.57522964478\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.84162306786, min: -0.818280875683, mean: 0.0171514376998, std: 0.426272183657\n",
      "valid accuracy 0.899\n",
      "batch 50, ep 0, training accuracy 0.91\n",
      "f : 9474.08789062, q : 121503.835938, p : 112753.28125, l : 641.164428711\n",
      "batch 50, ep 50, training accuracy 0.91\n",
      "f : 10297.8837891, q : 121401.875, p : 111757.070312, l : 610.772766113\n",
      "batch 50, ep 100, training accuracy 0.91\n",
      "f : 9821.36230469, q : 121429.65625, p : 112218.539062, l : 607.734191895\n",
      "batch 50, ep 150, training accuracy 0.91\n",
      "f : 9619.0, q : 121381.078125, p : 112337.117188, l : 607.544494629\n",
      "layer0/q_pos/mu:0\n",
      "max: 41.8350067139, min: -38.4916610718, mean: -0.000570377043914, std: 8.76448249817\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.79010891914, min: -0.944055259228, mean: 0.00260560703464, std: 0.436852574348\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.6805591583, min: -29.4614677429, mean: 0.392090320587, std: 8.67806243896\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.0059299469, min: -0.849460661411, mean: 0.0450051911175, std: 0.458372890949\n",
      "valid accuracy 0.8996\n",
      "batch 51, ep 0, training accuracy 0.855\n",
      "f : 9664.97460938, q : 121368.765625, p : 112591.25, l : 824.126525879\n",
      "batch 51, ep 50, training accuracy 0.91\n",
      "f : 12627.8339844, q : 121359.4375, p : 109345.257812, l : 601.640869141\n",
      "batch 51, ep 100, training accuracy 0.91\n",
      "f : 10531.7734375, q : 121262.476562, p : 111388.046875, l : 592.049682617\n",
      "batch 51, ep 150, training accuracy 0.91\n",
      "f : 9879.49023438, q : 121305.875, p : 112030.820312, l : 589.35723877\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.9561843872, min: -36.1656913757, mean: 0.066189289093, std: 8.80375766754\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.19692587852, min: -0.987909436226, mean: -0.0033547305502, std: 0.4386729002\n",
      "layer1/q_pos/mu:0\n",
      "max: 31.2036647797, min: -28.5012588501, mean: 0.266368210316, std: 8.39800739288\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.59162759781, min: -2.17392706871, mean: -0.0636353865266, std: 0.485888212919\n",
      "valid accuracy 0.8929\n",
      "batch 52, ep 0, training accuracy 0.93\n",
      "f : 9284.8125, q : 121329.796875, p : 112411.132812, l : 451.143218994\n",
      "batch 52, ep 50, training accuracy 0.93\n",
      "f : 10129.1220703, q : 121198.1875, p : 111527.25, l : 409.342590332\n",
      "batch 52, ep 100, training accuracy 0.925\n",
      "f : 9602.21191406, q : 121217.820312, p : 111982.710938, l : 406.484924316\n",
      "batch 52, ep 150, training accuracy 0.93\n",
      "f : 9434.05957031, q : 121240.15625, p : 112100.8125, l : 408.435913086\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.3536300659, min: -34.9612159729, mean: -0.0387397259474, std: 8.7025604248\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.85051178932, min: -0.927606642246, mean: -0.00108871143311, std: 0.439532250166\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.5274448395, min: -26.2612285614, mean: -0.160377383232, std: 8.3067407608\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.66242933273, min: -1.02248072624, mean: 0.0213078074157, std: 0.438186019659\n",
      "valid accuracy 0.8971\n",
      "batch 53, ep 0, training accuracy 0.9\n",
      "f : 9500.88476562, q : 121272.109375, p : 112369.789062, l : 669.819580078\n",
      "batch 53, ep 50, training accuracy 0.915\n",
      "f : 10348.9882812, q : 121161.890625, p : 111335.476562, l : 625.96081543\n",
      "batch 53, ep 100, training accuracy 0.915\n",
      "f : 9849.39550781, q : 121075.03125, p : 111882.96875, l : 629.349609375\n",
      "batch 53, ep 150, training accuracy 0.91\n",
      "f : 9607.90039062, q : 121067.632812, p : 112150.15625, l : 624.622680664\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.785774231, min: -34.2562713623, mean: 0.0388009883463, std: 8.78538513184\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.80316448212, min: -0.926467239857, mean: 0.00135320518166, std: 0.438128709793\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.9112148285, min: -22.6731758118, mean: 0.166267350316, std: 8.28549480438\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.75189507008, min: -1.03770577908, mean: 0.00472807046026, std: 0.453747242689\n",
      "valid accuracy 0.8981\n",
      "batch 54, ep 0, training accuracy 0.955\n",
      "f : 9333.6171875, q : 121117.828125, p : 112234.375, l : 505.199829102\n",
      "batch 54, ep 50, training accuracy 0.955\n",
      "f : 10135.5517578, q : 121007.617188, p : 111324.40625, l : 487.986053467\n",
      "batch 54, ep 100, training accuracy 0.955\n",
      "f : 9670.50390625, q : 120998.5625, p : 111856.5625, l : 486.784515381\n",
      "batch 54, ep 150, training accuracy 0.955\n",
      "f : 9489.73339844, q : 120968.46875, p : 111999.96875, l : 486.361419678\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.0668144226, min: -35.3437385559, mean: 0.0334069356322, std: 8.71326732635\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.49361681938, min: -0.931534647942, mean: 0.00164831615984, std: 0.440671294928\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.2375297546, min: -22.1098384857, mean: 0.312201201916, std: 8.42551994324\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.30946755409, min: -0.954135298729, mean: -0.0217485427856, std: 0.446480512619\n",
      "valid accuracy 0.9\n",
      "batch 55, ep 0, training accuracy 0.92\n",
      "f : 9369.47167969, q : 120934.726562, p : 112141.226562, l : 534.482299805\n",
      "batch 55, ep 50, training accuracy 0.92\n",
      "f : 10158.6503906, q : 120989.96875, p : 111273.070312, l : 521.857543945\n",
      "batch 55, ep 100, training accuracy 0.92\n",
      "f : 9689.13574219, q : 121010.757812, p : 111796.414062, l : 519.476928711\n",
      "batch 55, ep 150, training accuracy 0.92\n",
      "f : 9507.01171875, q : 120903.476562, p : 111898.828125, l : 520.61505127\n",
      "layer0/q_pos/mu:0\n",
      "max: 39.0548477173, min: -36.8317947388, mean: 0.0274298805743, std: 8.66285324097\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.35896396637, min: -0.929550230503, mean: -0.00339230685495, std: 0.4364977777\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.2839603424, min: -26.0922584534, mean: -0.180861830711, std: 8.46552753448\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.42754197121, min: -0.835056126118, mean: -0.0302436798811, std: 0.48012650013\n",
      "valid accuracy 0.8997\n",
      "batch 56, ep 0, training accuracy 0.9\n",
      "f : 9450.75, q : 120921.21875, p : 112076.328125, l : 616.842651367\n",
      "batch 56, ep 50, training accuracy 0.91\n",
      "f : 10239.8261719, q : 120810.117188, p : 111267.796875, l : 593.799499512\n",
      "batch 56, ep 100, training accuracy 0.92\n",
      "f : 9769.92578125, q : 120864.40625, p : 111612.578125, l : 589.764282227\n",
      "batch 56, ep 150, training accuracy 0.92\n",
      "f : 9538.71679688, q : 120924.226562, p : 111920.398438, l : 589.051391602\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.7404174805, min: -34.8648872375, mean: -0.0719801113009, std: 8.59657478333\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.84712266922, min: -0.928068041801, mean: 0.00044561814866, std: 0.436003804207\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.0087223053, min: -27.0464820862, mean: 0.120199270546, std: 8.44223499298\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.63519859314, min: -0.824454367161, mean: 0.00322731933556, std: 0.421496331692\n",
      "valid accuracy 0.9013\n",
      "batch 57, ep 0, training accuracy 0.855\n",
      "f : 9684.51757812, q : 120874.570312, p : 112046.484375, l : 854.536193848\n",
      "batch 57, ep 50, training accuracy 0.875\n",
      "f : 10477.1787109, q : 120810.960938, p : 111046.625, l : 797.145874023\n",
      "batch 57, ep 100, training accuracy 0.875\n",
      "f : 10005.234375, q : 120837.5, p : 111535.515625, l : 795.138305664\n",
      "batch 57, ep 150, training accuracy 0.875\n",
      "f : 9811.96484375, q : 120805.554688, p : 111666.257812, l : 795.126647949\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.7574081421, min: -39.570690155, mean: 0.0355997644365, std: 8.64107036591\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.58856511116, min: -0.956163704395, mean: -0.00230270531029, std: 0.438780546188\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.0360145569, min: -23.0920810699, mean: -0.20952360332, std: 8.02886390686\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.96964919567, min: -0.960210800171, mean: -0.00677649304271, std: 0.428426146507\n",
      "valid accuracy 0.9035\n",
      "batch 58, ep 0, training accuracy 0.82\n",
      "f : 9997.1171875, q : 120779.070312, p : 111909.960938, l : 1169.37744141\n",
      "batch 58, ep 50, training accuracy 0.84\n",
      "f : 12620.5517578, q : 120614.171875, p : 109012.4375, l : 1007.89697266\n",
      "batch 58, ep 100, training accuracy 0.84\n",
      "f : 10283.2402344, q : 120754.820312, p : 111344.539062, l : 1000.27819824\n",
      "batch 58, ep 150, training accuracy 0.835\n",
      "f : 10096.5917969, q : 120637.101562, p : 111655.757812, l : 996.60534668\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.9425773621, min: -31.9960956573, mean: -0.00391684286296, std: 8.66129589081\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.5763835907, min: -0.928324818611, mean: 0.00024004271836, std: 0.435627400875\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.4592590332, min: -25.1901760101, mean: 0.409724652767, std: 8.38965511322\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.73065471649, min: -1.03603363037, mean: -0.00564800295979, std: 0.46779742837\n",
      "valid accuracy 0.9049\n",
      "batch 59, ep 0, training accuracy 0.93\n",
      "f : 9405.36035156, q : 120603.640625, p : 111832.46875, l : 571.72253418\n",
      "batch 59, ep 50, training accuracy 0.935\n",
      "f : 10181.171875, q : 120552.3125, p : 110924.335938, l : 556.255004883\n",
      "batch 59, ep 100, training accuracy 0.935\n",
      "f : 9719.93652344, q : 120593.59375, p : 111447.296875, l : 555.647216797\n",
      "batch 59, ep 150, training accuracy 0.935\n",
      "f : 9511.5625, q : 120685.820312, p : 111588.554688, l : 554.565368652\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.3045082092, min: -32.6073799133, mean: -0.0472657009959, std: 8.51519870758\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.82820820808, min: -0.979025244713, mean: -0.00486139347777, std: 0.439863950014\n",
      "layer1/q_pos/mu:0\n",
      "max: 30.5596923828, min: -21.3496742249, mean: 0.343318372965, std: 8.26260280609\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.56262397766, min: -0.833668887615, mean: 0.00782997440547, std: 0.450215131044\n",
      "valid accuracy 0.9047\n",
      "batch 60, ep 0, training accuracy 0.905\n",
      "f : 9551.671875, q : 120584.117188, p : 111756.117188, l : 721.619506836\n",
      "batch 60, ep 50, training accuracy 0.925\n",
      "f : 10320.1582031, q : 120544.679688, p : 110738.953125, l : 624.019348145\n",
      "batch 60, ep 100, training accuracy 0.925\n",
      "f : 9841.95214844, q : 120482.882812, p : 111292.015625, l : 613.024536133\n",
      "batch 60, ep 150, training accuracy 0.93\n",
      "f : 9671.22167969, q : 120488.882812, p : 111503.476562, l : 610.983276367\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.3632736206, min: -36.0177841187, mean: -0.0370252840221, std: 8.6160326004\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.64157986641, min: -0.938264489174, mean: 0.000879059254657, std: 0.438789188862\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.3575668335, min: -23.2548618317, mean: 0.273787438869, std: 8.43060970306\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.46779668331, min: -1.07830643654, mean: 0.011816018261, std: 0.4550819695\n",
      "valid accuracy 0.8956\n",
      "batch 61, ep 0, training accuracy 0.87\n",
      "f : 9677.70703125, q : 120430.796875, p : 111769.46875, l : 849.998657227\n",
      "batch 61, ep 50, training accuracy 0.89\n",
      "f : 10399.3261719, q : 120483.289062, p : 110662.28125, l : 765.378723145\n",
      "batch 61, ep 100, training accuracy 0.895\n",
      "f : 9945.99511719, q : 120404.070312, p : 111204.460938, l : 748.498718262\n",
      "batch 61, ep 150, training accuracy 0.9\n",
      "f : 9773.78417969, q : 120366.84375, p : 111306.867188, l : 747.412231445\n",
      "layer0/q_pos/mu:0\n",
      "max: 39.3573646545, min: -34.3969459534, mean: -0.0940317884088, std: 8.57397270203\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.56466722488, min: -0.945925474167, mean: -0.00275900191627, std: 0.435808777809\n",
      "layer1/q_pos/mu:0\n",
      "max: 36.7549057007, min: -27.6470737457, mean: 0.307552009821, std: 8.06420898438\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.77377307415, min: -1.45026111603, mean: -0.012694391422, std: 0.474755465984\n",
      "valid accuracy 0.9023\n",
      "batch 62, ep 0, training accuracy 0.845\n",
      "f : 9749.20996094, q : 120425.046875, p : 111494.867188, l : 920.02142334\n",
      "batch 62, ep 50, training accuracy 0.86\n",
      "f : 12291.15625, q : 120316.820312, p : 108881.585938, l : 816.907836914\n",
      "batch 62, ep 100, training accuracy 0.86\n",
      "f : 9993.61914062, q : 120256.320312, p : 111039.703125, l : 800.468505859\n",
      "batch 62, ep 150, training accuracy 0.86\n",
      "f : 9837.41308594, q : 120319.632812, p : 111322.320312, l : 796.708679199\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.0395202637, min: -35.4560813904, mean: -0.0804729387164, std: 8.52970790863\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.75647950172, min: -0.944245874882, mean: -0.00548219727352, std: 0.43949714303\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.0957164764, min: -22.5436401367, mean: 0.0993484482169, std: 8.07067680359\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.46036589146, min: -1.0484957695, mean: 0.00953060202301, std: 0.448867619038\n",
      "valid accuracy 0.9044\n",
      "batch 63, ep 0, training accuracy 0.87\n",
      "f : 9783.57617188, q : 120350.25, p : 111483.09375, l : 952.172973633\n",
      "batch 63, ep 50, training accuracy 0.88\n",
      "f : 10522.2646484, q : 120269.726562, p : 110695.34375, l : 917.399291992\n",
      "batch 63, ep 100, training accuracy 0.885\n",
      "f : 10097.5800781, q : 120265.625, p : 111073.734375, l : 911.596069336\n",
      "batch 63, ep 150, training accuracy 0.88\n",
      "f : 9914.83105469, q : 120264.046875, p : 111256.507812, l : 912.46307373\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.5530891418, min: -37.5822219849, mean: -0.0789816975594, std: 8.48781299591\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.80066490173, min: -0.947538018227, mean: -0.00317821302451, std: 0.434637099504\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.8306121826, min: -24.7275524139, mean: -0.356713563204, std: 7.92185211182\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.8505294323, min: -0.767857730389, mean: 0.00075330544496, std: 0.449225515127\n",
      "valid accuracy 0.906\n",
      "batch 64, ep 0, training accuracy 0.885\n",
      "f : 9568.83691406, q : 120235.367188, p : 111524.875, l : 737.728271484\n",
      "batch 64, ep 50, training accuracy 0.895\n",
      "f : 12069.1826172, q : 120178.851562, p : 108801.429688, l : 710.995910645\n",
      "batch 64, ep 100, training accuracy 0.895\n",
      "f : 9880.45410156, q : 120136.679688, p : 110946.742188, l : 710.959106445\n",
      "batch 64, ep 150, training accuracy 0.895\n",
      "f : 9700.20117188, q : 120132.75, p : 111151.75, l : 713.712768555\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.6816482544, min: -35.8075370789, mean: -0.0652673169971, std: 8.48045921326\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.70332479477, min: -0.921753823757, mean: 0.000140043746796, std: 0.440109163523\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.7552947998, min: -21.4623413086, mean: -0.0701111108065, std: 8.31070327759\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.64578604698, min: -0.816413581371, mean: 0.0188271272928, std: 0.436755776405\n",
      "valid accuracy 0.9027\n",
      "batch 65, ep 0, training accuracy 0.815\n",
      "f : 10032.9785156, q : 120166.265625, p : 111356.0625, l : 1197.46850586\n",
      "batch 65, ep 50, training accuracy 0.82\n",
      "f : 10789.1074219, q : 120080.4375, p : 110515.835938, l : 1144.14904785\n",
      "batch 65, ep 100, training accuracy 0.82\n",
      "f : 10333.7333984, q : 120169.25, p : 110959.148438, l : 1154.92199707\n",
      "batch 65, ep 150, training accuracy 0.82\n",
      "f : 10140.6083984, q : 120100.203125, p : 111154.820312, l : 1147.99462891\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.6842269897, min: -31.1137046814, mean: 0.0304578654468, std: 8.4701833725\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.53804588318, min: -0.921314060688, mean: -0.00179962697439, std: 0.437844783068\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.4260311127, min: -22.4263820648, mean: 0.245236322284, std: 8.42968177795\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.177952528, min: -0.878283917904, mean: 0.029885744676, std: 0.451485514641\n",
      "valid accuracy 0.9035\n",
      "batch 66, ep 0, training accuracy 0.905\n",
      "f : 9412.109375, q : 120070.59375, p : 111375.617188, l : 581.947387695\n",
      "batch 66, ep 50, training accuracy 0.915\n",
      "f : 10160.2578125, q : 120106.195312, p : 110451.398438, l : 563.440795898\n",
      "batch 66, ep 100, training accuracy 0.92\n",
      "f : 9720.25390625, q : 120028.992188, p : 110915.296875, l : 560.755126953\n",
      "batch 66, ep 150, training accuracy 0.92\n",
      "f : 9508.04492188, q : 120108.085938, p : 111084.28125, l : 560.848815918\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.1203231812, min: -32.2850570679, mean: 0.0402675829828, std: 8.44966983795\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.70615696907, min: -0.906119763851, mean: 0.000596112397034, std: 0.438300073147\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.6658363342, min: -27.1548023224, mean: -0.624264538288, std: 8.12210178375\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.57796466351, min: -0.842037796974, mean: 0.0139666367322, std: 0.448663383722\n",
      "valid accuracy 0.9037\n",
      "batch 67, ep 0, training accuracy 0.915\n",
      "f : 9353.25683594, q : 120090.617188, p : 111239.484375, l : 518.928222656\n",
      "batch 67, ep 50, training accuracy 0.925\n",
      "f : 10119.6425781, q : 120013.78125, p : 110416.203125, l : 504.78604126\n",
      "batch 67, ep 100, training accuracy 0.93\n",
      "f : 9665.9765625, q : 119982.046875, p : 110864.703125, l : 503.662597656\n",
      "batch 67, ep 150, training accuracy 0.92\n",
      "f : 9479.14941406, q : 120063.476562, p : 111104.625, l : 502.548217773\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.4659233093, min: -33.2964668274, mean: -0.0208325888962, std: 8.43363571167\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.19541978836, min: -0.942674219608, mean: -0.000370570021914, std: 0.434375673532\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.9596118927, min: -25.1681976318, mean: 0.509362220764, std: 7.98598670959\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68572247028, min: -0.78331887722, mean: 0.0137067325413, std: 0.409042090178\n",
      "valid accuracy 0.9044\n",
      "batch 68, ep 0, training accuracy 0.835\n",
      "f : 9702.33789062, q : 119991.023438, p : 111218.460938, l : 869.473754883\n",
      "batch 68, ep 50, training accuracy 0.835\n",
      "f : 10439.9667969, q : 119967.960938, p : 110387.992188, l : 838.296691895\n",
      "batch 68, ep 100, training accuracy 0.84\n",
      "f : 10021.4189453, q : 119902.921875, p : 110691.273438, l : 838.489379883\n",
      "batch 68, ep 150, training accuracy 0.835\n",
      "f : 9793.30957031, q : 119883.429688, p : 111047.25, l : 837.356933594\n",
      "layer0/q_pos/mu:0\n",
      "max: 40.2221336365, min: -35.7193183899, mean: 0.0112061072141, std: 8.45098876953\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.53820705414, min: -0.949262797832, mean: -0.00108737207484, std: 0.434329867363\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.1253223419, min: -19.4117507935, mean: 0.35571333766, std: 8.39387321472\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.46883952618, min: -0.818023622036, mean: 0.0185221564025, std: 0.397958576679\n",
      "valid accuracy 0.9056\n",
      "batch 69, ep 0, training accuracy 0.84\n",
      "f : 9788.5, q : 119941.921875, p : 111168.015625, l : 958.473388672\n",
      "batch 69, ep 50, training accuracy 0.845\n",
      "f : 10558.6494141, q : 119968.875, p : 110263.210938, l : 909.553955078\n",
      "batch 69, ep 100, training accuracy 0.855\n",
      "f : 10090.5341797, q : 119851.96875, p : 110720.59375, l : 913.372680664\n",
      "batch 69, ep 150, training accuracy 0.85\n",
      "f : 9920.97851562, q : 119901.921875, p : 110868.25, l : 909.056640625\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.5693664551, min: -38.5450325012, mean: 0.0236485004425, std: 8.4240732193\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.55539155006, min: -0.927413165569, mean: -0.00381618156098, std: 0.436902552843\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.2700138092, min: -33.5983848572, mean: 0.0919840484858, std: 8.28959751129\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.33361983299, min: -1.04608082771, mean: 0.0104812225327, std: 0.437375456095\n",
      "valid accuracy 0.9017\n",
      "batch 70, ep 0, training accuracy 0.835\n",
      "f : 9787.55371094, q : 119928.648438, p : 111145.835938, l : 951.044311523\n",
      "batch 70, ep 50, training accuracy 0.855\n",
      "f : 10582.9648438, q : 119833.09375, p : 110111.90625, l : 885.152770996\n",
      "batch 70, ep 100, training accuracy 0.86\n",
      "f : 10114.5761719, q : 119713.210938, p : 110641.804688, l : 883.038513184\n",
      "batch 70, ep 150, training accuracy 0.86\n",
      "f : 9931.05761719, q : 119731.679688, p : 110726.421875, l : 884.176513672\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.2925720215, min: -32.7286529541, mean: -0.00847769156098, std: 8.38868713379\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.9713139534, min: -0.913233995438, mean: -0.00135497457813, std: 0.434837222099\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.1327838898, min: -25.4449043274, mean: 0.0463385619223, std: 8.35409927368\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.04758143425, min: -1.03968381882, mean: 0.014544907026, std: 0.439769238234\n",
      "valid accuracy 0.9055\n",
      "batch 71, ep 0, training accuracy 0.84\n",
      "f : 9904.26367188, q : 119755.375, p : 110961.953125, l : 1075.92077637\n",
      "batch 71, ep 50, training accuracy 0.85\n",
      "f : 10623.5146484, q : 119716.351562, p : 110165.734375, l : 1038.22277832\n",
      "batch 71, ep 100, training accuracy 0.845\n",
      "f : 10203.7285156, q : 119813.953125, p : 110632.523438, l : 1041.62561035\n",
      "batch 71, ep 150, training accuracy 0.845\n",
      "f : 10019.5302734, q : 119753.59375, p : 110790.320312, l : 1043.37255859\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.9081420898, min: -36.0843696594, mean: 0.0471899621189, std: 8.40490245819\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.36817574501, min: -0.939396083355, mean: -0.00132655561902, std: 0.434281647205\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.2288570404, min: -23.9519882202, mean: 0.946011662483, std: 8.39532756805\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.87378883362, min: -0.876404345036, mean: 0.00111526192632, std: 0.434839129448\n",
      "valid accuracy 0.9047\n",
      "batch 72, ep 0, training accuracy 0.9\n",
      "f : 9571.6875, q : 119824.78125, p : 110870.28125, l : 742.522338867\n",
      "batch 72, ep 50, training accuracy 0.91\n",
      "f : 10303.1445312, q : 119712.5, p : 110193.445312, l : 704.574035645\n",
      "batch 72, ep 100, training accuracy 0.91\n",
      "f : 9867.13476562, q : 119705.132812, p : 110583.320312, l : 706.577697754\n",
      "batch 72, ep 150, training accuracy 0.905\n",
      "f : 9646.73144531, q : 119821.820312, p : 110814.78125, l : 707.798950195\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.9504051208, min: -40.4020957947, mean: 0.00364743755199, std: 8.41273784637\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.05178427696, min: -0.943471372128, mean: 0.002802062314, std: 0.43585178256\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.2945919037, min: -24.2307109833, mean: 0.435885041952, std: 7.69034528732\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.73297417164, min: -0.87076830864, mean: -0.00509590469301, std: 0.450719326735\n",
      "valid accuracy 0.9052\n",
      "batch 73, ep 0, training accuracy 0.795\n",
      "f : 10165.5878906, q : 119754.960938, p : 110959.34375, l : 1327.10119629\n",
      "batch 73, ep 50, training accuracy 0.835\n",
      "f : 12622.5400391, q : 119610.695312, p : 108174.828125, l : 1102.74682617\n",
      "batch 73, ep 100, training accuracy 0.845\n",
      "f : 10906.1826172, q : 119641.945312, p : 109806.25, l : 1082.95996094\n",
      "batch 73, ep 150, training accuracy 0.845\n",
      "f : 10481.4169922, q : 119720.09375, p : 110129.5625, l : 1077.36938477\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.066570282, min: -37.5792922974, mean: -0.0424142181873, std: 8.57102680206\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.99326753616, min: -0.940323531628, mean: -0.00312354485504, std: 0.436852961779\n",
      "layer1/q_pos/mu:0\n",
      "max: 29.1605129242, min: -38.2154388428, mean: -0.689846396446, std: 8.09048652649\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.46938169003, min: -2.99299740791, mean: -0.0304841026664, std: 0.49119797349\n",
      "valid accuracy 0.8955\n",
      "batch 74, ep 0, training accuracy 0.855\n",
      "f : 9628.14550781, q : 119618.734375, p : 110828.960938, l : 787.696899414\n",
      "batch 74, ep 50, training accuracy 0.875\n",
      "f : 10331.2871094, q : 119502.054688, p : 109961.8125, l : 734.982177734\n",
      "batch 74, ep 100, training accuracy 0.875\n",
      "f : 9889.09375, q : 119655.125, p : 110447.859375, l : 737.112792969\n",
      "batch 74, ep 150, training accuracy 0.875\n",
      "f : 9719.05371094, q : 119661.445312, p : 110656.171875, l : 736.981079102\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.8359298706, min: -31.8310127258, mean: 0.0166436769068, std: 8.34407138824\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.72137355804, min: -0.922952830791, mean: -0.00482910079882, std: 0.43699246645\n",
      "layer1/q_pos/mu:0\n",
      "max: 33.8377532959, min: -22.4717006683, mean: -0.197145432234, std: 7.94143104553\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.74115586281, min: -0.756470918655, mean: -0.00273170182481, std: 0.439340978861\n",
      "valid accuracy 0.8998\n",
      "batch 75, ep 0, training accuracy 0.87\n",
      "f : 9660.16113281, q : 119611.882812, p : 110805.289062, l : 822.151306152\n",
      "batch 75, ep 50, training accuracy 0.885\n",
      "f : 10374.0722656, q : 119572.171875, p : 109962.789062, l : 776.525390625\n",
      "batch 75, ep 100, training accuracy 0.88\n",
      "f : 9931.68164062, q : 119532.132812, p : 110432.835938, l : 780.024780273\n",
      "batch 75, ep 150, training accuracy 0.885\n",
      "f : 9744.45019531, q : 119548.429688, p : 110565.046875, l : 777.211303711\n",
      "layer0/q_pos/mu:0\n",
      "max: 41.0838127136, min: -34.7527656555, mean: -0.00675163418055, std: 8.39627742767\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.35085535049, min: -0.930546462536, mean: -0.00236876844428, std: 0.438130915165\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.6220188141, min: -30.7350406647, mean: 0.104118168354, std: 7.89874172211\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.38017368317, min: -0.815438628197, mean: -0.0176202692091, std: 0.436231762171\n",
      "valid accuracy 0.9028\n",
      "batch 76, ep 0, training accuracy 0.885\n",
      "f : 9521.96289062, q : 119640.867188, p : 110755.210938, l : 694.701171875\n",
      "batch 76, ep 50, training accuracy 0.91\n",
      "f : 10243.2851562, q : 119467.132812, p : 109943.40625, l : 657.128417969\n",
      "batch 76, ep 100, training accuracy 0.905\n",
      "f : 9823.77246094, q : 119484.03125, p : 110308.867188, l : 659.052856445\n",
      "batch 76, ep 150, training accuracy 0.91\n",
      "f : 9597.546875, q : 119611.21875, p : 110529.671875, l : 654.506469727\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.5478515625, min: -32.6090965271, mean: 0.0281188543886, std: 8.39445400238\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.45024228096, min: -0.939733803272, mean: 0.000947174150497, std: 0.436385333538\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.2773799896, min: -28.7947425842, mean: -0.252111107111, std: 8.21098899841\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.63727653027, min: -0.839603483677, mean: -0.00441435398534, std: 0.444819271564\n",
      "valid accuracy 0.9027\n",
      "batch 77, ep 0, training accuracy 0.89\n",
      "f : 9542.01367188, q : 119481.585938, p : 110680.484375, l : 706.772949219\n",
      "batch 77, ep 50, training accuracy 0.89\n",
      "f : 10265.5566406, q : 119409.34375, p : 109876.4375, l : 681.47088623\n",
      "batch 77, ep 100, training accuracy 0.895\n",
      "f : 9836.27734375, q : 119430.367188, p : 110299.945312, l : 685.425415039\n",
      "batch 77, ep 150, training accuracy 0.89\n",
      "f : 9627.41210938, q : 119403.734375, p : 110482.945312, l : 684.131774902\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.0808181763, min: -33.5662460327, mean: -0.0211674794555, std: 8.35605239868\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.86324715614, min: -0.953835725784, mean: -0.001521831844, std: 0.438300997019\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.3092708588, min: -30.285774231, mean: 0.395740896463, std: 8.24899959564\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.90448951721, min: -0.761503875256, mean: -0.00951821636409, std: 0.428162693977\n",
      "valid accuracy 0.9038\n",
      "batch 78, ep 0, training accuracy 0.89\n",
      "f : 9628.08496094, q : 119397.710938, p : 110576.671875, l : 794.12121582\n",
      "batch 78, ep 50, training accuracy 0.885\n",
      "f : 10326.6015625, q : 119441.765625, p : 109863.851562, l : 751.633544922\n",
      "batch 78, ep 100, training accuracy 0.9\n",
      "f : 9915.60839844, q : 119368.070312, p : 110225.835938, l : 746.932250977\n",
      "batch 78, ep 150, training accuracy 0.895\n",
      "f : 9741.97070312, q : 119366.273438, p : 110392.640625, l : 756.330993652\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.0851554871, min: -36.3242759705, mean: -0.0127319712192, std: 8.36410617828\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.83024191856, min: -0.932422399521, mean: -0.00182665628381, std: 0.43405893445\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.4631710052, min: -19.304681778, mean: 0.319469124079, std: 8.34122467041\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.7214345932, min: -0.815192401409, mean: -0.0139215374365, std: 0.438208222389\n",
      "valid accuracy 0.9056\n",
      "batch 79, ep 0, training accuracy 0.865\n",
      "f : 9732.15039062, q : 119378.117188, p : 110612.789062, l : 897.918273926\n",
      "batch 79, ep 50, training accuracy 0.865\n",
      "f : 10418.8261719, q : 119310.484375, p : 109760.984375, l : 860.957641602\n",
      "batch 79, ep 100, training accuracy 0.865\n",
      "f : 10013.9326172, q : 119388.640625, p : 110159.554688, l : 859.675048828\n",
      "batch 79, ep 150, training accuracy 0.865\n",
      "f : 9839.12988281, q : 119342.90625, p : 110343.34375, l : 862.091308594\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.1902732849, min: -34.7410316467, mean: -0.0204851217568, std: 8.29442119598\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.20288252831, min: -0.936711728573, mean: -0.00586199527606, std: 0.433789640665\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.5511054993, min: -25.8879776001, mean: -0.205696672201, std: 7.71568250656\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.35094225407, min: -0.882124185562, mean: 0.013974188827, std: 0.447253972292\n",
      "valid accuracy 0.9064\n",
      "batch 80, ep 0, training accuracy 0.89\n",
      "f : 9612.25878906, q : 119313.984375, p : 110663.71875, l : 783.692504883\n",
      "batch 80, ep 50, training accuracy 0.9\n",
      "f : 10342.8945312, q : 119390.765625, p : 109672.4375, l : 739.304077148\n",
      "batch 80, ep 100, training accuracy 0.9\n",
      "f : 9936.85839844, q : 119289.75, p : 110122.914062, l : 737.613037109\n",
      "batch 80, ep 150, training accuracy 0.9\n",
      "f : 9768.6328125, q : 119257.226562, p : 110314.148438, l : 737.833496094\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.3990707397, min: -36.5640296936, mean: 0.0459006391466, std: 8.34417819977\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.49848914146, min: -0.953120291233, mean: -0.00100742059294, std: 0.438096910715\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.1426925659, min: -21.8525733948, mean: -0.516747236252, std: 7.90756940842\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.96961474419, min: -1.02909266949, mean: -0.0096379565075, std: 0.458984315395\n",
      "valid accuracy 0.9054\n",
      "batch 81, ep 0, training accuracy 0.91\n",
      "f : 9391.70507812, q : 119337.8125, p : 110481.453125, l : 562.848754883\n",
      "batch 81, ep 50, training accuracy 0.925\n",
      "f : 10134.5976562, q : 119304.414062, p : 109689.132812, l : 532.168273926\n",
      "batch 81, ep 100, training accuracy 0.92\n",
      "f : 9699.3046875, q : 119268.0625, p : 110088.460938, l : 532.93572998\n",
      "batch 81, ep 150, training accuracy 0.92\n",
      "f : 9548.52929688, q : 119257.101562, p : 110166.476562, l : 532.604431152\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.6772575378, min: -33.4603385925, mean: -0.0138233536854, std: 8.3247718811\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.75731348991, min: -0.940754175186, mean: -0.00851520895958, std: 0.437715530396\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.9840908051, min: -23.3129634857, mean: -0.393193513155, std: 7.61224508286\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.25448107719, min: -1.00238633156, mean: 0.00837461836636, std: 0.447669625282\n",
      "valid accuracy 0.9076\n",
      "batch 82, ep 0, training accuracy 0.915\n",
      "f : 9511.44140625, q : 119260.054688, p : 110414.40625, l : 683.367614746\n",
      "batch 82, ep 50, training accuracy 0.92\n",
      "f : 10232.1816406, q : 119085.875, p : 109633.484375, l : 657.840393066\n",
      "batch 82, ep 100, training accuracy 0.92\n",
      "f : 9824.60644531, q : 119215.132812, p : 110073.523438, l : 657.426635742\n",
      "batch 82, ep 150, training accuracy 0.92\n",
      "f : 9591.66796875, q : 119177.609375, p : 110248.726562, l : 658.149169922\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.3586883545, min: -34.9331359863, mean: 0.0198147296906, std: 8.29541778564\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.57827091217, min: -0.938119590282, mean: -0.00335760065354, std: 0.43573230505\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.6996421814, min: -19.7263412476, mean: 0.226257413626, std: 8.04580402374\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.07350039482, min: -0.816065907478, mean: 0.0069746626541, std: 0.421168535948\n",
      "valid accuracy 0.9081\n",
      "batch 83, ep 0, training accuracy 0.85\n",
      "f : 9674.93847656, q : 119162.195312, p : 110315.320312, l : 841.629882812\n",
      "batch 83, ep 50, training accuracy 0.86\n",
      "f : 10372.5146484, q : 119107.78125, p : 109580.585938, l : 807.952514648\n",
      "batch 83, ep 100, training accuracy 0.855\n",
      "f : 9967.43359375, q : 119230.445312, p : 109973.640625, l : 809.124755859\n",
      "batch 83, ep 150, training accuracy 0.855\n",
      "f : 9788.93164062, q : 119197.640625, p : 110194.484375, l : 801.938232422\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.2348175049, min: -33.6038589478, mean: 0.0171061083674, std: 8.28874397278\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.32519984245, min: -0.931032776833, mean: -0.00355660333298, std: 0.435694336891\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.308713913, min: -25.8373241425, mean: 0.263659358025, std: 7.86214780807\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.94777214527, min: -1.03147315979, mean: -0.0153597528115, std: 0.422097861767\n",
      "valid accuracy 0.9081\n",
      "batch 84, ep 0, training accuracy 0.88\n",
      "f : 9553.44140625, q : 119172.515625, p : 110323.359375, l : 720.168518066\n",
      "batch 84, ep 50, training accuracy 0.88\n",
      "f : 10240.7636719, q : 119066.640625, p : 109542.359375, l : 689.461242676\n",
      "batch 84, ep 100, training accuracy 0.88\n",
      "f : 9826.56542969, q : 119071.429688, p : 109930.242188, l : 689.893981934\n",
      "batch 84, ep 150, training accuracy 0.88\n",
      "f : 9671.50097656, q : 119103.203125, p : 110132.078125, l : 689.267089844\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.7510414124, min: -40.6771850586, mean: 0.0343398265541, std: 8.27151298523\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.67285084724, min: -0.93517690897, mean: -0.000244894239586, std: 0.437687367201\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.3158760071, min: -21.5876331329, mean: 0.841791272163, std: 8.00621604919\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.50223743916, min: -0.800512909889, mean: 0.0375288650393, std: 0.454973638058\n",
      "valid accuracy 0.9078\n",
      "batch 85, ep 0, training accuracy 0.875\n",
      "f : 9669.66699219, q : 119128.625, p : 110237.109375, l : 835.158447266\n",
      "batch 85, ep 50, training accuracy 0.885\n",
      "f : 10369.1542969, q : 119133.773438, p : 109534.960938, l : 812.095458984\n",
      "batch 85, ep 100, training accuracy 0.88\n",
      "f : 9953.98535156, q : 118960.789062, p : 109846.226562, l : 815.483032227\n",
      "batch 85, ep 150, training accuracy 0.885\n",
      "f : 9743.83886719, q : 119114.226562, p : 110042.601562, l : 815.264343262\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.1661148071, min: -39.3101463318, mean: -0.0891451388597, std: 8.27874946594\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.59621191025, min: -0.945153295994, mean: 0.00095087493537, std: 0.437663823366\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.3299999237, min: -20.9458580017, mean: 0.0207567699254, std: 7.96844577789\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.33949410915, min: -0.773095786572, mean: -0.000539275701158, std: 0.465856194496\n",
      "valid accuracy 0.9073\n",
      "batch 86, ep 0, training accuracy 0.935\n",
      "f : 9376.38769531, q : 119047.007812, p : 110246.078125, l : 543.061767578\n",
      "batch 86, ep 50, training accuracy 0.93\n",
      "f : 10085.1904297, q : 119069.953125, p : 109478.289062, l : 525.026245117\n",
      "batch 86, ep 100, training accuracy 0.93\n",
      "f : 9659.10644531, q : 119095.0, p : 109871.320312, l : 524.685546875\n",
      "batch 86, ep 150, training accuracy 0.935\n",
      "f : 9456.65917969, q : 118998.421875, p : 110106.875, l : 523.24987793\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.1135654449, min: -29.9700336456, mean: 0.00154977745842, std: 8.27264976501\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.61210441589, min: -0.920227587223, mean: -0.000716690439731, std: 0.437439411879\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.009305954, min: -23.0395431519, mean: -0.0419941022992, std: 7.61571359634\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.1407930851, min: -0.815224230289, mean: 0.000219415916945, std: 0.446974366903\n",
      "valid accuracy 0.9075\n",
      "batch 87, ep 0, training accuracy 0.865\n",
      "f : 9797.18066406, q : 119078.546875, p : 110127.257812, l : 962.539611816\n",
      "batch 87, ep 50, training accuracy 0.87\n",
      "f : 10528.5048828, q : 119018.585938, p : 109307.726562, l : 908.507202148\n",
      "batch 87, ep 100, training accuracy 0.875\n",
      "f : 10109.0566406, q : 118945.984375, p : 109858.296875, l : 909.744384766\n",
      "batch 87, ep 150, training accuracy 0.87\n",
      "f : 9941.11523438, q : 118927.070312, p : 109937.75, l : 906.551452637\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.6628913879, min: -32.4554595947, mean: -0.0255254544318, std: 8.26256656647\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.44499444962, min: -0.936967670918, mean: -0.000826012983453, std: 0.43463653326\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.0295600891, min: -24.4691123962, mean: -0.545048415661, std: 8.05707168579\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.43030238152, min: -1.03194272518, mean: -0.0186068806797, std: 0.469422966242\n",
      "valid accuracy 0.9048\n",
      "batch 88, ep 0, training accuracy 0.875\n",
      "f : 9638.50097656, q : 119016.515625, p : 110221.773438, l : 815.129516602\n",
      "batch 88, ep 50, training accuracy 0.885\n",
      "f : 10334.9628906, q : 118972.75, p : 109374.453125, l : 780.64465332\n",
      "batch 88, ep 100, training accuracy 0.88\n",
      "f : 9920.02050781, q : 118940.992188, p : 109826.53125, l : 781.856811523\n",
      "batch 88, ep 150, training accuracy 0.89\n",
      "f : 9770.53222656, q : 118941.414062, p : 109924.671875, l : 781.907958984\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.1186180115, min: -35.0734939575, mean: 0.023659273982, std: 8.21212291718\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.29157757759, min: -0.927822589874, mean: -0.00345314317383, std: 0.436392724514\n",
      "layer1/q_pos/mu:0\n",
      "max: 32.8454856873, min: -27.6205348969, mean: 0.439203470945, std: 7.5886516571\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.27266359329, min: -0.876708745956, mean: 0.000288189155981, std: 0.458185434341\n",
      "valid accuracy 0.9042\n",
      "batch 89, ep 0, training accuracy 0.905\n",
      "f : 9502.95019531, q : 119000.65625, p : 110101.929688, l : 669.110107422\n",
      "batch 89, ep 50, training accuracy 0.91\n",
      "f : 10213.1191406, q : 118876.671875, p : 109351.453125, l : 644.722595215\n",
      "batch 89, ep 100, training accuracy 0.91\n",
      "f : 9785.91699219, q : 118861.414062, p : 109820.4375, l : 644.841186523\n",
      "batch 89, ep 150, training accuracy 0.91\n",
      "f : 9625.01074219, q : 118900.0, p : 109970.273438, l : 647.788696289\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.0106239319, min: -35.5756874084, mean: -0.0692010074854, std: 8.22742080688\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.8763563633, min: -0.935156285763, mean: -0.00387546140701, std: 0.436119675636\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.095621109, min: -23.024356842, mean: -0.316979497671, std: 7.79769849777\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.54844081402, min: -0.760958254337, mean: 0.0100352875888, std: 0.428075164557\n",
      "valid accuracy 0.9042\n",
      "batch 90, ep 0, training accuracy 0.92\n",
      "f : 9371.73828125, q : 118963.054688, p : 110116.648438, l : 540.716186523\n",
      "batch 90, ep 50, training accuracy 0.92\n",
      "f : 10055.0019531, q : 118858.625, p : 109332.546875, l : 508.694000244\n",
      "batch 90, ep 100, training accuracy 0.925\n",
      "f : 9646.11621094, q : 118817.601562, p : 109726.914062, l : 511.959716797\n",
      "batch 90, ep 150, training accuracy 0.92\n",
      "f : 9457.30664062, q : 118832.492188, p : 109951.953125, l : 510.795776367\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.4797477722, min: -31.3959178925, mean: 0.00823097769171, std: 8.14632797241\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.6751537323, min: -0.928392887115, mean: -0.00606540543959, std: 0.434825032949\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.0682754517, min: -28.1612033844, mean: -0.442533642054, std: 8.03553295135\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.55552566051, min: -0.871015906334, mean: 0.00433372007683, std: 0.429609388113\n",
      "valid accuracy 0.9059\n",
      "batch 91, ep 0, training accuracy 0.92\n",
      "f : 9344.87207031, q : 118876.609375, p : 110080.78125, l : 514.712402344\n",
      "batch 91, ep 50, training accuracy 0.935\n",
      "f : 11558.5507812, q : 118744.578125, p : 107737.789062, l : 477.839202881\n",
      "batch 91, ep 100, training accuracy 0.93\n",
      "f : 9648.04980469, q : 118826.085938, p : 109619.234375, l : 478.823425293\n",
      "batch 91, ep 150, training accuracy 0.945\n",
      "f : 9491.55566406, q : 118738.289062, p : 109841.515625, l : 478.96206665\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.8717460632, min: -32.4677467346, mean: 0.0141963306814, std: 8.2513589859\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.68420267105, min: -0.942765712738, mean: 0.0013240192784, std: 0.436465501785\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.188627243, min: -26.4036331177, mean: 0.300390928984, std: 7.57182359695\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.24834704399, min: -1.02130746841, mean: 0.00234764697962, std: 0.432155758142\n",
      "valid accuracy 0.9017\n",
      "batch 92, ep 0, training accuracy 0.92\n",
      "f : 9604.85058594, q : 118769.53125, p : 109980.96875, l : 768.088684082\n",
      "batch 92, ep 50, training accuracy 0.92\n",
      "f : 10291.6523438, q : 118694.109375, p : 109183.28125, l : 743.078613281\n",
      "batch 92, ep 100, training accuracy 0.92\n",
      "f : 9887.58203125, q : 118733.320312, p : 109602.5625, l : 745.685302734\n",
      "batch 92, ep 150, training accuracy 0.925\n",
      "f : 9735.90429688, q : 118706.132812, p : 109733.421875, l : 745.44921875\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.5929946899, min: -32.0692520142, mean: -0.015705479309, std: 8.20132446289\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.52634334564, min: -0.9454190135, mean: 0.00313408183865, std: 0.433829188347\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.3669395447, min: -23.7428474426, mean: 0.28624394536, std: 7.77854633331\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.56547701359, min: -0.768287301064, mean: -0.00762288877741, std: 0.444891750813\n",
      "valid accuracy 0.9013\n",
      "batch 93, ep 0, training accuracy 0.905\n",
      "f : 9466.52246094, q : 118745.0, p : 109899.992188, l : 632.404968262\n",
      "batch 93, ep 50, training accuracy 0.905\n",
      "f : 10154.6279297, q : 118697.195312, p : 109189.929688, l : 589.613647461\n",
      "batch 93, ep 100, training accuracy 0.91\n",
      "f : 9734.74023438, q : 118676.460938, p : 109589.695312, l : 590.664916992\n",
      "batch 93, ep 150, training accuracy 0.905\n",
      "f : 9581.47070312, q : 118685.789062, p : 109693.734375, l : 590.332214355\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.7379722595, min: -36.8844032288, mean: -0.00350576150231, std: 8.17795181274\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.501121521, min: -0.962084710598, mean: -1.73787884705e-05, std: 0.43298587203\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.5741424561, min: -20.508228302, mean: -0.0179296601564, std: 7.65461015701\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.92106735706, min: -0.892495214939, mean: -0.0464101321995, std: 0.433578848839\n",
      "valid accuracy 0.9043\n",
      "batch 94, ep 0, training accuracy 0.915\n",
      "f : 9419.26171875, q : 118659.53125, p : 109908.085938, l : 585.032897949\n",
      "batch 94, ep 50, training accuracy 0.92\n",
      "f : 10087.1484375, q : 118638.804688, p : 109255.9375, l : 546.625488281\n",
      "batch 94, ep 100, training accuracy 0.915\n",
      "f : 9693.91601562, q : 118703.070312, p : 109541.609375, l : 551.017578125\n",
      "batch 94, ep 150, training accuracy 0.92\n",
      "f : 9538.88671875, q : 118684.539062, p : 109644.804688, l : 549.807128906\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.2462997437, min: -30.8759307861, mean: -0.0214843973517, std: 8.18735218048\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.9717874527, min: -0.938226997852, mean: -0.00457570748404, std: 0.434041291475\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.3814888, min: -22.2408885956, mean: -0.0566093884408, std: 7.59276247025\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.03907418251, min: -0.834715306759, mean: 0.00528363185003, std: 0.429752349854\n",
      "valid accuracy 0.9059\n",
      "batch 95, ep 0, training accuracy 0.875\n",
      "f : 9490.04589844, q : 118677.257812, p : 109864.3125, l : 659.983215332\n",
      "batch 95, ep 50, training accuracy 0.88\n",
      "f : 10150.9560547, q : 118627.71875, p : 108999.453125, l : 621.671081543\n",
      "batch 95, ep 100, training accuracy 0.88\n",
      "f : 9763.29589844, q : 118623.046875, p : 109482.421875, l : 614.891906738\n",
      "batch 95, ep 150, training accuracy 0.88\n",
      "f : 9590.17675781, q : 118621.15625, p : 109707.90625, l : 616.902709961\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.1118507385, min: -32.0469436646, mean: -0.024925455451, std: 8.15350914001\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.54861688614, min: -0.920978724957, mean: -0.00333661772311, std: 0.438408762217\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.8438091278, min: -24.1190032959, mean: -0.289210259914, std: 7.86631774902\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.95155262947, min: -0.778181910515, mean: -0.0188480336219, std: 0.467601746321\n",
      "valid accuracy 0.9092\n",
      "batch 96, ep 0, training accuracy 0.875\n",
      "f : 9588.98144531, q : 118638.109375, p : 109831.234375, l : 761.788696289\n",
      "batch 96, ep 50, training accuracy 0.89\n",
      "f : 10263.3574219, q : 118585.039062, p : 109036.695312, l : 726.402587891\n",
      "batch 96, ep 100, training accuracy 0.89\n",
      "f : 9875.20214844, q : 118633.703125, p : 109396.046875, l : 724.673339844\n",
      "batch 96, ep 150, training accuracy 0.895\n",
      "f : 9684.79882812, q : 118512.632812, p : 109643.78125, l : 725.081665039\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.4732971191, min: -33.7641029358, mean: 0.034611929208, std: 8.18253231049\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.82093095779, min: -0.948472440243, mean: -0.0067939190194, std: 0.438394963741\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.73528862, min: -29.0637969971, mean: 0.302678912878, std: 8.0259847641\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.50765609741, min: -0.857940614223, mean: 0.0162769146264, std: 0.455253571272\n",
      "valid accuracy 0.9085\n",
      "batch 97, ep 0, training accuracy 0.875\n",
      "f : 9610.01660156, q : 118606.515625, p : 109732.960938, l : 780.860473633\n",
      "batch 97, ep 50, training accuracy 0.88\n",
      "f : 10285.9316406, q : 118540.5625, p : 109044.289062, l : 724.215454102\n",
      "batch 97, ep 100, training accuracy 0.88\n",
      "f : 9871.58398438, q : 118538.984375, p : 109497.640625, l : 728.584106445\n",
      "batch 97, ep 150, training accuracy 0.88\n",
      "f : 9713.640625, q : 118522.515625, p : 109588.679688, l : 724.817749023\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.6074295044, min: -35.8949928284, mean: 0.0201903413981, std: 8.17517662048\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.458963871, min: -0.940782129765, mean: 0.00139102351386, std: 0.433559238911\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.9699363708, min: -22.79545784, mean: -0.0495847947896, std: 8.01209831238\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.66164422035, min: -0.927214682102, mean: -0.0045067104511, std: 0.438177883625\n",
      "valid accuracy 0.909\n",
      "batch 98, ep 0, training accuracy 0.95\n",
      "f : 9212.59960938, q : 118596.320312, p : 109761.335938, l : 383.878967285\n",
      "batch 98, ep 50, training accuracy 0.95\n",
      "f : 9913.47265625, q : 118509.929688, p : 109008.4375, l : 366.814758301\n",
      "batch 98, ep 100, training accuracy 0.95\n",
      "f : 9440.50683594, q : 118481.335938, p : 109457.921875, l : 364.89855957\n",
      "batch 98, ep 150, training accuracy 0.95\n",
      "f : 9300.97851562, q : 118578.382812, p : 109577.203125, l : 367.613494873\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.6276168823, min: -33.6432952881, mean: -0.0312643758953, std: 8.11435699463\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.60283112526, min: -0.920289456844, mean: -0.0041320878081, std: 0.436296701431\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.6124820709, min: -24.399597168, mean: 0.130288243294, std: 7.7379655838\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.44942188263, min: -0.798388898373, mean: 0.0438777282834, std: 0.454451709986\n",
      "valid accuracy 0.9099\n",
      "batch 99, ep 0, training accuracy 0.86\n",
      "f : 9635.64160156, q : 118462.34375, p : 109704.796875, l : 802.58392334\n",
      "batch 99, ep 50, training accuracy 0.875\n",
      "f : 11795.5390625, q : 118566.96875, p : 107370.664062, l : 756.543457031\n",
      "batch 99, ep 100, training accuracy 0.885\n",
      "f : 10343.1142578, q : 118558.242188, p : 108967.84375, l : 745.860595703\n",
      "batch 99, ep 150, training accuracy 0.88\n",
      "f : 9771.234375, q : 118570.148438, p : 109449.570312, l : 745.465942383\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.360584259, min: -38.7577552795, mean: -0.0388779342175, std: 8.16064834595\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.62076663971, min: -0.934189915657, mean: -0.00724768312648, std: 0.434972822666\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.0683670044, min: -24.2307872772, mean: 0.273609250784, std: 7.92097139359\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.7970097065, min: -1.019490242, mean: -0.020747711882, std: 0.446859329939\n",
      "valid accuracy 0.9097\n",
      "batch 100, ep 0, training accuracy 0.865\n",
      "f : 9696.31738281, q : 118430.375, p : 109640.742188, l : 861.68939209\n",
      "batch 100, ep 50, training accuracy 0.885\n",
      "f : 10389.1611328, q : 118384.179688, p : 108920.125, l : 825.425598145\n",
      "batch 100, ep 100, training accuracy 0.885\n",
      "f : 9985.94628906, q : 118426.492188, p : 109252.3125, l : 823.791870117\n",
      "batch 100, ep 150, training accuracy 0.89\n",
      "f : 9843.63671875, q : 118415.570312, p : 109520.664062, l : 824.786560059\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.9044914246, min: -30.9513778687, mean: 0.00376244727522, std: 8.12288284302\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.79936027527, min: -0.918353796005, mean: -0.00372141017579, std: 0.435315817595\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.5438079834, min: -20.6919059753, mean: 0.550347805023, std: 7.53023862839\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.62211823463, min: -1.034760952, mean: -0.0467477925122, std: 0.466428697109\n",
      "valid accuracy 0.9089\n",
      "batch 101, ep 0, training accuracy 0.935\n",
      "f : 9483.41503906, q : 118380.53125, p : 109599.8125, l : 651.143493652\n",
      "batch 101, ep 50, training accuracy 0.935\n",
      "f : 10153.4335938, q : 118356.117188, p : 108820.492188, l : 629.157897949\n",
      "batch 101, ep 100, training accuracy 0.94\n",
      "f : 9768.49511719, q : 118469.125, p : 109224.171875, l : 623.708557129\n",
      "batch 101, ep 150, training accuracy 0.93\n",
      "f : 9566.76953125, q : 118418.195312, p : 109427.734375, l : 627.739562988\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.7320175171, min: -34.6571998596, mean: 0.00297564198263, std: 8.09025382996\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.63501858711, min: -0.950413227081, mean: -0.00397338299081, std: 0.433581590652\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.8411426544, min: -28.8482074738, mean: 0.344972133636, std: 7.44051837921\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.29606688023, min: -0.827383458614, mean: 0.0115995379165, std: 0.44488337636\n",
      "valid accuracy 0.9081\n",
      "batch 102, ep 0, training accuracy 0.935\n",
      "f : 9384.79394531, q : 118367.78125, p : 109541.882812, l : 552.623413086\n",
      "batch 102, ep 50, training accuracy 0.94\n",
      "f : 10039.6132812, q : 118371.265625, p : 108896.914062, l : 535.695068359\n",
      "batch 102, ep 100, training accuracy 0.94\n",
      "f : 9664.79589844, q : 118410.695312, p : 109220.742188, l : 536.093078613\n",
      "batch 102, ep 150, training accuracy 0.94\n",
      "f : 9449.90820312, q : 118318.5625, p : 109428.640625, l : 535.891235352\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.7309837341, min: -31.7037734985, mean: 0.021772833541, std: 8.1096572876\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.90877103806, min: -0.930919289589, mean: 0.000864424393512, std: 0.436062961817\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.9888916016, min: -19.5203590393, mean: 0.0501251295209, std: 7.85383272171\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.59975469112, min: -0.807695925236, mean: -0.003515353892, std: 0.448547393084\n",
      "valid accuracy 0.9083\n",
      "batch 103, ep 0, training accuracy 0.88\n",
      "f : 9658.49511719, q : 118348.1875, p : 109620.0, l : 831.296264648\n",
      "batch 103, ep 50, training accuracy 0.9\n",
      "f : 10318.1582031, q : 118408.539062, p : 108810.421875, l : 783.179870605\n",
      "batch 103, ep 100, training accuracy 0.9\n",
      "f : 9919.75097656, q : 118306.15625, p : 109072.515625, l : 786.824707031\n",
      "batch 103, ep 150, training accuracy 0.9\n",
      "f : 9775.06347656, q : 118271.734375, p : 109265.953125, l : 788.12689209\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.7136116028, min: -31.8239898682, mean: 0.00332926260307, std: 8.11225032806\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.42348527908, min: -0.923929691315, mean: -0.00206846115179, std: 0.433975785971\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.2580738068, min: -19.6586112976, mean: -0.176547005773, std: 7.73275279999\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.66254866123, min: -0.821482717991, mean: 0.0133300842717, std: 0.450728237629\n",
      "valid accuracy 0.9062\n",
      "batch 104, ep 0, training accuracy 0.88\n",
      "f : 9811.56445312, q : 118321.195312, p : 109438.445312, l : 983.088134766\n",
      "batch 104, ep 50, training accuracy 0.885\n",
      "f : 10467.1640625, q : 118256.8125, p : 108796.632812, l : 935.08605957\n",
      "batch 104, ep 100, training accuracy 0.885\n",
      "f : 10077.5839844, q : 118237.632812, p : 109204.25, l : 941.533081055\n",
      "batch 104, ep 150, training accuracy 0.895\n",
      "f : 9919.95800781, q : 118318.382812, p : 109378.789062, l : 934.385253906\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.5643043518, min: -36.4337158203, mean: 0.0770183801651, std: 8.07592105865\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.73875021935, min: -0.932883024216, mean: -0.00715682283044, std: 0.435844480991\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.8762283325, min: -26.9445514679, mean: -0.16722612083, std: 7.72234964371\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.88463151455, min: -0.832208395004, mean: -0.00715351384133, std: 0.434835225344\n",
      "valid accuracy 0.9049\n",
      "batch 105, ep 0, training accuracy 0.92\n",
      "f : 9556.36621094, q : 118333.890625, p : 109439.53125, l : 723.512512207\n",
      "batch 105, ep 50, training accuracy 0.925\n",
      "f : 10223.8203125, q : 118329.421875, p : 108778.953125, l : 702.775024414\n",
      "batch 105, ep 100, training accuracy 0.925\n",
      "f : 9834.51464844, q : 118298.382812, p : 109174.640625, l : 700.520996094\n",
      "batch 105, ep 150, training accuracy 0.93\n",
      "f : 9639.76660156, q : 118311.59375, p : 109293.328125, l : 703.996643066\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.9653129578, min: -33.0159721375, mean: -0.0186501163989, std: 8.09928417206\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.91697072983, min: -0.947797238827, mean: -0.00113375892397, std: 0.433578312397\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.0048694611, min: -23.204328537, mean: -0.565037667751, std: 8.11995887756\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.58368515968, min: -0.803586661816, mean: 0.00899142306298, std: 0.427989661694\n",
      "valid accuracy 0.9059\n",
      "batch 106, ep 0, training accuracy 0.925\n",
      "f : 9374.12890625, q : 118224.414062, p : 109482.289062, l : 542.183959961\n",
      "batch 106, ep 50, training accuracy 0.95\n",
      "f : 10014.6582031, q : 118195.726562, p : 108726.671875, l : 506.018310547\n",
      "batch 106, ep 100, training accuracy 0.95\n",
      "f : 9646.94726562, q : 118248.507812, p : 109162.53125, l : 509.715576172\n",
      "batch 106, ep 150, training accuracy 0.95\n",
      "f : 9495.8046875, q : 118219.703125, p : 109267.09375, l : 513.09576416\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.3413276672, min: -33.8267593384, mean: -0.0122900176793, std: 8.13201904297\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.51367163658, min: -0.928950548172, mean: -0.00575918192044, std: 0.439711928368\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.8419513702, min: -23.2953853607, mean: -0.128590002656, std: 7.82759428024\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.88838028908, min: -0.835322916508, mean: 0.00293181464076, std: 0.415331572294\n",
      "valid accuracy 0.9075\n",
      "batch 107, ep 0, training accuracy 0.925\n",
      "f : 9441.78320312, q : 118223.4375, p : 109391.40625, l : 610.85369873\n",
      "batch 107, ep 50, training accuracy 0.925\n",
      "f : 11441.7128906, q : 118208.109375, p : 107299.78125, l : 582.296630859\n",
      "batch 107, ep 100, training accuracy 0.925\n",
      "f : 9726.375, q : 118229.5625, p : 109098.976562, l : 578.390075684\n",
      "batch 107, ep 150, training accuracy 0.925\n",
      "f : 9573.94824219, q : 118205.390625, p : 109186.539062, l : 578.724182129\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.1802902222, min: -32.0375938416, mean: 0.0457731001079, std: 8.08541107178\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.47548627853, min: -0.926227509975, mean: -0.00519159436226, std: 0.435810893774\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.7903175354, min: -23.6452102661, mean: -0.287124425173, std: 8.00785923004\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.41020023823, min: -1.09072554111, mean: -0.00124127999879, std: 0.448180228472\n",
      "valid accuracy 0.9076\n",
      "batch 108, ep 0, training accuracy 0.94\n",
      "f : 9378.171875, q : 118189.375, p : 109472.703125, l : 545.297241211\n",
      "batch 108, ep 50, training accuracy 0.94\n",
      "f : 10033.4912109, q : 118203.539062, p : 108674.960938, l : 528.656982422\n",
      "batch 108, ep 100, training accuracy 0.94\n",
      "f : 9665.13671875, q : 118214.523438, p : 109026.210938, l : 527.625427246\n",
      "batch 108, ep 150, training accuracy 0.94\n",
      "f : 9504.36914062, q : 118140.867188, p : 109178.421875, l : 527.606079102\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.9909133911, min: -32.0305557251, mean: -0.0457101911306, std: 8.04014587402\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.55408143997, min: -0.899339258671, mean: -0.00189844530541, std: 0.433195233345\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.4288730621, min: -24.2454185486, mean: 0.16067391634, std: 7.42665147781\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.59200620651, min: -0.871107637882, mean: -0.0132239721715, std: 0.428826987743\n",
      "valid accuracy 0.9082\n",
      "batch 109, ep 0, training accuracy 0.925\n",
      "f : 9358.06347656, q : 118105.703125, p : 109351.164062, l : 529.739501953\n",
      "batch 109, ep 50, training accuracy 0.93\n",
      "f : 10013.5, q : 118102.34375, p : 108653.640625, l : 510.383850098\n",
      "batch 109, ep 100, training accuracy 0.925\n",
      "f : 9634.77734375, q : 118051.390625, p : 109009.40625, l : 507.745819092\n",
      "batch 109, ep 150, training accuracy 0.93\n",
      "f : 9449.20898438, q : 118079.640625, p : 109213.75, l : 505.807037354\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.2102813721, min: -30.2315826416, mean: -0.0438265874982, std: 8.02397441864\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.41761660576, min: -0.948065519333, mean: -0.0016901526833, std: 0.435430526733\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.8070907593, min: -26.4314899445, mean: -0.108824983239, std: 7.55992984772\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.69606363773, min: -0.928579092026, mean: 0.0187521148473, std: 0.423062056303\n",
      "valid accuracy 0.9082\n",
      "batch 110, ep 0, training accuracy 0.895\n",
      "f : 9518.61132812, q : 118079.046875, p : 109266.71875, l : 686.860717773\n",
      "batch 110, ep 50, training accuracy 0.895\n",
      "f : 10200.7792969, q : 118142.5, p : 108588.96875, l : 654.069091797\n",
      "batch 110, ep 100, training accuracy 0.895\n",
      "f : 9779.64160156, q : 118125.640625, p : 108934.789062, l : 653.95300293\n",
      "batch 110, ep 150, training accuracy 0.895\n",
      "f : 9623.09179688, q : 118095.242188, p : 109109.320312, l : 655.130981445\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.4101924896, min: -32.4705619812, mean: 0.0224196016788, std: 8.08181476593\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.87958455086, min: -0.968613266945, mean: -0.00588021986187, std: 0.435636520386\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.4571456909, min: -20.3214187622, mean: 0.130347877741, std: 7.57222223282\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.57983851433, min: -0.899535179138, mean: -0.0320030860603, std: 0.447713345289\n",
      "valid accuracy 0.908\n",
      "batch 111, ep 0, training accuracy 0.925\n",
      "f : 9503.81445312, q : 118128.710938, p : 109258.390625, l : 678.01763916\n",
      "batch 111, ep 50, training accuracy 0.925\n",
      "f : 10186.9443359, q : 118075.96875, p : 108492.273438, l : 641.466308594\n",
      "batch 111, ep 100, training accuracy 0.925\n",
      "f : 9770.68261719, q : 118106.289062, p : 108861.039062, l : 641.066589355\n",
      "batch 111, ep 150, training accuracy 0.925\n",
      "f : 9622.42675781, q : 118009.335938, p : 109121.789062, l : 640.137329102\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.4889144897, min: -33.8644752502, mean: -0.00121274753474, std: 8.09523677826\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.49256205559, min: -0.949731349945, mean: -0.000510488869622, std: 0.434693604708\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.5420017242, min: -23.5525150299, mean: -0.36263486743, std: 7.85955762863\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.36778533459, min: -0.838106393814, mean: 0.00884476862848, std: 0.450716972351\n",
      "valid accuracy 0.9094\n",
      "batch 112, ep 0, training accuracy 0.825\n",
      "f : 9856.82714844, q : 118053.648438, p : 109236.039062, l : 1028.48046875\n",
      "batch 112, ep 50, training accuracy 0.835\n",
      "f : 11816.8759766, q : 118035.101562, p : 107099.84375, l : 977.164001465\n",
      "batch 112, ep 100, training accuracy 0.84\n",
      "f : 10126.0253906, q : 118094.132812, p : 108875.414062, l : 968.484619141\n",
      "batch 112, ep 150, training accuracy 0.83\n",
      "f : 9967.73535156, q : 118059.289062, p : 108975.148438, l : 966.788818359\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.7929191589, min: -31.8519382477, mean: 0.00397582678124, std: 8.11632347107\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.69959568977, min: -0.945294678211, mean: -0.00624018535018, std: 0.435441046953\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.145734787, min: -23.2416095734, mean: -0.356229245663, std: 7.94868803024\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.04412651062, min: -1.00761830807, mean: -0.000652503978927, std: 0.444736480713\n",
      "valid accuracy 0.908\n",
      "batch 113, ep 0, training accuracy 0.88\n",
      "f : 9545.91796875, q : 118013.335938, p : 109218.101562, l : 718.244628906\n",
      "batch 113, ep 50, training accuracy 0.88\n",
      "f : 10192.7890625, q : 118022.734375, p : 108478.445312, l : 675.567993164\n",
      "batch 113, ep 100, training accuracy 0.88\n",
      "f : 9813.29296875, q : 117878.234375, p : 108912.539062, l : 675.620605469\n",
      "batch 113, ep 150, training accuracy 0.88\n",
      "f : 9644.86621094, q : 118012.804688, p : 108972.078125, l : 677.461425781\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.5872020721, min: -31.4507713318, mean: 0.0875310003757, std: 8.02200222015\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.91133737564, min: -0.933681845665, mean: -0.00321844732389, std: 0.431094884872\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.411272049, min: -20.9921474457, mean: 0.274359762669, std: 7.56837844849\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.82643902302, min: -0.890723049641, mean: -0.0277786031365, std: 0.394230782986\n",
      "valid accuracy 0.9076\n",
      "batch 114, ep 0, training accuracy 0.94\n",
      "f : 9262.86328125, q : 118034.289062, p : 109169.03125, l : 436.85333252\n",
      "batch 114, ep 50, training accuracy 0.945\n",
      "f : 9931.07128906, q : 117946.1875, p : 108470.976562, l : 422.194946289\n",
      "batch 114, ep 100, training accuracy 0.94\n",
      "f : 9505.65429688, q : 117912.835938, p : 108944.523438, l : 422.055023193\n",
      "batch 114, ep 150, training accuracy 0.945\n",
      "f : 9333.08691406, q : 117992.625, p : 109055.679688, l : 422.124084473\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.7533740997, min: -30.3830032349, mean: -0.00996681582183, std: 7.98093032837\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.27414464951, min: -0.931832313538, mean: -0.00238924496807, std: 0.43508297205\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.406452179, min: -21.2129669189, mean: -0.694200098515, std: 7.65634155273\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.43069195747, min: -0.811921656132, mean: 0.0158628895879, std: 0.418492734432\n",
      "valid accuracy 0.9061\n",
      "batch 115, ep 0, training accuracy 0.9\n",
      "f : 9529.34179688, q : 117923.148438, p : 109140.0, l : 702.353759766\n",
      "batch 115, ep 50, training accuracy 0.895\n",
      "f : 10175.8232422, q : 117965.820312, p : 108381.296875, l : 656.394897461\n",
      "batch 115, ep 100, training accuracy 0.9\n",
      "f : 9787.18164062, q : 117865.515625, p : 108759.117188, l : 655.267089844\n",
      "batch 115, ep 150, training accuracy 0.9\n",
      "f : 9624.02148438, q : 117898.046875, p : 108867.695312, l : 654.024291992\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.8588142395, min: -29.9469547272, mean: -0.0664794892073, std: 8.05314254761\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.76195240021, min: -0.95075917244, mean: -0.00721714505926, std: 0.437285631895\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.4807834625, min: -23.7350025177, mean: 0.8626973629, std: 7.48430967331\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.6821038723, min: -0.789171636105, mean: -0.0205661356449, std: 0.41469925642\n",
      "valid accuracy 0.9079\n",
      "batch 116, ep 0, training accuracy 0.915\n",
      "f : 9402.73046875, q : 117900.671875, p : 109115.632812, l : 573.299804688\n",
      "batch 116, ep 50, training accuracy 0.92\n",
      "f : 10056.6972656, q : 117890.992188, p : 108330.289062, l : 547.118652344\n",
      "batch 116, ep 100, training accuracy 0.92\n",
      "f : 9660.46679688, q : 117894.007812, p : 108719.765625, l : 547.743164062\n",
      "batch 116, ep 150, training accuracy 0.92\n",
      "f : 9506.03417969, q : 117929.492188, p : 108904.507812, l : 546.596984863\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.634979248, min: -33.7410812378, mean: -0.00932026002556, std: 7.98820590973\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.46641111374, min: -0.938774585724, mean: -0.0088713504374, std: 0.433489561081\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.1172676086, min: -20.49243927, mean: -0.0113884275779, std: 7.65175437927\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68179953098, min: -0.900045633316, mean: 0.00692714098841, std: 0.427455961704\n",
      "valid accuracy 0.9091\n",
      "batch 117, ep 0, training accuracy 0.91\n",
      "f : 9463.0859375, q : 117980.65625, p : 109119.21875, l : 635.427734375\n",
      "batch 117, ep 50, training accuracy 0.91\n",
      "f : 10109.5429688, q : 117931.234375, p : 108337.109375, l : 606.756225586\n",
      "batch 117, ep 100, training accuracy 0.91\n",
      "f : 9732.68164062, q : 117938.1875, p : 108720.828125, l : 603.158813477\n",
      "batch 117, ep 150, training accuracy 0.905\n",
      "f : 9583.95410156, q : 117818.296875, p : 108930.460938, l : 605.524291992\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.4144859314, min: -34.7627639771, mean: -0.066118568182, std: 8.06154823303\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.03075313568, min: -0.948039233685, mean: -0.00324337440543, std: 0.433886379004\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.030412674, min: -20.4092178345, mean: 0.479823440313, std: 7.58546876907\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.20412802696, min: -0.809659183025, mean: 0.00481961714104, std: 0.419705361128\n",
      "valid accuracy 0.9098\n",
      "batch 118, ep 0, training accuracy 0.895\n",
      "f : 9507.87695312, q : 117932.109375, p : 109059.617188, l : 675.419311523\n",
      "batch 118, ep 50, training accuracy 0.9\n",
      "f : 10142.8291016, q : 117898.46875, p : 108334.21875, l : 657.353515625\n",
      "batch 118, ep 100, training accuracy 0.9\n",
      "f : 9779.75976562, q : 117911.976562, p : 108691.132812, l : 654.01739502\n",
      "batch 118, ep 150, training accuracy 0.9\n",
      "f : 9615.7890625, q : 117828.234375, p : 108977.5, l : 653.686767578\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.2313804626, min: -37.7251434326, mean: 0.00602841190994, std: 8.01489830017\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.63705396652, min: -0.913015663624, mean: -0.00632320623845, std: 0.435397863388\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.7867527008, min: -18.9525089264, mean: 0.384252309799, std: 7.88178730011\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68810236454, min: -0.819442272186, mean: 0.0348220542073, std: 0.410706222057\n",
      "valid accuracy 0.9101\n",
      "batch 119, ep 0, training accuracy 0.895\n",
      "f : 9584.7265625, q : 117791.742188, p : 109077.96875, l : 754.734069824\n",
      "batch 119, ep 50, training accuracy 0.895\n",
      "f : 10249.7402344, q : 117820.859375, p : 108376.03125, l : 728.28527832\n",
      "batch 119, ep 100, training accuracy 0.9\n",
      "f : 9839.14160156, q : 117796.265625, p : 108701.59375, l : 724.605834961\n",
      "batch 119, ep 150, training accuracy 0.895\n",
      "f : 9693.64648438, q : 117808.539062, p : 108877.757812, l : 728.362548828\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.4724578857, min: -33.836933136, mean: 0.0773650929332, std: 8.03264904022\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.64498996735, min: -0.922909736633, mean: -0.00797335896641, std: 0.43703430891\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.8946781158, min: -22.997127533, mean: -0.0987614393234, std: 7.62305116653\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.84923815727, min: -0.816421806812, mean: -0.00494664441794, std: 0.438401132822\n",
      "valid accuracy 0.9116\n",
      "batch 120, ep 0, training accuracy 0.9\n",
      "f : 9440.6796875, q : 117904.757812, p : 108977.242188, l : 609.3203125\n",
      "batch 120, ep 50, training accuracy 0.915\n",
      "f : 10095.34375, q : 117798.976562, p : 108210.609375, l : 590.577209473\n",
      "batch 120, ep 100, training accuracy 0.915\n",
      "f : 9709.70214844, q : 117774.21875, p : 108676.734375, l : 587.032409668\n",
      "batch 120, ep 150, training accuracy 0.915\n",
      "f : 9510.85644531, q : 117873.007812, p : 108868.328125, l : 589.981872559\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.7486591339, min: -34.5404243469, mean: -0.0638604536653, std: 7.99977731705\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.09358978271, min: -0.955757379532, mean: -0.00476156361401, std: 0.435328602791\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.7470645905, min: -28.2116603851, mean: 0.0495389290154, std: 8.1349029541\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.53131914139, min: -0.864590287209, mean: 0.0230660866946, std: 0.434064656496\n",
      "valid accuracy 0.911\n",
      "batch 121, ep 0, training accuracy 0.875\n",
      "f : 9504.61621094, q : 117774.632812, p : 108890.289062, l : 673.861816406\n",
      "batch 121, ep 50, training accuracy 0.89\n",
      "f : 10168.8417969, q : 117738.265625, p : 108234.9375, l : 654.229248047\n",
      "batch 121, ep 100, training accuracy 0.885\n",
      "f : 9775.97265625, q : 117797.40625, p : 108729.65625, l : 652.683349609\n",
      "batch 121, ep 150, training accuracy 0.875\n",
      "f : 9574.1171875, q : 117726.914062, p : 108969.039062, l : 651.291381836\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.859375, min: -35.5611686707, mean: 0.00535793695599, std: 7.95780181885\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.334015131, min: -0.928758859634, mean: -0.00218591513112, std: 0.434169888496\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.0179958344, min: -20.9891319275, mean: 0.569818735123, std: 7.52516031265\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.60750365257, min: -0.840142905712, mean: 0.0132334008813, std: 0.452131569386\n",
      "valid accuracy 0.9115\n",
      "batch 122, ep 0, training accuracy 0.895\n",
      "f : 9636.35644531, q : 117718.820312, p : 108939.640625, l : 801.402648926\n",
      "batch 122, ep 50, training accuracy 0.89\n",
      "f : 10258.6425781, q : 117777.59375, p : 108180.195312, l : 728.067016602\n",
      "batch 122, ep 100, training accuracy 0.895\n",
      "f : 9896.73535156, q : 117724.945312, p : 108595.898438, l : 728.535949707\n",
      "batch 122, ep 150, training accuracy 0.89\n",
      "f : 9717.86621094, q : 117761.890625, p : 108801.34375, l : 726.391601562\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.756193161, min: -33.5771865845, mean: 0.0210390612483, std: 7.98098516464\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.72132587433, min: -0.939673781395, mean: 0.000924031832255, std: 0.436712026596\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.2165985107, min: -22.8950881958, mean: -0.291040539742, std: 7.44337034225\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.93999242783, min: -1.01529991627, mean: -0.00292342645116, std: 0.413003712893\n",
      "valid accuracy 0.9107\n",
      "batch 123, ep 0, training accuracy 0.825\n",
      "f : 9895.48144531, q : 117756.742188, p : 108875.117188, l : 1068.12426758\n",
      "batch 123, ep 50, training accuracy 0.87\n",
      "f : 10519.4111328, q : 117717.40625, p : 108100.398438, l : 934.25\n",
      "batch 123, ep 100, training accuracy 0.865\n",
      "f : 10123.7382812, q : 117655.789062, p : 108489.945312, l : 932.745117188\n",
      "batch 123, ep 150, training accuracy 0.88\n",
      "f : 9977.53027344, q : 117686.90625, p : 108552.0625, l : 935.335449219\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.0129737854, min: -37.4121665955, mean: -0.0457203127444, std: 7.95596837997\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.77135801315, min: -0.920081734657, mean: -0.00373635464348, std: 0.434095323086\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.8445110321, min: -24.1760787964, mean: 0.242794305086, std: 7.73496055603\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.08813643456, min: -1.10579276085, mean: -0.00996960978955, std: 0.435392081738\n",
      "valid accuracy 0.9079\n",
      "batch 124, ep 0, training accuracy 0.875\n",
      "f : 9585.3359375, q : 117692.523438, p : 108929.976562, l : 751.59777832\n",
      "batch 124, ep 50, training accuracy 0.885\n",
      "f : 10217.3378906, q : 117712.046875, p : 108211.960938, l : 702.624633789\n",
      "batch 124, ep 100, training accuracy 0.885\n",
      "f : 9832.84667969, q : 117644.015625, p : 108553.710938, l : 697.810058594\n",
      "batch 124, ep 150, training accuracy 0.885\n",
      "f : 9656.38867188, q : 117630.21875, p : 108740.40625, l : 704.127685547\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.3504104614, min: -32.8100318909, mean: -0.0543456599116, std: 7.98305702209\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.60871458054, min: -0.946652293205, mean: -0.000609903538134, std: 0.436278402805\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.7415714264, min: -23.8383998871, mean: -0.183066129684, std: 7.83765554428\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.53009319305, min: -0.807902276516, mean: -0.00098606327083, std: 0.448234975338\n",
      "valid accuracy 0.9103\n",
      "batch 125, ep 0, training accuracy 0.915\n",
      "f : 9455.42285156, q : 117718.226562, p : 108848.03125, l : 622.857666016\n",
      "batch 125, ep 50, training accuracy 0.915\n",
      "f : 10091.9472656, q : 117647.742188, p : 108132.617188, l : 592.192443848\n",
      "batch 125, ep 100, training accuracy 0.925\n",
      "f : 9708.54589844, q : 117651.9375, p : 108587.898438, l : 591.409240723\n",
      "batch 125, ep 150, training accuracy 0.93\n",
      "f : 9554.51660156, q : 117664.992188, p : 108760.976562, l : 595.166992188\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.4422149658, min: -33.6991081238, mean: -0.0107907252386, std: 7.95303916931\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.79809951782, min: -0.949008464813, mean: -0.000232756690821, std: 0.434995025396\n",
      "layer1/q_pos/mu:0\n",
      "max: 29.3376331329, min: -26.9305438995, mean: -0.365068078041, std: 7.71810293198\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68563830853, min: -0.744634866714, mean: 0.0020250142552, std: 0.421662330627\n",
      "valid accuracy 0.9103\n",
      "batch 126, ep 0, training accuracy 0.89\n",
      "f : 9519.56152344, q : 117620.304688, p : 108827.0, l : 691.423400879\n",
      "batch 126, ep 50, training accuracy 0.895\n",
      "f : 10176.2949219, q : 117604.492188, p : 108199.382812, l : 666.096740723\n",
      "batch 126, ep 100, training accuracy 0.895\n",
      "f : 9788.62890625, q : 117596.148438, p : 108513.179688, l : 664.198486328\n",
      "batch 126, ep 150, training accuracy 0.895\n",
      "f : 9630.98242188, q : 117649.078125, p : 108601.0, l : 665.26385498\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.4602622986, min: -31.2962684631, mean: -0.0389368310571, std: 7.96815776825\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.58759903908, min: -0.92485588789, mean: -0.00339890411124, std: 0.435766547918\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.2687950134, min: -28.7230415344, mean: 0.42394721508, std: 7.42443752289\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.54999876022, min: -0.81252425909, mean: -0.0149001805112, std: 0.431345045567\n",
      "valid accuracy 0.911\n",
      "batch 127, ep 0, training accuracy 0.925\n",
      "f : 9380.94628906, q : 117613.28125, p : 108742.601562, l : 546.882324219\n",
      "batch 127, ep 50, training accuracy 0.935\n",
      "f : 10008.5009766, q : 117679.023438, p : 108019.734375, l : 528.726867676\n",
      "batch 127, ep 100, training accuracy 0.94\n",
      "f : 9641.25976562, q : 117504.890625, p : 108472.867188, l : 524.43182373\n",
      "batch 127, ep 150, training accuracy 0.935\n",
      "f : 9468.95117188, q : 117551.8125, p : 108616.625, l : 526.642211914\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.3179740906, min: -33.6140022278, mean: 0.0392029769719, std: 7.94665622711\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.97958707809, min: -0.914756119251, mean: -0.00377678009681, std: 0.438236415386\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.1282558441, min: -21.9772396088, mean: -0.128282248974, std: 7.39745950699\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.30756664276, min: -0.819712162018, mean: -0.0384039022028, std: 0.423407047987\n",
      "valid accuracy 0.9116\n",
      "batch 128, ep 0, training accuracy 0.905\n",
      "f : 9388.03613281, q : 117661.703125, p : 108645.695312, l : 560.677124023\n",
      "batch 128, ep 50, training accuracy 0.91\n",
      "f : 10034.1220703, q : 117501.351562, p : 108122.875, l : 540.710998535\n",
      "batch 128, ep 100, training accuracy 0.915\n",
      "f : 9658.3125, q : 117569.328125, p : 108531.945312, l : 537.677124023\n",
      "batch 128, ep 150, training accuracy 0.92\n",
      "f : 9515.89746094, q : 117486.789062, p : 108629.765625, l : 537.63269043\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.5918273926, min: -34.3687362671, mean: 0.0574006587267, std: 7.94895267487\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.5772755146, min: -0.919435977936, mean: -0.00658388016745, std: 0.4333306849\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.4373321533, min: -24.6971855164, mean: -0.266080111265, std: 7.46456336975\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.02130055428, min: -0.79292678833, mean: 0.0416078977287, std: 0.427673965693\n",
      "valid accuracy 0.9126\n",
      "batch 129, ep 0, training accuracy 0.905\n",
      "f : 9509.73339844, q : 117472.234375, p : 108659.085938, l : 681.54486084\n",
      "batch 129, ep 50, training accuracy 0.905\n",
      "f : 10217.7070312, q : 117442.679688, p : 107943.28125, l : 654.820251465\n",
      "batch 129, ep 100, training accuracy 0.905\n",
      "f : 9775.22949219, q : 117523.960938, p : 108420.28125, l : 658.687744141\n",
      "batch 129, ep 150, training accuracy 0.9\n",
      "f : 9637.92285156, q : 117589.945312, p : 108602.835938, l : 654.229187012\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.8900947571, min: -35.8670463562, mean: 0.0252321567386, std: 7.97914981842\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.23905086517, min: -0.94451546669, mean: -0.00243371445686, std: 0.436239391565\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.8860225677, min: -26.3996295929, mean: 0.304628044367, std: 7.60431241989\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.63632178307, min: -0.813081741333, mean: 0.0159223396331, std: 0.428217411041\n",
      "valid accuracy 0.912\n",
      "batch 130, ep 0, training accuracy 0.935\n",
      "f : 9323.375, q : 117524.375, p : 108641.507812, l : 489.771514893\n",
      "batch 130, ep 50, training accuracy 0.935\n",
      "f : 9947.21875, q : 117460.0625, p : 107963.34375, l : 472.208190918\n",
      "batch 130, ep 100, training accuracy 0.935\n",
      "f : 9589.34375, q : 117514.421875, p : 108417.28125, l : 470.965942383\n",
      "batch 130, ep 150, training accuracy 0.935\n",
      "f : 9392.69042969, q : 117462.320312, p : 108644.929688, l : 473.308013916\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.016330719, min: -34.2021865845, mean: -0.0451034829021, std: 7.8588476181\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.55228662491, min: -0.924523830414, mean: -0.00504034524783, std: 0.433871090412\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.1202297211, min: -18.6430511475, mean: -0.225982025266, std: 7.31960916519\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.39743423462, min: -0.863389909267, mean: -0.0166320819408, std: 0.457752466202\n",
      "valid accuracy 0.9125\n",
      "batch 131, ep 0, training accuracy 0.91\n",
      "f : 9640.61328125, q : 117493.242188, p : 108695.757812, l : 807.922912598\n",
      "batch 131, ep 50, training accuracy 0.91\n",
      "f : 10273.3574219, q : 117490.0, p : 108087.960938, l : 779.708984375\n",
      "batch 131, ep 100, training accuracy 0.91\n",
      "f : 9884.64257812, q : 117556.710938, p : 108455.28125, l : 777.104370117\n",
      "batch 131, ep 150, training accuracy 0.91\n",
      "f : 9731.0, q : 117465.210938, p : 108504.65625, l : 776.262512207\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.80286026, min: -32.2534103394, mean: -0.0767739191651, std: 7.88181972504\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.33380150795, min: -0.923249721527, mean: -0.00187506119255, std: 0.435963153839\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.7327365875, min: -18.7103061676, mean: 0.656250178814, std: 7.55770683289\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.53706145287, min: -0.800119578838, mean: 0.00442781252787, std: 0.445900321007\n",
      "valid accuracy 0.9131\n",
      "batch 132, ep 0, training accuracy 0.865\n",
      "f : 9688.13085938, q : 117450.953125, p : 108545.40625, l : 857.263183594\n",
      "batch 132, ep 50, training accuracy 0.875\n",
      "f : 10308.0507812, q : 117371.90625, p : 107968.296875, l : 807.520751953\n",
      "batch 132, ep 100, training accuracy 0.87\n",
      "f : 9934.42675781, q : 117453.695312, p : 108267.289062, l : 806.681640625\n",
      "batch 132, ep 150, training accuracy 0.86\n",
      "f : 9766.19824219, q : 117375.226562, p : 108531.101562, l : 809.675048828\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.1023769379, min: -36.8311347961, mean: 0.02412401326, std: 7.97570419312\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.31772971153, min: -0.939169406891, mean: -0.00352494162507, std: 0.439684092999\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.5919685364, min: -18.8907794952, mean: 0.368225157261, std: 7.2686753273\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.74410307407, min: -0.799456954002, mean: 0.020683594048, std: 0.430066287518\n",
      "valid accuracy 0.9112\n",
      "batch 133, ep 0, training accuracy 0.865\n",
      "f : 9878.2578125, q : 117421.09375, p : 108617.585938, l : 1041.82189941\n",
      "batch 133, ep 50, training accuracy 0.87\n",
      "f : 10484.1865234, q : 117481.84375, p : 107851.617188, l : 978.887207031\n",
      "batch 133, ep 100, training accuracy 0.87\n",
      "f : 10110.7744141, q : 117511.851562, p : 108306.007812, l : 982.915222168\n",
      "batch 133, ep 150, training accuracy 0.87\n",
      "f : 9967.77441406, q : 117456.75, p : 108453.804688, l : 980.909484863\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.1116256714, min: -33.5567970276, mean: 0.0586274750531, std: 7.98398637772\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.55388307571, min: -0.948467254639, mean: -0.00595751032233, std: 0.438084304333\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.5768070221, min: -22.6092414856, mean: -0.0341994054615, std: 7.3254108429\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.2050204277, min: -0.851155638695, mean: -0.00948135741055, std: 0.418277859688\n",
      "valid accuracy 0.9125\n",
      "batch 134, ep 0, training accuracy 0.925\n",
      "f : 9480.07910156, q : 117428.570312, p : 108662.90625, l : 652.619873047\n",
      "batch 134, ep 50, training accuracy 0.925\n",
      "f : 10118.5195312, q : 117424.796875, p : 107974.445312, l : 626.713623047\n",
      "batch 134, ep 100, training accuracy 0.925\n",
      "f : 9652.99609375, q : 117496.539062, p : 108433.398438, l : 629.064880371\n",
      "batch 134, ep 150, training accuracy 0.925\n",
      "f : 9547.52246094, q : 117334.320312, p : 108476.828125, l : 628.268310547\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.8876266479, min: -35.4461326599, mean: 0.0131984725595, std: 7.90496063232\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.84256076813, min: -0.925168395042, mean: -0.00453256769106, std: 0.437012553215\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.436914444, min: -21.3027248383, mean: -0.295191168785, std: 7.50950574875\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.76317560673, min: -0.815186619759, mean: -0.00789225194603, std: 0.432658195496\n",
      "valid accuracy 0.9132\n",
      "batch 135, ep 0, training accuracy 0.91\n",
      "f : 9542.81835938, q : 117363.804688, p : 108549.703125, l : 716.279907227\n",
      "batch 135, ep 50, training accuracy 0.915\n",
      "f : 10155.9189453, q : 117349.15625, p : 107905.09375, l : 688.144165039\n",
      "batch 135, ep 100, training accuracy 0.915\n",
      "f : 9749.49414062, q : 117325.851562, p : 108288.71875, l : 689.921936035\n",
      "batch 135, ep 150, training accuracy 0.915\n",
      "f : 9615.546875, q : 117441.0625, p : 108480.484375, l : 688.105224609\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.1521282196, min: -37.0248069763, mean: 0.00216033030301, std: 7.96305513382\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.88648462296, min: -0.923305392265, mean: -0.00238519185223, std: 0.432726711035\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.5744285583, min: -20.2560558319, mean: 0.381106376648, std: 7.54126310349\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.41777539253, min: -0.78081035614, mean: -0.020633045584, std: 0.455437660217\n",
      "valid accuracy 0.9133\n",
      "batch 136, ep 0, training accuracy 0.88\n",
      "f : 9605.06542969, q : 117411.101562, p : 108540.492188, l : 779.788330078\n",
      "batch 136, ep 50, training accuracy 0.89\n",
      "f : 10200.2890625, q : 117354.757812, p : 107804.453125, l : 717.035888672\n",
      "batch 136, ep 100, training accuracy 0.89\n",
      "f : 9852.53125, q : 117310.867188, p : 108260.0625, l : 714.18145752\n",
      "batch 136, ep 150, training accuracy 0.885\n",
      "f : 9699.84179688, q : 117339.148438, p : 108272.1875, l : 710.518493652\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.1220664978, min: -33.1582756042, mean: -0.0894820019603, std: 7.85909032822\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.68870091438, min: -0.943805575371, mean: -0.00733081065118, std: 0.433073461056\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.2108573914, min: -23.3371524811, mean: 0.341463655233, std: 7.59239387512\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.03760957718, min: -0.903554797173, mean: -0.027485229075, std: 0.406730145216\n",
      "valid accuracy 0.9115\n",
      "batch 137, ep 0, training accuracy 0.905\n",
      "f : 9457.65527344, q : 117405.15625, p : 108518.046875, l : 629.080322266\n",
      "batch 137, ep 50, training accuracy 0.91\n",
      "f : 10082.4863281, q : 117340.46875, p : 107876.71875, l : 610.028686523\n",
      "batch 137, ep 100, training accuracy 0.905\n",
      "f : 9725.90527344, q : 117369.726562, p : 108214.671875, l : 609.880004883\n",
      "batch 137, ep 150, training accuracy 0.91\n",
      "f : 9574.58496094, q : 117354.671875, p : 108301.171875, l : 606.22857666\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.2738609314, min: -30.5700130463, mean: 0.0559533722699, std: 7.92140293121\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.52325749397, min: -0.937171041965, mean: -0.00417779758573, std: 0.433685958385\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.6939678192, min: -21.6108150482, mean: -0.157312959433, std: 7.9037604332\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.49983608723, min: -0.865897595882, mean: 0.0137145174667, std: 0.41835179925\n",
      "valid accuracy 0.9106\n",
      "batch 138, ep 0, training accuracy 0.885\n",
      "f : 9586.69140625, q : 117252.851562, p : 108439.210938, l : 753.488525391\n",
      "batch 138, ep 50, training accuracy 0.885\n",
      "f : 10190.2607422, q : 117297.921875, p : 107865.71875, l : 708.463928223\n",
      "batch 138, ep 100, training accuracy 0.885\n",
      "f : 9843.70117188, q : 117271.320312, p : 108201.007812, l : 700.851623535\n",
      "batch 138, ep 150, training accuracy 0.885\n",
      "f : 9689.58398438, q : 117358.59375, p : 108399.257812, l : 701.872558594\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.5324325562, min: -30.7908210754, mean: 0.0118655981496, std: 7.94606924057\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.81752586365, min: -0.924547791481, mean: -0.0110449437052, std: 0.435508012772\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.0937652588, min: -24.2622127533, mean: 0.101560406387, std: 7.41752910614\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.64323925972, min: -0.851785957813, mean: -0.0128539158031, std: 0.420557051897\n",
      "valid accuracy 0.9124\n",
      "batch 139, ep 0, training accuracy 0.905\n",
      "f : 9362.2421875, q : 117311.421875, p : 108453.5625, l : 531.607421875\n",
      "batch 139, ep 50, training accuracy 0.91\n",
      "f : 10007.2001953, q : 117298.070312, p : 107813.078125, l : 512.423339844\n",
      "batch 139, ep 100, training accuracy 0.91\n",
      "f : 9617.984375, q : 117252.859375, p : 108191.5625, l : 513.182250977\n",
      "batch 139, ep 150, training accuracy 0.905\n",
      "f : 9423.58203125, q : 117286.679688, p : 108355.140625, l : 511.33996582\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.2895622253, min: -35.6700325012, mean: 0.0444575957954, std: 7.83207130432\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.63329291344, min: -0.954259216785, mean: -0.00328510068357, std: 0.435364603996\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.0533752441, min: -18.3490104675, mean: -0.669738888741, std: 7.32293319702\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.42658531666, min: -0.814644932747, mean: -0.019063429907, std: 0.406050652266\n",
      "valid accuracy 0.9111\n",
      "batch 140, ep 0, training accuracy 0.925\n",
      "f : 9346.19921875, q : 117309.890625, p : 108554.460938, l : 516.160522461\n",
      "batch 140, ep 50, training accuracy 0.925\n",
      "f : 9992.30078125, q : 117319.117188, p : 107728.117188, l : 497.383026123\n",
      "batch 140, ep 100, training accuracy 0.93\n",
      "f : 9599.67773438, q : 117175.28125, p : 108102.875, l : 497.192199707\n",
      "batch 140, ep 150, training accuracy 0.93\n",
      "f : 9469.16210938, q : 117226.375, p : 108328.882812, l : 498.04586792\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.6049804688, min: -30.7278938293, mean: 0.0386064685881, std: 7.88531970978\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.92622113228, min: -0.929055571556, mean: -0.00474456045777, std: 0.43693575263\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.5548000336, min: -26.633026123, mean: 0.0924588218331, std: 7.36816930771\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.53737819195, min: -0.905777871609, mean: -0.00760983768851, std: 0.436199605465\n",
      "valid accuracy 0.9101\n",
      "batch 141, ep 0, training accuracy 0.885\n",
      "f : 9599.5703125, q : 117315.90625, p : 108415.3125, l : 771.987792969\n",
      "batch 141, ep 50, training accuracy 0.9\n",
      "f : 10199.6064453, q : 117216.210938, p : 107769.742188, l : 734.426513672\n",
      "batch 141, ep 100, training accuracy 0.9\n",
      "f : 9847.47949219, q : 117260.304688, p : 108106.445312, l : 731.182006836\n",
      "batch 141, ep 150, training accuracy 0.9\n",
      "f : 9684.79394531, q : 117203.210938, p : 108292.90625, l : 731.772888184\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.8238258362, min: -32.8949737549, mean: 0.022531863302, std: 7.84338855743\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.70270562172, min: -0.917080640793, mean: -0.00175344920717, std: 0.435027390718\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.5148410797, min: -21.5343952179, mean: -0.0535975433886, std: 7.19448947906\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68341064453, min: -0.813486278057, mean: 0.0129603380337, std: 0.418156176805\n",
      "valid accuracy 0.9115\n",
      "batch 142, ep 0, training accuracy 0.925\n",
      "f : 9427.04296875, q : 117283.875, p : 108453.171875, l : 597.741699219\n",
      "batch 142, ep 50, training accuracy 0.925\n",
      "f : 10044.4941406, q : 117181.304688, p : 107765.898438, l : 583.007751465\n",
      "batch 142, ep 100, training accuracy 0.92\n",
      "f : 9705.79394531, q : 117244.1875, p : 108052.054688, l : 582.834960938\n",
      "batch 142, ep 150, training accuracy 0.925\n",
      "f : 9545.31054688, q : 117195.804688, p : 108249.257812, l : 583.235351562\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.3378410339, min: -31.0944881439, mean: 0.0219617579132, std: 7.8747677803\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.37751865387, min: -0.926321089268, mean: -0.00521849095821, std: 0.434220820665\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.2619190216, min: -25.0050106049, mean: -0.496573358774, std: 7.49726676941\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.36561918259, min: -0.862647771835, mean: -0.0132014788687, std: 0.433667182922\n",
      "valid accuracy 0.9125\n",
      "batch 143, ep 0, training accuracy 0.9\n",
      "f : 9678.26855469, q : 117185.890625, p : 108353.414062, l : 844.997314453\n",
      "batch 143, ep 50, training accuracy 0.9\n",
      "f : 10286.2539062, q : 117175.023438, p : 107680.585938, l : 799.59777832\n",
      "batch 143, ep 100, training accuracy 0.9\n",
      "f : 9927.4921875, q : 117185.859375, p : 108100.390625, l : 799.116027832\n",
      "batch 143, ep 150, training accuracy 0.9\n",
      "f : 9784.29882812, q : 117180.492188, p : 108254.5625, l : 803.893737793\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.8379592896, min: -29.2000598907, mean: -0.00739258574322, std: 7.88430976868\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.7176117897, min: -0.921682178974, mean: -0.00401893630624, std: 0.434457063675\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.9128131866, min: -20.8570308685, mean: -0.366450279951, std: 7.03246355057\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.07799267769, min: -0.859216034412, mean: -0.0118111167103, std: 0.42459154129\n",
      "valid accuracy 0.9135\n",
      "batch 144, ep 0, training accuracy 0.94\n",
      "f : 9331.60351562, q : 117231.445312, p : 108365.34375, l : 498.305664062\n",
      "batch 144, ep 50, training accuracy 0.94\n",
      "f : 9951.76953125, q : 117195.539062, p : 107687.601562, l : 467.019042969\n",
      "batch 144, ep 100, training accuracy 0.945\n",
      "f : 9580.60839844, q : 117235.90625, p : 108109.476562, l : 467.391296387\n",
      "batch 144, ep 150, training accuracy 0.945\n",
      "f : 9442.62890625, q : 117162.4375, p : 108223.46875, l : 467.233825684\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.2251472473, min: -34.5221710205, mean: -0.0274633225054, std: 7.89601278305\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.68941307068, min: -0.918539881706, mean: -0.00432590441778, std: 0.433748781681\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.6704978943, min: -24.278886795, mean: 0.121969126165, std: 7.63397502899\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.63824272156, min: -0.817332565784, mean: -0.0206099636853, std: 0.435875505209\n",
      "valid accuracy 0.9122\n",
      "batch 145, ep 0, training accuracy 0.875\n",
      "f : 9668.2421875, q : 117208.609375, p : 108388.304688, l : 838.698669434\n",
      "batch 145, ep 50, training accuracy 0.88\n",
      "f : 10256.7597656, q : 117233.03125, p : 107651.882812, l : 801.829406738\n",
      "batch 145, ep 100, training accuracy 0.885\n",
      "f : 9914.14746094, q : 117168.84375, p : 108103.4375, l : 800.270202637\n",
      "batch 145, ep 150, training accuracy 0.875\n",
      "f : 9747.84863281, q : 117155.460938, p : 108180.351562, l : 797.564331055\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.1697654724, min: -31.8469314575, mean: -0.0430876612663, std: 7.869617939\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.66129732132, min: -0.931957662106, mean: -0.0017815050669, std: 0.434550881386\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.5896053314, min: -20.317861557, mean: 0.497294902802, std: 7.61670732498\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.84333086014, min: -0.802371263504, mean: 0.0165387578309, std: 0.475850045681\n",
      "valid accuracy 0.9128\n",
      "batch 146, ep 0, training accuracy 0.905\n",
      "f : 9577.35449219, q : 117162.335938, p : 108197.34375, l : 748.441223145\n",
      "batch 146, ep 50, training accuracy 0.92\n",
      "f : 10205.4179688, q : 117060.203125, p : 107650.0, l : 720.130371094\n",
      "batch 146, ep 100, training accuracy 0.915\n",
      "f : 9831.78027344, q : 117122.914062, p : 108026.078125, l : 724.32244873\n",
      "batch 146, ep 150, training accuracy 0.91\n",
      "f : 9671.36035156, q : 117091.5625, p : 108145.40625, l : 726.269592285\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.6774291992, min: -33.6781997681, mean: 0.0226240511984, std: 7.94724750519\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.85597252846, min: -0.911465704441, mean: -0.00513920979574, std: 0.435389786959\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.6144390106, min: -23.8060874939, mean: 0.241852015257, std: 7.46235275269\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.76204180717, min: -0.828157067299, mean: -0.0101105971262, std: 0.418119311333\n",
      "valid accuracy 0.9122\n",
      "batch 147, ep 0, training accuracy 0.9\n",
      "f : 9492.23925781, q : 117116.609375, p : 108245.109375, l : 662.403808594\n",
      "batch 147, ep 50, training accuracy 0.915\n",
      "f : 10085.3056641, q : 117009.445312, p : 107582.21875, l : 620.907592773\n",
      "batch 147, ep 100, training accuracy 0.915\n",
      "f : 9737.92480469, q : 117124.71875, p : 108000.523438, l : 619.433776855\n",
      "batch 147, ep 150, training accuracy 0.915\n",
      "f : 9553.55859375, q : 117114.34375, p : 108112.539062, l : 618.635375977\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.7810688019, min: -28.6609134674, mean: 0.0434683784842, std: 7.84444284439\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.30328416824, min: -0.924691677094, mean: -0.0037093248684, std: 0.434579908848\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.9025783539, min: -20.2088375092, mean: -0.568759918213, std: 7.26618480682\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.91715598106, min: -0.855062842369, mean: 0.00564073817804, std: 0.448988676071\n",
      "valid accuracy 0.9124\n",
      "batch 148, ep 0, training accuracy 0.915\n",
      "f : 9466.68457031, q : 117067.296875, p : 108253.234375, l : 636.579101562\n",
      "batch 148, ep 50, training accuracy 0.915\n",
      "f : 10077.109375, q : 117084.554688, p : 107603.375, l : 614.000366211\n",
      "batch 148, ep 100, training accuracy 0.91\n",
      "f : 9718.25390625, q : 117107.445312, p : 107927.976562, l : 612.082763672\n",
      "batch 148, ep 150, training accuracy 0.915\n",
      "f : 9557.43554688, q : 117082.765625, p : 108088.875, l : 614.474609375\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.2417869568, min: -28.1615314484, mean: 0.0363735333085, std: 7.85250759125\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.8346760273, min: -0.941297829151, mean: -0.00572567014024, std: 0.43526828289\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.2125034332, min: -23.1908931732, mean: -0.022180698812, std: 7.38755226135\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.28640341759, min: -0.762106895447, mean: -0.0335614867508, std: 0.434207290411\n",
      "valid accuracy 0.9128\n",
      "batch 149, ep 0, training accuracy 0.84\n",
      "f : 9904.93359375, q : 117129.367188, p : 108291.148438, l : 1076.08032227\n",
      "batch 149, ep 50, training accuracy 0.855\n",
      "f : 10493.3007812, q : 116946.398438, p : 107565.195312, l : 1023.76306152\n",
      "batch 149, ep 100, training accuracy 0.855\n",
      "f : 10154.3330078, q : 117056.859375, p : 107907.929688, l : 1026.85009766\n",
      "batch 149, ep 150, training accuracy 0.845\n",
      "f : 9971.00292969, q : 116971.515625, p : 108109.015625, l : 1023.6697998\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.2580070496, min: -31.2717113495, mean: -0.00372094870545, std: 7.85261440277\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.575953722, min: -0.945203006268, mean: -0.0028164209798, std: 0.433231115341\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.0591754913, min: -20.852602005, mean: -0.216123297811, std: 7.00498104095\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.31501817703, min: -0.946538507938, mean: -0.0107001233846, std: 0.457484841347\n",
      "valid accuracy 0.9135\n",
      "batch 150, ep 0, training accuracy 0.87\n",
      "f : 9744.77832031, q : 116970.929688, p : 108199.671875, l : 919.390991211\n",
      "batch 150, ep 50, training accuracy 0.875\n",
      "f : 10337.0488281, q : 116965.179688, p : 107519.148438, l : 849.054199219\n",
      "batch 150, ep 100, training accuracy 0.87\n",
      "f : 9974.27148438, q : 117034.789062, p : 107918.476562, l : 853.880249023\n",
      "batch 150, ep 150, training accuracy 0.87\n",
      "f : 9832.13085938, q : 116980.625, p : 108044.851562, l : 844.337036133\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.6583709717, min: -31.8686752319, mean: -0.0806000456214, std: 7.80935525894\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.13123106956, min: -0.939661681652, mean: -0.00453167315573, std: 0.431379079819\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.0569343567, min: -18.0509872437, mean: -0.62150478363, std: 7.05982112885\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.45390665531, min: -0.915506541729, mean: 0.0279267597944, std: 0.414512395859\n",
      "valid accuracy 0.9104\n",
      "batch 151, ep 0, training accuracy 0.94\n",
      "f : 9354.37988281, q : 116969.40625, p : 108174.90625, l : 521.657592773\n",
      "batch 151, ep 50, training accuracy 0.935\n",
      "f : 9938.33203125, q : 116973.828125, p : 107574.601562, l : 501.32220459\n",
      "batch 151, ep 100, training accuracy 0.93\n",
      "f : 9603.86035156, q : 116952.328125, p : 107916.632812, l : 502.795501709\n",
      "batch 151, ep 150, training accuracy 0.93\n",
      "f : 9459.26269531, q : 117008.398438, p : 108019.054688, l : 502.600097656\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.5816230774, min: -31.7610321045, mean: -0.0344291143119, std: 7.85344839096\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.83299040794, min: -0.941309332848, mean: -0.00262721907347, std: 0.437228232622\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.8440322876, min: -25.3296699524, mean: 0.0855721160769, std: 7.72835016251\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.7054361105, min: -0.794563114643, mean: -0.00651657255366, std: 0.447527676821\n",
      "valid accuracy 0.9118\n",
      "batch 152, ep 0, training accuracy 0.87\n",
      "f : 9555.16308594, q : 116986.296875, p : 108158.507812, l : 727.960571289\n",
      "batch 152, ep 50, training accuracy 0.89\n",
      "f : 10145.6708984, q : 116965.867188, p : 107548.226562, l : 691.284179688\n",
      "batch 152, ep 100, training accuracy 0.895\n",
      "f : 9810.87695312, q : 116994.601562, p : 107862.398438, l : 690.903564453\n",
      "batch 152, ep 150, training accuracy 0.885\n",
      "f : 9662.30078125, q : 117012.34375, p : 107970.84375, l : 690.612304688\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.1942214966, min: -30.4304943085, mean: -0.0169112998992, std: 7.85798311234\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.76034188271, min: -0.921150326729, mean: -0.0069322232157, std: 0.433758854866\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.7697353363, min: -20.8930683136, mean: 0.230087816715, std: 7.46079730988\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.99625039101, min: -0.845257341862, mean: 0.0100240185857, std: 0.411390691996\n",
      "valid accuracy 0.9131\n",
      "batch 153, ep 0, training accuracy 0.885\n",
      "f : 9643.93261719, q : 116935.953125, p : 108181.867188, l : 814.96472168\n",
      "batch 153, ep 50, training accuracy 0.89\n",
      "f : 10248.2285156, q : 116906.984375, p : 107459.859375, l : 771.276123047\n",
      "batch 153, ep 100, training accuracy 0.89\n",
      "f : 9887.30957031, q : 116973.03125, p : 107809.054688, l : 769.039855957\n",
      "batch 153, ep 150, training accuracy 0.885\n",
      "f : 9719.10058594, q : 116963.773438, p : 108050.539062, l : 770.83001709\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.8694057465, min: -29.5439453125, mean: 0.0560124404728, std: 7.82874202728\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.81766605377, min: -0.943631291389, mean: -0.00464318413287, std: 0.436568319798\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.3277816772, min: -22.8180541992, mean: -0.13710232079, std: 6.91929388046\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.76106917858, min: -0.806364238262, mean: -0.0181883983314, std: 0.442690700293\n",
      "valid accuracy 0.9112\n",
      "batch 154, ep 0, training accuracy 0.875\n",
      "f : 9574.19238281, q : 116861.226562, p : 108166.234375, l : 741.864929199\n",
      "batch 154, ep 50, training accuracy 0.89\n",
      "f : 10154.9941406, q : 116855.257812, p : 107448.617188, l : 699.182495117\n",
      "batch 154, ep 100, training accuracy 0.89\n",
      "f : 9811.3828125, q : 116906.367188, p : 107696.382812, l : 696.019958496\n",
      "batch 154, ep 150, training accuracy 0.89\n",
      "f : 9663.32617188, q : 116900.078125, p : 107916.226562, l : 698.466125488\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.4805755615, min: -32.500541687, mean: 0.0377694889903, std: 7.79721641541\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.44408130646, min: -0.9265666008, mean: -0.00703958049417, std: 0.437002569437\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.9579391479, min: -18.4967708588, mean: 0.360649079084, std: 7.63850355148\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.60458147526, min: -0.81578117609, mean: -0.0366469249129, std: 0.46597251296\n",
      "valid accuracy 0.9104\n",
      "batch 155, ep 0, training accuracy 0.9\n",
      "f : 9724.60058594, q : 116888.109375, p : 108130.328125, l : 900.389343262\n",
      "batch 155, ep 50, training accuracy 0.9\n",
      "f : 10325.8144531, q : 116905.335938, p : 107445.234375, l : 865.290588379\n",
      "batch 155, ep 100, training accuracy 0.9\n",
      "f : 9980.55566406, q : 116920.851562, p : 107818.132812, l : 862.020263672\n",
      "batch 155, ep 150, training accuracy 0.9\n",
      "f : 9823.96777344, q : 116889.796875, p : 107844.59375, l : 861.07421875\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.3855781555, min: -31.8317146301, mean: -0.0258210022002, std: 7.83563947678\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.47515058517, min: -0.912483513355, mean: -0.00374493910931, std: 0.434562265873\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.9735431671, min: -24.2385730743, mean: 0.354647517204, std: 7.0732254982\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.77858674526, min: -0.796780824661, mean: 0.0047442461364, std: 0.459490925074\n",
      "valid accuracy 0.9109\n",
      "batch 156, ep 0, training accuracy 0.84\n",
      "f : 9805.00195312, q : 116866.039062, p : 108038.085938, l : 971.960754395\n",
      "batch 156, ep 50, training accuracy 0.865\n",
      "f : 10396.578125, q : 116867.164062, p : 107419.015625, l : 929.768615723\n",
      "batch 156, ep 100, training accuracy 0.865\n",
      "f : 10045.3447266, q : 116901.453125, p : 107650.96875, l : 928.924560547\n",
      "batch 156, ep 150, training accuracy 0.865\n",
      "f : 9857.51464844, q : 116842.164062, p : 107898.640625, l : 928.407470703\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.478427887, min: -30.234790802, mean: 0.0408044606447, std: 7.81596517563\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.03075027466, min: -0.940827906132, mean: -0.0120832519606, std: 0.435548514128\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.2750778198, min: -25.601556778, mean: 0.0345470197499, std: 7.74225711823\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.30065226555, min: -0.87577599287, mean: -0.0243500899523, std: 0.410836398602\n",
      "valid accuracy 0.9123\n",
      "batch 157, ep 0, training accuracy 0.9\n",
      "f : 9481.67089844, q : 116875.21875, p : 108083.648438, l : 646.337341309\n",
      "batch 157, ep 50, training accuracy 0.91\n",
      "f : 10101.9121094, q : 116840.976562, p : 107300.703125, l : 617.05456543\n",
      "batch 157, ep 100, training accuracy 0.91\n",
      "f : 9729.53222656, q : 116818.734375, p : 107680.203125, l : 615.434448242\n",
      "batch 157, ep 150, training accuracy 0.91\n",
      "f : 9588.48046875, q : 116848.796875, p : 107871.460938, l : 620.491394043\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.8296909332, min: -31.205783844, mean: -0.00141478481237, std: 7.82444190979\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.81955528259, min: -0.923866331577, mean: -0.00438465736806, std: 0.434059917927\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.4239940643, min: -23.4127388, mean: 0.0694563016295, std: 7.36585760117\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.06712341309, min: -0.825054705143, mean: -0.00520324707031, std: 0.421147942543\n",
      "valid accuracy 0.9119\n",
      "batch 158, ep 0, training accuracy 0.87\n",
      "f : 9722.21582031, q : 116784.421875, p : 107976.742188, l : 891.42199707\n",
      "batch 158, ep 50, training accuracy 0.875\n",
      "f : 10328.5957031, q : 116776.515625, p : 107421.742188, l : 856.216308594\n",
      "batch 158, ep 100, training accuracy 0.87\n",
      "f : 9977.34765625, q : 116743.0, p : 107771.929688, l : 856.907958984\n",
      "batch 158, ep 150, training accuracy 0.87\n",
      "f : 9795.13769531, q : 116844.875, p : 107923.3125, l : 855.471618652\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.1567668915, min: -34.4769325256, mean: 0.0240230653435, std: 7.78605985641\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.64158129692, min: -0.93906879425, mean: -0.00207749125548, std: 0.435423582792\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.0239009857, min: -21.3846759796, mean: 0.256733715534, std: 7.35846471786\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.7810997963, min: -0.844995081425, mean: -0.00179903372191, std: 0.451993405819\n",
      "valid accuracy 0.9123\n",
      "batch 159, ep 0, training accuracy 0.89\n",
      "f : 9471.47558594, q : 116877.515625, p : 107993.03125, l : 642.201293945\n",
      "batch 159, ep 50, training accuracy 0.895\n",
      "f : 10055.8984375, q : 116839.664062, p : 107385.117188, l : 610.200500488\n",
      "batch 159, ep 100, training accuracy 0.905\n",
      "f : 9718.96191406, q : 116812.398438, p : 107705.476562, l : 610.237792969\n",
      "batch 159, ep 150, training accuracy 0.895\n",
      "f : 9590.78417969, q : 116844.21875, p : 107849.515625, l : 608.624023438\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.2603473663, min: -32.5961952209, mean: 0.035794313997, std: 7.78979825974\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.26358795166, min: -0.910011053085, mean: -0.00253288308159, std: 0.434184730053\n",
      "layer1/q_pos/mu:0\n",
      "max: 29.7508220673, min: -22.4771537781, mean: -0.720625281334, std: 7.48071670532\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.52259290218, min: -0.989107131958, mean: -0.0368690043688, std: 0.438731282949\n",
      "valid accuracy 0.9113\n",
      "batch 160, ep 0, training accuracy 0.87\n",
      "f : 9575.99511719, q : 116804.859375, p : 107962.046875, l : 748.971801758\n",
      "batch 160, ep 50, training accuracy 0.9\n",
      "f : 10174.5058594, q : 116746.5, p : 107334.53125, l : 708.131958008\n",
      "batch 160, ep 100, training accuracy 0.905\n",
      "f : 9817.73730469, q : 116733.921875, p : 107585.578125, l : 711.655395508\n",
      "batch 160, ep 150, training accuracy 0.905\n",
      "f : 9691.19335938, q : 116789.664062, p : 107848.976562, l : 710.539672852\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.5996627808, min: -32.2108573914, mean: 0.0771468132734, std: 7.80715942383\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.3473303318, min: -0.971268773079, mean: -0.0046145231463, std: 0.431850582361\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.4490013123, min: -22.068605423, mean: 0.39747351408, std: 7.52387475967\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.946428895, min: -0.833447635174, mean: 0.00595257105306, std: 0.445105969906\n",
      "valid accuracy 0.9129\n",
      "batch 161, ep 0, training accuracy 0.865\n",
      "f : 9737.546875, q : 116743.789062, p : 107919.15625, l : 908.341186523\n",
      "batch 161, ep 50, training accuracy 0.86\n",
      "f : 10655.2529297, q : 116732.328125, p : 106966.234375, l : 848.152099609\n",
      "batch 161, ep 100, training accuracy 0.87\n",
      "f : 9976.99414062, q : 116836.34375, p : 107637.757812, l : 847.982727051\n",
      "batch 161, ep 150, training accuracy 0.865\n",
      "f : 9821.7421875, q : 116750.8125, p : 107755.609375, l : 849.114318848\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.2308120728, min: -37.9856643677, mean: 0.0113287316635, std: 7.80224227905\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.39648246765, min: -0.936277329922, mean: -0.00570875359699, std: 0.436423629522\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.2222270966, min: -26.0194168091, mean: 1.04318463802, std: 7.3596997261\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.07636427879, min: -0.84074473381, mean: -0.00742433452979, std: 0.451358139515\n",
      "valid accuracy 0.9145\n",
      "batch 162, ep 0, training accuracy 0.845\n",
      "f : 9667.5390625, q : 116775.25, p : 107878.679688, l : 836.536560059\n",
      "batch 162, ep 50, training accuracy 0.855\n",
      "f : 10255.4423828, q : 116741.59375, p : 107289.632812, l : 794.577880859\n",
      "batch 162, ep 100, training accuracy 0.855\n",
      "f : 9916.64257812, q : 116759.703125, p : 107628.726562, l : 798.059692383\n",
      "batch 162, ep 150, training accuracy 0.86\n",
      "f : 9744.32128906, q : 116738.992188, p : 107792.789062, l : 794.395751953\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.8426189423, min: -30.445104599, mean: -0.0475605875254, std: 7.76978397369\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.65009856224, min: -0.9380402565, mean: -0.00566930603236, std: 0.434958070517\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.4224338531, min: -18.5970783234, mean: 0.641168296337, std: 7.35190963745\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.92717945576, min: -0.826262295246, mean: -0.00309388479218, std: 0.46511220932\n",
      "valid accuracy 0.9138\n",
      "batch 163, ep 0, training accuracy 0.9\n",
      "f : 9569.13476562, q : 116768.851562, p : 107909.242188, l : 741.220703125\n",
      "batch 163, ep 50, training accuracy 0.9\n",
      "f : 10168.5996094, q : 116752.1875, p : 107200.960938, l : 716.642272949\n",
      "batch 163, ep 100, training accuracy 0.9\n",
      "f : 9819.61523438, q : 116821.648438, p : 107557.851562, l : 715.432006836\n",
      "batch 163, ep 150, training accuracy 0.9\n",
      "f : 9678.59667969, q : 116666.0, p : 107653.21875, l : 718.088867188\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.3032875061, min: -31.8633995056, mean: 0.0389268510044, std: 7.78206205368\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.54319858551, min: -0.953370034695, mean: -0.00408970285207, std: 0.438211649656\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.7908248901, min: -21.7671051025, mean: 0.213766142726, std: 7.59413003922\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.04546833038, min: -0.890355587006, mean: -0.0689957514405, std: 0.435799300671\n",
      "valid accuracy 0.9138\n",
      "batch 164, ep 0, training accuracy 0.925\n",
      "f : 9455.11523438, q : 116745.164062, p : 107894.679688, l : 627.16796875\n",
      "batch 164, ep 50, training accuracy 0.925\n",
      "f : 10081.0078125, q : 116636.195312, p : 107243.78125, l : 607.61730957\n",
      "batch 164, ep 100, training accuracy 0.925\n",
      "f : 9727.91210938, q : 116671.804688, p : 107592.929688, l : 606.481628418\n",
      "batch 164, ep 150, training accuracy 0.93\n",
      "f : 9571.7265625, q : 116719.164062, p : 107813.984375, l : 605.49017334\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.214717865, min: -32.2437515259, mean: 0.0186097007245, std: 7.85195493698\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.39115905762, min: -0.937628090382, mean: -0.000506128708366, std: 0.435793966055\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.7135467529, min: -29.2357769012, mean: -0.302399635315, std: 7.03014707565\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.26419520378, min: -0.829193294048, mean: 0.00866781920195, std: 0.434612989426\n",
      "valid accuracy 0.9133\n",
      "batch 165, ep 0, training accuracy 0.915\n",
      "f : 9421.24707031, q : 116649.390625, p : 107889.015625, l : 589.415405273\n",
      "batch 165, ep 50, training accuracy 0.925\n",
      "f : 10308.1240234, q : 116681.710938, p : 106870.96875, l : 548.357727051\n",
      "batch 165, ep 100, training accuracy 0.93\n",
      "f : 9666.60839844, q : 116774.921875, p : 107577.242188, l : 550.533691406\n",
      "batch 165, ep 150, training accuracy 0.925\n",
      "f : 9521.99902344, q : 116620.609375, p : 107693.789062, l : 552.248901367\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.5173187256, min: -36.4886436462, mean: 0.0185989309102, std: 7.76148033142\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.49376392365, min: -0.919248223305, mean: -0.00643813377246, std: 0.434956640005\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.7137069702, min: -19.9636745453, mean: -0.396591067314, std: 7.50894498825\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.98502087593, min: -0.784416258335, mean: 0.0121309505776, std: 0.447059988976\n",
      "valid accuracy 0.9128\n",
      "batch 166, ep 0, training accuracy 0.895\n",
      "f : 9572.66796875, q : 116684.3125, p : 107833.46875, l : 745.556518555\n",
      "batch 166, ep 50, training accuracy 0.895\n",
      "f : 10178.2382812, q : 116644.5625, p : 107161.804688, l : 712.593688965\n",
      "batch 166, ep 100, training accuracy 0.9\n",
      "f : 9824.12792969, q : 116680.195312, p : 107552.203125, l : 713.475036621\n",
      "batch 166, ep 150, training accuracy 0.9\n",
      "f : 9679.09863281, q : 116682.429688, p : 107667.242188, l : 710.080688477\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.5146865845, min: -29.0733737946, mean: 0.058015525341, std: 7.79445695877\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.53075933456, min: -0.948388874531, mean: -0.00597999664024, std: 0.437219142914\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.8403511047, min: -23.0528678894, mean: -0.140246078372, std: 7.19824266434\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.40571498871, min: -0.822710752487, mean: -0.0101133948192, std: 0.420089364052\n",
      "valid accuracy 0.9137\n",
      "batch 167, ep 0, training accuracy 0.9\n",
      "f : 9518.84375, q : 116696.3125, p : 107874.695312, l : 691.929626465\n",
      "batch 167, ep 50, training accuracy 0.905\n",
      "f : 10130.4765625, q : 116667.492188, p : 107253.976562, l : 659.86706543\n",
      "batch 167, ep 100, training accuracy 0.905\n",
      "f : 9771.86132812, q : 116644.921875, p : 107522.484375, l : 661.060546875\n",
      "batch 167, ep 150, training accuracy 0.905\n",
      "f : 9626.44140625, q : 116651.992188, p : 107753.757812, l : 658.103027344\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.4104194641, min: -34.3260879517, mean: -0.00409296480939, std: 7.78186511993\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.52938079834, min: -0.952308118343, mean: -0.00531805260107, std: 0.434804588556\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.0501155853, min: -22.8844833374, mean: -0.133443877101, std: 7.13979673386\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.73067736626, min: -0.848748385906, mean: 0.00950669124722, std: 0.436796277761\n",
      "valid accuracy 0.9125\n",
      "batch 168, ep 0, training accuracy 0.93\n",
      "f : 9316.80566406, q : 116661.859375, p : 107820.890625, l : 489.086730957\n",
      "batch 168, ep 50, training accuracy 0.93\n",
      "f : 9923.46777344, q : 116646.164062, p : 107217.984375, l : 472.349975586\n",
      "batch 168, ep 100, training accuracy 0.93\n",
      "f : 9571.33203125, q : 116557.171875, p : 107561.914062, l : 472.298553467\n",
      "batch 168, ep 150, training accuracy 0.93\n",
      "f : 9409.66503906, q : 116664.984375, p : 107675.875, l : 473.881622314\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.6856880188, min: -34.3653678894, mean: -0.00684527074918, std: 7.775867939\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.61059474945, min: -0.92654722929, mean: -0.00592627888545, std: 0.438644140959\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.1254692078, min: -24.8226299286, mean: -0.328885048628, std: 7.30643606186\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.05475664139, min: -0.887379527092, mean: 0.00757541088387, std: 0.437425225973\n",
      "valid accuracy 0.912\n",
      "batch 169, ep 0, training accuracy 0.965\n",
      "f : 9157.31738281, q : 116519.976562, p : 107782.460938, l : 326.636749268\n",
      "batch 169, ep 50, training accuracy 0.97\n",
      "f : 9762.97167969, q : 116670.296875, p : 107189.664062, l : 317.540771484\n",
      "batch 169, ep 100, training accuracy 0.965\n",
      "f : 9418.19140625, q : 116562.007812, p : 107492.046875, l : 316.472015381\n",
      "batch 169, ep 150, training accuracy 0.965\n",
      "f : 9257.78222656, q : 116615.617188, p : 107664.546875, l : 315.42565918\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.4532852173, min: -32.0620727539, mean: -0.00743289478123, std: 7.71484804153\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.38934063911, min: -0.933009266853, mean: -0.00657761981711, std: 0.432784259319\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.044210434, min: -20.6793117523, mean: -0.270610690117, std: 6.97858285904\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.17895364761, min: -0.769571483135, mean: -0.0293452795595, std: 0.455927252769\n",
      "valid accuracy 0.9116\n",
      "batch 170, ep 0, training accuracy 0.925\n",
      "f : 9350.10839844, q : 116569.820312, p : 107791.132812, l : 521.872436523\n",
      "batch 170, ep 50, training accuracy 0.935\n",
      "f : 9965.234375, q : 116670.703125, p : 107186.367188, l : 506.555725098\n",
      "batch 170, ep 100, training accuracy 0.94\n",
      "f : 9601.56933594, q : 116651.96875, p : 107486.328125, l : 509.084442139\n",
      "batch 170, ep 150, training accuracy 0.93\n",
      "f : 9468.47753906, q : 116537.984375, p : 107663.140625, l : 507.199768066\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.6615028381, min: -32.1067581177, mean: 0.0133422072977, std: 7.76785612106\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.54704499245, min: -0.918118774891, mean: -0.00487018330023, std: 0.436046749353\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.6639766693, min: -20.6122722626, mean: -0.281762331724, std: 7.75217247009\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.43812131882, min: -0.876842737198, mean: 0.00050741690211, std: 0.457045197487\n",
      "valid accuracy 0.9121\n",
      "batch 171, ep 0, training accuracy 0.935\n",
      "f : 9250.46777344, q : 116500.601562, p : 107706.335938, l : 421.010620117\n",
      "batch 171, ep 50, training accuracy 0.945\n",
      "f : 9851.81738281, q : 116595.921875, p : 107070.945312, l : 394.550689697\n",
      "batch 171, ep 100, training accuracy 0.945\n",
      "f : 9496.23339844, q : 116469.632812, p : 107533.765625, l : 394.712036133\n",
      "batch 171, ep 150, training accuracy 0.945\n",
      "f : 9334.87792969, q : 116528.414062, p : 107601.453125, l : 393.865112305\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.0524215698, min: -32.1025390625, mean: 0.0316949374974, std: 7.74499750137\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.38570547104, min: -0.912110209465, mean: -0.00618655001745, std: 0.435645103455\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.3490180969, min: -19.2716846466, mean: 0.064060382545, std: 6.97551250458\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.96982681751, min: -0.830721735954, mean: -0.0284987445921, std: 0.462137967348\n",
      "valid accuracy 0.912\n",
      "batch 172, ep 0, training accuracy 0.865\n",
      "f : 9689.57910156, q : 116612.867188, p : 107777.6875, l : 862.880371094\n",
      "batch 172, ep 50, training accuracy 0.865\n",
      "f : 10272.8359375, q : 116434.46875, p : 107096.40625, l : 814.637939453\n",
      "batch 172, ep 100, training accuracy 0.865\n",
      "f : 9935.625, q : 116522.390625, p : 107443.382812, l : 814.528808594\n",
      "batch 172, ep 150, training accuracy 0.87\n",
      "f : 9770.87792969, q : 116529.046875, p : 107653.875, l : 809.58996582\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.6896972656, min: -30.0525722504, mean: 0.0214318372309, std: 7.73349809647\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.9855556488, min: -0.929164528847, mean: -0.00314264837652, std: 0.434204846621\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.7449855804, min: -21.8426055908, mean: -0.146758288145, std: 7.1171631813\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.49656414986, min: -0.835332870483, mean: -0.00763066066429, std: 0.433416932821\n",
      "valid accuracy 0.9132\n",
      "batch 173, ep 0, training accuracy 0.87\n",
      "f : 9562.20605469, q : 116471.1875, p : 107653.375, l : 731.200500488\n",
      "batch 173, ep 50, training accuracy 0.88\n",
      "f : 10152.0429688, q : 116565.5, p : 107050.671875, l : 698.744384766\n",
      "batch 173, ep 100, training accuracy 0.88\n",
      "f : 9810.6953125, q : 116509.890625, p : 107360.46875, l : 700.610961914\n",
      "batch 173, ep 150, training accuracy 0.875\n",
      "f : 9642.23925781, q : 116499.320312, p : 107511.171875, l : 701.176452637\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.0753326416, min: -30.8618946075, mean: 0.0590026006103, std: 7.76948785782\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.75353598595, min: -0.943848311901, mean: -0.00382378185168, std: 0.435833245516\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.5649356842, min: -23.6704540253, mean: 0.292976468801, std: 7.34881639481\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.69647192955, min: -0.79189401865, mean: -0.0120840445161, std: 0.443062782288\n",
      "valid accuracy 0.9116\n",
      "batch 174, ep 0, training accuracy 0.895\n",
      "f : 9548.93457031, q : 116527.03125, p : 107655.601562, l : 721.162597656\n",
      "batch 174, ep 50, training accuracy 0.895\n",
      "f : 10136.8125, q : 116402.90625, p : 107063.351562, l : 677.323974609\n",
      "batch 174, ep 100, training accuracy 0.89\n",
      "f : 9783.16796875, q : 116525.421875, p : 107423.351562, l : 680.883056641\n",
      "batch 174, ep 150, training accuracy 0.895\n",
      "f : 9651.57128906, q : 116436.835938, p : 107552.734375, l : 680.188171387\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.5034103394, min: -31.3525314331, mean: 0.0102711142972, std: 7.77625417709\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.84307360649, min: -0.936636507511, mean: -0.00638631451875, std: 0.434492379427\n",
      "layer1/q_pos/mu:0\n",
      "max: 28.1441860199, min: -22.9014148712, mean: 0.191738650203, std: 7.11592721939\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.82830512524, min: -0.83107727766, mean: 0.0019566246774, std: 0.409127265215\n",
      "valid accuracy 0.9142\n",
      "batch 175, ep 0, training accuracy 0.915\n",
      "f : 9308.05566406, q : 116514.132812, p : 107671.179688, l : 476.714233398\n",
      "batch 175, ep 50, training accuracy 0.92\n",
      "f : 9893.796875, q : 116415.140625, p : 107073.875, l : 453.18850708\n",
      "batch 175, ep 100, training accuracy 0.915\n",
      "f : 9559.61230469, q : 116402.90625, p : 107464.625, l : 453.261962891\n",
      "batch 175, ep 150, training accuracy 0.925\n",
      "f : 9430.19726562, q : 116509.914062, p : 107528.664062, l : 454.859771729\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.6050796509, min: -31.1568775177, mean: 0.0826936066151, std: 7.73621368408\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.27367591858, min: -0.960927069187, mean: -0.000823653128464, std: 0.437666684389\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.9491348267, min: -26.5203533173, mean: -0.743987798691, std: 7.3064622879\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.77002048492, min: -0.791450083256, mean: 0.00723959133029, std: 0.433566451073\n",
      "valid accuracy 0.9128\n",
      "batch 176, ep 0, training accuracy 0.93\n",
      "f : 9387.44433594, q : 116475.039062, p : 107611.148438, l : 560.577209473\n",
      "batch 176, ep 50, training accuracy 0.93\n",
      "f : 9982.72070312, q : 116421.617188, p : 106996.546875, l : 544.282287598\n",
      "batch 176, ep 100, training accuracy 0.93\n",
      "f : 9641.01855469, q : 116404.320312, p : 107359.765625, l : 542.971496582\n",
      "batch 176, ep 150, training accuracy 0.93\n",
      "f : 9497.23242188, q : 116386.53125, p : 107432.257812, l : 544.771362305\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.3924293518, min: -29.8403224945, mean: -0.0291323270649, std: 7.76464700699\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.61135959625, min: -0.939738154411, mean: -0.00745263136923, std: 0.434526860714\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.0539302826, min: -23.675321579, mean: -0.117706909776, std: 7.32136392593\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.5745755434, min: -0.705452919006, mean: -0.0101595791057, std: 0.420289069414\n",
      "valid accuracy 0.9137\n",
      "batch 177, ep 0, training accuracy 0.91\n",
      "f : 9460.80859375, q : 116367.851562, p : 107663.476562, l : 628.099609375\n",
      "batch 177, ep 50, training accuracy 0.915\n",
      "f : 10023.5146484, q : 116424.460938, p : 106974.476562, l : 594.905456543\n",
      "batch 177, ep 100, training accuracy 0.915\n",
      "f : 9704.28320312, q : 116487.382812, p : 107262.726562, l : 594.687744141\n",
      "batch 177, ep 150, training accuracy 0.91\n",
      "f : 9556.29589844, q : 116427.453125, p : 107452.03125, l : 594.93737793\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.1919021606, min: -30.7457923889, mean: -0.0125184832141, std: 7.74646091461\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.35643339157, min: -0.927124857903, mean: -0.00116561923642, std: 0.431830614805\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.7244243622, min: -19.7791805267, mean: 0.114531062543, std: 7.57039070129\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.40454864502, min: -0.873934209347, mean: 0.0153796644881, std: 0.423723906279\n",
      "valid accuracy 0.913\n",
      "batch 178, ep 0, training accuracy 0.92\n",
      "f : 9414.26367188, q : 116445.476562, p : 107644.664062, l : 587.068969727\n",
      "batch 178, ep 50, training accuracy 0.93\n",
      "f : 10006.6816406, q : 116440.726562, p : 106980.148438, l : 568.221801758\n",
      "batch 178, ep 100, training accuracy 0.925\n",
      "f : 9656.31347656, q : 116486.476562, p : 107285.25, l : 564.288208008\n",
      "batch 178, ep 150, training accuracy 0.925\n",
      "f : 9530.45800781, q : 116417.414062, p : 107526.320312, l : 565.353637695\n",
      "layer0/q_pos/mu:0\n",
      "max: 40.9550628662, min: -32.4758453369, mean: -0.0050560394302, std: 7.71526813507\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.36002111435, min: -0.953824877739, mean: -0.00402246927842, std: 0.435507267714\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.4668464661, min: -25.4859008789, mean: 0.372698128223, std: 7.15704298019\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.94360423088, min: -0.819317638874, mean: -0.00607683137059, std: 0.42965978384\n",
      "valid accuracy 0.9114\n",
      "batch 179, ep 0, training accuracy 0.885\n",
      "f : 9405.71484375, q : 116468.773438, p : 107542.953125, l : 578.864746094\n",
      "batch 179, ep 50, training accuracy 0.92\n",
      "f : 9991.71679688, q : 116434.882812, p : 107002.039062, l : 542.979125977\n",
      "batch 179, ep 100, training accuracy 0.915\n",
      "f : 9635.99609375, q : 116367.78125, p : 107198.015625, l : 544.666503906\n",
      "batch 179, ep 150, training accuracy 0.915\n",
      "f : 9502.14550781, q : 116388.78125, p : 107437.9375, l : 542.143188477\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.9585132599, min: -34.7213668823, mean: -0.00155561743304, std: 7.69184112549\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.46416687965, min: -0.938018381596, mean: -0.00448681320995, std: 0.439915269613\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.4923286438, min: -21.7011165619, mean: -0.0588804371655, std: 7.48643112183\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.57767784595, min: -0.779672265053, mean: -0.0101575711742, std: 0.44961977005\n",
      "valid accuracy 0.9122\n",
      "batch 180, ep 0, training accuracy 0.895\n",
      "f : 9509.6328125, q : 116335.601562, p : 107597.71875, l : 679.724365234\n",
      "batch 180, ep 50, training accuracy 0.9\n",
      "f : 10088.3613281, q : 116284.65625, p : 106889.3125, l : 643.482299805\n",
      "batch 180, ep 100, training accuracy 0.915\n",
      "f : 9752.05078125, q : 116390.375, p : 107253.3125, l : 645.692321777\n",
      "batch 180, ep 150, training accuracy 0.91\n",
      "f : 9579.11816406, q : 116397.875, p : 107394.796875, l : 643.385070801\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.9127559662, min: -31.1187667847, mean: -0.0371363386512, std: 7.6667599678\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.53145718575, min: -0.921555042267, mean: -0.00274393963628, std: 0.436990827322\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.4703979492, min: -22.3195209503, mean: 0.0995759367943, std: 7.30975389481\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.88233911991, min: -0.802763044834, mean: 0.0124768102542, std: 0.411620169878\n",
      "valid accuracy 0.9104\n",
      "batch 181, ep 0, training accuracy 0.92\n",
      "f : 9382.23046875, q : 116365.476562, p : 107530.695312, l : 552.344116211\n",
      "batch 181, ep 50, training accuracy 0.93\n",
      "f : 9955.54589844, q : 116369.664062, p : 106978.367188, l : 518.000183105\n",
      "batch 181, ep 100, training accuracy 0.93\n",
      "f : 9623.34570312, q : 116297.476562, p : 107245.390625, l : 516.190429688\n",
      "batch 181, ep 150, training accuracy 0.93\n",
      "f : 9466.44140625, q : 116326.640625, p : 107412.53125, l : 520.069946289\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.2254905701, min: -30.1591796875, mean: -0.00780210457742, std: 7.70991754532\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.59362578392, min: -0.976580023766, mean: -0.00614892318845, std: 0.434337258339\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.671257019, min: -21.9564800262, mean: -0.0246825870126, std: 7.44071245193\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.09529066086, min: -0.811409235001, mean: 0.00139803043567, std: 0.446147918701\n",
      "valid accuracy 0.9116\n",
      "batch 182, ep 0, training accuracy 0.895\n",
      "f : 9571.02246094, q : 116333.789062, p : 107553.335938, l : 741.422729492\n",
      "batch 182, ep 50, training accuracy 0.9\n",
      "f : 10152.7070312, q : 116340.492188, p : 106861.929688, l : 688.570739746\n",
      "batch 182, ep 100, training accuracy 0.9\n",
      "f : 9802.1640625, q : 116301.226562, p : 107290.335938, l : 692.515014648\n",
      "batch 182, ep 150, training accuracy 0.9\n",
      "f : 9642.58203125, q : 116399.695312, p : 107337.507812, l : 694.323852539\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.078327179, min: -31.8278636932, mean: 0.0350739583373, std: 7.69061851501\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.77910470963, min: -0.911820650101, mean: -0.00100598239806, std: 0.438395798206\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.7390594482, min: -24.978012085, mean: 0.5482827425, std: 6.84841060638\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.8278440237, min: -0.801505506039, mean: -0.0142215993255, std: 0.404998391867\n",
      "valid accuracy 0.9106\n",
      "batch 183, ep 0, training accuracy 0.91\n",
      "f : 9302.08007812, q : 116346.109375, p : 107539.914062, l : 472.726654053\n",
      "batch 183, ep 50, training accuracy 0.925\n",
      "f : 9899.01269531, q : 116218.796875, p : 106933.804688, l : 444.84677124\n",
      "batch 183, ep 100, training accuracy 0.925\n",
      "f : 9539.99804688, q : 116308.632812, p : 107212.617188, l : 447.16229248\n",
      "batch 183, ep 150, training accuracy 0.93\n",
      "f : 9408.05761719, q : 116257.53125, p : 107365.726562, l : 447.474365234\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.9535217285, min: -31.5253639221, mean: -0.0522544793785, std: 7.71740531921\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.46845197678, min: -0.928128898144, mean: -0.00509499944746, std: 0.438623189926\n",
      "layer1/q_pos/mu:0\n",
      "max: 31.0047855377, min: -25.2587108612, mean: 0.526648640633, std: 6.97916078568\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.61929690838, min: -0.897373735905, mean: 0.00992339663208, std: 0.420928627253\n",
      "valid accuracy 0.9111\n",
      "batch 184, ep 0, training accuracy 0.92\n",
      "f : 9413.67578125, q : 116295.9375, p : 107514.265625, l : 579.889282227\n",
      "batch 184, ep 50, training accuracy 0.93\n",
      "f : 9972.61523438, q : 116328.90625, p : 106879.765625, l : 546.783569336\n",
      "batch 184, ep 100, training accuracy 0.925\n",
      "f : 9655.5625, q : 116296.0, p : 107189.976562, l : 543.68560791\n",
      "batch 184, ep 150, training accuracy 0.925\n",
      "f : 9479.15527344, q : 116298.703125, p : 107284.476562, l : 546.063110352\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.7337036133, min: -31.933588028, mean: 0.0115997707471, std: 7.67021656036\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.56537485123, min: -0.950663208961, mean: -0.00734047032893, std: 0.437877595425\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.0499572754, min: -24.8653373718, mean: -0.366643220186, std: 7.47774267197\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.84094274044, min: -0.880114078522, mean: 0.00196503917687, std: 0.429987162352\n",
      "valid accuracy 0.9102\n",
      "batch 185, ep 0, training accuracy 0.885\n",
      "f : 9571.93359375, q : 116294.171875, p : 107471.976562, l : 741.10925293\n",
      "batch 185, ep 50, training accuracy 0.9\n",
      "f : 10155.3427734, q : 116235.75, p : 106840.570312, l : 701.842895508\n",
      "batch 185, ep 100, training accuracy 0.905\n",
      "f : 9795.35644531, q : 116232.875, p : 107178.65625, l : 703.333190918\n",
      "batch 185, ep 150, training accuracy 0.905\n",
      "f : 9668.40429688, q : 116271.335938, p : 107351.296875, l : 703.807983398\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.8119029999, min: -29.3525066376, mean: 0.0162836071104, std: 7.73675012589\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.49912881851, min: -0.935574054718, mean: -0.00536374049261, std: 0.435796737671\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.4155960083, min: -24.9318599701, mean: 0.0315264388919, std: 7.45577144623\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.21355557442, min: -0.807517468929, mean: -0.0342072546482, std: 0.426697134972\n",
      "valid accuracy 0.9102\n",
      "batch 186, ep 0, training accuracy 0.875\n",
      "f : 9945.26269531, q : 116298.8125, p : 107446.375, l : 1116.0612793\n",
      "batch 186, ep 50, training accuracy 0.87\n",
      "f : 10477.3789062, q : 116229.546875, p : 106729.203125, l : 1035.73364258\n",
      "batch 186, ep 100, training accuracy 0.87\n",
      "f : 10158.1113281, q : 116250.820312, p : 107169.539062, l : 1042.50354004\n",
      "batch 186, ep 150, training accuracy 0.87\n",
      "f : 10012.6904297, q : 116291.078125, p : 107326.359375, l : 1038.03125\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.5637969971, min: -30.8141403198, mean: 0.074739292264, std: 7.71588277817\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.70789265633, min: -0.923996567726, mean: -0.00600008666515, std: 0.439098358154\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.5404758453, min: -23.176864624, mean: -0.377022594213, std: 7.54311561584\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68558287621, min: -0.823075771332, mean: -0.0154052041471, std: 0.431608974934\n",
      "valid accuracy 0.9132\n",
      "batch 187, ep 0, training accuracy 0.81\n",
      "f : 10025.0839844, q : 116268.640625, p : 107427.96875, l : 1201.89697266\n",
      "batch 187, ep 50, training accuracy 0.83\n",
      "f : 10540.1425781, q : 116269.359375, p : 106741.96875, l : 1065.70141602\n",
      "batch 187, ep 100, training accuracy 0.835\n",
      "f : 10219.0820312, q : 116192.515625, p : 107031.351562, l : 1063.29199219\n",
      "batch 187, ep 150, training accuracy 0.83\n",
      "f : 10035.0380859, q : 116286.695312, p : 107223.734375, l : 1061.40930176\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.036315918, min: -35.8163948059, mean: 0.0107168620452, std: 7.70183324814\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.93370461464, min: -0.958782792091, mean: -0.00426459079608, std: 0.430837839842\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.8907585144, min: -20.9779663086, mean: -0.610622406006, std: 7.69170045853\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.64470362663, min: -0.854569375515, mean: 0.0214816108346, std: 0.433865427971\n",
      "valid accuracy 0.9139\n",
      "batch 188, ep 0, training accuracy 0.91\n",
      "f : 9485.32714844, q : 116187.359375, p : 107447.789062, l : 660.129455566\n",
      "batch 188, ep 50, training accuracy 0.915\n",
      "f : 10076.9785156, q : 116247.695312, p : 106805.65625, l : 629.911743164\n",
      "batch 188, ep 100, training accuracy 0.91\n",
      "f : 9733.76953125, q : 116217.765625, p : 107082.375, l : 629.81262207\n",
      "batch 188, ep 150, training accuracy 0.91\n",
      "f : 9598.47460938, q : 116200.070312, p : 107280.523438, l : 627.608093262\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.3209991455, min: -32.3638725281, mean: 0.00922290142626, std: 7.66490077972\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.94781637192, min: -0.927781641483, mean: -0.00407322216779, std: 0.43529972434\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.5977287292, min: -24.0055141449, mean: 0.660325706005, std: 7.06643390656\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.11461317539, min: -0.853024423122, mean: -0.030195446685, std: 0.463280618191\n",
      "valid accuracy 0.9141\n",
      "batch 189, ep 0, training accuracy 0.9\n",
      "f : 9565.95703125, q : 116172.5, p : 107427.390625, l : 742.996459961\n",
      "batch 189, ep 50, training accuracy 0.91\n",
      "f : 10157.2304688, q : 116275.453125, p : 106824.382812, l : 715.352478027\n",
      "batch 189, ep 100, training accuracy 0.915\n",
      "f : 9819.86816406, q : 116141.195312, p : 107082.859375, l : 714.009643555\n",
      "batch 189, ep 150, training accuracy 0.915\n",
      "f : 9631.45117188, q : 116112.546875, p : 107250.570312, l : 715.269836426\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.0879592896, min: -34.1713180542, mean: -0.0554019473493, std: 7.61888027191\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.09513878822, min: -0.915033280849, mean: -0.00535283004865, std: 0.432321697474\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.6516857147, min: -19.9371814728, mean: -0.246914610267, std: 7.59399080276\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.78466403484, min: -0.926999330521, mean: -0.0215778648853, std: 0.451554208994\n",
      "valid accuracy 0.9141\n",
      "batch 190, ep 0, training accuracy 0.93\n",
      "f : 9340.34082031, q : 116206.34375, p : 107378.03125, l : 513.446533203\n",
      "batch 190, ep 50, training accuracy 0.925\n",
      "f : 9910.38867188, q : 116232.929688, p : 106650.835938, l : 478.823852539\n",
      "batch 190, ep 100, training accuracy 0.925\n",
      "f : 9584.72851562, q : 116184.6875, p : 106989.5625, l : 480.306549072\n",
      "batch 190, ep 150, training accuracy 0.925\n",
      "f : 9424.73242188, q : 116084.304688, p : 107234.007812, l : 478.565307617\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.3488121033, min: -31.3651332855, mean: -0.0166740827262, std: 7.66679668427\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.66673493385, min: -0.937302827835, mean: -0.00659706164151, std: 0.438783466816\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.6013050079, min: -19.3935642242, mean: 0.723793208599, std: 7.22572040558\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.55420875549, min: -0.884812474251, mean: -0.00348883657716, std: 0.450008094311\n",
      "valid accuracy 0.9137\n",
      "batch 191, ep 0, training accuracy 0.9\n",
      "f : 9471.89453125, q : 116173.328125, p : 107301.96875, l : 640.042358398\n",
      "batch 191, ep 50, training accuracy 0.905\n",
      "f : 10043.9873047, q : 116157.820312, p : 106724.976562, l : 606.212890625\n",
      "batch 191, ep 100, training accuracy 0.905\n",
      "f : 9700.56542969, q : 116171.507812, p : 107078.804688, l : 604.914916992\n",
      "batch 191, ep 150, training accuracy 0.905\n",
      "f : 9572.81933594, q : 116176.710938, p : 107249.296875, l : 606.389587402\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.9501152039, min: -30.0937671661, mean: 0.0321034230292, std: 7.65225791931\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.300604105, min: -0.933476030827, mean: -0.00412561558187, std: 0.433761268854\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.2978248596, min: -26.2378368378, mean: -0.652824819088, std: 6.8760099411\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.48488974571, min: -0.860480904579, mean: 0.016904739663, std: 0.448333501816\n",
      "valid accuracy 0.9129\n",
      "batch 192, ep 0, training accuracy 0.89\n",
      "f : 9574.66210938, q : 116159.109375, p : 107346.3125, l : 744.266418457\n",
      "batch 192, ep 50, training accuracy 0.89\n",
      "f : 10147.7001953, q : 116117.09375, p : 106775.34375, l : 716.465637207\n",
      "batch 192, ep 100, training accuracy 0.89\n",
      "f : 9793.20214844, q : 116092.023438, p : 107051.539062, l : 722.915893555\n",
      "batch 192, ep 150, training accuracy 0.89\n",
      "f : 9677.0703125, q : 116119.351562, p : 107148.484375, l : 716.791870117\n",
      "layer0/q_pos/mu:0\n",
      "max: 37.8442192078, min: -30.9457988739, mean: 0.0418108776212, std: 7.67567014694\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.8896586895, min: -0.932301223278, mean: -0.00385520816781, std: 0.433472245932\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.9779262543, min: -27.5630588531, mean: -0.111588694155, std: 7.63929700851\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.52971994877, min: -0.868200719357, mean: 0.0165546629578, std: 0.433256477118\n",
      "valid accuracy 0.9139\n",
      "batch 193, ep 0, training accuracy 0.885\n",
      "f : 9506.29296875, q : 116099.226562, p : 107260.984375, l : 679.008972168\n",
      "batch 193, ep 50, training accuracy 0.89\n",
      "f : 10065.2138672, q : 116118.09375, p : 106769.328125, l : 651.414733887\n",
      "batch 193, ep 100, training accuracy 0.885\n",
      "f : 9745.53808594, q : 116091.320312, p : 106996.726562, l : 651.608581543\n",
      "batch 193, ep 150, training accuracy 0.89\n",
      "f : 9586.94140625, q : 116118.242188, p : 107154.929688, l : 652.128295898\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.6579360962, min: -29.7488822937, mean: 0.00851074699312, std: 7.65704345703\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.5488884449, min: -0.924665033817, mean: -0.00266766385175, std: 0.434691458941\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.3403491974, min: -22.5365066528, mean: -0.222394600511, std: 7.47898197174\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.96107137203, min: -0.776503205299, mean: -0.00355386035517, std: 0.414146631956\n",
      "valid accuracy 0.9131\n",
      "batch 194, ep 0, training accuracy 0.965\n",
      "f : 9207.17382812, q : 116120.085938, p : 107305.3125, l : 383.202575684\n",
      "batch 194, ep 50, training accuracy 0.965\n",
      "f : 9785.77246094, q : 116111.8125, p : 106614.0625, l : 365.611877441\n",
      "batch 194, ep 100, training accuracy 0.97\n",
      "f : 9451.50390625, q : 116075.640625, p : 107013.273438, l : 364.080535889\n",
      "batch 194, ep 150, training accuracy 0.965\n",
      "f : 9320.69726562, q : 116048.28125, p : 107205.53125, l : 362.105010986\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.7373580933, min: -33.3431091309, mean: -0.0928992554545, std: 7.68766975403\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.45285367966, min: -0.919604599476, mean: -0.0057987398468, std: 0.434065163136\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.2135906219, min: -25.5577163696, mean: 0.811594545841, std: 7.49869060516\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.92172300816, min: -0.721981585026, mean: -0.0151879955083, std: 0.44071996212\n",
      "valid accuracy 0.9135\n",
      "batch 195, ep 0, training accuracy 0.925\n",
      "f : 9362.12207031, q : 116101.9375, p : 107260.359375, l : 530.193237305\n",
      "batch 195, ep 50, training accuracy 0.925\n",
      "f : 9933.94140625, q : 116079.210938, p : 106641.882812, l : 501.101715088\n",
      "batch 195, ep 100, training accuracy 0.925\n",
      "f : 9593.18652344, q : 116101.90625, p : 106948.835938, l : 501.738739014\n",
      "batch 195, ep 150, training accuracy 0.925\n",
      "f : 9463.66894531, q : 116097.398438, p : 107086.804688, l : 498.647735596\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.4621238708, min: -31.2353801727, mean: 0.00703748548403, std: 7.62752246857\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.85788989067, min: -0.94304728508, mean: -0.00440751900896, std: 0.439462900162\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.3706874847, min: -21.9150543213, mean: 0.626735806465, std: 7.33117008209\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.00587797165, min: -0.848893940449, mean: 0.0129229705781, std: 0.452311694622\n",
      "valid accuracy 0.9133\n",
      "batch 196, ep 0, training accuracy 0.885\n",
      "f : 9644.00390625, q : 116028.609375, p : 107304.609375, l : 813.060668945\n",
      "batch 196, ep 50, training accuracy 0.885\n",
      "f : 10207.0146484, q : 116016.171875, p : 106608.648438, l : 775.00402832\n",
      "batch 196, ep 100, training accuracy 0.885\n",
      "f : 9863.42578125, q : 116063.390625, p : 106977.859375, l : 765.412475586\n",
      "batch 196, ep 150, training accuracy 0.885\n",
      "f : 9729.3046875, q : 116047.171875, p : 107136.359375, l : 767.914855957\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.7828960419, min: -30.6202487946, mean: 0.0139531344175, std: 7.63679552078\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.69491362572, min: -0.929447770119, mean: -0.00257332040928, std: 0.433931440115\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.5059814453, min: -18.8143424988, mean: 0.0789349973202, std: 7.0243563652\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.73823952675, min: -0.820430219173, mean: 0.0155527740717, std: 0.441746294498\n",
      "valid accuracy 0.9135\n",
      "batch 197, ep 0, training accuracy 0.895\n",
      "f : 9649.83886719, q : 115994.671875, p : 107246.390625, l : 813.568115234\n",
      "batch 197, ep 50, training accuracy 0.905\n",
      "f : 10201.7978516, q : 116022.1875, p : 106630.039062, l : 763.831665039\n",
      "batch 197, ep 100, training accuracy 0.905\n",
      "f : 9882.36035156, q : 116037.0625, p : 106875.320312, l : 762.479858398\n",
      "batch 197, ep 150, training accuracy 0.905\n",
      "f : 9713.33105469, q : 116040.117188, p : 107075.09375, l : 761.897216797\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.4610137939, min: -32.1145401001, mean: 0.0371582955122, std: 7.64490604401\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.86799192429, min: -0.947942018509, mean: -0.00106621917803, std: 0.433239370584\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.7062168121, min: -20.6184368134, mean: -0.39199000597, std: 7.29438018799\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.96715474129, min: -0.886252164841, mean: -0.0352679081261, std: 0.407052606344\n",
      "valid accuracy 0.9134\n",
      "batch 198, ep 0, training accuracy 0.92\n",
      "f : 9535.91308594, q : 116010.039062, p : 107237.507812, l : 706.412353516\n",
      "batch 198, ep 50, training accuracy 0.925\n",
      "f : 10098.9189453, q : 116062.335938, p : 106644.023438, l : 658.481323242\n",
      "batch 198, ep 100, training accuracy 0.925\n",
      "f : 9768.87988281, q : 115997.40625, p : 106911.109375, l : 653.683227539\n",
      "batch 198, ep 150, training accuracy 0.92\n",
      "f : 9608.62011719, q : 116027.179688, p : 107122.554688, l : 655.05090332\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.6488189697, min: -28.9460124969, mean: 0.0134730143473, std: 7.58965063095\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.04427528381, min: -0.920092761517, mean: -0.00601097755134, std: 0.437668919563\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.0483818054, min: -22.8815307617, mean: 0.0463774949312, std: 7.28930807114\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.06343698502, min: -0.900053977966, mean: -0.0154822515324, std: 0.387857377529\n",
      "valid accuracy 0.9143\n",
      "batch 199, ep 0, training accuracy 0.86\n",
      "f : 9586.62304688, q : 115971.664062, p : 107092.890625, l : 763.450317383\n",
      "batch 199, ep 50, training accuracy 0.88\n",
      "f : 10146.2939453, q : 116070.335938, p : 106548.046875, l : 709.811035156\n",
      "batch 199, ep 100, training accuracy 0.88\n",
      "f : 9809.01660156, q : 116044.671875, p : 106869.28125, l : 707.250610352\n",
      "batch 199, ep 150, training accuracy 0.885\n",
      "f : 9650.58496094, q : 116030.960938, p : 107112.796875, l : 704.611083984\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.769077301, min: -29.9909343719, mean: -0.0250431764871, std: 7.68575048447\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.9285402298, min: -0.967281460762, mean: -0.00173076032661, std: 0.432238250971\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.8394165039, min: -26.2736530304, mean: 0.321714103222, std: 7.30232143402\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.92658126354, min: -0.87250483036, mean: -0.00578643241897, std: 0.421126276255\n",
      "valid accuracy 0.9138\n",
      "batch 200, ep 0, training accuracy 0.91\n",
      "f : 9370.84667969, q : 116024.96875, p : 107180.078125, l : 542.311950684\n",
      "batch 200, ep 50, training accuracy 0.905\n",
      "f : 9937.50292969, q : 115925.5, p : 106508.640625, l : 516.936218262\n",
      "batch 200, ep 100, training accuracy 0.91\n",
      "f : 9614.890625, q : 115970.351562, p : 106882.5, l : 520.586914062\n",
      "batch 200, ep 150, training accuracy 0.91\n",
      "f : 9489.21289062, q : 115922.851562, p : 106976.132812, l : 517.16418457\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.1350135803, min: -30.6829986572, mean: 0.0351594984531, std: 7.64516687393\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.5580728054, min: -0.932431161404, mean: -0.0044844886288, std: 0.433225005865\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.7642765045, min: -20.7324829102, mean: 0.454152345657, std: 7.3765501976\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.99617624283, min: -0.817407846451, mean: -0.00182252586819, std: 0.437052607536\n",
      "valid accuracy 0.915\n",
      "batch 201, ep 0, training accuracy 0.905\n",
      "f : 9436.93359375, q : 115945.75, p : 107205.539062, l : 604.955993652\n",
      "batch 201, ep 50, training accuracy 0.92\n",
      "f : 9996.50976562, q : 115966.4375, p : 106546.617188, l : 570.353942871\n",
      "batch 201, ep 100, training accuracy 0.925\n",
      "f : 9671.42773438, q : 116069.648438, p : 106839.53125, l : 569.076538086\n",
      "batch 201, ep 150, training accuracy 0.93\n",
      "f : 9533.03417969, q : 115989.914062, p : 107013.710938, l : 571.940979004\n",
      "layer0/q_pos/mu:0\n",
      "max: 28.5576000214, min: -29.8912639618, mean: 0.0331880748272, std: 7.6536283493\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.83094334602, min: -0.916204273701, mean: -0.00353209511377, std: 0.437924563885\n",
      "layer1/q_pos/mu:0\n",
      "max: 17.4410266876, min: -21.7859764099, mean: 0.235872983932, std: 7.14474105835\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.83866715431, min: -0.842046976089, mean: 0.0143274683505, std: 0.436027377844\n",
      "valid accuracy 0.9155\n",
      "batch 202, ep 0, training accuracy 0.925\n",
      "f : 9467.79296875, q : 115954.78125, p : 107133.742188, l : 635.62689209\n",
      "batch 202, ep 50, training accuracy 0.93\n",
      "f : 10033.5332031, q : 115914.414062, p : 106495.515625, l : 611.090209961\n",
      "batch 202, ep 100, training accuracy 0.93\n",
      "f : 9704.07617188, q : 115937.890625, p : 106840.335938, l : 617.190124512\n",
      "batch 202, ep 150, training accuracy 0.925\n",
      "f : 9571.43066406, q : 115928.203125, p : 106975.945312, l : 613.462036133\n",
      "layer0/q_pos/mu:0\n",
      "max: 28.3195953369, min: -29.8119983673, mean: 0.0137301627547, std: 7.66445159912\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.42675352097, min: -0.945826232433, mean: -0.00546332076192, std: 0.431275755167\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.5092849731, min: -20.4739532471, mean: 0.0960404127836, std: 7.07072544098\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.90345752239, min: -0.91868519783, mean: -0.00460646115243, std: 0.431163340807\n",
      "valid accuracy 0.9151\n",
      "batch 203, ep 0, training accuracy 0.92\n",
      "f : 9356.94628906, q : 115872.125, p : 107140.914062, l : 527.109008789\n",
      "batch 203, ep 50, training accuracy 0.915\n",
      "f : 9917.46777344, q : 115893.96875, p : 106597.367188, l : 509.910095215\n",
      "batch 203, ep 100, training accuracy 0.92\n",
      "f : 9614.32617188, q : 115936.734375, p : 106867.039062, l : 509.239135742\n",
      "batch 203, ep 150, training accuracy 0.92\n",
      "f : 9422.33300781, q : 115902.210938, p : 107066.890625, l : 510.955413818\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.6080970764, min: -29.8992824554, mean: 0.0103288358077, std: 7.62493085861\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.96849131584, min: -0.924861133099, mean: -0.00391512550414, std: 0.436123996973\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.6353302002, min: -19.7968540192, mean: -0.273920357227, std: 7.45083427429\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.38609361649, min: -0.819412887096, mean: -0.00489367404953, std: 0.44168651104\n",
      "valid accuracy 0.9152\n",
      "batch 204, ep 0, training accuracy 0.915\n",
      "f : 9364.21289062, q : 115936.664062, p : 107075.179688, l : 533.286010742\n",
      "batch 204, ep 50, training accuracy 0.93\n",
      "f : 9936.94921875, q : 115967.179688, p : 106539.578125, l : 512.408203125\n",
      "batch 204, ep 100, training accuracy 0.925\n",
      "f : 9604.8359375, q : 115850.710938, p : 106824.976562, l : 512.476501465\n",
      "batch 204, ep 150, training accuracy 0.93\n",
      "f : 9456.12890625, q : 115926.03125, p : 106935.320312, l : 511.488433838\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.3063468933, min: -31.9216976166, mean: -0.00282621546648, std: 7.60418510437\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.69299983978, min: -0.922284543514, mean: -0.000731499574613, std: 0.435892313719\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.4113693237, min: -24.4522895813, mean: 0.0714388415217, std: 6.76419067383\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.5322034359, min: -0.764619588852, mean: 0.0106497909874, std: 0.457113236189\n",
      "valid accuracy 0.9148\n",
      "batch 205, ep 0, training accuracy 0.915\n",
      "f : 9434.74902344, q : 115875.039062, p : 107179.304688, l : 603.637695312\n",
      "batch 205, ep 50, training accuracy 0.935\n",
      "f : 10008.4658203, q : 115887.53125, p : 106414.679688, l : 569.993774414\n",
      "batch 205, ep 100, training accuracy 0.92\n",
      "f : 9676.80664062, q : 115858.28125, p : 106803.085938, l : 575.263793945\n",
      "batch 205, ep 150, training accuracy 0.915\n",
      "f : 9497.59082031, q : 115970.007812, p : 107066.507812, l : 572.919677734\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.8007698059, min: -30.5231361389, mean: -0.00466891750693, std: 7.60691070557\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.88905119896, min: -0.929415285587, mean: -0.00978258624673, std: 0.432840883732\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.8076305389, min: -26.0356826782, mean: 0.0120697915554, std: 6.55955171585\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.86537194252, min: -0.805068790913, mean: -0.0111367320642, std: 0.456213235855\n",
      "valid accuracy 0.9154\n",
      "batch 206, ep 0, training accuracy 0.865\n",
      "f : 9708.68066406, q : 115863.40625, p : 107109.671875, l : 891.389892578\n",
      "batch 206, ep 50, training accuracy 0.88\n",
      "f : 10242.4980469, q : 115906.84375, p : 106381.484375, l : 819.199829102\n",
      "batch 206, ep 100, training accuracy 0.875\n",
      "f : 9927.87207031, q : 115815.890625, p : 106731.71875, l : 817.462280273\n",
      "batch 206, ep 150, training accuracy 0.875\n",
      "f : 9776.4453125, q : 115819.757812, p : 106999.421875, l : 815.666625977\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.0582027435, min: -33.1464157104, mean: 0.0123013369739, std: 7.63881635666\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.9448428154, min: -0.948391497135, mean: -0.00628982437775, std: 0.439370393753\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.7951698303, min: -26.7230014801, mean: 0.207998588681, std: 7.03978824615\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.74512147903, min: -0.829159975052, mean: 0.0161725021899, std: 0.415402501822\n",
      "valid accuracy 0.9123\n",
      "batch 207, ep 0, training accuracy 0.86\n",
      "f : 9707.93457031, q : 115872.195312, p : 107106.71875, l : 873.504394531\n",
      "batch 207, ep 50, training accuracy 0.865\n",
      "f : 10262.6474609, q : 115970.15625, p : 106472.226562, l : 827.643005371\n",
      "batch 207, ep 100, training accuracy 0.865\n",
      "f : 9930.26953125, q : 115892.585938, p : 106796.851562, l : 824.706420898\n",
      "batch 207, ep 150, training accuracy 0.865\n",
      "f : 9778.70507812, q : 115828.757812, p : 106954.773438, l : 825.781982422\n",
      "layer0/q_pos/mu:0\n",
      "max: 36.827205658, min: -30.3759994507, mean: -0.0703539475799, std: 7.57632637024\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.49330925941, min: -0.923012554646, mean: -0.00333209428936, std: 0.436314463615\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.9078350067, min: -16.51612854, mean: -0.187960281968, std: 7.01197576523\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.9514465332, min: -0.759991765022, mean: -0.0145274270326, std: 0.421391189098\n",
      "valid accuracy 0.9134\n",
      "batch 208, ep 0, training accuracy 0.935\n",
      "f : 9351.23242188, q : 115890.90625, p : 106977.804688, l : 522.246826172\n",
      "batch 208, ep 50, training accuracy 0.935\n",
      "f : 9895.16796875, q : 115834.617188, p : 106406.585938, l : 497.275695801\n",
      "batch 208, ep 100, training accuracy 0.935\n",
      "f : 9597.02832031, q : 115821.554688, p : 106699.382812, l : 496.621520996\n",
      "batch 208, ep 150, training accuracy 0.935\n",
      "f : 9416.96484375, q : 115832.03125, p : 106905.445312, l : 498.855682373\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.6710720062, min: -28.3145542145, mean: -0.00667372252792, std: 7.60653114319\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.63156223297, min: -0.948408186436, mean: -0.00443313037977, std: 0.435592889786\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.687833786, min: -23.0649147034, mean: 0.0508349984884, std: 7.34253454208\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.96749901772, min: -0.888036072254, mean: -0.0180177558213, std: 0.452768623829\n",
      "valid accuracy 0.9134\n",
      "batch 209, ep 0, training accuracy 0.91\n",
      "f : 9449.3671875, q : 115885.078125, p : 107044.148438, l : 626.66394043\n",
      "batch 209, ep 50, training accuracy 0.92\n",
      "f : 10043.1835938, q : 115798.304688, p : 106376.453125, l : 595.912414551\n",
      "batch 209, ep 100, training accuracy 0.92\n",
      "f : 9684.11816406, q : 115894.921875, p : 106761.75, l : 592.571655273\n",
      "batch 209, ep 150, training accuracy 0.92\n",
      "f : 9524.98828125, q : 115827.90625, p : 106887.484375, l : 593.06829834\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.5944824219, min: -28.830368042, mean: 0.0249078944325, std: 7.60879468918\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.73504376411, min: -0.951867878437, mean: -0.00532740680501, std: 0.43449690938\n",
      "layer1/q_pos/mu:0\n",
      "max: 23.4792785645, min: -26.232257843, mean: -0.490880429745, std: 7.13607645035\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.60491418839, min: -0.848084032536, mean: -0.0167439710349, std: 0.40946996212\n",
      "valid accuracy 0.9133\n",
      "batch 210, ep 0, training accuracy 0.895\n",
      "f : 9588.00585938, q : 115794.359375, p : 106974.023438, l : 753.688598633\n",
      "batch 210, ep 50, training accuracy 0.89\n",
      "f : 10132.4658203, q : 115782.734375, p : 106381.976562, l : 698.989379883\n",
      "batch 210, ep 100, training accuracy 0.89\n",
      "f : 9800.66992188, q : 115841.078125, p : 106696.90625, l : 696.686279297\n",
      "batch 210, ep 150, training accuracy 0.89\n",
      "f : 9667.72460938, q : 115777.007812, p : 106778.179688, l : 698.206970215\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.5450630188, min: -28.2274990082, mean: -0.0448428727686, std: 7.64154672623\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.27541399002, min: -0.941868960857, mean: 0.00108004664071, std: 0.435276091099\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.4099845886, min: -16.512096405, mean: 0.107165984809, std: 6.91081762314\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.65740549564, min: -0.7781701684, mean: -0.00733066722751, std: 0.426245868206\n",
      "valid accuracy 0.9131\n",
      "batch 211, ep 0, training accuracy 0.845\n",
      "f : 9693.83886719, q : 115893.65625, p : 106901.609375, l : 873.445007324\n",
      "batch 211, ep 50, training accuracy 0.86\n",
      "f : 10248.8535156, q : 115821.828125, p : 106330.125, l : 808.901733398\n",
      "batch 211, ep 100, training accuracy 0.86\n",
      "f : 9909.79980469, q : 115778.0625, p : 106785.625, l : 810.530151367\n",
      "batch 211, ep 150, training accuracy 0.86\n",
      "f : 9783.11816406, q : 115764.046875, p : 106760.5625, l : 807.645568848\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.1534957886, min: -33.531539917, mean: 0.08581584692, std: 7.57260227203\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.89841079712, min: -0.936456739902, mean: -0.00362793402746, std: 0.433280080557\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.2395477295, min: -31.0224227905, mean: -0.21149456501, std: 7.15402507782\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.93659162521, min: -0.810564637184, mean: -0.0103374272585, std: 0.43127566576\n",
      "valid accuracy 0.9139\n",
      "batch 212, ep 0, training accuracy 0.9\n",
      "f : 9859.62988281, q : 115770.09375, p : 106921.132812, l : 1031.86865234\n",
      "batch 212, ep 50, training accuracy 0.905\n",
      "f : 10383.7041016, q : 115797.648438, p : 106337.328125, l : 946.836669922\n",
      "batch 212, ep 100, training accuracy 0.905\n",
      "f : 10062.4765625, q : 115722.695312, p : 106579.539062, l : 950.009460449\n",
      "batch 212, ep 150, training accuracy 0.915\n",
      "f : 9941.61914062, q : 115728.09375, p : 106779.023438, l : 950.30456543\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.6775150299, min: -28.4399299622, mean: -0.0302120633423, std: 7.54989051819\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.33572816849, min: -0.954252839088, mean: -0.00443372968584, std: 0.435006856918\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.928981781, min: -26.0866947174, mean: -0.149401023984, std: 7.55407810211\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.50385355949, min: -0.890476644039, mean: -0.000146430611494, std: 0.418364733458\n",
      "valid accuracy 0.9147\n",
      "batch 213, ep 0, training accuracy 0.91\n",
      "f : 9550.46582031, q : 115750.148438, p : 106942.070312, l : 721.986694336\n",
      "batch 213, ep 50, training accuracy 0.91\n",
      "f : 10106.1835938, q : 115784.859375, p : 106427.195312, l : 697.102844238\n",
      "batch 213, ep 100, training accuracy 0.91\n",
      "f : 9783.01953125, q : 115698.367188, p : 106683.03125, l : 691.047363281\n",
      "batch 213, ep 150, training accuracy 0.91\n",
      "f : 9629.21972656, q : 115669.570312, p : 106790.4375, l : 692.989868164\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.027256012, min: -32.2625083923, mean: 0.000831003359053, std: 7.58842849731\n",
      "layer0/q_pos/rho:0\n",
      "max: 3.0166349411, min: -0.955353498459, mean: -0.000693175708875, std: 0.433601886034\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.5283145905, min: -20.9565105438, mean: 0.0983942747116, std: 7.27135753632\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.82159650326, min: -0.893790185452, mean: -0.00614467868581, std: 0.450396835804\n",
      "valid accuracy 0.9145\n",
      "batch 214, ep 0, training accuracy 0.895\n",
      "f : 9665.20800781, q : 115794.726562, p : 106906.898438, l : 838.115539551\n",
      "batch 214, ep 50, training accuracy 0.905\n",
      "f : 10226.9873047, q : 115730.164062, p : 106307.703125, l : 799.977905273\n",
      "batch 214, ep 100, training accuracy 0.9\n",
      "f : 9895.8203125, q : 115721.5, p : 106717.351562, l : 799.367492676\n",
      "batch 214, ep 150, training accuracy 0.9\n",
      "f : 9766.54785156, q : 115808.867188, p : 106814.117188, l : 796.438720703\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.7604579926, min: -30.4526882172, mean: 0.0410261414945, std: 7.60574865341\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.4470937252, min: -0.920458257198, mean: -0.00657449616119, std: 0.434890806675\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.0928859711, min: -20.8229255676, mean: 0.14136646688, std: 7.11962509155\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.60241222382, min: -0.816180408001, mean: 0.00655571045354, std: 0.456407338381\n",
      "valid accuracy 0.9142\n",
      "batch 215, ep 0, training accuracy 0.89\n",
      "f : 9510.55761719, q : 115814.085938, p : 106950.375, l : 681.705322266\n",
      "batch 215, ep 50, training accuracy 0.905\n",
      "f : 10044.2080078, q : 115741.117188, p : 106380.007812, l : 605.711181641\n",
      "batch 215, ep 100, training accuracy 0.91\n",
      "f : 9717.52441406, q : 115732.710938, p : 106627.140625, l : 605.754150391\n",
      "batch 215, ep 150, training accuracy 0.915\n",
      "f : 9548.75, q : 115763.804688, p : 106768.890625, l : 606.927856445\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.6167564392, min: -30.1849060059, mean: -0.0327138602734, std: 7.6029086113\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.52629899979, min: -0.93664765358, mean: -0.00394044630229, std: 0.433558106422\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.6975078583, min: -20.7171115875, mean: -0.285982906818, std: 7.23469305038\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.48309898376, min: -0.884054481983, mean: -0.031445518136, std: 0.465313255787\n",
      "valid accuracy 0.9162\n",
      "batch 216, ep 0, training accuracy 0.93\n",
      "f : 9318.58203125, q : 115739.703125, p : 106864.234375, l : 488.790771484\n",
      "batch 216, ep 50, training accuracy 0.93\n",
      "f : 10222.2167969, q : 115815.890625, p : 105972.273438, l : 469.237121582\n",
      "batch 216, ep 100, training accuracy 0.935\n",
      "f : 9557.33496094, q : 115617.28125, p : 106585.21875, l : 467.344329834\n",
      "batch 216, ep 150, training accuracy 0.935\n",
      "f : 9418.33203125, q : 115662.796875, p : 106774.984375, l : 469.659912109\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.1491928101, min: -29.4995269775, mean: -0.0777150690556, std: 7.57980155945\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.88067674637, min: -0.917075455189, mean: -0.00510319834575, std: 0.437900155783\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.7669219971, min: -18.8057117462, mean: -0.361818730831, std: 6.97514200211\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68368315697, min: -0.90213239193, mean: -0.0161109007895, std: 0.433127075434\n",
      "valid accuracy 0.9161\n",
      "batch 217, ep 0, training accuracy 0.92\n",
      "f : 9249.11816406, q : 115659.226562, p : 106809.367188, l : 422.011749268\n",
      "batch 217, ep 50, training accuracy 0.935\n",
      "f : 9809.11621094, q : 115655.320312, p : 106281.78125, l : 399.481750488\n",
      "batch 217, ep 100, training accuracy 0.93\n",
      "f : 9477.84667969, q : 115650.421875, p : 106584.023438, l : 399.206115723\n",
      "batch 217, ep 150, training accuracy 0.94\n",
      "f : 9317.91796875, q : 115635.78125, p : 106707.179688, l : 402.389984131\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.7598571777, min: -32.9155311584, mean: 0.0172040145844, std: 7.60494852066\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.66765570641, min: -0.920087635517, mean: -0.0042691314593, std: 0.435281336308\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.219039917, min: -20.0943202972, mean: -0.673697292805, std: 7.14508771896\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.71187758446, min: -0.793171465397, mean: -0.00850630644709, std: 0.419156223536\n",
      "valid accuracy 0.9152\n",
      "batch 218, ep 0, training accuracy 0.92\n",
      "f : 9427.51855469, q : 115622.25, p : 106853.601562, l : 598.193359375\n",
      "batch 218, ep 50, training accuracy 0.92\n",
      "f : 9971.92578125, q : 115674.84375, p : 106301.539062, l : 551.765014648\n",
      "batch 218, ep 100, training accuracy 0.92\n",
      "f : 9647.80664062, q : 115746.96875, p : 106567.445312, l : 560.328613281\n",
      "batch 218, ep 150, training accuracy 0.92\n",
      "f : 9489.76855469, q : 115692.28125, p : 106718.9375, l : 558.243164062\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.1931533813, min: -32.641204834, mean: -0.0602244213223, std: 7.52196598053\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.94114279747, min: -0.928033769131, mean: -0.00212723971345, std: 0.433979958296\n",
      "layer1/q_pos/mu:0\n",
      "max: 24.2495479584, min: -24.5130119324, mean: -0.540954113007, std: 7.11923742294\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.71321547031, min: -0.861886143684, mean: -0.0100409658626, std: 0.434513568878\n",
      "valid accuracy 0.9154\n",
      "batch 219, ep 0, training accuracy 0.885\n",
      "f : 9559.94238281, q : 115633.414062, p : 106834.570312, l : 737.393310547\n",
      "batch 219, ep 50, training accuracy 0.91\n",
      "f : 10109.9335938, q : 115659.882812, p : 106266.085938, l : 695.247375488\n",
      "batch 219, ep 100, training accuracy 0.905\n",
      "f : 9789.91113281, q : 115704.015625, p : 106552.773438, l : 691.960571289\n",
      "batch 219, ep 150, training accuracy 0.9\n",
      "f : 9634.8203125, q : 115669.796875, p : 106646.421875, l : 695.622070312\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.0259284973, min: -28.1935653687, mean: 0.00926132407039, std: 7.58047819138\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.34115386009, min: -0.944226980209, mean: -0.00773433689028, std: 0.43600744009\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.3348407745, min: -22.6022701263, mean: 0.10126336664, std: 7.30070209503\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.88766527176, min: -0.813004851341, mean: 0.00833906698972, std: 0.433339804411\n",
      "valid accuracy 0.9161\n",
      "batch 220, ep 0, training accuracy 0.885\n",
      "f : 9491.46484375, q : 115661.28125, p : 106749.921875, l : 661.586914062\n",
      "batch 220, ep 50, training accuracy 0.91\n",
      "f : 10016.4521484, q : 115640.429688, p : 106209.179688, l : 612.391845703\n",
      "batch 220, ep 100, training accuracy 0.91\n",
      "f : 9711.47167969, q : 115534.046875, p : 106476.882812, l : 606.462646484\n",
      "batch 220, ep 150, training accuracy 0.915\n",
      "f : 9557.79785156, q : 115658.890625, p : 106734.734375, l : 610.089904785\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.680305481, min: -31.006521225, mean: 0.0610483847558, std: 7.56968355179\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.35473895073, min: -0.941707909107, mean: -0.0035244859755, std: 0.434710979462\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.8401184082, min: -20.0168457031, mean: 0.401101350784, std: 7.22986793518\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.33384680748, min: -0.894774675369, mean: -0.00422045309097, std: 0.42053103447\n",
      "valid accuracy 0.9165\n",
      "batch 221, ep 0, training accuracy 0.89\n",
      "f : 9676.38476562, q : 115552.726562, p : 106829.296875, l : 849.828735352\n",
      "batch 221, ep 50, training accuracy 0.895\n",
      "f : 10187.5654297, q : 115638.515625, p : 106153.15625, l : 779.62121582\n",
      "batch 221, ep 100, training accuracy 0.895\n",
      "f : 9879.38964844, q : 115632.367188, p : 106559.859375, l : 771.268798828\n",
      "batch 221, ep 150, training accuracy 0.895\n",
      "f : 9703.68945312, q : 115638.664062, p : 106694.820312, l : 779.148620605\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.4561405182, min: -34.9774780273, mean: -0.0640543922782, std: 7.50726318359\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.75481343269, min: -0.942462623119, mean: 0.000212767190533, std: 0.435688376427\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.6321353912, min: -21.1597080231, mean: -0.219261795282, std: 6.57724761963\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.46200430393, min: -0.866548061371, mean: 0.00578891253099, std: 0.437920063734\n",
      "valid accuracy 0.9161\n",
      "batch 222, ep 0, training accuracy 0.94\n",
      "f : 9356.65917969, q : 115620.382812, p : 106800.257812, l : 527.765625\n",
      "batch 222, ep 50, training accuracy 0.94\n",
      "f : 9940.70703125, q : 115559.195312, p : 106132.84375, l : 513.577941895\n",
      "batch 222, ep 100, training accuracy 0.94\n",
      "f : 9607.28027344, q : 115587.03125, p : 106608.414062, l : 514.196472168\n",
      "batch 222, ep 150, training accuracy 0.94\n",
      "f : 9440.20507812, q : 115596.421875, p : 106715.085938, l : 513.28717041\n",
      "layer0/q_pos/mu:0\n",
      "max: 32.2514801025, min: -30.0765895844, mean: -0.0182197969407, std: 7.61548948288\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.54842352867, min: -0.948349773884, mean: -0.00681676249951, std: 0.438987344503\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.7767562866, min: -19.1615600586, mean: 0.054848279804, std: 7.24537658691\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.68535673618, min: -0.878406226635, mean: -0.00300667528063, std: 0.412911355495\n",
      "valid accuracy 0.9156\n",
      "batch 223, ep 0, training accuracy 0.93\n",
      "f : 9290.43066406, q : 115567.632812, p : 106798.710938, l : 459.682098389\n",
      "batch 223, ep 50, training accuracy 0.94\n",
      "f : 9832.67675781, q : 115600.898438, p : 106116.375, l : 439.268280029\n",
      "batch 223, ep 100, training accuracy 0.945\n",
      "f : 9527.20214844, q : 115695.617188, p : 106575.789062, l : 435.175323486\n",
      "batch 223, ep 150, training accuracy 0.945\n",
      "f : 9359.47167969, q : 115593.65625, p : 106746.5625, l : 440.668762207\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.967502594, min: -31.8436069489, mean: 0.026066545397, std: 7.56315469742\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.82604455948, min: -0.965504586697, mean: -0.00806866306812, std: 0.437959015369\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.2113170624, min: -20.6786766052, mean: -0.411425888538, std: 7.19585847855\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.6230494976, min: -0.901353061199, mean: -0.00276841176674, std: 0.441122680902\n",
      "valid accuracy 0.9161\n",
      "batch 224, ep 0, training accuracy 0.87\n",
      "f : 9589.73828125, q : 115617.710938, p : 106680.429688, l : 757.520141602\n",
      "batch 224, ep 50, training accuracy 0.875\n",
      "f : 10152.2568359, q : 115610.273438, p : 106226.164062, l : 719.942810059\n",
      "batch 224, ep 100, training accuracy 0.875\n",
      "f : 9811.40039062, q : 115512.5625, p : 106484.546875, l : 720.681152344\n",
      "batch 224, ep 150, training accuracy 0.875\n",
      "f : 9689.47167969, q : 115564.15625, p : 106625.789062, l : 722.500488281\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.44115448, min: -28.2167320251, mean: 0.0307679269463, std: 7.5296998024\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.9658370018, min: -0.910850048065, mean: -0.00630116835237, std: 0.436649858952\n",
      "layer1/q_pos/mu:0\n",
      "max: 17.6339893341, min: -19.7637672424, mean: 0.166359618306, std: 7.13363218307\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.67019581795, min: -0.855927884579, mean: -0.0142778698355, std: 0.440984249115\n",
      "valid accuracy 0.9156\n",
      "batch 225, ep 0, training accuracy 0.9\n",
      "f : 9627.54296875, q : 115534.289062, p : 106721.359375, l : 801.820922852\n",
      "batch 225, ep 50, training accuracy 0.905\n",
      "f : 10157.7636719, q : 115547.703125, p : 106143.015625, l : 762.901123047\n",
      "batch 225, ep 100, training accuracy 0.905\n",
      "f : 9865.80078125, q : 115534.453125, p : 106476.046875, l : 759.560180664\n",
      "batch 225, ep 150, training accuracy 0.905\n",
      "f : 9721.38085938, q : 115584.914062, p : 106549.65625, l : 757.883300781\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.9568271637, min: -27.3938179016, mean: -0.00996050238609, std: 7.52213096619\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.70357966423, min: -0.949849665165, mean: -0.00508385291323, std: 0.434269338846\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.8891296387, min: -20.6269607544, mean: -0.162170857191, std: 7.5144276619\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.53652203083, min: -0.867050766945, mean: -0.0152958314866, std: 0.435101360083\n",
      "valid accuracy 0.916\n",
      "batch 226, ep 0, training accuracy 0.93\n",
      "f : 9271.76660156, q : 115558.515625, p : 106694.695312, l : 440.944396973\n",
      "batch 226, ep 50, training accuracy 0.935\n",
      "f : 9799.91308594, q : 115576.351562, p : 106116.929688, l : 421.696502686\n",
      "batch 226, ep 100, training accuracy 0.93\n",
      "f : 9498.94433594, q : 115448.101562, p : 106433.148438, l : 420.54675293\n",
      "batch 226, ep 150, training accuracy 0.935\n",
      "f : 9350.83105469, q : 115600.546875, p : 106580.59375, l : 419.863830566\n",
      "layer0/q_pos/mu:0\n",
      "max: 34.3939399719, min: -33.3862838745, mean: -0.0157122947276, std: 7.56718444824\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.7885248661, min: -0.893081843853, mean: -0.00665944488719, std: 0.432412981987\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.4765052795, min: -21.2490978241, mean: 0.568088173866, std: 7.03306913376\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.8098410368, min: -0.831407546997, mean: -0.0128383832052, std: 0.419553399086\n",
      "valid accuracy 0.9159\n",
      "batch 227, ep 0, training accuracy 0.87\n",
      "f : 9714.91699219, q : 115499.09375, p : 106712.460938, l : 888.050292969\n",
      "batch 227, ep 50, training accuracy 0.88\n",
      "f : 10276.3300781, q : 115456.898438, p : 106088.015625, l : 850.480529785\n",
      "batch 227, ep 100, training accuracy 0.88\n",
      "f : 9946.46582031, q : 115458.085938, p : 106425.375, l : 847.955749512\n",
      "batch 227, ep 150, training accuracy 0.88\n",
      "f : 9805.35839844, q : 115451.953125, p : 106580.429688, l : 848.93359375\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.2191390991, min: -32.6734161377, mean: 0.0444921851158, std: 7.59557676315\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.74391388893, min: -0.95517039299, mean: -0.00297723687254, std: 0.432631254196\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.8141078949, min: -25.6457843781, mean: 0.217204809189, std: 6.88577318192\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.63943111897, min: -0.86362183094, mean: 0.00213436339982, std: 0.408539801836\n",
      "valid accuracy 0.9163\n",
      "batch 228, ep 0, training accuracy 0.89\n",
      "f : 9498.27441406, q : 115517.679688, p : 106621.195312, l : 672.075317383\n",
      "batch 228, ep 50, training accuracy 0.895\n",
      "f : 10057.625, q : 115455.46875, p : 106093.296875, l : 648.073547363\n",
      "batch 228, ep 100, training accuracy 0.9\n",
      "f : 9733.98046875, q : 115497.78125, p : 106395.890625, l : 649.652526855\n",
      "batch 228, ep 150, training accuracy 0.9\n",
      "f : 9610.08691406, q : 115474.601562, p : 106572.929688, l : 646.113037109\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.2452373505, min: -33.4641647339, mean: -0.00254929391667, std: 7.54057741165\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.58431649208, min: -0.931690692902, mean: -0.005042495206, std: 0.438159197569\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.9512634277, min: -19.5609169006, mean: -0.0975146666169, std: 7.28748369217\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.41685318947, min: -0.832383215427, mean: -0.00584953324869, std: 0.432898044586\n",
      "valid accuracy 0.9163\n",
      "batch 229, ep 0, training accuracy 0.865\n",
      "f : 9696.05957031, q : 115394.5625, p : 106645.640625, l : 870.308532715\n",
      "batch 229, ep 50, training accuracy 0.875\n",
      "f : 10242.0517578, q : 115474.164062, p : 106103.578125, l : 840.560302734\n",
      "batch 229, ep 100, training accuracy 0.87\n",
      "f : 9929.42773438, q : 115394.8125, p : 106401.804688, l : 841.122924805\n",
      "batch 229, ep 150, training accuracy 0.87\n",
      "f : 9782.265625, q : 115472.046875, p : 106579.046875, l : 839.651794434\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.0184841156, min: -33.396270752, mean: -0.061274446547, std: 7.55914783478\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.48477864265, min: -0.941942751408, mean: -0.00257210968994, std: 0.434007763863\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.5293712616, min: -23.1008834839, mean: 0.113557256758, std: 7.2938580513\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.61810469627, min: -0.877221226692, mean: -0.00600143522024, std: 0.455099254847\n",
      "valid accuracy 0.9156\n",
      "batch 230, ep 0, training accuracy 0.88\n",
      "f : 9623.96582031, q : 115365.570312, p : 106658.5, l : 796.430664062\n",
      "batch 230, ep 50, training accuracy 0.895\n",
      "f : 10158.5400391, q : 115496.375, p : 106009.3125, l : 729.719604492\n",
      "batch 230, ep 100, training accuracy 0.895\n",
      "f : 9837.64648438, q : 115481.21875, p : 106366.1875, l : 728.831542969\n",
      "batch 230, ep 150, training accuracy 0.895\n",
      "f : 9701.47070312, q : 115585.992188, p : 106506.148438, l : 731.422607422\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.7256259918, min: -30.8746986389, mean: -0.072123721242, std: 7.57983398438\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.49434709549, min: -0.922614395618, mean: -0.00502835446969, std: 0.433197438717\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.1277732849, min: -29.1829433441, mean: 0.221807867289, std: 7.15205287933\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.51174712181, min: -0.760388791561, mean: -0.01547951065, std: 0.42390075326\n",
      "valid accuracy 0.9158\n",
      "batch 231, ep 0, training accuracy 0.875\n",
      "f : 9729.19824219, q : 115457.546875, p : 106587.085938, l : 906.429748535\n",
      "batch 231, ep 50, training accuracy 0.88\n",
      "f : 10277.953125, q : 115381.132812, p : 106048.734375, l : 866.358154297\n",
      "batch 231, ep 100, training accuracy 0.885\n",
      "f : 9956.55371094, q : 115421.0625, p : 106350.320312, l : 869.695617676\n",
      "batch 231, ep 150, training accuracy 0.88\n",
      "f : 9828.96972656, q : 115402.125, p : 106437.375, l : 865.348571777\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.9022254944, min: -33.6765327454, mean: 0.0417000725865, std: 7.57474374771\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.63000512123, min: -0.91888666153, mean: -0.000299124250887, std: 0.434454470873\n",
      "layer1/q_pos/mu:0\n",
      "max: 18.286655426, min: -18.6620960236, mean: 0.318286716938, std: 7.37092399597\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.37666141987, min: -0.794849574566, mean: -0.00548618752509, std: 0.468695640564\n",
      "valid accuracy 0.9156\n",
      "batch 232, ep 0, training accuracy 0.915\n",
      "f : 9406.29003906, q : 115432.367188, p : 106613.296875, l : 579.51940918\n",
      "batch 232, ep 50, training accuracy 0.93\n",
      "f : 9964.90820312, q : 115440.492188, p : 105999.867188, l : 545.834960938\n",
      "batch 232, ep 100, training accuracy 0.935\n",
      "f : 9633.25976562, q : 115410.125, p : 106377.085938, l : 546.247253418\n",
      "batch 232, ep 150, training accuracy 0.935\n",
      "f : 9506.08203125, q : 115314.65625, p : 106424.828125, l : 544.497741699\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.5390281677, min: -33.4036369324, mean: -0.0811638906598, std: 7.53056812286\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.74947166443, min: -0.934946656227, mean: -0.00588107574731, std: 0.438890516758\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.0764064789, min: -20.1772403717, mean: 0.115508534014, std: 7.24118328094\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.11179161072, min: -0.826751589775, mean: -0.0132966106758, std: 0.462905853987\n",
      "valid accuracy 0.9142\n",
      "batch 233, ep 0, training accuracy 0.905\n",
      "f : 9399.23632812, q : 115433.234375, p : 106534.90625, l : 571.74230957\n",
      "batch 233, ep 50, training accuracy 0.91\n",
      "f : 9955.52832031, q : 115314.164062, p : 105917.0, l : 545.767333984\n",
      "batch 233, ep 100, training accuracy 0.92\n",
      "f : 9631.23046875, q : 115483.585938, p : 106316.101562, l : 545.075927734\n",
      "batch 233, ep 150, training accuracy 0.915\n",
      "f : 9466.54882812, q : 115412.09375, p : 106481.226562, l : 548.293640137\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.7739181519, min: -30.5145359039, mean: -0.0359780229628, std: 7.54521036148\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.66334462166, min: -0.925208568573, mean: -0.0082431146875, std: 0.430512905121\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.0020713806, min: -20.6332530975, mean: -0.0249173324555, std: 7.38261938095\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.6833268404, min: -0.847407460213, mean: 0.0111469104886, std: 0.452787965536\n",
      "valid accuracy 0.9155\n",
      "batch 234, ep 0, training accuracy 0.915\n",
      "f : 9361.48144531, q : 115403.140625, p : 106616.140625, l : 531.869262695\n",
      "batch 234, ep 50, training accuracy 0.93\n",
      "f : 9892.36132812, q : 115412.921875, p : 106031.9375, l : 495.065460205\n",
      "batch 234, ep 100, training accuracy 0.93\n",
      "f : 9582.06640625, q : 115337.210938, p : 106277.570312, l : 494.619445801\n",
      "batch 234, ep 150, training accuracy 0.925\n",
      "f : 9441.09960938, q : 115462.484375, p : 106453.851562, l : 496.213317871\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.4469985962, min: -32.2128334045, mean: -0.0477390289307, std: 7.57711982727\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.869161129, min: -0.920166969299, mean: -0.00329529982992, std: 0.434268027544\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.016210556, min: -24.3491344452, mean: 0.368196159601, std: 7.04943084717\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.33863580227, min: -0.893750548363, mean: -0.00455275131389, std: 0.439294308424\n",
      "valid accuracy 0.9154\n",
      "batch 235, ep 0, training accuracy 0.915\n",
      "f : 9355.02636719, q : 115345.585938, p : 106543.625, l : 528.940490723\n",
      "batch 235, ep 50, training accuracy 0.925\n",
      "f : 9915.00195312, q : 115414.898438, p : 105985.421875, l : 493.406433105\n",
      "batch 235, ep 100, training accuracy 0.92\n",
      "f : 9574.9921875, q : 115381.601562, p : 106192.617188, l : 493.928283691\n",
      "batch 235, ep 150, training accuracy 0.92\n",
      "f : 9425.32910156, q : 115367.757812, p : 106391.75, l : 494.726898193\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.5772094727, min: -30.5319232941, mean: -0.0508392527699, std: 7.48211717606\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.39656329155, min: -0.96806871891, mean: -0.00683899782598, std: 0.43467232585\n",
      "layer1/q_pos/mu:0\n",
      "max: 20.5712013245, min: -19.249830246, mean: -0.329033225775, std: 6.8749666214\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.77768778801, min: -0.840508043766, mean: 0.0172879435122, std: 0.415745079517\n",
      "valid accuracy 0.9156\n",
      "batch 236, ep 0, training accuracy 0.855\n",
      "f : 9717.67578125, q : 115366.679688, p : 106494.601562, l : 890.131225586\n",
      "batch 236, ep 50, training accuracy 0.88\n",
      "f : 10260.3818359, q : 115300.210938, p : 105931.734375, l : 835.679504395\n",
      "batch 236, ep 100, training accuracy 0.865\n",
      "f : 9920.43359375, q : 115318.4375, p : 106295.4375, l : 835.468505859\n",
      "batch 236, ep 150, training accuracy 0.875\n",
      "f : 9779.19628906, q : 115446.53125, p : 106411.328125, l : 832.452148438\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.1647090912, min: -30.6481666565, mean: 0.129521846771, std: 7.52568340302\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.70645618439, min: -0.96915769577, mean: -0.00346746621653, std: 0.434671312571\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.5400180817, min: -22.3944778442, mean: 0.144684314728, std: 6.87355852127\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.79412341118, min: -0.833080947399, mean: -0.0409889817238, std: 0.428506612778\n",
      "valid accuracy 0.9164\n",
      "batch 237, ep 0, training accuracy 0.905\n",
      "f : 9450.00976562, q : 115337.5, p : 106479.226562, l : 622.251953125\n",
      "batch 237, ep 50, training accuracy 0.91\n",
      "f : 9985.70507812, q : 115315.367188, p : 105907.710938, l : 583.419189453\n",
      "batch 237, ep 100, training accuracy 0.905\n",
      "f : 9677.5, q : 115370.625, p : 106224.703125, l : 587.401245117\n",
      "batch 237, ep 150, training accuracy 0.905\n",
      "f : 9545.26367188, q : 115384.351562, p : 106456.101562, l : 582.872436523\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.2887420654, min: -29.7308063507, mean: -0.0126088997349, std: 7.54439210892\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.35208439827, min: -0.928588449955, mean: -0.00328690791503, std: 0.437930703163\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.653137207, min: -19.35181427, mean: 0.0702834203839, std: 7.66626358032\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.36541938782, min: -0.915139734745, mean: 0.02417139709, std: 0.425851106644\n",
      "valid accuracy 0.9164\n",
      "batch 238, ep 0, training accuracy 0.895\n",
      "f : 9559.77539062, q : 115264.734375, p : 106411.648438, l : 729.639465332\n",
      "batch 238, ep 50, training accuracy 0.91\n",
      "f : 10087.3603516, q : 115246.28125, p : 105954.679688, l : 673.546875\n",
      "batch 238, ep 100, training accuracy 0.91\n",
      "f : 9768.10449219, q : 115297.789062, p : 106217.820312, l : 672.164001465\n",
      "batch 238, ep 150, training accuracy 0.91\n",
      "f : 9618.28613281, q : 115207.296875, p : 106395.921875, l : 673.514160156\n",
      "layer0/q_pos/mu:0\n",
      "max: 39.0009651184, min: -30.4672908783, mean: 0.00560921570286, std: 7.51138067245\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.82161140442, min: -0.92335909605, mean: -0.00569526897743, std: 0.434312075377\n",
      "layer1/q_pos/mu:0\n",
      "max: 25.0376644135, min: -19.1159286499, mean: 0.460432529449, std: 7.44435358047\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.08195018768, min: -0.861559331417, mean: -0.0163255091757, std: 0.464377254248\n",
      "valid accuracy 0.9154\n",
      "batch 239, ep 0, training accuracy 0.905\n",
      "f : 9478.16015625, q : 115257.234375, p : 106505.664062, l : 649.077514648\n",
      "batch 239, ep 50, training accuracy 0.91\n",
      "f : 10019.5126953, q : 115290.859375, p : 105968.539062, l : 604.796508789\n",
      "batch 239, ep 100, training accuracy 0.91\n",
      "f : 9699.96191406, q : 115317.992188, p : 106204.492188, l : 603.731262207\n",
      "batch 239, ep 150, training accuracy 0.91\n",
      "f : 9576.41992188, q : 115314.257812, p : 106297.265625, l : 608.650878906\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.1592178345, min: -34.4014968872, mean: -0.058228302747, std: 7.50641012192\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.89760327339, min: -0.919582486153, mean: -0.00464147236198, std: 0.435217440128\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.6760444641, min: -23.2671394348, mean: -0.181253165007, std: 7.09496927261\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.04270482063, min: -0.825379133224, mean: 0.00453830137849, std: 0.400650769472\n",
      "valid accuracy 0.9171\n",
      "batch 240, ep 0, training accuracy 0.945\n",
      "f : 9210.24707031, q : 115247.945312, p : 106447.703125, l : 382.755310059\n",
      "batch 240, ep 50, training accuracy 0.955\n",
      "f : 9753.29785156, q : 115314.367188, p : 105808.992188, l : 355.344970703\n",
      "batch 240, ep 100, training accuracy 0.955\n",
      "f : 9426.56445312, q : 115263.4375, p : 106175.539062, l : 354.884460449\n",
      "batch 240, ep 150, training accuracy 0.955\n",
      "f : 9306.31347656, q : 115291.625, p : 106385.898438, l : 350.342010498\n",
      "layer0/q_pos/mu:0\n",
      "max: 31.2221755981, min: -34.4274787903, mean: -0.0104273343459, std: 7.51819562912\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.76099157333, min: -0.947534799576, mean: -0.00766631402075, std: 0.434251487255\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.5517044067, min: -22.182390213, mean: 0.215646639466, std: 7.03858947754\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.97550940514, min: -0.83744430542, mean: -0.0149279236794, std: 0.447145402431\n",
      "valid accuracy 0.9168\n",
      "batch 241, ep 0, training accuracy 0.915\n",
      "f : 9466.53515625, q : 115297.195312, p : 106450.929688, l : 638.808288574\n",
      "batch 241, ep 50, training accuracy 0.925\n",
      "f : 10008.7695312, q : 115311.148438, p : 105838.15625, l : 603.015380859\n",
      "batch 241, ep 100, training accuracy 0.92\n",
      "f : 9686.80761719, q : 115308.242188, p : 106170.226562, l : 601.129150391\n",
      "batch 241, ep 150, training accuracy 0.925\n",
      "f : 9537.24121094, q : 115223.53125, p : 106324.710938, l : 605.981262207\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.8045196533, min: -32.3503494263, mean: -0.00673458352685, std: 7.50638341904\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.5584654808, min: -0.955113053322, mean: -0.00121228839271, std: 0.431581169367\n",
      "layer1/q_pos/mu:0\n",
      "max: 26.2414550781, min: -20.5180606842, mean: -0.571930348873, std: 6.84691762924\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.41900682449, min: -0.850365579128, mean: -0.00737642962486, std: 0.448151141405\n",
      "valid accuracy 0.9157\n",
      "batch 242, ep 0, training accuracy 0.925\n",
      "f : 9302.23535156, q : 115369.617188, p : 106490.125, l : 472.466918945\n",
      "batch 242, ep 50, training accuracy 0.94\n",
      "f : 9845.41699219, q : 115272.96875, p : 105885.21875, l : 446.380218506\n",
      "batch 242, ep 100, training accuracy 0.94\n",
      "f : 9520.97070312, q : 115178.875, p : 106175.5, l : 447.873352051\n",
      "batch 242, ep 150, training accuracy 0.935\n",
      "f : 9401.8984375, q : 115230.195312, p : 106249.921875, l : 448.990478516\n",
      "layer0/q_pos/mu:0\n",
      "max: 33.9757919312, min: -31.3500003815, mean: 0.0520622506738, std: 7.47665929794\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.73647785187, min: -0.921853721142, mean: -0.00449067074805, std: 0.4370701015\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.9285697937, min: -25.6721992493, mean: -0.203202292323, std: 7.20827198029\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.18689990044, min: -0.853397130966, mean: -0.0177704133093, std: 0.438970297575\n",
      "valid accuracy 0.9153\n",
      "batch 243, ep 0, training accuracy 0.945\n",
      "f : 9230.04394531, q : 115228.15625, p : 106372.664062, l : 401.999908447\n",
      "batch 243, ep 50, training accuracy 0.95\n",
      "f : 9778.29589844, q : 115249.34375, p : 105807.71875, l : 373.610229492\n",
      "batch 243, ep 100, training accuracy 0.95\n",
      "f : 9468.77148438, q : 115190.648438, p : 106142.875, l : 376.120819092\n",
      "batch 243, ep 150, training accuracy 0.95\n",
      "f : 9328.97753906, q : 115210.359375, p : 106224.03125, l : 375.083007812\n",
      "layer0/q_pos/mu:0\n",
      "max: 35.1987953186, min: -31.6491985321, mean: 0.0152045926079, std: 7.52483272552\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.66225218773, min: -0.933911144733, mean: -0.0032961347606, std: 0.436611652374\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.7305355072, min: -25.7295761108, mean: -0.411306291819, std: 7.09517669678\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.62513506413, min: -0.791246533394, mean: 0.00344563322142, std: 0.422612190247\n",
      "valid accuracy 0.9163\n",
      "batch 244, ep 0, training accuracy 0.875\n",
      "f : 9571.30078125, q : 115274.859375, p : 106373.234375, l : 740.675964355\n",
      "batch 244, ep 50, training accuracy 0.875\n",
      "f : 10100.9042969, q : 115216.4375, p : 105771.539062, l : 683.588867188\n",
      "batch 244, ep 100, training accuracy 0.875\n",
      "f : 9783.63183594, q : 115216.828125, p : 106128.34375, l : 689.265991211\n",
      "batch 244, ep 150, training accuracy 0.875\n",
      "f : 9642.89550781, q : 115167.148438, p : 106320.992188, l : 686.219360352\n",
      "layer0/q_pos/mu:0\n",
      "max: 28.1764354706, min: -27.6952800751, mean: 0.0477325469255, std: 7.53155136108\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.47196125984, min: -0.929911315441, mean: -0.00636639911681, std: 0.433191001415\n",
      "layer1/q_pos/mu:0\n",
      "max: 27.6311225891, min: -21.588924408, mean: 0.478407651186, std: 7.15645122528\n",
      "layer1/q_pos/rho:0\n",
      "max: 2.07421660423, min: -0.864852905273, mean: 0.00811304803938, std: 0.422741889954\n",
      "valid accuracy 0.9151\n",
      "batch 245, ep 0, training accuracy 0.87\n",
      "f : 9710.44824219, q : 115190.726562, p : 106415.15625, l : 885.589233398\n",
      "batch 245, ep 50, training accuracy 0.88\n",
      "f : 10235.765625, q : 115235.242188, p : 105771.914062, l : 843.653808594\n",
      "batch 245, ep 100, training accuracy 0.88\n",
      "f : 9942.11914062, q : 115141.148438, p : 106073.835938, l : 843.29675293\n",
      "batch 245, ep 150, training accuracy 0.89\n",
      "f : 9801.4921875, q : 115245.132812, p : 106250.507812, l : 842.777160645\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.292224884, min: -33.7093963623, mean: 0.00951606035233, std: 7.5017414093\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.98094630241, min: -0.926714420319, mean: -0.00267415237613, std: 0.433387458324\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.1523704529, min: -19.9661426544, mean: -0.0316337049007, std: 6.68646526337\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.61649894714, min: -0.798895001411, mean: -0.0337898544967, std: 0.450973778963\n",
      "valid accuracy 0.9157\n",
      "batch 246, ep 0, training accuracy 0.925\n",
      "f : 9380.88378906, q : 115191.8125, p : 106381.1875, l : 557.527770996\n",
      "batch 246, ep 50, training accuracy 0.925\n",
      "f : 10224.7128906, q : 115237.085938, p : 105444.664062, l : 509.16104126\n",
      "batch 246, ep 100, training accuracy 0.925\n",
      "f : 9588.93164062, q : 115155.875, p : 106102.890625, l : 509.656982422\n",
      "batch 246, ep 150, training accuracy 0.925\n",
      "f : 9467.66308594, q : 115270.382812, p : 106322.015625, l : 506.132385254\n",
      "layer0/q_pos/mu:0\n",
      "max: 28.7899875641, min: -35.4438819885, mean: 0.0461055226624, std: 7.45795536041\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.55814099312, min: -0.948707163334, mean: -0.00444038631395, std: 0.43648648262\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.5174064636, min: -24.5060901642, mean: -0.455893427134, std: 6.70856237411\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.66692578793, min: -0.911176204681, mean: 0.0178130622953, std: 0.419841319323\n",
      "valid accuracy 0.9156\n",
      "batch 247, ep 0, training accuracy 0.84\n",
      "f : 9986.50878906, q : 115150.507812, p : 106356.960938, l : 1159.48474121\n",
      "batch 247, ep 50, training accuracy 0.835\n",
      "f : 10485.9199219, q : 115126.6875, p : 105685.492188, l : 1059.68554688\n",
      "batch 247, ep 100, training accuracy 0.84\n",
      "f : 10176.9453125, q : 115254.804688, p : 106093.765625, l : 1061.43591309\n",
      "batch 247, ep 150, training accuracy 0.835\n",
      "f : 10049.0195312, q : 115114.164062, p : 106192.898438, l : 1057.23217773\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.6931037903, min: -35.9360313416, mean: -0.0396457947791, std: 7.52663707733\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.4204492569, min: -0.944711148739, mean: -0.00556276924908, std: 0.436613500118\n",
      "layer1/q_pos/mu:0\n",
      "max: 19.3483848572, min: -20.7221336365, mean: 0.202595800161, std: 7.13481998444\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.90574860573, min: -0.886240184307, mean: -0.0179720241576, std: 0.441690802574\n",
      "valid accuracy 0.9156\n",
      "batch 248, ep 0, training accuracy 0.91\n",
      "f : 9497.52539062, q : 115229.53125, p : 106286.859375, l : 667.250732422\n",
      "batch 248, ep 50, training accuracy 0.925\n",
      "f : 10063.1767578, q : 115168.125, p : 105787.703125, l : 638.770019531\n",
      "batch 248, ep 100, training accuracy 0.915\n",
      "f : 9709.19628906, q : 115162.1875, p : 106079.507812, l : 638.877868652\n",
      "batch 248, ep 150, training accuracy 0.92\n",
      "f : 9599.87792969, q : 115043.632812, p : 106119.570312, l : 637.632202148\n",
      "layer0/q_pos/mu:0\n",
      "max: 29.3183670044, min: -32.6514129639, mean: -0.0102467574179, std: 7.50063085556\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.55749630928, min: -0.925587236881, mean: -0.0045355479233, std: 0.436887830496\n",
      "layer1/q_pos/mu:0\n",
      "max: 21.0706520081, min: -23.4038238525, mean: 0.101576134562, std: 7.01552867889\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.78849184513, min: -0.848849952221, mean: -0.0153450705111, std: 0.419250756502\n",
      "valid accuracy 0.917\n",
      "batch 249, ep 0, training accuracy 0.875\n",
      "f : 9823.54882812, q : 115072.570312, p : 106281.257812, l : 992.018310547\n",
      "batch 249, ep 50, training accuracy 0.88\n",
      "f : 10292.0332031, q : 115130.75, p : 105581.0625, l : 861.667480469\n",
      "batch 249, ep 100, training accuracy 0.88\n",
      "f : 9993.96191406, q : 115120.828125, p : 106038.375, l : 851.692016602\n",
      "batch 249, ep 150, training accuracy 0.88\n",
      "f : 9861.30078125, q : 115133.554688, p : 106154.117188, l : 853.122558594\n",
      "layer0/q_pos/mu:0\n",
      "max: 30.2719898224, min: -31.2891368866, mean: 0.0605756863952, std: 7.49463653564\n",
      "layer0/q_pos/rho:0\n",
      "max: 2.58193039894, min: -0.924433350563, mean: -0.000742661650293, std: 0.434641033411\n",
      "layer1/q_pos/mu:0\n",
      "max: 22.6670131683, min: -21.8036766052, mean: 0.122265428305, std: 6.78691053391\n",
      "layer1/q_pos/rho:0\n",
      "max: 1.42477571964, min: -0.871977627277, mean: -0.0154511015862, std: 0.436824560165\n",
      "valid accuracy 0.9165\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for i in range(n_batches):\n",
    "    \n",
    "    bnn.reset_lr()\n",
    "    \n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        feed = {bnn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "        \n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "        #if ep > 5 and np.mean(fs[-25:]) < np.mean(fs[-15:]):\n",
    "        if ep > 5 and np.mean(fs[-25:]) < v_f:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "                \n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "            \n",
    "            \n",
    "#             print (\"--- learning rate decayed ---\")\n",
    "#             print bnn.get_lr()\n",
    "\n",
    "        if ep % 50 == 0:\n",
    "            train_accuracy = bnn.validate(feed)\n",
    "\n",
    "            print(\"batch %d, ep %d, training accuracy %g\"%(i, ep, train_accuracy))\n",
    "            print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        bnn.train(feed)\n",
    "    \n",
    "    \n",
    "    bnn.print_ewcgrads(feed)\n",
    "    \n",
    "    vacc = bnn.validate({bnn.x: x_valid, bnn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict ={bnn.x: x_valid, bnn.t: t_valid})\n",
    "    test_writer.add_summary(summary, i)\n",
    "    \n",
    "#     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "#         bnn.decay_lr()\n",
    "    \n",
    "    bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Normal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "nn = nn_shson.nn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, only_loglike = True, ewc = False)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31326168751822286"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for i in range(n_batches):\n",
    "    \n",
    "    nn.reset_lr()\n",
    "    \n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        feed = {nn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                nn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "        '''\n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "        '''\n",
    "        #if ep > 5 and np.mean(fs[-25:]) < np.mean(fs[-15:]):\n",
    "        if ep > 5 and np.mean(fs[-25:]) < v_f:\n",
    "            if patience == 0:\n",
    "                last_lr = nn.get_lr()\n",
    "                nn.decay_lr()\n",
    "                patience = 3\n",
    "                \n",
    "                if nn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "            \n",
    "            \n",
    "#             print (\"--- learning rate decayed ---\")\n",
    "#             print bnn.get_lr()\n",
    "\n",
    "        if ep % 50 == 0:\n",
    "            train_accuracy = nn.validate(feed)\n",
    "\n",
    "            print(\"batch %d, ep %d, training accuracy %g\"%(i, ep, train_accuracy))\n",
    "            #print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        nn.train(feed)\n",
    "    \n",
    "    \n",
    "    #bnn.print_ewcgrads(feed)\n",
    "    \n",
    "    vacc = nn.validate({nn.x: x_valid, nn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict ={nn.x: x_valid, nn.t: t_valid})\n",
    "    test_writer.add_summary(summary, i)\n",
    "    \n",
    "#     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "#         bnn.decay_lr()\n",
    "    \n",
    "    #bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Normal NN + EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "enn = nn_shson.nn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, only_loglike = False, ewc = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "taccs = list()\n",
    "vaccs = list()\n",
    "for i in range(n_batches):\n",
    "    \n",
    "    enn.reset_lr()\n",
    "    \n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        feed = {enn.x: x_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                enn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "        '''\n",
    "        v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "        fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "        '''\n",
    "        #if ep > 5 and np.mean(fs[-25:]) < np.mean(fs[-15:]):\n",
    "        if ep > 5 and np.mean(fs[-25:]) < v_f:\n",
    "            if patience == 0:\n",
    "                last_lr = enn.get_lr()\n",
    "                enn.decay_lr()\n",
    "                patience = 3\n",
    "                \n",
    "                if enn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "            \n",
    "            \n",
    "#             print (\"--- learning rate decayed ---\")\n",
    "#             print bnn.get_lr()\n",
    "\n",
    "        if ep % 50 == 0:\n",
    "            train_accuracy = enn.validate(feed)\n",
    "\n",
    "            print(\"batch %d, ep %d, training accuracy %g\"%(i, ep, train_accuracy))\n",
    "            #print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        enn.train(feed)\n",
    "    \n",
    "    \n",
    "    #bnn.print_ewcgrads(feed)\n",
    "    \n",
    "    vacc = enn.validate({enn.x: x_valid, enn.t: t_valid})\n",
    "    vaccs.append(vacc)\n",
    "    taccs.append(train_accuracy)\n",
    "    print(\"valid accuracy %g\"%vacc)\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict ={enn.x: x_valid, enn.t: t_valid})\n",
    "    test_writer.add_summary(summary, i)\n",
    "    \n",
    "#     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "#         bnn.decay_lr()\n",
    "    \n",
    "    enn.update_prior()\n",
    "    #bnn.print_params()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(taccs, 'b')\n",
    "plt.plot(vaccs, 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
