{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bcnn_shson_171114 import *\n",
    "import nn_shson\n",
    "from shson_exp_manager import *\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_to_onehot(nums, n_labels):\n",
    "    results = list()\n",
    "    for i in range(len(nums)):\n",
    "        res = np.zeros([n_labels])\n",
    "        res[nums[i]] = 1\n",
    "        results.append(res)\n",
    "    return np.asarray(results, dtype = 'float32')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290, 476, 531, 412, 667, 470, 656, 123, 167, 378, 357, 729, 324, 327, 271, 681, 155, 75, 755, 316]\n",
      "[398, 598, 337, 481, 192, 554, 297, 296, 157, 72, 29, 778, 513, 407, 264, 420, 69, 508, 690, 504]\n"
     ]
    }
   ],
   "source": [
    "mnist = h5py.File('mnist.hdf5', 'r')\n",
    "\n",
    "random.seed(1337)\n",
    "\n",
    "perm1 = range(784)\n",
    "perm2 = range(784)\n",
    "perm3 = range(784)\n",
    "perm4 = range(784)\n",
    "perm5 = range(784)\n",
    "perm6 = range(784)\n",
    "\n",
    "random.shuffle(perm1)\n",
    "random.shuffle(perm2)\n",
    "random.shuffle(perm3)\n",
    "random.shuffle(perm4)\n",
    "random.shuffle(perm5)\n",
    "random.shuffle(perm6)\n",
    "\n",
    "print perm1[0:20]\n",
    "print perm2[0:20]\n",
    "\n",
    "x_train = list()\n",
    "x_valid = list()\n",
    "x_test = list()\n",
    "\n",
    "x_train.append(mnist['train_data'][()])\n",
    "x_train.append(mnist['train_data'][()][:, perm1])\n",
    "x_train.append(mnist['train_data'][()][:, perm2])\n",
    "x_train.append(mnist['train_data'][()][:, perm3])\n",
    "x_train.append(mnist['train_data'][()][:, perm4])\n",
    "x_train.append(mnist['train_data'][()][:, perm5])\n",
    "x_train.append(mnist['train_data'][()][:, perm6])\n",
    "t_train = num_to_onehot(mnist['train_label'][()], 10)\n",
    "x_valid.append(mnist['valid_data'][()])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm1])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm2])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm3])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm4])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm5])\n",
    "x_valid.append(mnist['valid_data'][()][:, perm6])\n",
    "t_valid = num_to_onehot(mnist['valid_label'][()], 10)\n",
    "x_test.append(mnist['test_data'][()])\n",
    "x_test.append(mnist['test_data'][()][:, perm1])\n",
    "x_test.append(mnist['test_data'][()][:, perm2])\n",
    "x_test.append(mnist['test_data'][()][:, perm3])\n",
    "x_test.append(mnist['test_data'][()][:, perm4])\n",
    "x_test.append(mnist['test_data'][()][:, perm5])\n",
    "x_test.append(mnist['test_data'][()][:, perm6])\n",
    "t_test = num_to_onehot(mnist['test_label'][()], 10)\n",
    "\n",
    "mnist.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accs(accs, ep):\n",
    "    res = \"\"\n",
    "    for acc in accs:\n",
    "        res += \" {:.4f}\".format(acc[ep])\n",
    "    \n",
    "    print res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gal's BCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv layer done\n",
      "conv layer done\n",
      "(20, ?, 7, 7, 64)\n",
      "(20, ?, 3136)\n",
      "fc layer done\n",
      "fc layer done\n",
      "(20, ?, 10)\n",
      "[(<tf.Tensor 'gradients/AddN_14:0' shape=(5, 5, 1, 32) dtype=float32>, <tf.Variable 'conv_layer0/q_pos/mu:0' shape=(5, 5, 1, 32) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_15:0' shape=(5, 5, 1, 32) dtype=float32>, <tf.Variable 'conv_layer0/q_pos/rho:0' shape=(5, 5, 1, 32) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_11:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv_layer1/q_pos/mu:0' shape=(3, 3, 32, 64) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_12:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv_layer1/q_pos/rho:0' shape=(3, 3, 32, 64) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_6:0' shape=(3137, 100) dtype=float32>, <tf.Variable 'fc_layer2/q_pos/mu:0' shape=(3137, 100) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_8:0' shape=(3137, 100) dtype=float32>, <tf.Variable 'fc_layer2/q_pos/rho:0' shape=(3137, 100) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_7:0' shape=(101, 10) dtype=float32>, <tf.Variable 'fc_layer3/q_pos/mu:0' shape=(101, 10) dtype=float32_ref>), (<tf.Tensor 'gradients/AddN_9:0' shape=(101, 10) dtype=float32>, <tf.Variable 'fc_layer3/q_pos/rho:0' shape=(101, 10) dtype=float32_ref>)]\n"
     ]
    }
   ],
   "source": [
    "bcnn_gal = bcnn_model_g([28, 28, 1], [[5, 5, 1, 32],[3, 3, 32, 64]], [True, True], [7 * 7 * 64, 100, 10], mu = 0.1, rhos = [-1., 1., 10.], n_samples = 20, \\\n",
    "                outact = tf.nn.relu, lr = 1e-4, ewc = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves_bcnn_gal/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, batch 0, training accuracy 0.11\n",
      "ep 0, batch 50, training accuracy 0.785\n",
      "ep 0, batch 100, training accuracy 0.83\n",
      "ep 0, batch 150, training accuracy 0.9\n",
      "ep 0, batch 200, training accuracy 0.955\n",
      "valid accuracy: 0.9539 0.0983 0.0936 0.1031 0.0943 0.0906 0.0813\n",
      "valid accuracy: 0.9636 0.106 0.092 0.1143 0.1023 0.1252 0.0828\n",
      "valid accuracy: 0.9725 0.0882 0.1 0.0965 0.1085 0.1105 0.0829\n",
      "valid accuracy: 0.9743 0.0867 0.116 0.0973 0.1022 0.1219 0.0817\n",
      "valid accuracy: 0.9777 0.1024 0.1135 0.0905 0.109 0.1178 0.0818\n",
      "valid accuracy: 0.979 0.1032 0.1174 0.0862 0.1084 0.1233 0.082\n",
      "valid accuracy: 0.973 0.1032 0.1207 0.0854 0.1164 0.1294 0.0887\n",
      "valid accuracy: 0.9803 0.1011 0.1125 0.0927 0.1149 0.1219 0.0904\n",
      "valid accuracy: 0.9823 0.0974 0.1048 0.0959 0.1128 0.0992 0.0838\n",
      "valid accuracy: 0.9833 0.0956 0.1102 0.1058 0.1034 0.1292 0.0825\n",
      "valid accuracy: 0.9842 0.1029 0.1104 0.0995 0.1089 0.1183 0.083\n",
      "valid accuracy: 0.9839 0.1081 0.1149 0.0992 0.1066 0.1174 0.0835\n",
      "valid accuracy: 0.984 0.1102 0.1057 0.0934 0.1067 0.1208 0.0844\n",
      "valid accuracy: 0.9848 0.0935 0.1087 0.1002 0.1028 0.1201 0.0827\n",
      "valid accuracy: 0.9844 0.1024 0.1153 0.0977 0.1035 0.1127 0.0912\n",
      "valid accuracy: 0.9864 0.0985 0.1085 0.1031 0.1024 0.1252 0.0912\n",
      "valid accuracy: 0.9852 0.097 0.1088 0.1062 0.0935 0.1289 0.0846\n",
      "valid accuracy: 0.9871 0.0946 0.1111 0.0925 0.0994 0.1181 0.0906\n",
      "valid accuracy: 0.9852 0.0932 0.1129 0.1018 0.0991 0.1281 0.097\n",
      "valid accuracy: 0.9868 0.0904 0.1126 0.1054 0.0956 0.1202 0.098\n",
      "valid accuracy: 0.9884 0.0947 0.1114 0.1087 0.0969 0.1173 0.0921\n",
      "valid accuracy: 0.9864 0.0941 0.1111 0.1069 0.0962 0.1193 0.0905\n",
      "valid accuracy: 0.9888 0.0926 0.112 0.1087 0.0941 0.1261 0.0909\n",
      "valid accuracy: 0.9883 0.0974 0.111 0.1089 0.0971 0.1205 0.0925\n",
      "valid accuracy: 0.9886 0.0953 0.1145 0.1038 0.0926 0.1197 0.0917\n",
      "valid accuracy: 0.9886 0.0966 0.1133 0.1031 0.0972 0.1198 0.0946\n",
      "valid accuracy: 0.989 0.0979 0.11 0.1061 0.1005 0.1196 0.0969\n",
      "valid accuracy: 0.9891 0.0928 0.1118 0.1066 0.0972 0.124 0.0968\n",
      "valid accuracy: 0.9893 0.0949 0.1139 0.1054 0.0938 0.1226 0.0926\n",
      "valid accuracy: 0.9895 0.0958 0.1132 0.102 0.0939 0.1228 0.0965\n",
      "valid accuracy: 0.9889 0.0957 0.1131 0.1042 0.0971 0.1201 0.0938\n",
      "valid accuracy: 0.9895 0.0928 0.1156 0.1048 0.0964 0.1214 0.0901\n",
      "valid accuracy: 0.9891 0.0973 0.1153 0.1094 0.0965 0.1228 0.0915\n",
      "valid accuracy: 0.9897 0.0952 0.1149 0.1093 0.097 0.1207 0.0912\n",
      "valid accuracy: 0.9894 0.0922 0.1128 0.1075 0.0974 0.1254 0.0904\n",
      "valid accuracy: 0.99 0.0942 0.1137 0.1058 0.0966 0.1253 0.0902\n",
      "valid accuracy: 0.989 0.0946 0.1141 0.1061 0.0951 0.1282 0.092\n",
      "valid accuracy: 0.9897 0.0919 0.1131 0.1066 0.096 0.1241 0.0911\n",
      "valid accuracy: 0.9892 0.0935 0.1104 0.1062 0.0957 0.1248 0.0921\n",
      "valid accuracy: 0.9895 0.0937 0.1113 0.1058 0.0934 0.1223 0.0926\n",
      "valid accuracy: 0.9902 0.094 0.1122 0.1059 0.0977 0.1228 0.0916\n",
      "valid accuracy: 0.9896 0.0951 0.114 0.111 0.0963 0.1256 0.0918\n",
      "valid accuracy: 0.9901 0.0966 0.1148 0.108 0.0971 0.1254 0.0912\n",
      "valid accuracy: 0.9896 0.0932 0.1134 0.1057 0.0957 0.1223 0.0928\n",
      "valid accuracy: 0.9891 0.0922 0.1124 0.1072 0.0963 0.1226 0.0936\n",
      "valid accuracy: 0.9902 0.0946 0.1138 0.1034 0.0958 0.1239 0.0922\n",
      "valid accuracy: 0.99 0.0952 0.1108 0.1067 0.0966 0.1244 0.0943\n",
      "valid accuracy: 0.9899 0.0973 0.114 0.106 0.0971 0.1213 0.0936\n",
      "valid accuracy: 0.9898 0.0948 0.1147 0.1077 0.0942 0.1237 0.0909\n",
      "valid accuracy: 0.9896 0.0938 0.1116 0.1059 0.0955 0.1205 0.0922\n",
      "ep 50, batch 0, training accuracy 0.985\n",
      "ep 50, batch 50, training accuracy 0.99\n",
      "ep 50, batch 100, training accuracy 0.985\n",
      "ep 50, batch 150, training accuracy 0.99\n",
      "ep 50, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.99 0.0959 0.1129 0.1063 0.0947 0.1194 0.0947\n",
      "valid accuracy: 0.9898 0.0955 0.1118 0.1052 0.0963 0.1225 0.0933\n",
      "valid accuracy: 0.9892 0.0944 0.1148 0.1075 0.0968 0.1215 0.0936\n",
      "valid accuracy: 0.989 0.094 0.1149 0.1093 0.0942 0.1208 0.0947\n",
      "valid accuracy: 0.9896 0.0942 0.1136 0.1088 0.0931 0.124 0.0898\n",
      "valid accuracy: 0.9897 0.0948 0.1133 0.1069 0.0952 0.1246 0.0951\n",
      "valid accuracy: 0.9897 0.0944 0.1164 0.1079 0.0954 0.1228 0.0925\n",
      "valid accuracy: 0.9895 0.0957 0.1134 0.1041 0.0953 0.1208 0.0927\n",
      "valid accuracy: 0.9901 0.0942 0.1106 0.1065 0.0958 0.1249 0.0934\n",
      "valid accuracy: 0.9897 0.0966 0.1171 0.1052 0.098 0.1223 0.0921\n",
      "valid accuracy: 0.9899 0.096 0.1137 0.1036 0.0971 0.1245 0.0936\n",
      "valid accuracy: 0.9896 0.0963 0.1115 0.1075 0.0968 0.1226 0.0939\n",
      "valid accuracy: 0.9902 0.0924 0.1138 0.1073 0.0932 0.1237 0.0937\n",
      "valid accuracy: 0.9892 0.0923 0.1129 0.1064 0.0944 0.1202 0.0938\n",
      "valid accuracy: 0.9895 0.0961 0.11 0.1049 0.0965 0.1225 0.0935\n",
      "valid accuracy: 0.9899 0.0942 0.1142 0.1062 0.0935 0.122 0.093\n",
      "valid accuracy: 0.9901 0.0946 0.1145 0.1056 0.0988 0.1224 0.0923\n",
      "valid accuracy: 0.9898 0.097 0.114 0.1064 0.0962 0.1191 0.0921\n",
      "valid accuracy: 0.99 0.0944 0.1115 0.1062 0.0973 0.1247 0.0912\n",
      "valid accuracy: 0.9901 0.0928 0.1133 0.1037 0.0976 0.1226 0.0924\n",
      "valid accuracy: 0.9898 0.0941 0.1143 0.1063 0.0966 0.1258 0.0922\n",
      "valid accuracy: 0.9894 0.0944 0.1116 0.1089 0.0982 0.1259 0.0948\n",
      "valid accuracy: 0.9893 0.0954 0.1133 0.1075 0.0958 0.125 0.0924\n",
      "valid accuracy: 0.9891 0.0938 0.1147 0.1042 0.0972 0.1239 0.0918\n",
      "valid accuracy: 0.9893 0.0957 0.1145 0.1067 0.0959 0.1238 0.0943\n",
      "valid accuracy: 0.9902 0.0971 0.1129 0.1044 0.0958 0.1248 0.0932\n",
      "valid accuracy: 0.9895 0.0943 0.1119 0.1065 0.0963 0.1226 0.0904\n",
      "valid accuracy: 0.9893 0.0954 0.1146 0.1068 0.0967 0.1252 0.0918\n",
      "valid accuracy: 0.9897 0.0969 0.1148 0.1071 0.0967 0.1257 0.0926\n",
      "valid accuracy: 0.9899 0.0926 0.115 0.1041 0.096 0.1222 0.0923\n",
      "valid accuracy: 0.9898 0.0942 0.1155 0.1053 0.096 0.1227 0.0918\n",
      "valid accuracy: 0.9893 0.0963 0.1134 0.1052 0.0972 0.1235 0.0927\n",
      "valid accuracy: 0.9899 0.0936 0.114 0.1079 0.0972 0.1223 0.0922\n",
      "valid accuracy: 0.9893 0.0943 0.1146 0.107 0.0972 0.1228 0.0913\n",
      "valid accuracy: 0.9887 0.096 0.1148 0.1077 0.098 0.1255 0.0923\n",
      "valid accuracy: 0.99 0.0928 0.1118 0.1075 0.0969 0.1215 0.0939\n",
      "valid accuracy: 0.9891 0.0924 0.1126 0.105 0.0982 0.1245 0.0923\n",
      "valid accuracy: 0.9902 0.0967 0.1123 0.1083 0.0959 0.1218 0.0925\n",
      "valid accuracy: 0.9898 0.0959 0.1134 0.1044 0.0963 0.1232 0.0935\n",
      "valid accuracy: 0.9897 0.0915 0.1149 0.1066 0.0971 0.1225 0.0912\n",
      "valid accuracy: 0.9895 0.0955 0.1127 0.1078 0.095 0.1217 0.096\n",
      "valid accuracy: 0.9892 0.0955 0.1136 0.1036 0.0966 0.1241 0.0928\n",
      "valid accuracy: 0.9903 0.0955 0.1129 0.1046 0.0958 0.1213 0.094\n",
      "valid accuracy: 0.9896 0.0956 0.1142 0.1062 0.095 0.1222 0.0925\n",
      "valid accuracy: 0.9895 0.0953 0.1126 0.1075 0.0982 0.1236 0.0951\n",
      "valid accuracy: 0.9898 0.093 0.1141 0.1058 0.0964 0.1275 0.094\n",
      "valid accuracy: 0.9893 0.0941 0.115 0.1059 0.0951 0.1235 0.0938\n",
      "valid accuracy: 0.9894 0.0923 0.1137 0.1054 0.0945 0.122 0.0937\n",
      "valid accuracy: 0.9893 0.097 0.1147 0.1061 0.0982 0.1239 0.0916\n",
      "valid accuracy: 0.9896 0.0946 0.1132 0.1058 0.0959 0.1238 0.0931\n",
      "ep 100, batch 0, training accuracy 0.985\n",
      "ep 100, batch 50, training accuracy 0.99\n",
      "ep 100, batch 100, training accuracy 0.985\n",
      "ep 100, batch 150, training accuracy 0.985\n",
      "ep 100, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9895 0.0945 0.1157 0.1066 0.096 0.1219 0.09\n",
      "valid accuracy: 0.989 0.0942 0.1125 0.107 0.0979 0.1217 0.0943\n",
      "valid accuracy: 0.9898 0.0948 0.1132 0.1057 0.0956 0.1212 0.0937\n",
      "valid accuracy: 0.99 0.0922 0.1133 0.1064 0.0975 0.1236 0.0942\n",
      "valid accuracy: 0.9898 0.0978 0.1136 0.1078 0.0972 0.1236 0.0915\n",
      "valid accuracy: 0.9891 0.0962 0.1139 0.1082 0.0949 0.1245 0.0937\n",
      "valid accuracy: 0.9895 0.0949 0.1132 0.1055 0.0966 0.1239 0.0942\n",
      "valid accuracy: 0.9895 0.094 0.1131 0.1049 0.097 0.1229 0.0942\n",
      "valid accuracy: 0.9891 0.0952 0.114 0.1072 0.0962 0.1214 0.0904\n",
      "valid accuracy: 0.9897 0.0952 0.1135 0.1074 0.0973 0.1216 0.0897\n",
      "valid accuracy: 0.9895 0.0938 0.1108 0.1056 0.0933 0.1229 0.0906\n",
      "valid accuracy: 0.9897 0.0957 0.1162 0.1063 0.0962 0.122 0.0932\n",
      "valid accuracy: 0.9895 0.0955 0.1142 0.106 0.0942 0.1213 0.0934\n",
      "valid accuracy: 0.99 0.0944 0.1104 0.1053 0.0966 0.1238 0.0918\n",
      "valid accuracy: 0.9895 0.0968 0.1138 0.1079 0.0973 0.1211 0.0926\n",
      "valid accuracy: 0.9894 0.0957 0.1146 0.1061 0.097 0.1236 0.0898\n",
      "valid accuracy: 0.9895 0.0921 0.1138 0.1065 0.0956 0.1235 0.0948\n",
      "valid accuracy: 0.9896 0.0958 0.1131 0.1063 0.0962 0.1232 0.0909\n",
      "valid accuracy: 0.9897 0.093 0.1138 0.1065 0.0945 0.1259 0.0932\n",
      "valid accuracy: 0.9891 0.0939 0.1134 0.1042 0.0973 0.1252 0.0942\n",
      "valid accuracy: 0.989 0.0927 0.1135 0.1073 0.0987 0.1223 0.0901\n",
      "valid accuracy: 0.9894 0.0956 0.1126 0.1062 0.0972 0.1218 0.0945\n",
      "valid accuracy: 0.9892 0.0934 0.1146 0.1073 0.0948 0.1207 0.0929\n",
      "valid accuracy: 0.9896 0.0952 0.1163 0.1048 0.0978 0.1246 0.0921\n",
      "valid accuracy: 0.9893 0.0978 0.1143 0.1053 0.0982 0.1213 0.0915\n",
      "valid accuracy: 0.99 0.0961 0.1132 0.1051 0.0959 0.1261 0.0925\n",
      "valid accuracy: 0.9901 0.0958 0.1135 0.1053 0.0973 0.1242 0.0943\n",
      "valid accuracy: 0.9896 0.0978 0.115 0.1047 0.0969 0.1241 0.0929\n",
      "valid accuracy: 0.9892 0.0956 0.1113 0.1068 0.0977 0.123 0.0936\n",
      "valid accuracy: 0.9894 0.0947 0.1108 0.1076 0.0971 0.1205 0.0927\n",
      "valid accuracy: 0.9896 0.0941 0.1139 0.1062 0.097 0.1203 0.0939\n",
      "valid accuracy: 0.9893 0.0965 0.113 0.1067 0.0952 0.1219 0.0924\n",
      "valid accuracy: 0.9894 0.0942 0.1117 0.1044 0.0978 0.1229 0.0901\n",
      "valid accuracy: 0.9889 0.0941 0.1132 0.1068 0.0984 0.1222 0.0921\n",
      "valid accuracy: 0.9896 0.0968 0.1128 0.1054 0.0967 0.1237 0.0922\n",
      "valid accuracy: 0.9899 0.0986 0.1143 0.107 0.0963 0.1235 0.0917\n",
      "valid accuracy: 0.9896 0.0939 0.1126 0.1068 0.097 0.1241 0.0906\n",
      "valid accuracy: 0.9897 0.096 0.1134 0.1063 0.0935 0.1243 0.0915\n",
      "valid accuracy: 0.9893 0.095 0.1123 0.1056 0.0965 0.125 0.093\n",
      "valid accuracy: 0.9902 0.0934 0.1146 0.1024 0.0971 0.1237 0.0939\n",
      "valid accuracy: 0.9897 0.0957 0.1135 0.107 0.0946 0.1222 0.0945\n",
      "valid accuracy: 0.9893 0.0956 0.114 0.1077 0.0954 0.1258 0.0934\n",
      "valid accuracy: 0.9898 0.0943 0.115 0.109 0.0956 0.1239 0.0922\n",
      "valid accuracy: 0.9894 0.0952 0.1157 0.107 0.0962 0.1208 0.0917\n",
      "valid accuracy: 0.9895 0.095 0.1148 0.1063 0.096 0.1228 0.0913\n",
      "valid accuracy: 0.9888 0.0956 0.1147 0.1057 0.0965 0.1238 0.093\n",
      "valid accuracy: 0.9895 0.0954 0.1133 0.1073 0.0937 0.1237 0.0912\n",
      "valid accuracy: 0.9895 0.0951 0.1139 0.1049 0.0966 0.1209 0.0942\n",
      "valid accuracy: 0.9898 0.0964 0.1125 0.1057 0.0967 0.1211 0.0932\n",
      "valid accuracy: 0.9893 0.0965 0.113 0.1073 0.0966 0.1253 0.0932\n",
      "ep 150, batch 0, training accuracy 0.975\n",
      "ep 150, batch 50, training accuracy 0.99\n",
      "ep 150, batch 100, training accuracy 0.99\n",
      "ep 150, batch 150, training accuracy 0.995\n",
      "ep 150, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9892 0.0946 0.1144 0.1061 0.0931 0.1232 0.0929\n",
      "valid accuracy: 0.9892 0.0937 0.1153 0.1074 0.0948 0.1238 0.0921\n",
      "valid accuracy: 0.9894 0.0947 0.1116 0.1048 0.095 0.1215 0.0941\n",
      "valid accuracy: 0.9894 0.0961 0.1143 0.1067 0.0937 0.123 0.0925\n",
      "valid accuracy: 0.9895 0.0928 0.1156 0.105 0.0936 0.1226 0.0939\n",
      "valid accuracy: 0.9899 0.0968 0.1135 0.1084 0.0977 0.1239 0.0896\n",
      "valid accuracy: 0.9904 0.0931 0.1142 0.1057 0.0946 0.1236 0.0912\n",
      "valid accuracy: 0.9893 0.0948 0.114 0.1065 0.0974 0.1221 0.0904\n",
      "valid accuracy: 0.9895 0.0925 0.1144 0.1034 0.0936 0.1227 0.0912\n",
      "valid accuracy: 0.9897 0.0956 0.1143 0.1067 0.0946 0.1226 0.0931\n",
      "valid accuracy: 0.99 0.0947 0.1144 0.1056 0.0971 0.1241 0.0953\n",
      "valid accuracy: 0.9894 0.0968 0.115 0.106 0.0959 0.1227 0.0912\n",
      "valid accuracy: 0.9898 0.0939 0.1132 0.1037 0.0986 0.1215 0.0919\n",
      "valid accuracy: 0.9896 0.0929 0.1138 0.1039 0.0949 0.1228 0.0937\n",
      "valid accuracy: 0.9892 0.093 0.1148 0.1089 0.095 0.1246 0.0909\n",
      "valid accuracy: 0.9901 0.0965 0.1137 0.108 0.0964 0.1254 0.092\n",
      "valid accuracy: 0.9899 0.0937 0.113 0.1059 0.0972 0.1222 0.0931\n",
      "valid accuracy: 0.9902 0.0935 0.1135 0.1063 0.0947 0.1235 0.0934\n",
      "valid accuracy: 0.9897 0.095 0.1116 0.1056 0.0944 0.1234 0.0928\n",
      "valid accuracy: 0.9895 0.0933 0.1133 0.1037 0.0969 0.1234 0.0916\n",
      "valid accuracy: 0.9896 0.094 0.1128 0.1041 0.0957 0.1241 0.0925\n",
      "valid accuracy: 0.99 0.095 0.1142 0.1053 0.0942 0.1231 0.0909\n",
      "valid accuracy: 0.9897 0.0947 0.1127 0.106 0.0941 0.1239 0.0941\n",
      "valid accuracy: 0.9894 0.0921 0.1125 0.1047 0.0975 0.1235 0.0952\n",
      "valid accuracy: 0.9897 0.0961 0.116 0.1062 0.0961 0.125 0.095\n",
      "valid accuracy: 0.9893 0.0961 0.1117 0.1073 0.0936 0.1232 0.0934\n",
      "valid accuracy: 0.9893 0.0935 0.1128 0.1054 0.097 0.123 0.0935\n",
      "valid accuracy: 0.9895 0.0958 0.112 0.1086 0.0955 0.124 0.0927\n",
      "valid accuracy: 0.9896 0.0949 0.1131 0.108 0.0952 0.1226 0.093\n",
      "valid accuracy: 0.9894 0.0959 0.1123 0.1085 0.0966 0.1207 0.0921\n",
      "valid accuracy: 0.9893 0.0934 0.1139 0.1067 0.0948 0.1234 0.0939\n",
      "valid accuracy: 0.9894 0.0936 0.1145 0.1076 0.0925 0.1212 0.0927\n",
      "valid accuracy: 0.9893 0.094 0.115 0.1072 0.0966 0.124 0.0946\n",
      "valid accuracy: 0.9899 0.0917 0.1135 0.1066 0.096 0.1242 0.0926\n",
      "valid accuracy: 0.9896 0.0951 0.1132 0.1042 0.0956 0.1241 0.0914\n",
      "valid accuracy: 0.9898 0.0932 0.1158 0.1068 0.0977 0.1199 0.095\n",
      "valid accuracy: 0.9893 0.0936 0.1126 0.1052 0.0941 0.124 0.0926\n",
      "valid accuracy: 0.9901 0.0909 0.1141 0.1064 0.0978 0.1213 0.091\n",
      "valid accuracy: 0.99 0.0955 0.1147 0.1051 0.0977 0.1255 0.0939\n",
      "valid accuracy: 0.9896 0.0952 0.113 0.105 0.0939 0.1242 0.0945\n",
      "valid accuracy: 0.9893 0.0953 0.1131 0.1063 0.0996 0.1226 0.0905\n",
      "valid accuracy: 0.989 0.0963 0.1147 0.1054 0.096 0.1247 0.0919\n",
      "valid accuracy: 0.9893 0.0933 0.117 0.1055 0.0963 0.1235 0.0952\n",
      "valid accuracy: 0.9898 0.0934 0.1125 0.1063 0.0971 0.1227 0.093\n",
      "valid accuracy: 0.9898 0.0942 0.113 0.1058 0.0952 0.1255 0.0922\n",
      "valid accuracy: 0.9894 0.0933 0.1121 0.107 0.0985 0.1225 0.0928\n",
      "valid accuracy: 0.9899 0.0937 0.1154 0.1063 0.0948 0.1252 0.0904\n",
      "valid accuracy: 0.9903 0.0945 0.1133 0.1054 0.0975 0.1261 0.0937\n",
      "valid accuracy: 0.9894 0.0951 0.1118 0.1054 0.0953 0.1274 0.0905\n",
      "valid accuracy: 0.9898 0.0935 0.1138 0.1049 0.0962 0.123 0.0941\n",
      "ep 200, batch 0, training accuracy 0.985\n",
      "ep 200, batch 50, training accuracy 0.99\n",
      "ep 200, batch 100, training accuracy 0.985\n",
      "ep 200, batch 150, training accuracy 0.99\n",
      "ep 200, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9897 0.0926 0.1103 0.1058 0.0969 0.1245 0.0927\n",
      "valid accuracy: 0.9896 0.0954 0.114 0.1065 0.0947 0.1242 0.094\n",
      "valid accuracy: 0.9894 0.096 0.1135 0.1057 0.0972 0.1227 0.0919\n",
      "valid accuracy: 0.9894 0.0956 0.1133 0.1075 0.0955 0.1225 0.0929\n",
      "valid accuracy: 0.9895 0.0922 0.1126 0.1049 0.0976 0.1217 0.0922\n",
      "valid accuracy: 0.9893 0.0947 0.1139 0.1038 0.0957 0.1257 0.0913\n",
      "valid accuracy: 0.9888 0.0958 0.1152 0.1089 0.0949 0.123 0.0922\n",
      "valid accuracy: 0.9898 0.0949 0.1135 0.1083 0.0976 0.1223 0.0929\n",
      "valid accuracy: 0.9899 0.0939 0.1137 0.107 0.096 0.1244 0.0923\n",
      "valid accuracy: 0.9896 0.0944 0.1117 0.1069 0.0973 0.1238 0.092\n",
      "valid accuracy: 0.9897 0.0943 0.1127 0.1041 0.0953 0.1241 0.092\n",
      "valid accuracy: 0.9889 0.0923 0.1128 0.1064 0.0956 0.1245 0.0911\n",
      "valid accuracy: 0.99 0.0953 0.1148 0.1052 0.0964 0.1234 0.0932\n",
      "valid accuracy: 0.9897 0.097 0.1125 0.1064 0.0951 0.1247 0.0908\n",
      "valid accuracy: 0.9899 0.094 0.1138 0.1071 0.0973 0.1246 0.0934\n",
      "valid accuracy: 0.9895 0.0927 0.1145 0.1081 0.0984 0.1215 0.0981\n",
      "valid accuracy: 0.9893 0.094 0.1126 0.1041 0.0974 0.1239 0.0909\n",
      "valid accuracy: 0.9895 0.095 0.1136 0.1058 0.0954 0.1239 0.092\n",
      "valid accuracy: 0.9898 0.0941 0.1133 0.1051 0.0937 0.1228 0.0932\n",
      "valid accuracy: 0.9888 0.0944 0.1105 0.1052 0.0951 0.1234 0.0923\n",
      "valid accuracy: 0.989 0.0972 0.1124 0.1047 0.095 0.1234 0.0927\n",
      "valid accuracy: 0.9897 0.0938 0.1143 0.1064 0.0965 0.1236 0.0939\n",
      "valid accuracy: 0.9896 0.097 0.1143 0.1061 0.0959 0.125 0.0921\n",
      "valid accuracy: 0.9893 0.095 0.1136 0.1054 0.0949 0.122 0.0901\n",
      "valid accuracy: 0.9896 0.094 0.1147 0.1065 0.0975 0.1236 0.0942\n",
      "valid accuracy: 0.9896 0.0939 0.112 0.1057 0.0954 0.1243 0.0922\n",
      "valid accuracy: 0.9898 0.0958 0.1115 0.106 0.0958 0.1262 0.0915\n",
      "valid accuracy: 0.9901 0.0943 0.114 0.1078 0.0966 0.1192 0.091\n",
      "valid accuracy: 0.9894 0.0939 0.1129 0.1037 0.0958 0.1241 0.0939\n",
      "valid accuracy: 0.9894 0.0945 0.111 0.1075 0.0994 0.126 0.0953\n",
      "valid accuracy: 0.9894 0.0948 0.1123 0.1049 0.0952 0.1243 0.0918\n",
      "valid accuracy: 0.9894 0.0947 0.1134 0.1065 0.0961 0.1228 0.091\n",
      "valid accuracy: 0.9893 0.093 0.1151 0.1063 0.0959 0.1237 0.0903\n",
      "valid accuracy: 0.9894 0.0955 0.111 0.1088 0.0959 0.1225 0.0911\n",
      "valid accuracy: 0.9892 0.0936 0.1087 0.1073 0.0953 0.1228 0.0924\n",
      "valid accuracy: 0.9898 0.0931 0.1119 0.1076 0.0972 0.1252 0.0944\n",
      "valid accuracy: 0.9896 0.0924 0.1116 0.1078 0.0971 0.1224 0.0951\n",
      "valid accuracy: 0.9889 0.096 0.1125 0.1071 0.0958 0.1227 0.0925\n",
      "valid accuracy: 0.9901 0.0945 0.1126 0.1042 0.0954 0.1211 0.0927\n",
      "valid accuracy: 0.9898 0.0949 0.114 0.1061 0.0946 0.1251 0.0925\n",
      "valid accuracy: 0.9902 0.0942 0.1137 0.1069 0.0956 0.1226 0.0939\n",
      "valid accuracy: 0.9899 0.0956 0.1117 0.1051 0.0951 0.124 0.0915\n",
      "valid accuracy: 0.9896 0.093 0.111 0.1028 0.0985 0.1248 0.0913\n",
      "valid accuracy: 0.9895 0.0948 0.115 0.1071 0.0962 0.1235 0.0891\n",
      "valid accuracy: 0.9892 0.0954 0.1139 0.1051 0.0954 0.1213 0.0909\n",
      "valid accuracy: 0.9903 0.0964 0.1148 0.107 0.093 0.1246 0.0916\n",
      "valid accuracy: 0.9894 0.0933 0.1128 0.1049 0.0963 0.1259 0.0924\n",
      "valid accuracy: 0.9896 0.0959 0.1133 0.1057 0.0962 0.1224 0.0959\n",
      "valid accuracy: 0.9899 0.0977 0.1137 0.1057 0.0961 0.1224 0.092\n",
      "valid accuracy: 0.9898 0.0957 0.1157 0.1047 0.0955 0.1234 0.0932\n",
      "ep 250, batch 0, training accuracy 0.98\n",
      "ep 250, batch 50, training accuracy 0.99\n",
      "ep 250, batch 100, training accuracy 0.99\n",
      "ep 250, batch 150, training accuracy 0.985\n",
      "ep 250, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9896 0.0944 0.1128 0.1048 0.0966 0.1229 0.0925\n",
      "valid accuracy: 0.9897 0.0941 0.1158 0.1061 0.0953 0.1227 0.0962\n",
      "valid accuracy: 0.9893 0.0939 0.1136 0.1062 0.0964 0.1233 0.0948\n",
      "valid accuracy: 0.9897 0.0954 0.1157 0.1045 0.0961 0.1217 0.0942\n",
      "valid accuracy: 0.9894 0.096 0.1141 0.1047 0.0954 0.1235 0.093\n",
      "valid accuracy: 0.9897 0.0943 0.1132 0.1083 0.096 0.1247 0.0918\n",
      "valid accuracy: 0.9892 0.094 0.1123 0.1046 0.0952 0.1227 0.0921\n",
      "valid accuracy: 0.9898 0.0944 0.1137 0.1075 0.0954 0.1253 0.0944\n",
      "valid accuracy: 0.9892 0.0939 0.1136 0.1068 0.0945 0.1231 0.093\n",
      "valid accuracy: 0.9904 0.0939 0.1152 0.1058 0.0981 0.1215 0.0936\n",
      "valid accuracy: 0.9893 0.0944 0.1146 0.1035 0.0943 0.1247 0.0913\n",
      "valid accuracy: 0.9898 0.0944 0.1137 0.1065 0.0952 0.123 0.0935\n",
      "valid accuracy: 0.9901 0.0939 0.1127 0.1065 0.0964 0.1234 0.0939\n",
      "valid accuracy: 0.9899 0.0949 0.1125 0.1046 0.0941 0.1245 0.0923\n",
      "valid accuracy: 0.9895 0.0937 0.1161 0.1076 0.0948 0.122 0.0938\n",
      "valid accuracy: 0.9891 0.0931 0.1123 0.1061 0.0949 0.1224 0.0929\n",
      "valid accuracy: 0.9897 0.0951 0.113 0.1064 0.0972 0.1215 0.0915\n",
      "valid accuracy: 0.9901 0.0947 0.1133 0.1078 0.0954 0.1251 0.0907\n",
      "valid accuracy: 0.9897 0.0963 0.1118 0.1061 0.0959 0.1217 0.0921\n",
      "valid accuracy: 0.9897 0.0943 0.1126 0.1068 0.0973 0.1245 0.0928\n",
      "valid accuracy: 0.9893 0.0944 0.1124 0.1088 0.0945 0.1236 0.091\n",
      "valid accuracy: 0.9897 0.0928 0.1114 0.1072 0.0958 0.1219 0.0918\n",
      "valid accuracy: 0.9891 0.0947 0.113 0.1076 0.0959 0.1236 0.0952\n",
      "valid accuracy: 0.9891 0.0949 0.1133 0.1079 0.0933 0.1227 0.0914\n",
      "valid accuracy: 0.9893 0.0957 0.114 0.1084 0.0962 0.1234 0.0932\n",
      "valid accuracy: 0.9894 0.0935 0.1135 0.1056 0.0956 0.122 0.0929\n",
      "valid accuracy: 0.9892 0.0945 0.114 0.1062 0.0972 0.1234 0.0906\n",
      "valid accuracy: 0.9902 0.0961 0.1144 0.1049 0.0951 0.124 0.0933\n",
      "valid accuracy: 0.9896 0.0976 0.1149 0.1063 0.097 0.1255 0.0954\n",
      "valid accuracy: 0.9894 0.0946 0.1174 0.1053 0.0967 0.1239 0.0913\n",
      "valid accuracy: 0.99 0.0981 0.1141 0.1068 0.0946 0.1231 0.0923\n",
      "valid accuracy: 0.9903 0.0958 0.1153 0.1069 0.0961 0.1227 0.092\n",
      "valid accuracy: 0.989 0.0928 0.1144 0.1032 0.0973 0.1224 0.0935\n",
      "valid accuracy: 0.9894 0.0945 0.1137 0.1072 0.0988 0.1248 0.0928\n",
      "valid accuracy: 0.9895 0.0947 0.1129 0.1074 0.0955 0.1229 0.0925\n",
      "valid accuracy: 0.9897 0.0972 0.1135 0.1074 0.0937 0.1233 0.09\n",
      "valid accuracy: 0.9897 0.0941 0.1113 0.1079 0.097 0.1222 0.0937\n",
      "valid accuracy: 0.9894 0.0977 0.1151 0.1068 0.0928 0.1235 0.0941\n",
      "valid accuracy: 0.9895 0.096 0.1153 0.1068 0.0954 0.1221 0.0907\n",
      "valid accuracy: 0.9895 0.0947 0.1124 0.1087 0.0964 0.1256 0.0937\n",
      "valid accuracy: 0.9897 0.0969 0.1134 0.106 0.0959 0.1224 0.0909\n",
      "valid accuracy: 0.9899 0.0964 0.1127 0.1053 0.097 0.1235 0.0914\n",
      "valid accuracy: 0.9898 0.0921 0.1139 0.1053 0.0944 0.1203 0.0933\n",
      "valid accuracy: 0.9894 0.0947 0.1147 0.1048 0.0971 0.1212 0.0938\n",
      "valid accuracy: 0.9903 0.0947 0.1165 0.1066 0.0944 0.122 0.0907\n",
      "valid accuracy: 0.9898 0.095 0.1153 0.1047 0.0972 0.1234 0.0935\n",
      "valid accuracy: 0.9897 0.0951 0.1142 0.1043 0.093 0.1273 0.0943\n",
      "valid accuracy: 0.99 0.0953 0.1131 0.1079 0.0954 0.1248 0.0927\n",
      "valid accuracy: 0.9898 0.0928 0.114 0.1061 0.0945 0.1253 0.0904\n",
      "valid accuracy: 0.9893 0.0956 0.1158 0.1072 0.094 0.1247 0.0936\n",
      "ep 300, batch 0, training accuracy 0.98\n",
      "ep 300, batch 50, training accuracy 0.99\n",
      "ep 300, batch 100, training accuracy 0.99\n",
      "ep 300, batch 150, training accuracy 0.99\n",
      "ep 300, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9893 0.0969 0.1105 0.1064 0.0967 0.1249 0.0945\n",
      "valid accuracy: 0.9898 0.0958 0.1131 0.1039 0.0962 0.1227 0.0926\n",
      "valid accuracy: 0.989 0.0961 0.1129 0.1063 0.0962 0.1238 0.0958\n",
      "valid accuracy: 0.9904 0.0928 0.1168 0.1077 0.0965 0.1225 0.0927\n",
      "valid accuracy: 0.9897 0.0962 0.1131 0.1038 0.0946 0.1202 0.0924\n",
      "valid accuracy: 0.9904 0.0944 0.1143 0.1076 0.0938 0.1236 0.0931\n",
      "valid accuracy: 0.9891 0.0938 0.1115 0.1077 0.0955 0.1254 0.0926\n",
      "valid accuracy: 0.9898 0.0969 0.1144 0.1074 0.0969 0.1233 0.0934\n",
      "valid accuracy: 0.989 0.096 0.111 0.106 0.0951 0.1259 0.0942\n",
      "valid accuracy: 0.9894 0.0938 0.1146 0.1075 0.0955 0.1243 0.0916\n",
      "valid accuracy: 0.9891 0.0938 0.1146 0.1067 0.0962 0.1213 0.0943\n",
      "valid accuracy: 0.9897 0.0949 0.1137 0.1057 0.0949 0.1218 0.0931\n",
      "valid accuracy: 0.9892 0.0955 0.1133 0.1078 0.0959 0.1219 0.0928\n",
      "valid accuracy: 0.9893 0.0941 0.1127 0.1032 0.0948 0.1229 0.0927\n",
      "valid accuracy: 0.9894 0.0948 0.1109 0.1039 0.0951 0.1234 0.0907\n",
      "valid accuracy: 0.9898 0.0943 0.1124 0.1043 0.095 0.1243 0.0943\n",
      "valid accuracy: 0.99 0.0955 0.1154 0.1053 0.0953 0.1236 0.0927\n",
      "valid accuracy: 0.9894 0.0952 0.1133 0.1059 0.0978 0.1249 0.0956\n",
      "valid accuracy: 0.9893 0.0923 0.113 0.1052 0.0931 0.1241 0.0922\n",
      "valid accuracy: 0.9898 0.0922 0.1148 0.105 0.097 0.1251 0.0906\n",
      "valid accuracy: 0.9896 0.0955 0.1138 0.1059 0.0958 0.1217 0.0922\n",
      "valid accuracy: 0.9899 0.0944 0.1118 0.1046 0.0954 0.1248 0.0922\n",
      "valid accuracy: 0.9898 0.0938 0.1124 0.1089 0.0956 0.1232 0.0915\n",
      "valid accuracy: 0.9897 0.091 0.1134 0.1055 0.0957 0.122 0.0916\n",
      "valid accuracy: 0.9896 0.0941 0.1116 0.1067 0.0968 0.1219 0.0909\n",
      "valid accuracy: 0.9896 0.0916 0.1134 0.1043 0.096 0.1239 0.0928\n",
      "valid accuracy: 0.9898 0.0966 0.1107 0.1059 0.0963 0.1264 0.0932\n",
      "valid accuracy: 0.9896 0.0963 0.1128 0.1049 0.097 0.1224 0.0917\n",
      "valid accuracy: 0.9894 0.0932 0.1144 0.1055 0.0974 0.121 0.0925\n",
      "valid accuracy: 0.9904 0.0932 0.1122 0.1062 0.0952 0.1222 0.0923\n",
      "valid accuracy: 0.9896 0.096 0.1147 0.1055 0.0974 0.1248 0.0938\n",
      "valid accuracy: 0.9902 0.0976 0.113 0.1059 0.0959 0.1266 0.0926\n",
      "valid accuracy: 0.9892 0.0955 0.1122 0.1067 0.0954 0.124 0.0942\n",
      "valid accuracy: 0.9899 0.0955 0.1116 0.1083 0.0959 0.1255 0.0943\n",
      "valid accuracy: 0.9895 0.0944 0.1122 0.1058 0.0948 0.1249 0.0924\n",
      "valid accuracy: 0.9894 0.0945 0.1141 0.1046 0.0958 0.1244 0.0911\n",
      "valid accuracy: 0.9891 0.0957 0.1128 0.1038 0.0958 0.1253 0.0939\n",
      "valid accuracy: 0.9895 0.0935 0.1117 0.1086 0.0962 0.1239 0.0943\n",
      "valid accuracy: 0.9896 0.0936 0.1163 0.1047 0.0962 0.1219 0.0918\n",
      "valid accuracy: 0.9899 0.093 0.1118 0.1067 0.0961 0.1224 0.0946\n",
      "valid accuracy: 0.9897 0.0949 0.1131 0.1067 0.0961 0.1213 0.0938\n",
      "valid accuracy: 0.9892 0.0945 0.1129 0.1072 0.0984 0.1228 0.0925\n",
      "valid accuracy: 0.9899 0.0958 0.1118 0.1084 0.0984 0.1218 0.0957\n",
      "valid accuracy: 0.99 0.0937 0.1131 0.1065 0.0967 0.1239 0.0917\n",
      "valid accuracy: 0.989 0.0979 0.1126 0.1067 0.0966 0.1215 0.0925\n",
      "valid accuracy: 0.9902 0.0946 0.1135 0.1073 0.0972 0.1226 0.0921\n",
      "valid accuracy: 0.9894 0.0931 0.1143 0.1069 0.0959 0.1233 0.0906\n",
      "valid accuracy: 0.9894 0.0969 0.1148 0.107 0.0956 0.1238 0.091\n",
      "valid accuracy: 0.989 0.0954 0.1122 0.105 0.0986 0.1242 0.093\n",
      "valid accuracy: 0.9896 0.0954 0.1123 0.105 0.0989 0.12 0.091\n",
      "ep 350, batch 0, training accuracy 0.975\n",
      "ep 350, batch 50, training accuracy 0.99\n",
      "ep 350, batch 100, training accuracy 0.99\n",
      "ep 350, batch 150, training accuracy 0.99\n",
      "ep 350, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9894 0.0937 0.1169 0.1065 0.0974 0.1244 0.0932\n",
      "valid accuracy: 0.9894 0.0943 0.1113 0.109 0.0958 0.1217 0.0935\n",
      "valid accuracy: 0.9895 0.0952 0.1148 0.1068 0.0962 0.1223 0.0931\n",
      "valid accuracy: 0.9899 0.0909 0.1142 0.1062 0.095 0.1242 0.093\n",
      "valid accuracy: 0.9889 0.0927 0.1127 0.1055 0.0971 0.1235 0.094\n",
      "valid accuracy: 0.9899 0.0937 0.1135 0.1042 0.0949 0.1227 0.0929\n",
      "valid accuracy: 0.9901 0.0961 0.1138 0.1064 0.0966 0.1227 0.0922\n",
      "valid accuracy: 0.9898 0.0956 0.1151 0.1038 0.0947 0.1242 0.09\n",
      "valid accuracy: 0.9893 0.0938 0.1141 0.1075 0.0967 0.1278 0.0924\n",
      "valid accuracy: 0.99 0.0953 0.1159 0.1069 0.0955 0.1203 0.0913\n",
      "valid accuracy: 0.9898 0.0943 0.1131 0.1059 0.0963 0.123 0.091\n",
      "valid accuracy: 0.9895 0.0939 0.1153 0.1067 0.0964 0.1246 0.0922\n",
      "valid accuracy: 0.9897 0.0951 0.1142 0.103 0.0974 0.1239 0.0926\n",
      "valid accuracy: 0.9895 0.094 0.1141 0.1066 0.095 0.1227 0.0916\n",
      "valid accuracy: 0.9895 0.0952 0.1164 0.107 0.0965 0.1235 0.0919\n",
      "valid accuracy: 0.9893 0.0939 0.1111 0.1061 0.0976 0.1212 0.0906\n",
      "valid accuracy: 0.9889 0.0955 0.1128 0.1066 0.096 0.1227 0.0914\n",
      "valid accuracy: 0.9893 0.0939 0.1112 0.1068 0.0942 0.1265 0.0915\n",
      "valid accuracy: 0.99 0.0973 0.1121 0.1076 0.0956 0.1224 0.0946\n",
      "valid accuracy: 0.9893 0.0947 0.1155 0.1063 0.0973 0.123 0.0914\n",
      "valid accuracy: 0.9898 0.0931 0.114 0.1046 0.095 0.1251 0.0903\n",
      "valid accuracy: 0.9899 0.0918 0.1133 0.1064 0.0995 0.1223 0.0946\n",
      "valid accuracy: 0.9895 0.0947 0.1121 0.1075 0.0941 0.1257 0.0909\n",
      "valid accuracy: 0.9902 0.0963 0.1127 0.106 0.0953 0.1237 0.0924\n",
      "valid accuracy: 0.9903 0.0958 0.11 0.108 0.0947 0.1235 0.0906\n",
      "valid accuracy: 0.9901 0.0942 0.1148 0.1057 0.0949 0.1225 0.0931\n",
      "valid accuracy: 0.9889 0.0967 0.1098 0.1042 0.0949 0.123 0.0954\n",
      "valid accuracy: 0.9895 0.0955 0.1149 0.1068 0.0964 0.1235 0.0946\n",
      "valid accuracy: 0.9896 0.0968 0.1117 0.1081 0.0949 0.125 0.0946\n",
      "valid accuracy: 0.9893 0.0954 0.1142 0.1039 0.0951 0.1225 0.0945\n",
      "valid accuracy: 0.9902 0.0943 0.1146 0.106 0.0956 0.123 0.0918\n",
      "valid accuracy: 0.9901 0.0955 0.1114 0.1061 0.0969 0.1233 0.0935\n",
      "valid accuracy: 0.9895 0.0962 0.1135 0.1057 0.0982 0.1253 0.0921\n",
      "valid accuracy: 0.9895 0.092 0.1154 0.1067 0.0949 0.124 0.0945\n",
      "valid accuracy: 0.9893 0.0956 0.1125 0.1062 0.0973 0.1248 0.0901\n",
      "valid accuracy: 0.9898 0.0976 0.1142 0.1054 0.0971 0.1247 0.0909\n",
      "valid accuracy: 0.9902 0.0966 0.1142 0.1066 0.0961 0.1238 0.0943\n",
      "valid accuracy: 0.9899 0.0941 0.112 0.105 0.0947 0.1232 0.0927\n",
      "valid accuracy: 0.9895 0.0924 0.1125 0.108 0.0946 0.1211 0.0907\n",
      "valid accuracy: 0.9896 0.0948 0.1093 0.1055 0.0974 0.1212 0.0949\n",
      "valid accuracy: 0.9894 0.0931 0.1118 0.1072 0.096 0.1242 0.0925\n",
      "valid accuracy: 0.9898 0.0968 0.1127 0.1077 0.0956 0.1226 0.0939\n",
      "valid accuracy: 0.9891 0.0958 0.1142 0.1078 0.0938 0.1259 0.0934\n",
      "valid accuracy: 0.9891 0.0965 0.1124 0.1051 0.096 0.1249 0.0928\n",
      "valid accuracy: 0.9898 0.0923 0.1135 0.1072 0.0953 0.1227 0.0925\n",
      "valid accuracy: 0.9898 0.0937 0.1152 0.1065 0.0947 0.1239 0.0939\n",
      "valid accuracy: 0.9897 0.0936 0.1106 0.1044 0.097 0.1255 0.0924\n",
      "valid accuracy: 0.9896 0.0965 0.1154 0.1083 0.0941 0.1258 0.0932\n",
      "valid accuracy: 0.9898 0.0949 0.1126 0.1044 0.0947 0.1235 0.0929\n",
      "valid accuracy: 0.9893 0.0956 0.1123 0.1068 0.0951 0.1229 0.0942\n",
      "ep 400, batch 0, training accuracy 0.985\n",
      "ep 400, batch 50, training accuracy 0.99\n",
      "ep 400, batch 100, training accuracy 0.995\n",
      "ep 400, batch 150, training accuracy 0.985\n",
      "ep 400, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9899 0.096 0.1149 0.1057 0.0955 0.1225 0.0922\n",
      "valid accuracy: 0.9898 0.0945 0.1136 0.1029 0.0946 0.1254 0.0924\n",
      "valid accuracy: 0.99 0.0966 0.1104 0.108 0.0971 0.1246 0.0954\n",
      "valid accuracy: 0.9897 0.0953 0.1135 0.1063 0.0965 0.1236 0.0937\n",
      "valid accuracy: 0.9899 0.0955 0.1167 0.1043 0.0971 0.1214 0.0918\n",
      "valid accuracy: 0.9893 0.0934 0.1144 0.1064 0.0951 0.121 0.0943\n",
      "valid accuracy: 0.9898 0.0963 0.1131 0.1047 0.095 0.1283 0.094\n",
      "valid accuracy: 0.9891 0.0968 0.1132 0.1064 0.0965 0.1234 0.0924\n",
      "valid accuracy: 0.9895 0.0922 0.1136 0.1037 0.0951 0.1238 0.0934\n",
      "valid accuracy: 0.9894 0.0935 0.113 0.1069 0.0962 0.1221 0.0934\n",
      "valid accuracy: 0.9895 0.0912 0.1142 0.107 0.0954 0.1222 0.0905\n",
      "valid accuracy: 0.99 0.0959 0.1129 0.1063 0.0971 0.1223 0.0915\n",
      "valid accuracy: 0.9894 0.0946 0.1138 0.1065 0.0962 0.1255 0.092\n",
      "valid accuracy: 0.9897 0.0957 0.1131 0.1054 0.0976 0.1243 0.0944\n",
      "valid accuracy: 0.9893 0.0926 0.114 0.1062 0.0954 0.1218 0.0933\n",
      "valid accuracy: 0.99 0.0937 0.1138 0.1065 0.0952 0.1244 0.0955\n",
      "valid accuracy: 0.9894 0.0934 0.1119 0.108 0.0938 0.1236 0.0953\n",
      "valid accuracy: 0.9897 0.096 0.1095 0.1044 0.0964 0.1256 0.0943\n",
      "valid accuracy: 0.99 0.0954 0.11 0.109 0.0957 0.1208 0.0898\n",
      "valid accuracy: 0.9899 0.0946 0.114 0.1056 0.0973 0.1248 0.0933\n",
      "valid accuracy: 0.9902 0.0954 0.1151 0.1057 0.0935 0.1229 0.0911\n",
      "valid accuracy: 0.9892 0.0965 0.1137 0.1083 0.0955 0.1256 0.0909\n",
      "valid accuracy: 0.9898 0.095 0.1152 0.107 0.0964 0.1252 0.0928\n",
      "valid accuracy: 0.9897 0.0934 0.1128 0.104 0.0972 0.1229 0.0905\n",
      "valid accuracy: 0.9896 0.0956 0.1154 0.1059 0.098 0.1215 0.0917\n",
      "valid accuracy: 0.99 0.0956 0.1139 0.1056 0.0954 0.1208 0.0968\n",
      "valid accuracy: 0.9893 0.0945 0.1125 0.1063 0.0969 0.1215 0.0923\n",
      "valid accuracy: 0.9895 0.0935 0.1119 0.1059 0.0975 0.1227 0.0917\n",
      "valid accuracy: 0.9898 0.095 0.1114 0.1091 0.0971 0.1253 0.0943\n",
      "valid accuracy: 0.9895 0.0968 0.1135 0.1063 0.0955 0.1232 0.0935\n",
      "valid accuracy: 0.9897 0.094 0.1156 0.1062 0.095 0.1256 0.0918\n",
      "valid accuracy: 0.9903 0.0956 0.1128 0.1054 0.0964 0.1233 0.0908\n",
      "valid accuracy: 0.99 0.0946 0.1137 0.1077 0.0957 0.125 0.0899\n",
      "valid accuracy: 0.9895 0.0928 0.1125 0.104 0.0987 0.1214 0.0943\n",
      "valid accuracy: 0.9897 0.0936 0.1142 0.1082 0.0982 0.1237 0.0933\n",
      "valid accuracy: 0.9893 0.096 0.1094 0.106 0.0963 0.1234 0.0903\n",
      "valid accuracy: 0.9895 0.0956 0.1122 0.107 0.0969 0.1241 0.0923\n",
      "valid accuracy: 0.9894 0.0953 0.1109 0.105 0.0982 0.1244 0.0944\n",
      "valid accuracy: 0.9893 0.096 0.1108 0.1068 0.0955 0.121 0.0939\n",
      "valid accuracy: 0.9897 0.0968 0.1138 0.1051 0.0955 0.1235 0.0939\n",
      "valid accuracy: 0.9902 0.0941 0.1126 0.1055 0.0983 0.1257 0.0915\n",
      "valid accuracy: 0.9895 0.0966 0.1138 0.1069 0.0951 0.12 0.0936\n",
      "valid accuracy: 0.9892 0.0952 0.1127 0.107 0.0972 0.1233 0.0933\n",
      "valid accuracy: 0.9895 0.0935 0.1118 0.1069 0.0938 0.1242 0.0923\n",
      "valid accuracy: 0.9899 0.095 0.1137 0.1074 0.0957 0.1221 0.0915\n",
      "valid accuracy: 0.9894 0.0942 0.1161 0.1061 0.094 0.1242 0.093\n",
      "valid accuracy: 0.9896 0.0932 0.1139 0.1082 0.0989 0.123 0.0877\n",
      "valid accuracy: 0.9901 0.0941 0.1142 0.11 0.0964 0.1217 0.0921\n",
      "valid accuracy: 0.9898 0.0934 0.1121 0.1029 0.096 0.1255 0.0935\n",
      "valid accuracy: 0.9899 0.0943 0.1137 0.1049 0.0963 0.1229 0.0906\n",
      "ep 450, batch 0, training accuracy 0.99\n",
      "ep 450, batch 50, training accuracy 0.99\n",
      "ep 450, batch 100, training accuracy 0.99\n",
      "ep 450, batch 150, training accuracy 0.99\n",
      "ep 450, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9897 0.095 0.1152 0.1073 0.0963 0.122 0.0955\n",
      "valid accuracy: 0.9899 0.0955 0.1136 0.106 0.0953 0.1222 0.0914\n",
      "valid accuracy: 0.9896 0.0935 0.1146 0.1068 0.0964 0.1233 0.091\n",
      "valid accuracy: 0.9898 0.0952 0.1124 0.1071 0.0947 0.1242 0.0919\n",
      "valid accuracy: 0.9901 0.096 0.1116 0.1061 0.0945 0.1238 0.0931\n",
      "valid accuracy: 0.9898 0.0956 0.1125 0.1078 0.0962 0.1235 0.0909\n",
      "valid accuracy: 0.9889 0.095 0.1122 0.1065 0.0992 0.1214 0.092\n",
      "valid accuracy: 0.9897 0.0975 0.1132 0.1076 0.0959 0.1226 0.0928\n",
      "valid accuracy: 0.9892 0.095 0.114 0.1034 0.0965 0.121 0.09\n",
      "valid accuracy: 0.9896 0.0949 0.114 0.1081 0.0961 0.1226 0.093\n",
      "valid accuracy: 0.9896 0.0945 0.1153 0.107 0.0956 0.1234 0.0936\n",
      "valid accuracy: 0.9898 0.0943 0.1124 0.1055 0.0964 0.1222 0.0931\n",
      "valid accuracy: 0.989 0.0966 0.1115 0.1077 0.0955 0.1228 0.0941\n",
      "valid accuracy: 0.9898 0.097 0.1108 0.1058 0.0966 0.1259 0.0922\n",
      "valid accuracy: 0.9893 0.0939 0.1148 0.1061 0.0964 0.1239 0.0936\n",
      "valid accuracy: 0.99 0.0928 0.1135 0.1067 0.0952 0.1259 0.0952\n",
      "valid accuracy: 0.9893 0.0946 0.1127 0.1081 0.0951 0.1235 0.0916\n",
      "valid accuracy: 0.9891 0.0925 0.1135 0.1063 0.0954 0.1241 0.0895\n",
      "valid accuracy: 0.9896 0.0931 0.1129 0.1055 0.0941 0.1238 0.0922\n",
      "valid accuracy: 0.9897 0.0939 0.1145 0.1053 0.095 0.1232 0.0936\n",
      "valid accuracy: 0.9894 0.0947 0.1142 0.1083 0.0975 0.1247 0.0922\n",
      "valid accuracy: 0.9897 0.0937 0.1153 0.1088 0.0944 0.1225 0.0918\n",
      "valid accuracy: 0.9898 0.0929 0.1142 0.1074 0.0948 0.1218 0.0919\n",
      "valid accuracy: 0.9897 0.0951 0.1146 0.1059 0.0945 0.1223 0.093\n",
      "valid accuracy: 0.9898 0.0959 0.1156 0.1049 0.0963 0.1231 0.0935\n",
      "valid accuracy: 0.9896 0.0947 0.1102 0.1053 0.0967 0.1236 0.0884\n",
      "valid accuracy: 0.9893 0.0954 0.1126 0.106 0.0935 0.1234 0.0915\n",
      "valid accuracy: 0.9895 0.0975 0.1139 0.1066 0.0985 0.1262 0.0907\n",
      "valid accuracy: 0.9898 0.0949 0.1146 0.1041 0.0959 0.124 0.09\n",
      "valid accuracy: 0.9896 0.0945 0.1146 0.1034 0.0947 0.1241 0.0927\n",
      "valid accuracy: 0.9894 0.0967 0.1136 0.1069 0.0961 0.1207 0.0918\n",
      "valid accuracy: 0.9899 0.0946 0.1128 0.1054 0.0937 0.1254 0.0898\n",
      "valid accuracy: 0.99 0.0967 0.1125 0.1041 0.0954 0.1238 0.092\n",
      "valid accuracy: 0.9897 0.0965 0.1135 0.1052 0.097 0.1242 0.0944\n",
      "valid accuracy: 0.99 0.0941 0.1143 0.1077 0.0962 0.1213 0.094\n",
      "valid accuracy: 0.9898 0.0939 0.1139 0.1062 0.0961 0.122 0.0949\n",
      "valid accuracy: 0.9901 0.0939 0.1117 0.1064 0.0945 0.1256 0.092\n",
      "valid accuracy: 0.99 0.0926 0.1142 0.1053 0.095 0.1218 0.0904\n",
      "valid accuracy: 0.9892 0.0934 0.1159 0.1086 0.0957 0.1252 0.0915\n",
      "valid accuracy: 0.99 0.0932 0.1146 0.1057 0.0956 0.1229 0.0935\n",
      "valid accuracy: 0.9893 0.0942 0.1131 0.1045 0.0976 0.1227 0.0943\n",
      "valid accuracy: 0.9899 0.0946 0.1137 0.1094 0.0943 0.1237 0.0921\n",
      "valid accuracy: 0.9896 0.0959 0.1158 0.108 0.0946 0.1244 0.0902\n",
      "valid accuracy: 0.99 0.0951 0.1159 0.1046 0.0957 0.1227 0.0924\n",
      "valid accuracy: 0.9896 0.0936 0.1142 0.1034 0.0962 0.124 0.096\n",
      "valid accuracy: 0.99 0.0937 0.1111 0.1081 0.0951 0.1246 0.0924\n",
      "valid accuracy: 0.9896 0.0924 0.1137 0.1085 0.0957 0.1238 0.0937\n",
      "valid accuracy: 0.9899 0.0952 0.1135 0.1087 0.097 0.1217 0.0926\n",
      "valid accuracy: 0.9902 0.0941 0.1118 0.1068 0.0963 0.1249 0.0894\n",
      "valid accuracy: 0.9897 0.0957 0.1141 0.1066 0.095 0.1253 0.0918\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "\n",
    "valid_size = batch_size\n",
    "n_split_valid = len(t_valid) / valid_size\n",
    "\n",
    "n_epochs = 500\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "taccs_bcnn_gal = list()\n",
    "#taccs_mean = list()\n",
    "vaccs_bcnn_gal = list()\n",
    "epochs_done = list()\n",
    "\n",
    "for i in range(n_datas):\n",
    "    vaccs_bcnn_gal.append(list())\n",
    "    \n",
    "for d in range(1):\n",
    "    bcnn_gal.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "#             feed = {bcnn_gal.x: np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 28, 28, 1)), \\\n",
    "#                     bcnn_gal.t: t_train[i*batch_size:(i+1)*batch_size], \\\n",
    "#                     bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5], \\\n",
    "#                     bcnn_gal.n_samples: 1}\n",
    "            feed = {bcnn_gal.x: np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 28, 28, 1)), \\\n",
    "                    bcnn_gal.t: t_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                    bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]}\n",
    "\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bcnn_gal.MCdropout(inp = np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 28, 28, 1)), \\\n",
    "                                                   tar = t_train[i*batch_size:(i+1)*batch_size], keep_probs = [0.5, 0.5, 0.5, 0.5], \\\n",
    "                                                   n_samples = 40)                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "\n",
    "            bcnn_gal.train(feed)\n",
    "\n",
    "        if ep > 5 and np.mean(taccs_bcnn_gal[-25:]) < taccs_bcnn_gal[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bcnn_gal.get_lr()\n",
    "                bcnn_gal.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bcnn_gal.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    epochs_done.append(ep)\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "                \n",
    "        if ep == (n_epochs) - 1: epochs_done.append(ep)\n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            valid_mean = 0.\n",
    "            for j in range(n_split_valid):\n",
    "                \n",
    "                valid_mean += bcnn_gal.MCdropout(inp = np.reshape(x_valid[i][j*valid_size:(j+1)*valid_size], (-1, 28, 28, 1)), \\\n",
    "                                                tar =  t_valid[j*valid_size:(j+1)*valid_size], keep_probs = [0.5, 0.5, 0.5, 0.5], \\\n",
    "                                                n_samples = 40)\n",
    "                \n",
    "            valid_mean /= n_split_valid\n",
    "            vaccs_bcnn_gal[i].append(valid_mean)\n",
    "            str_vacc += \" {:.5g}\".format(vaccs_bcnn_gal[i][-1])\n",
    "        \n",
    "        taccs_bcnn_gal.append(train_accuracy)\n",
    "        \n",
    "        print(str_vacc)\n",
    "\n",
    "        #summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "        #                                       bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]})\n",
    "        summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "                                               bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0, batch 0, training accuracy 0.105\n",
      "ep 0, batch 50, training accuracy 0.82\n",
      "ep 0, batch 100, training accuracy 0.83\n",
      "ep 0, batch 150, training accuracy 0.9\n",
      "ep 0, batch 200, training accuracy 0.94\n",
      "valid accuracy: 0.9332 0.0963 0.0967 0.1102 0.0939 0.0933 0.0743\n",
      "valid accuracy: 0.9547 0.1049 0.0927 0.1203 0.0985 0.1107 0.0708\n",
      "valid accuracy: 0.9372 0.1046 0.1038 0.117 0.1055 0.1038 0.0864\n",
      "valid accuracy: 0.9703 0.1151 0.1018 0.1219 0.1046 0.1052 0.0805\n",
      "valid accuracy: 0.9724 0.1173 0.1083 0.1165 0.1076 0.116 0.0851\n",
      "valid accuracy: 0.9768 0.1113 0.1027 0.1179 0.1141 0.1205 0.0885\n",
      "valid accuracy: 0.9784 0.1109 0.1086 0.1165 0.1076 0.1254 0.0858\n",
      "valid accuracy: 0.9808 0.1173 0.106 0.1158 0.1139 0.1217 0.1001\n",
      "valid accuracy: 0.9784 0.1127 0.1043 0.1199 0.1147 0.1245 0.0931\n",
      "valid accuracy: 0.9812 0.0995 0.1021 0.1181 0.1108 0.1256 0.0959\n",
      "valid accuracy: 0.9831 0.1104 0.1051 0.1052 0.1119 0.1233 0.0926\n",
      "valid accuracy: 0.9827 0.107 0.1084 0.1177 0.108 0.1331 0.0945\n",
      "valid accuracy: 0.9858 0.1122 0.1077 0.1116 0.1053 0.13 0.0962\n",
      "valid accuracy: 0.9847 0.1184 0.1041 0.1135 0.1068 0.1222 0.0932\n",
      "valid accuracy: 0.9861 0.114 0.0995 0.1137 0.1135 0.1163 0.0904\n",
      "valid accuracy: 0.9863 0.1089 0.1079 0.1123 0.1097 0.1269 0.107\n",
      "valid accuracy: 0.9862 0.1053 0.1078 0.1212 0.1091 0.1288 0.0959\n",
      "valid accuracy: 0.9863 0.1117 0.1053 0.1193 0.1135 0.1227 0.0995\n",
      "valid accuracy: 0.9862 0.1121 0.1067 0.118 0.1147 0.1262 0.1016\n",
      "valid accuracy: 0.9869 0.1129 0.1035 0.117 0.1137 0.1263 0.0981\n",
      "valid accuracy: 0.9868 0.1076 0.1092 0.1179 0.1134 0.1274 0.1026\n",
      "valid accuracy: 0.9861 0.1097 0.1099 0.1208 0.1078 0.1289 0.0984\n",
      "valid accuracy: 0.9865 0.1092 0.1104 0.1229 0.1115 0.1217 0.1001\n",
      "valid accuracy: 0.9867 0.1064 0.1119 0.1182 0.1116 0.1198 0.1033\n",
      "valid accuracy: 0.9864 0.1073 0.1133 0.1164 0.1111 0.124 0.103\n",
      "valid accuracy: 0.987 0.1061 0.1088 0.121 0.1116 0.1245 0.1\n",
      "valid accuracy: 0.987 0.1146 0.114 0.123 0.1128 0.1201 0.1032\n",
      "valid accuracy: 0.9873 0.1104 0.1104 0.1268 0.1127 0.1205 0.1023\n",
      "valid accuracy: 0.9872 0.1078 0.1095 0.1229 0.1075 0.1251 0.1027\n",
      "valid accuracy: 0.9871 0.1109 0.108 0.1232 0.1145 0.1228 0.1003\n",
      "valid accuracy: 0.9882 0.1077 0.114 0.123 0.1127 0.126 0.1019\n",
      "valid accuracy: 0.9872 0.1075 0.1049 0.1206 0.1097 0.1204 0.1058\n",
      "valid accuracy: 0.988 0.1103 0.1082 0.1229 0.1103 0.1221 0.1058\n",
      "valid accuracy: 0.9868 0.1101 0.1074 0.1238 0.1158 0.1201 0.1081\n",
      "valid accuracy: 0.9889 0.1108 0.1144 0.1185 0.113 0.1237 0.102\n",
      "valid accuracy: 0.987 0.1064 0.1098 0.1235 0.1103 0.1241 0.0999\n",
      "valid accuracy: 0.9876 0.1084 0.1124 0.1229 0.1125 0.1203 0.1037\n",
      "valid accuracy: 0.9884 0.1052 0.1115 0.13 0.1117 0.1241 0.1047\n",
      "valid accuracy: 0.9864 0.1045 0.1102 0.1323 0.1108 0.1246 0.1058\n",
      "valid accuracy: 0.9878 0.1056 0.1099 0.1318 0.1104 0.1242 0.1043\n",
      "valid accuracy: 0.9869 0.1042 0.1041 0.1372 0.1141 0.1231 0.1015\n",
      "valid accuracy: 0.9881 0.1044 0.1038 0.1344 0.1115 0.1207 0.1049\n",
      "valid accuracy: 0.9881 0.1054 0.1133 0.1243 0.1113 0.1243 0.1105\n",
      "valid accuracy: 0.9872 0.105 0.1111 0.1359 0.1156 0.1209 0.1073\n",
      "valid accuracy: 0.9894 0.1061 0.1073 0.1372 0.1186 0.1263 0.1069\n",
      "valid accuracy: 0.9894 0.1048 0.1114 0.137 0.1147 0.1293 0.1093\n",
      "valid accuracy: 0.9883 0.1056 0.1142 0.1364 0.1125 0.1196 0.105\n",
      "valid accuracy: 0.9883 0.1018 0.1131 0.1332 0.1134 0.1258 0.1024\n",
      "valid accuracy: 0.9892 0.0995 0.1124 0.1263 0.1079 0.1252 0.1061\n",
      "valid accuracy: 0.9886 0.106 0.1132 0.1312 0.1104 0.1215 0.1041\n",
      "ep 50, batch 0, training accuracy 0.98\n",
      "ep 50, batch 50, training accuracy 1\n",
      "ep 50, batch 100, training accuracy 0.99\n",
      "ep 50, batch 150, training accuracy 0.985\n",
      "ep 50, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9899 0.1089 0.111 0.1375 0.1079 0.1219 0.1039\n",
      "valid accuracy: 0.9876 0.1066 0.1081 0.1324 0.1118 0.1232 0.1067\n",
      "valid accuracy: 0.9883 0.1084 0.1066 0.1256 0.1061 0.1212 0.1056\n",
      "valid accuracy: 0.9889 0.1107 0.1118 0.1332 0.1123 0.1223 0.1036\n",
      "valid accuracy: 0.9881 0.1109 0.1133 0.1273 0.1117 0.1185 0.1031\n",
      "valid accuracy: 0.9889 0.1091 0.1141 0.1334 0.1061 0.1223 0.1044\n",
      "valid accuracy: 0.9897 0.1085 0.114 0.133 0.1132 0.1204 0.1054\n",
      "valid accuracy: 0.9891 0.1103 0.1197 0.135 0.1151 0.1164 0.1078\n",
      "valid accuracy: 0.9885 0.1056 0.1102 0.1334 0.1138 0.1205 0.1025\n",
      "valid accuracy: 0.9896 0.1062 0.1177 0.1339 0.1113 0.12 0.104\n",
      "valid accuracy: 0.9889 0.1055 0.1114 0.1379 0.1135 0.1247 0.1091\n",
      "valid accuracy: 0.9886 0.1051 0.1153 0.1312 0.1079 0.1215 0.1101\n",
      "valid accuracy: 0.9893 0.1053 0.1167 0.1303 0.1132 0.1205 0.1061\n",
      "valid accuracy: 0.9895 0.1053 0.1172 0.1363 0.1107 0.1237 0.1045\n",
      "valid accuracy: 0.989 0.1072 0.113 0.1356 0.1134 0.1181 0.1048\n",
      "valid accuracy: 0.9892 0.1037 0.1153 0.1371 0.1124 0.1202 0.1043\n",
      "valid accuracy: 0.9887 0.1074 0.1118 0.1345 0.1142 0.1236 0.1057\n",
      "valid accuracy: 0.9893 0.1031 0.1123 0.1383 0.1124 0.1204 0.1086\n",
      "valid accuracy: 0.9891 0.1082 0.1172 0.1326 0.1149 0.126 0.1082\n",
      "valid accuracy: 0.9893 0.1015 0.1135 0.1386 0.112 0.126 0.1047\n",
      "valid accuracy: 0.9891 0.1096 0.1161 0.137 0.1106 0.1243 0.1059\n",
      "valid accuracy: 0.9897 0.1066 0.1134 0.1335 0.1128 0.1236 0.1043\n",
      "valid accuracy: 0.9899 0.1056 0.1149 0.1369 0.1112 0.1208 0.1074\n",
      "valid accuracy: 0.9899 0.1059 0.1153 0.1313 0.1089 0.1227 0.1085\n",
      "valid accuracy: 0.9899 0.1083 0.1151 0.1412 0.1108 0.123 0.1099\n",
      "valid accuracy: 0.9883 0.1078 0.1143 0.1366 0.1144 0.12 0.1115\n",
      "valid accuracy: 0.9887 0.1053 0.1113 0.1346 0.109 0.1221 0.1068\n",
      "valid accuracy: 0.9895 0.1045 0.1157 0.1341 0.1137 0.1206 0.1054\n",
      "valid accuracy: 0.9889 0.1024 0.1147 0.1352 0.1106 0.1251 0.105\n",
      "valid accuracy: 0.9899 0.1041 0.1134 0.1375 0.1101 0.1226 0.1096\n",
      "valid accuracy: 0.989 0.1065 0.1166 0.1343 0.114 0.1234 0.1084\n",
      "valid accuracy: 0.9892 0.1052 0.114 0.1356 0.1101 0.1258 0.105\n",
      "valid accuracy: 0.9896 0.1029 0.1129 0.1364 0.1103 0.1163 0.1072\n",
      "valid accuracy: 0.9884 0.1081 0.1155 0.1342 0.1106 0.1145 0.1025\n",
      "valid accuracy: 0.9891 0.1095 0.114 0.1379 0.1125 0.1222 0.1079\n",
      "valid accuracy: 0.9891 0.1024 0.1127 0.1364 0.1109 0.1248 0.1058\n",
      "valid accuracy: 0.9886 0.1049 0.1156 0.1334 0.1111 0.1227 0.1068\n",
      "valid accuracy: 0.99 0.1053 0.1131 0.1352 0.113 0.1237 0.1063\n",
      "valid accuracy: 0.9887 0.1074 0.1123 0.1356 0.107 0.1243 0.1052\n",
      "valid accuracy: 0.9896 0.1035 0.1151 0.1371 0.1121 0.1224 0.1046\n",
      "valid accuracy: 0.9886 0.106 0.1105 0.1334 0.1113 0.1255 0.107\n",
      "valid accuracy: 0.9901 0.1068 0.1173 0.1354 0.1075 0.1211 0.1081\n",
      "valid accuracy: 0.9888 0.1062 0.117 0.1384 0.1082 0.1231 0.1095\n",
      "valid accuracy: 0.9901 0.1023 0.1125 0.1363 0.1163 0.1247 0.1055\n",
      "valid accuracy: 0.989 0.1109 0.1144 0.1337 0.108 0.1218 0.1097\n",
      "valid accuracy: 0.9887 0.1065 0.1115 0.1337 0.1096 0.118 0.1098\n",
      "valid accuracy: 0.9891 0.1061 0.1087 0.1324 0.1111 0.12 0.1069\n",
      "valid accuracy: 0.9893 0.1103 0.1114 0.1354 0.1083 0.1234 0.1024\n",
      "valid accuracy: 0.9892 0.1024 0.1154 0.1378 0.1123 0.1183 0.1021\n",
      "valid accuracy: 0.9895 0.1069 0.1138 0.1371 0.1088 0.1283 0.1039\n",
      "ep 100, batch 0, training accuracy 0.985\n",
      "ep 100, batch 50, training accuracy 0.995\n",
      "ep 100, batch 100, training accuracy 1\n",
      "ep 100, batch 150, training accuracy 0.99\n",
      "ep 100, batch 200, training accuracy 0.995\n",
      "valid accuracy: 0.9896 0.1058 0.1131 0.1371 0.1113 0.1197 0.1082\n",
      "valid accuracy: 0.989 0.1094 0.1098 0.1378 0.1133 0.1236 0.1062\n",
      "valid accuracy: 0.9889 0.1061 0.1152 0.1341 0.1102 0.1232 0.105\n",
      "valid accuracy: 0.9889 0.1055 0.1121 0.1335 0.1147 0.1236 0.1077\n",
      "valid accuracy: 0.9893 0.107 0.1141 0.135 0.1076 0.1214 0.1043\n",
      "valid accuracy: 0.9898 0.104 0.1125 0.1367 0.113 0.1213 0.1062\n",
      "valid accuracy: 0.9891 0.1059 0.1156 0.1388 0.1105 0.1246 0.1069\n",
      "valid accuracy: 0.9895 0.1054 0.1147 0.1388 0.1107 0.1272 0.1097\n",
      "valid accuracy: 0.9899 0.1065 0.1103 0.1381 0.1104 0.1231 0.1056\n",
      "valid accuracy: 0.9897 0.1074 0.1176 0.1382 0.11 0.1215 0.1088\n",
      "valid accuracy: 0.9898 0.1053 0.1105 0.1284 0.1093 0.1263 0.1045\n",
      "valid accuracy: 0.9891 0.1041 0.1133 0.1316 0.108 0.1236 0.1112\n",
      "valid accuracy: 0.9892 0.106 0.1158 0.1363 0.1153 0.1231 0.1031\n",
      "valid accuracy: 0.9892 0.1056 0.1127 0.1367 0.109 0.1213 0.1026\n",
      "valid accuracy: 0.9895 0.112 0.1146 0.1363 0.1137 0.1223 0.1095\n",
      "valid accuracy: 0.9896 0.1068 0.116 0.1322 0.1127 0.122 0.1045\n",
      "valid accuracy: 0.989 0.1071 0.1126 0.1362 0.1073 0.1232 0.1079\n",
      "valid accuracy: 0.9897 0.1033 0.1119 0.1333 0.1124 0.1225 0.1035\n",
      "valid accuracy: 0.9894 0.1086 0.1159 0.1345 0.113 0.1243 0.1068\n",
      "valid accuracy: 0.9892 0.1069 0.1155 0.1342 0.113 0.1225 0.1074\n",
      "valid accuracy: 0.9886 0.1056 0.1128 0.1378 0.1167 0.123 0.1073\n",
      "valid accuracy: 0.9892 0.1057 0.1117 0.1336 0.1135 0.1232 0.1112\n",
      "valid accuracy: 0.9888 0.1063 0.1166 0.1393 0.1115 0.1227 0.1045\n",
      "valid accuracy: 0.9894 0.1022 0.1135 0.1373 0.1127 0.1242 0.1043\n",
      "valid accuracy: 0.9893 0.1057 0.1145 0.1379 0.1142 0.1254 0.1092\n",
      "valid accuracy: 0.9894 0.1096 0.1113 0.1313 0.111 0.1193 0.1064\n",
      "valid accuracy: 0.9891 0.1061 0.117 0.1346 0.109 0.1217 0.1053\n",
      "valid accuracy: 0.9897 0.1043 0.1177 0.1323 0.1135 0.1255 0.1086\n",
      "valid accuracy: 0.99 0.1057 0.1121 0.1326 0.1118 0.1191 0.1071\n",
      "valid accuracy: 0.9894 0.1091 0.1086 0.135 0.1103 0.1205 0.1035\n",
      "valid accuracy: 0.9886 0.1076 0.1147 0.1326 0.1096 0.1272 0.1034\n",
      "valid accuracy: 0.9886 0.1043 0.1164 0.1354 0.115 0.1203 0.1064\n",
      "valid accuracy: 0.989 0.1054 0.1151 0.1347 0.1157 0.1246 0.1078\n",
      "valid accuracy: 0.9891 0.1078 0.1128 0.1351 0.1126 0.1209 0.1092\n",
      "valid accuracy: 0.9892 0.1096 0.11 0.1342 0.1113 0.1188 0.1047\n",
      "valid accuracy: 0.99 0.1065 0.1127 0.1318 0.113 0.1203 0.1053\n",
      "valid accuracy: 0.9889 0.1071 0.1127 0.1365 0.1128 0.1237 0.1073\n",
      "valid accuracy: 0.9889 0.1069 0.1124 0.1314 0.1089 0.1258 0.1085\n",
      "valid accuracy: 0.9895 0.106 0.1159 0.1342 0.1101 0.1185 0.1107\n",
      "valid accuracy: 0.9894 0.1072 0.119 0.1342 0.1151 0.1239 0.1114\n",
      "valid accuracy: 0.9891 0.1085 0.1125 0.1365 0.1122 0.1212 0.1077\n",
      "valid accuracy: 0.9893 0.1053 0.1102 0.1303 0.1149 0.1203 0.1048\n",
      "valid accuracy: 0.9897 0.1101 0.1146 0.1346 0.1125 0.1202 0.1096\n",
      "valid accuracy: 0.989 0.1059 0.1152 0.138 0.1085 0.1289 0.1097\n",
      "valid accuracy: 0.9896 0.1032 0.1162 0.1371 0.1069 0.1209 0.1067\n",
      "valid accuracy: 0.9895 0.1089 0.1131 0.1353 0.1084 0.1213 0.105\n",
      "valid accuracy: 0.9891 0.1038 0.1175 0.1346 0.1137 0.1214 0.1094\n",
      "valid accuracy: 0.9895 0.1075 0.1152 0.1364 0.1105 0.1201 0.1098\n",
      "valid accuracy: 0.9893 0.1047 0.1145 0.1328 0.1138 0.1187 0.1104\n",
      "valid accuracy: 0.9887 0.104 0.1172 0.1388 0.11 0.1234 0.1092\n",
      "ep 150, batch 0, training accuracy 0.985\n",
      "ep 150, batch 50, training accuracy 0.995\n",
      "ep 150, batch 100, training accuracy 0.99\n",
      "ep 150, batch 150, training accuracy 0.985\n",
      "ep 150, batch 200, training accuracy 0.99\n",
      "valid accuracy: 0.9895 0.1082 0.1165 0.1341 0.1097 0.1236 0.107\n",
      "valid accuracy: 0.9888 0.1044 0.1157 0.1339 0.113 0.1227 0.1078\n",
      "valid accuracy: 0.9896 0.1042 0.1141 0.1323 0.1161 0.124 0.1053\n",
      "valid accuracy: 0.9897 0.1075 0.1132 0.1372 0.1079 0.1238 0.1041\n",
      "valid accuracy: 0.9897 0.1042 0.1109 0.1362 0.1122 0.1206 0.1099\n",
      "valid accuracy: 0.9886 0.1023 0.1171 0.1399 0.1092 0.1221 0.1082\n",
      "valid accuracy: 0.9894 0.1056 0.1132 0.1379 0.1135 0.1237 0.1059\n",
      "valid accuracy: 0.9893 0.1096 0.1176 0.1378 0.114 0.1274 0.1046\n",
      "valid accuracy: 0.9888 0.105 0.1105 0.1343 0.1142 0.1227 0.1073\n",
      "valid accuracy: 0.9897 0.1078 0.1149 0.1339 0.1116 0.1274 0.1056\n",
      "valid accuracy: 0.9892 0.1061 0.1149 0.1358 0.1091 0.1205 0.1071\n",
      "valid accuracy: 0.9892 0.1071 0.114 0.1373 0.1082 0.1205 0.1046\n",
      "valid accuracy: 0.9889 0.107 0.1107 0.1391 0.1138 0.1264 0.1088\n",
      "valid accuracy: 0.9888 0.1047 0.113 0.1405 0.1104 0.1219 0.1046\n",
      "valid accuracy: 0.9887 0.1062 0.1166 0.1373 0.1079 0.1183 0.1044\n",
      "valid accuracy: 0.9892 0.1059 0.111 0.1323 0.1163 0.1236 0.1088\n",
      "valid accuracy: 0.9894 0.1076 0.1172 0.1341 0.113 0.1237 0.105\n",
      "valid accuracy: 0.9884 0.1056 0.1126 0.1357 0.1136 0.1247 0.1039\n",
      "valid accuracy: 0.9896 0.1058 0.114 0.1347 0.1121 0.123 0.1057\n",
      "valid accuracy: 0.9894 0.1081 0.1123 0.1369 0.1117 0.124 0.1099\n",
      "valid accuracy: 0.9896 0.103 0.1128 0.1335 0.1146 0.1275 0.1052\n",
      "valid accuracy: 0.9891 0.1057 0.1159 0.1372 0.1099 0.1239 0.1057\n",
      "valid accuracy: 0.9889 0.1087 0.1178 0.1351 0.1098 0.1189 0.1063\n",
      "valid accuracy: 0.9884 0.1009 0.1133 0.1359 0.1184 0.1238 0.1113\n",
      "valid accuracy: 0.9898 0.1057 0.1148 0.1363 0.1119 0.1227 0.1019\n",
      "valid accuracy: 0.9891 0.1067 0.1143 0.1399 0.1116 0.1217 0.1072\n",
      "valid accuracy: 0.9895 0.1072 0.1129 0.1381 0.1121 0.1191 0.1055\n",
      "valid accuracy: 0.99 0.1082 0.1131 0.1349 0.1129 0.1218 0.1079\n",
      "valid accuracy: 0.9884 0.1032 0.1185 0.1326 0.1082 0.1265 0.1089\n",
      "valid accuracy: 0.9885 0.1034 0.113 0.1366 0.1133 0.1194 0.1058\n",
      "valid accuracy: 0.9892 0.1076 0.1166 0.135 0.1059 0.1248 0.1082\n",
      "valid accuracy: 0.989 0.1055 0.1139 0.1337 0.1126 0.1229 0.1048\n",
      "valid accuracy: 0.9898 0.1014 0.1121 0.1378 0.1124 0.1235 0.1071\n",
      "valid accuracy: 0.9897 0.1057 0.1129 0.1362 0.1098 0.1253 0.1081\n",
      "valid accuracy: 0.9892 0.1062 0.1112 0.1357 0.1084 0.1233 0.106\n",
      "valid accuracy: 0.989 0.1017 0.112 0.1413 0.1109 0.1192 0.1076\n",
      "valid accuracy: 0.9896 0.1066 0.1157 0.1379 0.1108 0.121 0.1087\n",
      "valid accuracy: 0.9895 0.105 0.115 0.1338 0.1098 0.121 0.1041\n",
      "valid accuracy: 0.9892 0.1029 0.1132 0.1323 0.1101 0.1238 0.11\n",
      "valid accuracy: 0.9892 0.105 0.112 0.1365 0.1117 0.1196 0.1057\n",
      "valid accuracy: 0.9892 0.1041 0.1126 0.1359 0.1127 0.1233 0.1063\n",
      "valid accuracy: 0.9891 0.1043 0.1148 0.1369 0.1117 0.1213 0.108\n",
      "valid accuracy: 0.99 0.1046 0.113 0.1339 0.1081 0.1221 0.107\n",
      "valid accuracy: 0.9899 0.1025 0.1172 0.1323 0.1095 0.1222 0.1108\n",
      "valid accuracy: 0.9897 0.1073 0.1112 0.1357 0.1114 0.1195 0.1061\n",
      "valid accuracy: 0.99 0.1084 0.1135 0.1412 0.1117 0.1266 0.1116\n",
      "valid accuracy: 0.9891 0.1028 0.1116 0.1365 0.1062 0.1222 0.1034\n",
      "valid accuracy: 0.9891 0.1051 0.1151 0.1382 0.1155 0.1257 0.1066\n",
      "valid accuracy: 0.9903 0.1026 0.1142 0.1391 0.1059 0.1261 0.1101\n",
      "valid accuracy: 0.9897 0.1061 0.114 0.1382 0.1161 0.1299 0.1084\n",
      "ep 200, batch 0, training accuracy 0.985\n",
      "ep 200, batch 50, training accuracy 0.995\n",
      "ep 200, batch 100, training accuracy 0.995\n",
      "ep 200, batch 150, training accuracy 0.99\n",
      "ep 200, batch 200, training accuracy 0.99\n",
      "valid accuracy: 0.9896 0.1078 0.1154 0.1351 0.1075 0.1224 0.1115\n",
      "valid accuracy: 0.9891 0.1027 0.1138 0.1376 0.1106 0.1194 0.1026\n",
      "valid accuracy: 0.989 0.1068 0.1203 0.1362 0.1116 0.1259 0.1094\n",
      "valid accuracy: 0.9898 0.1026 0.1164 0.1352 0.1135 0.1227 0.1076\n",
      "valid accuracy: 0.99 0.1075 0.1099 0.1404 0.1141 0.1233 0.1061\n",
      "valid accuracy: 0.9889 0.1055 0.1165 0.1337 0.109 0.1237 0.1078\n",
      "valid accuracy: 0.9889 0.1078 0.1169 0.1379 0.1137 0.1244 0.1076\n",
      "valid accuracy: 0.9891 0.1058 0.117 0.1361 0.111 0.1228 0.1053\n",
      "valid accuracy: 0.9892 0.1032 0.1096 0.1332 0.1109 0.1213 0.1087\n",
      "valid accuracy: 0.989 0.1036 0.1113 0.1382 0.1159 0.1244 0.1068\n",
      "valid accuracy: 0.99 0.1054 0.1069 0.1388 0.1161 0.1214 0.1055\n",
      "valid accuracy: 0.9899 0.1042 0.1162 0.1384 0.1134 0.1215 0.1096\n",
      "valid accuracy: 0.9891 0.1028 0.1138 0.131 0.1141 0.1238 0.1062\n",
      "valid accuracy: 0.9889 0.1024 0.1158 0.1348 0.1083 0.1219 0.1072\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.09\n",
      "ep 0, batch 50, training accuracy 0.315\n",
      "ep 0, batch 100, training accuracy 0.505\n",
      "ep 0, batch 150, training accuracy 0.545\n",
      "ep 0, batch 200, training accuracy 0.705\n",
      "valid accuracy: 0.7735 0.7196 0.1239 0.1344 0.1246 0.1292 0.0978\n",
      "valid accuracy: 0.7168 0.8139 0.1211 0.1334 0.1009 0.1345 0.0948\n",
      "valid accuracy: 0.6326 0.865 0.1188 0.1298 0.1001 0.1301 0.0894\n",
      "valid accuracy: 0.5675 0.8653 0.1078 0.1365 0.0997 0.1335 0.0905\n",
      "valid accuracy: 0.5716 0.8879 0.1111 0.1283 0.0977 0.1165 0.0982\n",
      "valid accuracy: 0.5258 0.8974 0.1056 0.132 0.105 0.1243 0.1007\n",
      "valid accuracy: 0.5329 0.8957 0.1006 0.1329 0.1003 0.1196 0.091\n",
      "valid accuracy: 0.5171 0.9085 0.1127 0.1282 0.1004 0.1213 0.0985\n",
      "valid accuracy: 0.4958 0.9108 0.106 0.1292 0.1021 0.1141 0.105\n",
      "valid accuracy: 0.4969 0.9134 0.104 0.1254 0.1025 0.1039 0.1157\n",
      "valid accuracy: 0.511 0.9117 0.1076 0.1317 0.1156 0.1068 0.0951\n",
      "valid accuracy: 0.521 0.9184 0.1059 0.1267 0.1119 0.1039 0.106\n",
      "valid accuracy: 0.472 0.9211 0.093 0.1277 0.1047 0.0959 0.1036\n",
      "valid accuracy: 0.488 0.9212 0.0995 0.1313 0.1032 0.1033 0.1095\n",
      "valid accuracy: 0.4798 0.9277 0.0943 0.1286 0.1068 0.1004 0.1145\n",
      "valid accuracy: 0.4135 0.926 0.0975 0.1245 0.0981 0.0992 0.1073\n",
      "valid accuracy: 0.4427 0.9269 0.1002 0.1264 0.1042 0.1039 0.0978\n",
      "valid accuracy: 0.4056 0.9291 0.1052 0.1159 0.1065 0.1009 0.1045\n",
      "valid accuracy: 0.4408 0.9294 0.0998 0.13 0.1061 0.1081 0.1015\n",
      "valid accuracy: 0.4201 0.9361 0.1001 0.1221 0.1076 0.1052 0.0951\n",
      "valid accuracy: 0.3937 0.9303 0.0923 0.1273 0.1058 0.1062 0.0986\n",
      "valid accuracy: 0.3959 0.9349 0.0983 0.1266 0.107 0.1188 0.1006\n",
      "valid accuracy: 0.4165 0.936 0.1018 0.1235 0.1069 0.1065 0.0935\n",
      "valid accuracy: 0.4207 0.9334 0.1022 0.1225 0.1014 0.0986 0.0938\n",
      "valid accuracy: 0.4246 0.9363 0.0992 0.1251 0.095 0.1037 0.0897\n",
      "valid accuracy: 0.4335 0.9378 0.1008 0.13 0.111 0.1079 0.1097\n",
      "valid accuracy: 0.4006 0.9381 0.1008 0.1239 0.1075 0.0988 0.0903\n",
      "valid accuracy: 0.3968 0.9403 0.093 0.1232 0.0987 0.1029 0.0814\n",
      "valid accuracy: 0.3922 0.9385 0.093 0.1225 0.1126 0.1076 0.0847\n",
      "valid accuracy: 0.3809 0.9425 0.0996 0.1167 0.0991 0.1049 0.0874\n",
      "valid accuracy: 0.3751 0.944 0.1039 0.12 0.106 0.1025 0.0881\n",
      "valid accuracy: 0.3464 0.9452 0.1008 0.1193 0.1052 0.0943 0.0916\n",
      "valid accuracy: 0.3699 0.9393 0.0957 0.1227 0.1026 0.1094 0.0829\n",
      "valid accuracy: 0.374 0.9464 0.0954 0.1209 0.1068 0.0989 0.0861\n",
      "valid accuracy: 0.3685 0.9458 0.0983 0.1136 0.1036 0.1037 0.0868\n",
      "valid accuracy: 0.3857 0.9447 0.1013 0.1211 0.1094 0.1051 0.088\n",
      "valid accuracy: 0.3857 0.9476 0.1001 0.1158 0.102 0.1005 0.0846\n",
      "valid accuracy: 0.3739 0.946 0.093 0.121 0.1096 0.1029 0.084\n",
      "valid accuracy: 0.3809 0.9463 0.0966 0.1276 0.1044 0.1057 0.0848\n",
      "valid accuracy: 0.3853 0.9462 0.097 0.1215 0.1025 0.1005 0.0885\n",
      "valid accuracy: 0.371 0.9456 0.0964 0.1245 0.1005 0.1039 0.0884\n",
      "valid accuracy: 0.3727 0.9439 0.0977 0.1212 0.1026 0.1025 0.0895\n",
      "valid accuracy: 0.3746 0.9459 0.0989 0.121 0.1018 0.1025 0.0869\n",
      "valid accuracy: 0.3769 0.9458 0.0993 0.1227 0.1071 0.1003 0.0855\n",
      "valid accuracy: 0.3743 0.9481 0.0962 0.1208 0.1002 0.101 0.0886\n",
      "valid accuracy: 0.3778 0.9484 0.0973 0.1226 0.1007 0.1024 0.0874\n",
      "valid accuracy: 0.3701 0.9453 0.0961 0.1195 0.1058 0.1023 0.0878\n",
      "valid accuracy: 0.3722 0.9473 0.0959 0.1174 0.1037 0.1028 0.0856\n",
      "valid accuracy: 0.3743 0.9479 0.0972 0.123 0.1017 0.0991 0.0823\n",
      "valid accuracy: 0.3727 0.9463 0.1 0.1257 0.1009 0.1036 0.0893\n",
      "ep 50, batch 0, training accuracy 0.935\n",
      "ep 50, batch 50, training accuracy 0.96\n",
      "ep 50, batch 100, training accuracy 0.94\n",
      "ep 50, batch 150, training accuracy 0.935\n",
      "ep 50, batch 200, training accuracy 0.97\n",
      "valid accuracy: 0.3724 0.9477 0.0989 0.1234 0.1025 0.1001 0.0892\n",
      "valid accuracy: 0.3782 0.9484 0.1008 0.117 0.0972 0.1021 0.084\n",
      "valid accuracy: 0.3776 0.9475 0.0988 0.123 0.1025 0.1041 0.0884\n",
      "valid accuracy: 0.3725 0.9462 0.1005 0.122 0.1022 0.0973 0.0886\n",
      "valid accuracy: 0.3782 0.9453 0.1012 0.1226 0.1053 0.0971 0.0881\n",
      "valid accuracy: 0.379 0.9473 0.0995 0.1239 0.1052 0.1012 0.0872\n",
      "valid accuracy: 0.3793 0.9479 0.0979 0.1187 0.1042 0.1011 0.088\n",
      "valid accuracy: 0.3772 0.9483 0.0986 0.1224 0.1034 0.0959 0.0837\n",
      "valid accuracy: 0.3713 0.9445 0.0996 0.1231 0.1079 0.1014 0.0858\n",
      "valid accuracy: 0.3753 0.9474 0.0938 0.121 0.1044 0.1025 0.0865\n",
      "valid accuracy: 0.3725 0.9455 0.1003 0.1235 0.1037 0.0993 0.0858\n",
      "valid accuracy: 0.3747 0.9483 0.1002 0.1212 0.102 0.0997 0.0858\n",
      "valid accuracy: 0.3748 0.9482 0.1011 0.1261 0.1023 0.0995 0.0869\n",
      "valid accuracy: 0.3795 0.9452 0.0991 0.1252 0.1001 0.1032 0.0868\n",
      "valid accuracy: 0.3804 0.9476 0.098 0.1166 0.1046 0.0994 0.0851\n",
      "valid accuracy: 0.3749 0.9494 0.0969 0.1196 0.103 0.1039 0.0848\n",
      "valid accuracy: 0.3697 0.9485 0.1033 0.1176 0.1027 0.103 0.086\n",
      "valid accuracy: 0.3816 0.9451 0.0991 0.1223 0.1078 0.1011 0.0862\n",
      "valid accuracy: 0.379 0.9475 0.1029 0.1232 0.1022 0.1026 0.0866\n",
      "valid accuracy: 0.3687 0.9481 0.0984 0.118 0.1054 0.1046 0.0902\n",
      "valid accuracy: 0.3727 0.9475 0.0977 0.1244 0.1081 0.0981 0.0884\n",
      "valid accuracy: 0.3797 0.9491 0.1016 0.1223 0.1036 0.1001 0.0846\n",
      "valid accuracy: 0.376 0.9457 0.0961 0.1232 0.1007 0.1013 0.085\n",
      "valid accuracy: 0.3741 0.945 0.0989 0.1221 0.1032 0.0984 0.0868\n",
      "valid accuracy: 0.3748 0.9482 0.0953 0.1229 0.1036 0.1005 0.0843\n",
      "valid accuracy: 0.3761 0.9438 0.0982 0.1222 0.1064 0.1013 0.0853\n",
      "valid accuracy: 0.3758 0.9478 0.1003 0.1205 0.1077 0.0991 0.086\n",
      "valid accuracy: 0.3732 0.9472 0.096 0.1219 0.1044 0.1034 0.0887\n",
      "valid accuracy: 0.374 0.9471 0.0999 0.1249 0.1062 0.101 0.0877\n",
      "valid accuracy: 0.3752 0.946 0.1007 0.125 0.1037 0.1016 0.0845\n",
      "valid accuracy: 0.3778 0.948 0.0962 0.1215 0.1023 0.101 0.0861\n",
      "valid accuracy: 0.3772 0.9467 0.0996 0.1202 0.1041 0.1022 0.0874\n",
      "valid accuracy: 0.3752 0.9499 0.1001 0.121 0.1087 0.1013 0.0884\n",
      "valid accuracy: 0.3691 0.9454 0.093 0.1193 0.0997 0.1014 0.0896\n",
      "valid accuracy: 0.3849 0.9459 0.0953 0.1152 0.1049 0.1033 0.0831\n",
      "valid accuracy: 0.3742 0.946 0.098 0.1236 0.1027 0.1032 0.0864\n",
      "valid accuracy: 0.3811 0.9483 0.0967 0.1226 0.1058 0.0997 0.0888\n",
      "valid accuracy: 0.3771 0.9467 0.0983 0.1161 0.1042 0.1058 0.0853\n",
      "valid accuracy: 0.3777 0.9479 0.0939 0.1197 0.1011 0.1021 0.086\n",
      "valid accuracy: 0.3785 0.9464 0.0998 0.1203 0.1031 0.102 0.0875\n",
      "valid accuracy: 0.378 0.9485 0.097 0.1226 0.101 0.1005 0.0815\n",
      "valid accuracy: 0.3757 0.9473 0.1012 0.124 0.1027 0.0995 0.0899\n",
      "valid accuracy: 0.3797 0.9467 0.1035 0.1232 0.103 0.1033 0.0846\n",
      "valid accuracy: 0.3683 0.9459 0.1021 0.1216 0.099 0.0989 0.086\n",
      "valid accuracy: 0.3718 0.9469 0.1018 0.1213 0.1026 0.0988 0.0882\n",
      "valid accuracy: 0.3759 0.9455 0.0976 0.1209 0.1057 0.0947 0.0862\n",
      "valid accuracy: 0.3778 0.9463 0.0996 0.1197 0.1058 0.1009 0.0844\n",
      "valid accuracy: 0.3764 0.9491 0.1001 0.1231 0.1017 0.0999 0.0895\n",
      "valid accuracy: 0.3762 0.9464 0.0989 0.1181 0.1037 0.1041 0.0869\n",
      "valid accuracy: 0.3825 0.9464 0.0968 0.1199 0.1051 0.1 0.0875\n",
      "ep 100, batch 0, training accuracy 0.945\n",
      "ep 100, batch 50, training accuracy 0.96\n",
      "ep 100, batch 100, training accuracy 0.925\n",
      "ep 100, batch 150, training accuracy 0.915\n",
      "ep 100, batch 200, training accuracy 0.955\n",
      "valid accuracy: 0.3754 0.946 0.0962 0.1221 0.1062 0.1005 0.0906\n",
      "valid accuracy: 0.3765 0.947 0.1011 0.122 0.1046 0.1013 0.0857\n",
      "valid accuracy: 0.3786 0.9466 0.1007 0.1209 0.1052 0.0971 0.0872\n",
      "valid accuracy: 0.3758 0.9468 0.0981 0.1194 0.1051 0.104 0.0867\n",
      "valid accuracy: 0.3776 0.9455 0.0962 0.1237 0.1039 0.1003 0.0863\n",
      "valid accuracy: 0.3715 0.9463 0.0961 0.123 0.1075 0.1014 0.0843\n",
      "valid accuracy: 0.3763 0.9454 0.0967 0.1227 0.1056 0.1005 0.086\n",
      "valid accuracy: 0.373 0.9486 0.0981 0.1234 0.1107 0.1016 0.0846\n",
      "valid accuracy: 0.3738 0.9484 0.0955 0.1222 0.1052 0.1018 0.0835\n",
      "valid accuracy: 0.37 0.9457 0.0985 0.1235 0.101 0.1009 0.0834\n",
      "valid accuracy: 0.3771 0.9465 0.0966 0.1216 0.1027 0.102 0.0874\n",
      "valid accuracy: 0.3742 0.9475 0.0958 0.1241 0.105 0.0997 0.0885\n",
      "valid accuracy: 0.3766 0.9463 0.1012 0.1217 0.1031 0.1005 0.089\n",
      "valid accuracy: 0.3705 0.9479 0.0952 0.1195 0.1031 0.0996 0.0905\n",
      "valid accuracy: 0.3771 0.9477 0.0977 0.1229 0.1005 0.101 0.0869\n",
      "valid accuracy: 0.3768 0.9473 0.097 0.1203 0.1048 0.1062 0.0869\n",
      "valid accuracy: 0.3779 0.9479 0.0976 0.1224 0.1064 0.0998 0.087\n",
      "valid accuracy: 0.3825 0.9468 0.1002 0.1302 0.1065 0.0978 0.0878\n",
      "valid accuracy: 0.3793 0.9492 0.0982 0.1197 0.1072 0.1043 0.0846\n",
      "valid accuracy: 0.3708 0.9475 0.098 0.1214 0.1003 0.1002 0.0834\n",
      "valid accuracy: 0.3748 0.9464 0.0978 0.1202 0.1049 0.1006 0.0856\n",
      "valid accuracy: 0.3812 0.9467 0.0961 0.1214 0.1036 0.0991 0.0874\n",
      "valid accuracy: 0.3728 0.9472 0.0958 0.1237 0.104 0.1015 0.0909\n",
      "valid accuracy: 0.3828 0.9494 0.0998 0.1248 0.1021 0.1008 0.0865\n",
      "valid accuracy: 0.3796 0.9463 0.1008 0.1221 0.1068 0.0999 0.0837\n",
      "valid accuracy: 0.3737 0.9445 0.0932 0.1216 0.1045 0.1012 0.0867\n",
      "valid accuracy: 0.3818 0.9472 0.0993 0.1223 0.1083 0.0963 0.0854\n",
      "valid accuracy: 0.3713 0.9477 0.1003 0.1252 0.1037 0.1017 0.0868\n",
      "valid accuracy: 0.3755 0.9486 0.0967 0.1251 0.0993 0.0986 0.087\n",
      "valid accuracy: 0.3757 0.9494 0.0982 0.1237 0.106 0.0994 0.0857\n",
      "valid accuracy: 0.3742 0.9467 0.1016 0.1233 0.1037 0.0992 0.084\n",
      "valid accuracy: 0.3784 0.9473 0.1019 0.1243 0.1028 0.1019 0.0835\n",
      "valid accuracy: 0.3718 0.9448 0.098 0.1192 0.1032 0.0967 0.0897\n",
      "valid accuracy: 0.3808 0.9455 0.0984 0.123 0.1032 0.0998 0.0856\n",
      "valid accuracy: 0.3757 0.9468 0.0984 0.1221 0.1012 0.1015 0.0851\n",
      "valid accuracy: 0.3742 0.9462 0.1005 0.123 0.1045 0.1029 0.0861\n",
      "valid accuracy: 0.3748 0.9471 0.1012 0.1252 0.1046 0.101 0.0872\n",
      "valid accuracy: 0.3786 0.9489 0.1007 0.1223 0.1051 0.1007 0.0814\n",
      "valid accuracy: 0.3798 0.9463 0.099 0.1226 0.1063 0.1005 0.0873\n",
      "valid accuracy: 0.3792 0.9467 0.0974 0.1205 0.1005 0.1 0.0883\n",
      "valid accuracy: 0.3764 0.9439 0.1001 0.1229 0.1045 0.0995 0.0886\n",
      "valid accuracy: 0.3772 0.9467 0.0942 0.1244 0.1039 0.0995 0.0865\n",
      "valid accuracy: 0.3758 0.9487 0.096 0.1211 0.1016 0.1005 0.0862\n",
      "valid accuracy: 0.3781 0.9457 0.0999 0.1201 0.1064 0.0987 0.0845\n",
      "valid accuracy: 0.3789 0.949 0.0982 0.1201 0.1054 0.0999 0.0836\n",
      "valid accuracy: 0.3685 0.9485 0.0987 0.1234 0.1063 0.1026 0.0884\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.06\n",
      "ep 0, batch 50, training accuracy 0.45\n",
      "ep 0, batch 100, training accuracy 0.565\n",
      "ep 0, batch 150, training accuracy 0.615\n",
      "ep 0, batch 200, training accuracy 0.765\n",
      "valid accuracy: 0.1945 0.6526 0.7347 0.1125 0.1459 0.1235 0.1009\n",
      "valid accuracy: 0.188 0.5519 0.8231 0.1068 0.1526 0.1067 0.089\n",
      "valid accuracy: 0.1631 0.572 0.8505 0.0919 0.1307 0.0975 0.0954\n",
      "valid accuracy: 0.1394 0.5163 0.8798 0.099 0.1212 0.1018 0.1023\n",
      "valid accuracy: 0.1601 0.5073 0.8914 0.0992 0.1019 0.1053 0.1062\n",
      "valid accuracy: 0.157 0.4951 0.8954 0.093 0.1137 0.1039 0.1129\n",
      "valid accuracy: 0.1704 0.522 0.9002 0.1013 0.1119 0.1051 0.1137\n",
      "valid accuracy: 0.1545 0.4488 0.9046 0.0946 0.1111 0.097 0.1014\n",
      "valid accuracy: 0.1482 0.4162 0.9124 0.0986 0.1064 0.0973 0.1127\n",
      "valid accuracy: 0.1636 0.4847 0.9134 0.0927 0.1003 0.1007 0.1059\n",
      "valid accuracy: 0.1557 0.4577 0.9166 0.0922 0.1003 0.0982 0.1089\n",
      "valid accuracy: 0.1332 0.4584 0.9165 0.0879 0.1004 0.1035 0.1065\n",
      "valid accuracy: 0.1548 0.4218 0.9158 0.0901 0.1102 0.0943 0.1043\n",
      "valid accuracy: 0.1338 0.4013 0.9219 0.0869 0.0999 0.0954 0.1136\n",
      "valid accuracy: 0.1585 0.3905 0.9219 0.0832 0.0969 0.0967 0.115\n",
      "valid accuracy: 0.1659 0.3914 0.925 0.0867 0.1041 0.0966 0.122\n",
      "valid accuracy: 0.1349 0.3588 0.9268 0.0889 0.1093 0.0984 0.121\n",
      "valid accuracy: 0.1719 0.4164 0.9279 0.0834 0.0846 0.098 0.1099\n",
      "valid accuracy: 0.1702 0.3845 0.9315 0.0813 0.0924 0.0982 0.1084\n",
      "valid accuracy: 0.1448 0.365 0.9303 0.0859 0.1008 0.0975 0.1183\n",
      "valid accuracy: 0.1637 0.3501 0.9311 0.0907 0.086 0.0969 0.1185\n",
      "valid accuracy: 0.1903 0.3707 0.9305 0.0851 0.1101 0.0977 0.1057\n",
      "valid accuracy: 0.1837 0.3719 0.9341 0.0862 0.1007 0.1026 0.1101\n",
      "valid accuracy: 0.1702 0.3371 0.9346 0.0849 0.0848 0.0988 0.1082\n",
      "valid accuracy: 0.1525 0.3558 0.9366 0.0865 0.0992 0.0984 0.1163\n",
      "valid accuracy: 0.1479 0.3234 0.9346 0.0883 0.0889 0.1017 0.1099\n",
      "valid accuracy: 0.1608 0.3219 0.9372 0.0915 0.0901 0.1005 0.1177\n",
      "valid accuracy: 0.172 0.2989 0.9374 0.08 0.1103 0.1016 0.1052\n",
      "valid accuracy: 0.1556 0.3097 0.941 0.0817 0.0951 0.0969 0.1174\n",
      "valid accuracy: 0.1576 0.2866 0.9406 0.0821 0.0886 0.0987 0.122\n",
      "valid accuracy: 0.1646 0.3223 0.9404 0.0856 0.0991 0.1005 0.115\n",
      "valid accuracy: 0.169 0.2913 0.9444 0.0859 0.0909 0.098 0.1208\n",
      "valid accuracy: 0.1671 0.2919 0.9439 0.0888 0.0959 0.0958 0.1076\n",
      "valid accuracy: 0.165 0.2895 0.945 0.0888 0.1025 0.0936 0.1223\n",
      "valid accuracy: 0.1684 0.2628 0.9423 0.0878 0.094 0.1007 0.1192\n",
      "valid accuracy: 0.1688 0.2594 0.9411 0.0773 0.1005 0.0956 0.1082\n",
      "valid accuracy: 0.1575 0.2671 0.9417 0.0837 0.0921 0.0934 0.1102\n",
      "valid accuracy: 0.1519 0.2767 0.944 0.0808 0.1085 0.1029 0.1247\n",
      "valid accuracy: 0.1599 0.2784 0.9441 0.0849 0.1053 0.108 0.1253\n",
      "valid accuracy: 0.1455 0.2473 0.9441 0.0853 0.089 0.0999 0.1182\n",
      "valid accuracy: 0.1447 0.2818 0.948 0.0836 0.1003 0.0924 0.1108\n",
      "valid accuracy: 0.1357 0.2613 0.9466 0.0874 0.0954 0.1007 0.1183\n",
      "valid accuracy: 0.1562 0.2715 0.9462 0.0854 0.098 0.1019 0.1105\n",
      "valid accuracy: 0.1329 0.2507 0.9455 0.0908 0.1022 0.0963 0.1168\n",
      "valid accuracy: 0.1448 0.248 0.9485 0.0851 0.0897 0.1045 0.1177\n",
      "valid accuracy: 0.1493 0.2402 0.9499 0.084 0.1085 0.1083 0.1106\n",
      "valid accuracy: 0.1325 0.2484 0.9464 0.0829 0.1042 0.1009 0.1159\n",
      "valid accuracy: 0.168 0.2527 0.9473 0.0885 0.1005 0.1009 0.1108\n",
      "valid accuracy: 0.1328 0.2377 0.9455 0.0947 0.0898 0.0977 0.123\n",
      "valid accuracy: 0.1614 0.2536 0.9491 0.0979 0.0936 0.0968 0.1189\n",
      "ep 50, batch 0, training accuracy 0.96\n",
      "ep 50, batch 50, training accuracy 0.94\n",
      "ep 50, batch 100, training accuracy 0.91\n",
      "ep 50, batch 150, training accuracy 0.925\n",
      "ep 50, batch 200, training accuracy 0.94\n",
      "valid accuracy: 0.1683 0.24 0.9493 0.0947 0.0898 0.1016 0.1272\n",
      "valid accuracy: 0.1625 0.2139 0.9486 0.0845 0.0937 0.101 0.1135\n",
      "valid accuracy: 0.1608 0.2217 0.95 0.092 0.0918 0.101 0.1192\n",
      "valid accuracy: 0.1481 0.2264 0.951 0.0839 0.099 0.1038 0.1261\n",
      "valid accuracy: 0.161 0.252 0.9489 0.0825 0.0952 0.1003 0.1189\n",
      "valid accuracy: 0.1515 0.2255 0.9513 0.0889 0.0914 0.1031 0.1178\n",
      "valid accuracy: 0.1638 0.234 0.9514 0.0886 0.09 0.0998 0.1148\n",
      "valid accuracy: 0.15 0.2301 0.9548 0.0835 0.0907 0.1008 0.1239\n",
      "valid accuracy: 0.1422 0.2275 0.9518 0.0884 0.0849 0.1021 0.1213\n",
      "valid accuracy: 0.1505 0.245 0.9523 0.0767 0.0929 0.0972 0.1123\n",
      "valid accuracy: 0.1543 0.2424 0.9548 0.0861 0.0915 0.0986 0.1168\n",
      "valid accuracy: 0.1541 0.2427 0.9525 0.0863 0.0931 0.1028 0.1192\n",
      "valid accuracy: 0.1485 0.2256 0.9537 0.0859 0.0983 0.1021 0.1112\n",
      "valid accuracy: 0.151 0.2185 0.9549 0.0881 0.0919 0.1015 0.1171\n",
      "valid accuracy: 0.151 0.2169 0.9541 0.0872 0.0988 0.0996 0.1169\n",
      "valid accuracy: 0.1506 0.2221 0.9556 0.0853 0.0893 0.1045 0.1188\n",
      "valid accuracy: 0.1528 0.2157 0.9551 0.0872 0.0973 0.0997 0.1176\n",
      "valid accuracy: 0.1514 0.2226 0.9538 0.0854 0.0962 0.1009 0.1201\n",
      "valid accuracy: 0.1471 0.2163 0.9528 0.0848 0.0941 0.1044 0.1175\n",
      "valid accuracy: 0.1464 0.2282 0.954 0.0879 0.0963 0.1 0.1176\n",
      "valid accuracy: 0.1418 0.2267 0.9555 0.0872 0.0918 0.1011 0.1225\n",
      "valid accuracy: 0.1448 0.2268 0.9559 0.0854 0.0905 0.0997 0.1166\n",
      "valid accuracy: 0.1417 0.2245 0.9536 0.084 0.0963 0.0965 0.1195\n",
      "valid accuracy: 0.1441 0.2348 0.9524 0.0856 0.0908 0.0986 0.1165\n",
      "valid accuracy: 0.1446 0.2222 0.9544 0.0861 0.0937 0.1006 0.1182\n",
      "valid accuracy: 0.1443 0.2213 0.9551 0.088 0.0929 0.0989 0.1198\n",
      "valid accuracy: 0.1498 0.2242 0.9545 0.0854 0.0945 0.1013 0.1196\n",
      "valid accuracy: 0.1435 0.2258 0.955 0.0859 0.0965 0.1018 0.1224\n",
      "valid accuracy: 0.1441 0.2297 0.9538 0.083 0.0914 0.0971 0.119\n",
      "valid accuracy: 0.1478 0.2227 0.956 0.0862 0.0949 0.1021 0.1211\n",
      "valid accuracy: 0.143 0.2285 0.9549 0.0864 0.0982 0.0991 0.1198\n",
      "valid accuracy: 0.147 0.2242 0.9554 0.0844 0.0927 0.0991 0.1198\n",
      "valid accuracy: 0.1446 0.2253 0.9552 0.0855 0.0939 0.1026 0.1192\n",
      "valid accuracy: 0.1463 0.2268 0.9547 0.0887 0.0965 0.1003 0.1175\n",
      "valid accuracy: 0.1462 0.2204 0.9544 0.0861 0.0922 0.1002 0.1204\n",
      "valid accuracy: 0.1486 0.2284 0.954 0.0855 0.093 0.1009 0.1238\n",
      "valid accuracy: 0.1461 0.2197 0.9536 0.0857 0.0956 0.1007 0.1206\n",
      "valid accuracy: 0.1484 0.2274 0.955 0.0862 0.0905 0.1032 0.1205\n",
      "valid accuracy: 0.1424 0.2305 0.9563 0.0842 0.0955 0.1001 0.1164\n",
      "valid accuracy: 0.1456 0.223 0.9553 0.0873 0.0959 0.1032 0.1219\n",
      "valid accuracy: 0.146 0.2255 0.9554 0.0869 0.0897 0.1004 0.1196\n",
      "valid accuracy: 0.1486 0.2288 0.954 0.0863 0.0912 0.0982 0.1214\n",
      "valid accuracy: 0.1443 0.2241 0.9552 0.086 0.0912 0.1003 0.1182\n",
      "valid accuracy: 0.1486 0.2261 0.9538 0.0847 0.0918 0.1022 0.1193\n",
      "valid accuracy: 0.1439 0.2227 0.9529 0.0864 0.0944 0.1022 0.1166\n",
      "valid accuracy: 0.1468 0.2206 0.9527 0.0881 0.0929 0.0988 0.1192\n",
      "valid accuracy: 0.1456 0.2255 0.9536 0.0872 0.0952 0.0993 0.1204\n",
      "valid accuracy: 0.1464 0.2253 0.9549 0.0865 0.0946 0.1002 0.1211\n",
      "valid accuracy: 0.1471 0.2276 0.9554 0.087 0.0933 0.1024 0.1235\n",
      "valid accuracy: 0.1491 0.2228 0.9555 0.0854 0.0908 0.1005 0.1196\n",
      "ep 100, batch 0, training accuracy 0.96\n",
      "ep 100, batch 50, training accuracy 0.955\n",
      "ep 100, batch 100, training accuracy 0.94\n",
      "ep 100, batch 150, training accuracy 0.93\n",
      "ep 100, batch 200, training accuracy 0.955\n",
      "valid accuracy: 0.1455 0.2312 0.9541 0.089 0.0919 0.1044 0.1221\n",
      "valid accuracy: 0.147 0.2269 0.9553 0.0852 0.0913 0.0982 0.1244\n",
      "valid accuracy: 0.1465 0.2277 0.9538 0.087 0.0905 0.1005 0.1183\n",
      "valid accuracy: 0.146 0.2238 0.9554 0.085 0.0928 0.1 0.1209\n",
      "valid accuracy: 0.1478 0.2313 0.9537 0.0864 0.0914 0.1035 0.1233\n",
      "valid accuracy: 0.1458 0.2206 0.9535 0.0848 0.0907 0.0991 0.1208\n",
      "valid accuracy: 0.1448 0.2256 0.9529 0.0861 0.0916 0.0964 0.1236\n",
      "valid accuracy: 0.1456 0.231 0.9546 0.0851 0.0868 0.0995 0.1214\n",
      "valid accuracy: 0.1472 0.2241 0.9567 0.0855 0.0948 0.1007 0.12\n",
      "valid accuracy: 0.1456 0.2184 0.9567 0.0898 0.0921 0.1016 0.1213\n",
      "valid accuracy: 0.1423 0.2275 0.9557 0.088 0.0909 0.0996 0.1175\n",
      "valid accuracy: 0.1473 0.2301 0.955 0.085 0.0949 0.0988 0.1176\n",
      "valid accuracy: 0.1466 0.2322 0.9541 0.089 0.0913 0.0997 0.1197\n",
      "valid accuracy: 0.1458 0.2257 0.9545 0.0868 0.0946 0.1009 0.1208\n",
      "valid accuracy: 0.1446 0.2241 0.9552 0.0865 0.0926 0.1031 0.1202\n",
      "valid accuracy: 0.1447 0.227 0.9555 0.0856 0.0923 0.1029 0.1152\n",
      "valid accuracy: 0.1482 0.2279 0.9543 0.0861 0.0926 0.1001 0.1207\n",
      "valid accuracy: 0.1447 0.231 0.9516 0.0895 0.0917 0.1003 0.1173\n",
      "valid accuracy: 0.1463 0.2216 0.9552 0.0836 0.0954 0.1018 0.1195\n",
      "valid accuracy: 0.1474 0.2268 0.9543 0.0874 0.0929 0.1009 0.1188\n",
      "valid accuracy: 0.1476 0.2261 0.9548 0.0826 0.0924 0.1041 0.1198\n",
      "valid accuracy: 0.144 0.2307 0.9528 0.0859 0.0932 0.1 0.1201\n",
      "valid accuracy: 0.1459 0.2243 0.9552 0.0839 0.0901 0.1 0.1212\n",
      "valid accuracy: 0.1471 0.224 0.9545 0.0849 0.094 0.1021 0.1169\n",
      "valid accuracy: 0.1479 0.2291 0.954 0.0844 0.0922 0.1012 0.1235\n",
      "valid accuracy: 0.1463 0.2243 0.956 0.0877 0.0939 0.1039 0.1187\n",
      "valid accuracy: 0.1439 0.2298 0.9562 0.0842 0.0931 0.0998 0.1197\n",
      "valid accuracy: 0.1461 0.2267 0.9547 0.0878 0.0898 0.1002 0.1176\n",
      "valid accuracy: 0.1486 0.2214 0.9567 0.0861 0.0911 0.1034 0.1181\n",
      "valid accuracy: 0.145 0.2266 0.9553 0.0873 0.0957 0.0987 0.1197\n",
      "valid accuracy: 0.1446 0.226 0.9557 0.0832 0.0946 0.1012 0.1221\n",
      "valid accuracy: 0.1481 0.2288 0.9545 0.0857 0.0913 0.0992 0.1196\n",
      "valid accuracy: 0.1463 0.2306 0.9561 0.0848 0.0911 0.1016 0.1165\n",
      "valid accuracy: 0.1459 0.2266 0.9551 0.0853 0.0919 0.0997 0.1184\n",
      "valid accuracy: 0.1468 0.2266 0.9543 0.0839 0.0938 0.1006 0.1215\n",
      "valid accuracy: 0.1468 0.2304 0.9567 0.0885 0.092 0.1009 0.1214\n",
      "valid accuracy: 0.1451 0.2276 0.9538 0.0843 0.0926 0.102 0.117\n",
      "valid accuracy: 0.149 0.2262 0.9554 0.0869 0.0902 0.101 0.117\n",
      "valid accuracy: 0.1444 0.2289 0.9541 0.0848 0.0942 0.1 0.1189\n",
      "valid accuracy: 0.1449 0.224 0.9537 0.087 0.0912 0.1008 0.1171\n",
      "valid accuracy: 0.1414 0.2235 0.9541 0.0877 0.0928 0.1019 0.118\n",
      "valid accuracy: 0.1475 0.2301 0.9535 0.089 0.0919 0.1005 0.121\n",
      "valid accuracy: 0.1465 0.2257 0.9546 0.0856 0.0914 0.1011 0.1212\n",
      "valid accuracy: 0.1444 0.2321 0.9505 0.0834 0.0912 0.1005 0.1198\n",
      "valid accuracy: 0.1473 0.2231 0.9536 0.0864 0.0921 0.1003 0.1191\n",
      "valid accuracy: 0.1472 0.2287 0.9545 0.0849 0.0929 0.1012 0.1189\n",
      "valid accuracy: 0.1429 0.2305 0.954 0.0855 0.0908 0.1046 0.1219\n",
      "valid accuracy: 0.1477 0.2232 0.9533 0.0841 0.0944 0.1 0.1203\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.065\n",
      "ep 0, batch 50, training accuracy 0.47\n",
      "ep 0, batch 100, training accuracy 0.505\n",
      "ep 0, batch 150, training accuracy 0.585\n",
      "ep 0, batch 200, training accuracy 0.685\n",
      "valid accuracy: 0.0908 0.1687 0.8191 0.7301 0.0995 0.1154 0.115\n",
      "valid accuracy: 0.0788 0.1684 0.7838 0.8149 0.0971 0.107 0.0993\n",
      "valid accuracy: 0.0872 0.1704 0.7204 0.8514 0.0969 0.0984 0.0993\n",
      "valid accuracy: 0.0727 0.1531 0.7143 0.8708 0.0913 0.1093 0.0972\n",
      "valid accuracy: 0.0838 0.1769 0.6711 0.883 0.0959 0.1023 0.0944\n",
      "valid accuracy: 0.0749 0.1666 0.6559 0.8927 0.0882 0.1012 0.1056\n",
      "valid accuracy: 0.081 0.1704 0.6539 0.9038 0.0979 0.1021 0.1083\n",
      "valid accuracy: 0.0851 0.1658 0.5954 0.9052 0.0996 0.1065 0.1036\n",
      "valid accuracy: 0.0776 0.1589 0.5688 0.9089 0.0927 0.1087 0.1059\n",
      "valid accuracy: 0.0775 0.167 0.5763 0.9157 0.0896 0.1058 0.1054\n",
      "valid accuracy: 0.0705 0.1743 0.5403 0.9146 0.0864 0.0953 0.1092\n",
      "valid accuracy: 0.0901 0.1473 0.5578 0.921 0.0901 0.1021 0.1079\n",
      "valid accuracy: 0.0839 0.1704 0.5253 0.923 0.0923 0.0993 0.1122\n",
      "valid accuracy: 0.0866 0.1579 0.5026 0.9241 0.0932 0.0987 0.1118\n",
      "valid accuracy: 0.0754 0.1568 0.494 0.9289 0.0936 0.1008 0.1088\n",
      "valid accuracy: 0.0788 0.15 0.492 0.9304 0.0921 0.0938 0.11\n",
      "valid accuracy: 0.0833 0.1499 0.4829 0.9277 0.0904 0.0997 0.1068\n",
      "valid accuracy: 0.0794 0.1438 0.4886 0.928 0.0857 0.0995 0.1084\n",
      "valid accuracy: 0.0685 0.1467 0.4759 0.9331 0.0928 0.0934 0.1101\n",
      "valid accuracy: 0.0755 0.1572 0.4402 0.9357 0.0927 0.0937 0.1044\n",
      "valid accuracy: 0.0799 0.1611 0.4439 0.9377 0.0969 0.0959 0.1173\n",
      "valid accuracy: 0.0772 0.1554 0.417 0.9334 0.0937 0.0929 0.1109\n",
      "valid accuracy: 0.0974 0.1492 0.4345 0.9359 0.0855 0.0939 0.1096\n",
      "valid accuracy: 0.0913 0.1628 0.4423 0.9389 0.0982 0.0988 0.1294\n",
      "valid accuracy: 0.0901 0.1736 0.445 0.9397 0.0919 0.09 0.1155\n",
      "valid accuracy: 0.0809 0.1629 0.414 0.9393 0.096 0.091 0.129\n",
      "valid accuracy: 0.0768 0.1685 0.427 0.941 0.0933 0.1003 0.1177\n",
      "valid accuracy: 0.0786 0.1575 0.4412 0.9398 0.0928 0.1034 0.1156\n",
      "valid accuracy: 0.0808 0.1614 0.4274 0.9407 0.0947 0.0971 0.1198\n",
      "valid accuracy: 0.0735 0.1625 0.3855 0.9431 0.1004 0.0908 0.1162\n",
      "valid accuracy: 0.0771 0.151 0.3912 0.9402 0.0939 0.0908 0.1281\n",
      "valid accuracy: 0.0873 0.1678 0.3847 0.9445 0.0937 0.0972 0.1146\n",
      "valid accuracy: 0.0812 0.1509 0.409 0.944 0.0916 0.0935 0.1267\n",
      "valid accuracy: 0.0789 0.1622 0.4268 0.9449 0.0963 0.1006 0.113\n",
      "valid accuracy: 0.0691 0.1753 0.3962 0.9451 0.0972 0.098 0.1164\n",
      "valid accuracy: 0.0816 0.1616 0.4063 0.9457 0.0909 0.1036 0.1182\n",
      "valid accuracy: 0.0707 0.1555 0.4002 0.9483 0.0915 0.097 0.1321\n",
      "valid accuracy: 0.0725 0.1649 0.3835 0.9491 0.1013 0.1065 0.1263\n",
      "valid accuracy: 0.0812 0.1641 0.4157 0.9459 0.1059 0.1012 0.124\n",
      "valid accuracy: 0.0799 0.1649 0.3774 0.9501 0.0907 0.0951 0.1192\n",
      "valid accuracy: 0.0833 0.1584 0.3837 0.9482 0.0896 0.0989 0.1227\n",
      "valid accuracy: 0.0823 0.1685 0.3988 0.9479 0.099 0.0963 0.1218\n",
      "valid accuracy: 0.0895 0.1585 0.3774 0.9494 0.0883 0.0989 0.1179\n",
      "valid accuracy: 0.081 0.1574 0.387 0.9477 0.0875 0.1028 0.127\n",
      "valid accuracy: 0.0807 0.1558 0.3898 0.9503 0.0906 0.1023 0.1219\n",
      "valid accuracy: 0.0651 0.1673 0.3755 0.9485 0.0881 0.0961 0.1241\n",
      "valid accuracy: 0.0656 0.1692 0.3869 0.9488 0.0899 0.0947 0.1208\n",
      "valid accuracy: 0.0793 0.158 0.3997 0.9495 0.0926 0.0988 0.1277\n",
      "valid accuracy: 0.0764 0.1623 0.3667 0.9526 0.0964 0.0955 0.1222\n",
      "valid accuracy: 0.0731 0.1603 0.362 0.9532 0.0868 0.1026 0.1121\n",
      "ep 50, batch 0, training accuracy 0.95\n",
      "ep 50, batch 50, training accuracy 0.95\n",
      "ep 50, batch 100, training accuracy 0.93\n",
      "ep 50, batch 150, training accuracy 0.94\n",
      "ep 50, batch 200, training accuracy 0.955\n",
      "valid accuracy: 0.0693 0.1612 0.3761 0.9533 0.0875 0.1081 0.1191\n",
      "valid accuracy: 0.078 0.1535 0.3467 0.9521 0.0885 0.1014 0.1228\n",
      "valid accuracy: 0.075 0.1524 0.3527 0.9518 0.0929 0.1026 0.1279\n",
      "valid accuracy: 0.0709 0.146 0.327 0.9547 0.0873 0.1006 0.1274\n",
      "valid accuracy: 0.0579 0.1474 0.3339 0.9521 0.0956 0.1056 0.1254\n",
      "valid accuracy: 0.068 0.1537 0.331 0.9536 0.0971 0.0927 0.1263\n",
      "valid accuracy: 0.0639 0.1463 0.3431 0.952 0.1008 0.0945 0.1224\n",
      "valid accuracy: 0.067 0.158 0.3382 0.9551 0.0936 0.0984 0.1226\n",
      "valid accuracy: 0.0709 0.1553 0.338 0.9535 0.0878 0.1091 0.1175\n",
      "valid accuracy: 0.0711 0.1456 0.3283 0.955 0.0915 0.1012 0.118\n",
      "valid accuracy: 0.064 0.1437 0.3195 0.9556 0.0953 0.0945 0.1234\n",
      "valid accuracy: 0.0613 0.1493 0.3336 0.9554 0.1 0.1019 0.1245\n",
      "valid accuracy: 0.0654 0.1494 0.344 0.9547 0.0964 0.0993 0.1224\n",
      "valid accuracy: 0.0665 0.1585 0.3368 0.9547 0.0968 0.0968 0.1273\n",
      "valid accuracy: 0.0657 0.1531 0.3512 0.9541 0.0991 0.097 0.1184\n",
      "valid accuracy: 0.0642 0.1463 0.3297 0.9545 0.0958 0.1009 0.125\n",
      "valid accuracy: 0.064 0.1567 0.3399 0.9559 0.0957 0.1004 0.1242\n",
      "valid accuracy: 0.0645 0.1541 0.3442 0.9551 0.0983 0.097 0.1247\n",
      "valid accuracy: 0.0668 0.155 0.3391 0.9563 0.098 0.1 0.1226\n",
      "valid accuracy: 0.068 0.1523 0.3392 0.9578 0.0956 0.0986 0.1267\n",
      "valid accuracy: 0.0625 0.1549 0.3352 0.9568 0.0939 0.0999 0.1211\n",
      "valid accuracy: 0.0651 0.1576 0.3417 0.956 0.0965 0.1017 0.127\n",
      "valid accuracy: 0.0668 0.1595 0.3419 0.9561 0.0981 0.0986 0.1251\n",
      "valid accuracy: 0.0643 0.1544 0.337 0.9545 0.0977 0.0989 0.1245\n",
      "valid accuracy: 0.0647 0.1537 0.3368 0.9554 0.0963 0.1003 0.1255\n",
      "valid accuracy: 0.0629 0.1548 0.3365 0.9565 0.092 0.0981 0.1226\n",
      "valid accuracy: 0.0644 0.1511 0.3401 0.9534 0.0933 0.1021 0.125\n",
      "valid accuracy: 0.0627 0.1465 0.333 0.9556 0.0979 0.0996 0.1208\n",
      "valid accuracy: 0.0619 0.1533 0.3425 0.9569 0.0941 0.0974 0.125\n",
      "valid accuracy: 0.0642 0.1475 0.3399 0.9558 0.0934 0.0994 0.1234\n",
      "valid accuracy: 0.0663 0.1567 0.3434 0.9548 0.0965 0.0955 0.1248\n",
      "valid accuracy: 0.0651 0.1522 0.336 0.9576 0.0941 0.0985 0.1244\n",
      "valid accuracy: 0.0628 0.1585 0.3383 0.955 0.0947 0.1014 0.1263\n",
      "valid accuracy: 0.0655 0.1458 0.3405 0.956 0.0932 0.099 0.1247\n",
      "valid accuracy: 0.0656 0.1488 0.3404 0.9554 0.0974 0.1 0.1228\n",
      "valid accuracy: 0.0677 0.1494 0.3376 0.9557 0.0968 0.0979 0.126\n",
      "valid accuracy: 0.0649 0.1533 0.3376 0.9554 0.0935 0.1002 0.1269\n",
      "valid accuracy: 0.062 0.1539 0.3404 0.9556 0.0941 0.0999 0.1247\n",
      "valid accuracy: 0.0658 0.1505 0.3345 0.9559 0.0962 0.1019 0.1283\n",
      "valid accuracy: 0.0659 0.1582 0.3351 0.9549 0.0949 0.0992 0.1266\n",
      "valid accuracy: 0.064 0.1536 0.33 0.9548 0.0931 0.1007 0.1261\n",
      "valid accuracy: 0.0671 0.15 0.3379 0.9546 0.0963 0.0968 0.1277\n",
      "valid accuracy: 0.0649 0.1529 0.3422 0.9567 0.0981 0.0979 0.1277\n",
      "valid accuracy: 0.0637 0.1486 0.3362 0.9567 0.0967 0.0988 0.125\n",
      "valid accuracy: 0.0635 0.1551 0.3416 0.9578 0.0957 0.1007 0.1261\n",
      "valid accuracy: 0.0628 0.1505 0.3374 0.957 0.0981 0.0976 0.125\n",
      "valid accuracy: 0.0642 0.1574 0.3384 0.9561 0.0922 0.0979 0.1247\n",
      "valid accuracy: 0.0649 0.1527 0.3385 0.9576 0.0968 0.0964 0.1268\n",
      "valid accuracy: 0.0649 0.1545 0.3335 0.9554 0.0948 0.0983 0.126\n",
      "valid accuracy: 0.065 0.1516 0.3407 0.9561 0.0939 0.0999 0.1277\n",
      "ep 100, batch 0, training accuracy 0.945\n",
      "ep 100, batch 50, training accuracy 0.96\n",
      "ep 100, batch 100, training accuracy 0.955\n",
      "ep 100, batch 150, training accuracy 0.945\n",
      "ep 100, batch 200, training accuracy 0.975\n",
      "valid accuracy: 0.0655 0.1575 0.3378 0.9572 0.0972 0.0953 0.1261\n",
      "valid accuracy: 0.0672 0.1544 0.3391 0.9544 0.0936 0.0965 0.1283\n",
      "valid accuracy: 0.063 0.1519 0.3403 0.9565 0.0952 0.0964 0.1257\n",
      "valid accuracy: 0.0654 0.1601 0.3362 0.956 0.1009 0.1011 0.1291\n",
      "valid accuracy: 0.0638 0.1551 0.3403 0.9567 0.095 0.1028 0.1246\n",
      "valid accuracy: 0.0635 0.1553 0.3415 0.9552 0.0964 0.1001 0.1298\n",
      "valid accuracy: 0.0658 0.151 0.3399 0.9564 0.0949 0.0995 0.1249\n",
      "valid accuracy: 0.0648 0.1532 0.3396 0.9568 0.0958 0.1001 0.124\n",
      "valid accuracy: 0.0658 0.1493 0.3455 0.9547 0.0975 0.0983 0.1269\n",
      "valid accuracy: 0.0659 0.1542 0.3321 0.958 0.0988 0.1004 0.1254\n",
      "valid accuracy: 0.0662 0.152 0.335 0.954 0.0973 0.0995 0.1274\n",
      "valid accuracy: 0.0664 0.1513 0.3399 0.9529 0.0928 0.0998 0.1286\n",
      "valid accuracy: 0.0653 0.1582 0.3395 0.9547 0.0967 0.0998 0.1263\n",
      "valid accuracy: 0.0633 0.1536 0.3337 0.9548 0.0979 0.0945 0.1292\n",
      "valid accuracy: 0.0643 0.1576 0.3446 0.9552 0.0991 0.1026 0.1285\n",
      "valid accuracy: 0.0653 0.1535 0.3348 0.9534 0.0936 0.0962 0.1236\n",
      "valid accuracy: 0.0643 0.1563 0.3368 0.9573 0.0963 0.1 0.125\n",
      "valid accuracy: 0.0658 0.1559 0.3345 0.9553 0.0939 0.0999 0.1219\n",
      "valid accuracy: 0.0645 0.1543 0.3393 0.9549 0.097 0.0984 0.1236\n",
      "valid accuracy: 0.0647 0.156 0.3435 0.9562 0.0941 0.0992 0.1271\n",
      "valid accuracy: 0.0682 0.1547 0.3391 0.9548 0.0938 0.0976 0.1257\n",
      "valid accuracy: 0.0631 0.1517 0.3411 0.9557 0.0938 0.0974 0.1241\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.06\n",
      "ep 0, batch 50, training accuracy 0.385\n",
      "ep 0, batch 100, training accuracy 0.38\n",
      "ep 0, batch 150, training accuracy 0.5\n",
      "ep 0, batch 200, training accuracy 0.615\n",
      "valid accuracy: 0.1211 0.1509 0.2214 0.7284 0.6936 0.1268 0.1854\n",
      "valid accuracy: 0.1269 0.1334 0.2315 0.672 0.7974 0.1228 0.1749\n",
      "valid accuracy: 0.1405 0.1282 0.2089 0.6548 0.8369 0.1185 0.1545\n",
      "valid accuracy: 0.1467 0.1412 0.2004 0.595 0.8679 0.117 0.1408\n",
      "valid accuracy: 0.1432 0.1267 0.1957 0.6139 0.8823 0.1124 0.1347\n",
      "valid accuracy: 0.1489 0.1344 0.1793 0.5768 0.8952 0.109 0.1283\n",
      "valid accuracy: 0.1497 0.1282 0.1747 0.5761 0.8997 0.108 0.1314\n",
      "valid accuracy: 0.1283 0.1266 0.1418 0.6 0.909 0.1006 0.1317\n",
      "valid accuracy: 0.134 0.1288 0.1629 0.4966 0.9112 0.1118 0.1266\n",
      "valid accuracy: 0.1453 0.132 0.1679 0.5545 0.9166 0.1059 0.1308\n",
      "valid accuracy: 0.1456 0.1244 0.1582 0.5472 0.9212 0.1128 0.1221\n",
      "valid accuracy: 0.1401 0.1328 0.1704 0.5331 0.9198 0.1071 0.1212\n",
      "valid accuracy: 0.1534 0.1228 0.1474 0.4897 0.9244 0.1138 0.1243\n",
      "valid accuracy: 0.1528 0.1221 0.1635 0.5498 0.9243 0.1084 0.1176\n",
      "valid accuracy: 0.1559 0.1366 0.1526 0.5288 0.9266 0.1102 0.1257\n",
      "valid accuracy: 0.141 0.1326 0.1533 0.5027 0.9305 0.104 0.1251\n",
      "valid accuracy: 0.1434 0.1306 0.1467 0.52 0.9291 0.1118 0.1283\n",
      "valid accuracy: 0.1362 0.1259 0.1554 0.5269 0.9306 0.1105 0.128\n",
      "valid accuracy: 0.1489 0.1261 0.1702 0.5094 0.9349 0.1115 0.128\n",
      "valid accuracy: 0.1395 0.1261 0.1527 0.4825 0.9328 0.1072 0.1241\n",
      "valid accuracy: 0.1333 0.1255 0.1491 0.4885 0.9345 0.107 0.1178\n",
      "valid accuracy: 0.1338 0.1212 0.1545 0.5126 0.9356 0.1082 0.1241\n",
      "valid accuracy: 0.1245 0.123 0.1491 0.4785 0.9388 0.1075 0.1231\n",
      "valid accuracy: 0.1404 0.1296 0.1556 0.4982 0.9386 0.102 0.1235\n",
      "valid accuracy: 0.1388 0.1203 0.1502 0.5254 0.939 0.1028 0.1234\n",
      "valid accuracy: 0.1549 0.1298 0.1781 0.4668 0.9375 0.1015 0.1152\n",
      "valid accuracy: 0.1523 0.134 0.1613 0.4745 0.9404 0.1038 0.1224\n",
      "valid accuracy: 0.1346 0.135 0.1539 0.4783 0.937 0.106 0.1288\n",
      "valid accuracy: 0.147 0.1255 0.1595 0.4481 0.9378 0.0982 0.1238\n",
      "valid accuracy: 0.1556 0.1314 0.1684 0.4551 0.9422 0.0991 0.1222\n",
      "valid accuracy: 0.1488 0.1318 0.164 0.4232 0.9405 0.1055 0.1222\n",
      "valid accuracy: 0.1537 0.134 0.1606 0.4165 0.9418 0.1051 0.1182\n",
      "valid accuracy: 0.1536 0.1454 0.1809 0.4366 0.9415 0.1025 0.1171\n",
      "valid accuracy: 0.1478 0.1346 0.1661 0.4432 0.9441 0.1151 0.1173\n",
      "valid accuracy: 0.1528 0.1362 0.1555 0.4239 0.9436 0.1053 0.1222\n",
      "valid accuracy: 0.1544 0.1386 0.1884 0.4278 0.9449 0.1127 0.1161\n",
      "valid accuracy: 0.1517 0.1353 0.1867 0.3865 0.9485 0.1156 0.1219\n",
      "valid accuracy: 0.163 0.1399 0.1733 0.418 0.9471 0.118 0.122\n",
      "valid accuracy: 0.1551 0.1426 0.1392 0.345 0.9447 0.1078 0.1192\n",
      "valid accuracy: 0.1695 0.1397 0.1679 0.3898 0.9466 0.1056 0.1175\n",
      "valid accuracy: 0.1641 0.1414 0.1554 0.4179 0.9475 0.1113 0.1193\n",
      "valid accuracy: 0.1547 0.1456 0.1551 0.4076 0.9461 0.1117 0.1198\n",
      "valid accuracy: 0.159 0.1371 0.1471 0.3978 0.9472 0.1156 0.1277\n",
      "valid accuracy: 0.1708 0.1405 0.1457 0.382 0.9482 0.1157 0.1164\n",
      "valid accuracy: 0.1585 0.1323 0.1631 0.3511 0.9466 0.1017 0.117\n",
      "valid accuracy: 0.1563 0.133 0.1439 0.3908 0.9495 0.1049 0.1168\n",
      "valid accuracy: 0.1489 0.1428 0.1431 0.3772 0.9466 0.114 0.1235\n",
      "valid accuracy: 0.159 0.1413 0.1632 0.3974 0.9495 0.1149 0.1201\n",
      "valid accuracy: 0.1665 0.1389 0.1534 0.3802 0.9469 0.1148 0.119\n",
      "valid accuracy: 0.167 0.1392 0.1412 0.3702 0.9513 0.114 0.1135\n",
      "ep 50, batch 0, training accuracy 0.95\n",
      "ep 50, batch 50, training accuracy 0.945\n",
      "ep 50, batch 100, training accuracy 0.935\n",
      "ep 50, batch 150, training accuracy 0.915\n",
      "ep 50, batch 200, training accuracy 0.975\n",
      "valid accuracy: 0.1537 0.1364 0.1471 0.3466 0.9488 0.1065 0.1201\n",
      "valid accuracy: 0.1701 0.1327 0.1255 0.3458 0.9476 0.1115 0.1223\n",
      "valid accuracy: 0.1532 0.133 0.1601 0.3742 0.9493 0.1093 0.1166\n",
      "valid accuracy: 0.1531 0.1407 0.1487 0.3489 0.9526 0.1091 0.113\n",
      "valid accuracy: 0.1559 0.1396 0.1532 0.3449 0.9504 0.1114 0.1137\n",
      "valid accuracy: 0.1551 0.1325 0.1394 0.3534 0.9516 0.1141 0.1191\n",
      "valid accuracy: 0.156 0.1401 0.1331 0.3464 0.9537 0.111 0.1148\n",
      "valid accuracy: 0.1568 0.1359 0.139 0.3493 0.9515 0.1151 0.1188\n",
      "valid accuracy: 0.1662 0.1311 0.143 0.3309 0.953 0.1158 0.1152\n",
      "valid accuracy: 0.1704 0.1322 0.158 0.345 0.9522 0.1129 0.1201\n",
      "valid accuracy: 0.1659 0.1339 0.1477 0.3468 0.953 0.1154 0.1166\n",
      "valid accuracy: 0.1627 0.1325 0.1403 0.3508 0.953 0.1134 0.1177\n",
      "valid accuracy: 0.1689 0.1379 0.141 0.348 0.9528 0.1093 0.1183\n",
      "valid accuracy: 0.1648 0.1325 0.1462 0.3554 0.9544 0.111 0.1191\n",
      "valid accuracy: 0.1722 0.1359 0.1451 0.3498 0.9533 0.1138 0.1166\n",
      "valid accuracy: 0.169 0.1325 0.1379 0.3491 0.9528 0.1121 0.118\n",
      "valid accuracy: 0.1761 0.1331 0.1471 0.3566 0.9535 0.111 0.1173\n",
      "valid accuracy: 0.1688 0.1337 0.1406 0.3558 0.9539 0.1092 0.1155\n",
      "valid accuracy: 0.1732 0.1342 0.1382 0.3521 0.9545 0.1114 0.1117\n",
      "valid accuracy: 0.1655 0.1292 0.142 0.3506 0.9516 0.111 0.1143\n",
      "valid accuracy: 0.1693 0.1347 0.145 0.3556 0.9543 0.1106 0.118\n",
      "valid accuracy: 0.1697 0.136 0.1502 0.3585 0.9539 0.1121 0.1181\n",
      "valid accuracy: 0.1666 0.1329 0.1471 0.3581 0.9568 0.1108 0.119\n",
      "valid accuracy: 0.1678 0.1342 0.1425 0.3554 0.955 0.1085 0.1147\n",
      "valid accuracy: 0.1731 0.1285 0.1439 0.3558 0.9543 0.1123 0.1128\n",
      "valid accuracy: 0.1734 0.1321 0.1468 0.3558 0.9548 0.1117 0.1141\n",
      "valid accuracy: 0.1687 0.1366 0.1462 0.3598 0.9541 0.1124 0.114\n",
      "valid accuracy: 0.1729 0.1334 0.1467 0.3575 0.9533 0.1059 0.1143\n",
      "valid accuracy: 0.1664 0.1317 0.1448 0.3504 0.9523 0.1155 0.1167\n",
      "valid accuracy: 0.1714 0.1308 0.1467 0.3543 0.9538 0.1147 0.1165\n",
      "valid accuracy: 0.1709 0.1347 0.1478 0.3575 0.9541 0.1135 0.1203\n",
      "valid accuracy: 0.1671 0.1355 0.1474 0.3509 0.9537 0.1132 0.113\n",
      "valid accuracy: 0.1657 0.1389 0.148 0.3505 0.9542 0.1101 0.1154\n",
      "valid accuracy: 0.1683 0.1347 0.147 0.3515 0.9536 0.1089 0.1168\n",
      "valid accuracy: 0.1669 0.1357 0.146 0.3559 0.9532 0.1149 0.1158\n",
      "valid accuracy: 0.1653 0.1397 0.1478 0.3548 0.9521 0.1127 0.1133\n",
      "valid accuracy: 0.1711 0.1303 0.1445 0.3504 0.9546 0.1139 0.1164\n",
      "valid accuracy: 0.1644 0.1306 0.1491 0.3522 0.9559 0.1117 0.1127\n",
      "valid accuracy: 0.1695 0.1312 0.1459 0.3558 0.9538 0.1128 0.1132\n",
      "valid accuracy: 0.1687 0.1314 0.1405 0.3527 0.9545 0.114 0.119\n",
      "valid accuracy: 0.1674 0.1358 0.1508 0.3525 0.9542 0.1153 0.1152\n",
      "valid accuracy: 0.1695 0.1311 0.1444 0.3541 0.9523 0.1118 0.1142\n",
      "valid accuracy: 0.167 0.1314 0.1439 0.3576 0.9533 0.1078 0.1148\n",
      "valid accuracy: 0.1683 0.1291 0.15 0.3476 0.956 0.1123 0.1162\n",
      "valid accuracy: 0.1718 0.1409 0.1471 0.3522 0.9525 0.1128 0.1142\n",
      "valid accuracy: 0.1685 0.1354 0.1482 0.3558 0.9538 0.1157 0.1172\n",
      "valid accuracy: 0.1621 0.1349 0.1505 0.3422 0.9547 0.1135 0.1176\n",
      "valid accuracy: 0.1661 0.1319 0.1455 0.352 0.953 0.1087 0.1165\n",
      "valid accuracy: 0.1733 0.1364 0.1467 0.3489 0.9549 0.111 0.1177\n",
      "valid accuracy: 0.1692 0.1312 0.146 0.348 0.9553 0.1152 0.1129\n",
      "ep 100, batch 0, training accuracy 0.955\n",
      "ep 100, batch 50, training accuracy 0.95\n",
      "ep 100, batch 100, training accuracy 0.945\n",
      "ep 100, batch 150, training accuracy 0.935\n",
      "ep 100, batch 200, training accuracy 0.98\n",
      "valid accuracy: 0.1718 0.1368 0.1487 0.3524 0.9538 0.1133 0.1163\n",
      "valid accuracy: 0.1743 0.1324 0.1456 0.3502 0.9539 0.1136 0.1159\n",
      "valid accuracy: 0.1651 0.1365 0.1491 0.3536 0.9562 0.1176 0.1162\n",
      "valid accuracy: 0.1652 0.138 0.1476 0.3502 0.9546 0.1153 0.1136\n",
      "valid accuracy: 0.1687 0.1354 0.15 0.3522 0.9527 0.1147 0.1159\n",
      "valid accuracy: 0.1673 0.137 0.1427 0.3547 0.9561 0.1136 0.1164\n",
      "valid accuracy: 0.169 0.1377 0.1503 0.3536 0.9544 0.1147 0.1117\n",
      "valid accuracy: 0.1645 0.1369 0.1483 0.3467 0.9549 0.115 0.1176\n",
      "valid accuracy: 0.1701 0.135 0.141 0.3492 0.9558 0.1149 0.115\n",
      "valid accuracy: 0.1723 0.1357 0.1434 0.3491 0.9553 0.1094 0.1186\n",
      "valid accuracy: 0.1714 0.1326 0.1468 0.3533 0.9531 0.1121 0.1169\n",
      "valid accuracy: 0.1695 0.137 0.1449 0.3513 0.9538 0.1114 0.117\n",
      "valid accuracy: 0.1716 0.1336 0.1494 0.3499 0.9566 0.1189 0.12\n",
      "valid accuracy: 0.171 0.1405 0.1443 0.3504 0.9543 0.1124 0.1171\n",
      "valid accuracy: 0.1678 0.1343 0.1458 0.3541 0.9549 0.1126 0.1174\n",
      "valid accuracy: 0.1691 0.1349 0.1491 0.3456 0.9546 0.1173 0.1126\n",
      "valid accuracy: 0.1703 0.1381 0.1467 0.3568 0.9559 0.1109 0.1161\n",
      "valid accuracy: 0.1721 0.1334 0.1485 0.3564 0.9528 0.112 0.1164\n",
      "valid accuracy: 0.1691 0.1367 0.1497 0.3491 0.954 0.1145 0.1211\n",
      "valid accuracy: 0.1739 0.1373 0.1433 0.3526 0.9541 0.1146 0.1196\n",
      "valid accuracy: 0.169 0.1363 0.1475 0.3521 0.9541 0.1136 0.1178\n",
      "valid accuracy: 0.1703 0.1269 0.1459 0.3481 0.9549 0.1135 0.1158\n",
      "valid accuracy: 0.1697 0.1336 0.1474 0.3476 0.9529 0.1142 0.1162\n",
      "valid accuracy: 0.1687 0.1346 0.1495 0.3462 0.9542 0.115 0.1157\n",
      "valid accuracy: 0.1658 0.1352 0.1456 0.3474 0.9549 0.1115 0.1145\n",
      "valid accuracy: 0.169 0.1355 0.1441 0.3547 0.9546 0.1133 0.1123\n",
      "valid accuracy: 0.1736 0.1357 0.1509 0.3522 0.9522 0.1145 0.1196\n",
      "valid accuracy: 0.1682 0.1345 0.1488 0.35 0.9541 0.1089 0.1127\n",
      "valid accuracy: 0.1729 0.1375 0.1469 0.3527 0.9547 0.1173 0.1173\n",
      "valid accuracy: 0.1689 0.1313 0.1486 0.3526 0.9542 0.1137 0.1181\n",
      "valid accuracy: 0.1725 0.1394 0.1442 0.3525 0.9561 0.1094 0.1163\n",
      "valid accuracy: 0.1718 0.1389 0.1488 0.3491 0.9555 0.1158 0.112\n",
      "valid accuracy: 0.1672 0.134 0.1481 0.3503 0.956 0.1132 0.1133\n",
      "valid accuracy: 0.1707 0.1332 0.1443 0.3455 0.9545 0.1166 0.116\n",
      "valid accuracy: 0.1642 0.1367 0.1447 0.349 0.9542 0.1144 0.116\n",
      "valid accuracy: 0.168 0.1378 0.1486 0.351 0.9547 0.1145 0.1147\n",
      "valid accuracy: 0.1688 0.1347 0.1491 0.3572 0.9555 0.1117 0.1172\n",
      "valid accuracy: 0.1694 0.1372 0.148 0.345 0.9557 0.1173 0.1162\n",
      "valid accuracy: 0.168 0.1358 0.1507 0.3497 0.9535 0.1117 0.1141\n",
      "valid accuracy: 0.1721 0.1311 0.1481 0.3466 0.9529 0.111 0.1151\n",
      "valid accuracy: 0.1721 0.1313 0.1507 0.3489 0.9538 0.1137 0.1159\n",
      "valid accuracy: 0.1723 0.1359 0.1499 0.3479 0.9544 0.1166 0.1164\n",
      "valid accuracy: 0.1641 0.1372 0.1426 0.3517 0.9527 0.1098 0.119\n",
      "valid accuracy: 0.1685 0.1333 0.1477 0.3524 0.9543 0.1194 0.1162\n",
      "valid accuracy: 0.1712 0.1367 0.1548 0.3497 0.9535 0.1119 0.1149\n",
      "valid accuracy: 0.1718 0.1373 0.1411 0.3545 0.9548 0.1097 0.1174\n",
      "valid accuracy: 0.1667 0.1373 0.1491 0.3476 0.9563 0.1142 0.1156\n",
      "valid accuracy: 0.1719 0.1381 0.1457 0.3518 0.9543 0.1159 0.1175\n",
      "valid accuracy: 0.1651 0.1327 0.1465 0.3479 0.9553 0.1103 0.116\n",
      "valid accuracy: 0.172 0.1344 0.145 0.3487 0.9558 0.1146 0.1167\n",
      "ep 150, batch 0, training accuracy 0.965\n",
      "ep 150, batch 50, training accuracy 0.95\n",
      "ep 150, batch 100, training accuracy 0.94\n",
      "ep 150, batch 150, training accuracy 0.94\n",
      "ep 150, batch 200, training accuracy 0.98\n",
      "valid accuracy: 0.1704 0.1313 0.1493 0.3522 0.953 0.1135 0.1146\n",
      "valid accuracy: 0.1705 0.1369 0.1457 0.3492 0.9561 0.1113 0.1147\n",
      "valid accuracy: 0.1654 0.1371 0.1499 0.349 0.9554 0.1133 0.1174\n",
      "valid accuracy: 0.1682 0.1355 0.1459 0.3467 0.9547 0.1151 0.1202\n",
      "valid accuracy: 0.1721 0.1309 0.1474 0.3509 0.9545 0.1124 0.116\n",
      "valid accuracy: 0.1682 0.136 0.1486 0.352 0.9531 0.1116 0.1168\n",
      "valid accuracy: 0.1679 0.1388 0.1493 0.3454 0.9547 0.1069 0.1206\n",
      "valid accuracy: 0.1705 0.1388 0.1468 0.3476 0.954 0.1165 0.1129\n",
      "valid accuracy: 0.1688 0.1335 0.146 0.3544 0.9556 0.1139 0.1191\n",
      "valid accuracy: 0.1646 0.13 0.1476 0.3509 0.9547 0.1137 0.1178\n",
      "valid accuracy: 0.1668 0.1349 0.1463 0.3476 0.9549 0.1103 0.1189\n",
      "valid accuracy: 0.1675 0.1376 0.1486 0.3502 0.9552 0.1102 0.1182\n",
      "valid accuracy: 0.1738 0.1355 0.1392 0.3498 0.9517 0.1174 0.1182\n",
      "valid accuracy: 0.1689 0.1337 0.1455 0.3431 0.9555 0.1147 0.1168\n",
      "valid accuracy: 0.1681 0.1342 0.1447 0.3529 0.9538 0.1113 0.1176\n",
      "valid accuracy: 0.1711 0.1334 0.1515 0.3528 0.9523 0.1111 0.1155\n",
      "valid accuracy: 0.1699 0.1346 0.143 0.3495 0.9547 0.1128 0.1188\n",
      "valid accuracy: 0.1718 0.1329 0.1475 0.3496 0.9545 0.1132 0.1173\n",
      "valid accuracy: 0.1651 0.1359 0.1458 0.3524 0.9542 0.1138 0.1185\n",
      "valid accuracy: 0.1696 0.1324 0.1463 0.3469 0.9558 0.1121 0.1163\n",
      "valid accuracy: 0.171 0.133 0.1486 0.3491 0.9538 0.1136 0.116\n",
      "valid accuracy: 0.1685 0.1382 0.1493 0.3505 0.9537 0.1115 0.1182\n",
      "valid accuracy: 0.1698 0.1343 0.1476 0.348 0.9537 0.1136 0.121\n",
      "valid accuracy: 0.169 0.1393 0.147 0.3513 0.9553 0.109 0.1187\n",
      "valid accuracy: 0.1688 0.139 0.1479 0.3498 0.9554 0.1145 0.1183\n",
      "valid accuracy: 0.1681 0.1379 0.1487 0.3478 0.9547 0.1172 0.1164\n",
      "valid accuracy: 0.169 0.1371 0.1527 0.3541 0.9544 0.1124 0.118\n",
      "valid accuracy: 0.1666 0.1354 0.1477 0.3484 0.9528 0.1166 0.1177\n",
      "valid accuracy: 0.1679 0.1373 0.1474 0.3459 0.9556 0.111 0.1172\n",
      "valid accuracy: 0.1684 0.1373 0.1459 0.3508 0.9562 0.1138 0.1162\n",
      "valid accuracy: 0.1632 0.1308 0.1495 0.3465 0.9539 0.1138 0.119\n",
      "valid accuracy: 0.1701 0.1308 0.1496 0.3509 0.9529 0.1137 0.1104\n",
      "valid accuracy: 0.1703 0.1349 0.1475 0.3506 0.9525 0.115 0.111\n",
      "valid accuracy: 0.173 0.1336 0.1472 0.3471 0.9553 0.1161 0.1193\n",
      "valid accuracy: 0.1704 0.1312 0.1462 0.3474 0.9554 0.1193 0.1161\n",
      "valid accuracy: 0.1693 0.1354 0.1509 0.3503 0.9547 0.1126 0.1157\n",
      "valid accuracy: 0.1665 0.1384 0.1494 0.3583 0.9556 0.1121 0.1181\n",
      "valid accuracy: 0.1714 0.1368 0.1501 0.3549 0.954 0.114 0.1157\n",
      "valid accuracy: 0.1734 0.1374 0.1494 0.3505 0.9536 0.1138 0.1173\n",
      "valid accuracy: 0.1699 0.1354 0.1454 0.3468 0.9537 0.1143 0.1156\n",
      "valid accuracy: 0.1697 0.1362 0.1458 0.3456 0.9553 0.1168 0.1171\n",
      "valid accuracy: 0.1679 0.1335 0.147 0.3479 0.9555 0.1142 0.1163\n",
      "valid accuracy: 0.1671 0.135 0.1456 0.3535 0.9541 0.1153 0.1164\n",
      "valid accuracy: 0.1716 0.1381 0.1485 0.3501 0.9536 0.1133 0.1151\n",
      "valid accuracy: 0.1665 0.1348 0.1498 0.348 0.9544 0.1152 0.1184\n",
      "valid accuracy: 0.1733 0.1373 0.1503 0.3496 0.9553 0.1127 0.113\n",
      "valid accuracy: 0.1668 0.1357 0.1489 0.354 0.9552 0.1069 0.1193\n",
      "valid accuracy: 0.1721 0.1378 0.1509 0.3473 0.954 0.114 0.1211\n",
      "valid accuracy: 0.1654 0.1333 0.1456 0.3482 0.9536 0.1167 0.1153\n",
      "valid accuracy: 0.1703 0.1321 0.1456 0.3544 0.9565 0.1111 0.1156\n",
      "ep 200, batch 0, training accuracy 0.95\n",
      "ep 200, batch 50, training accuracy 0.925\n",
      "ep 200, batch 100, training accuracy 0.945\n",
      "ep 200, batch 150, training accuracy 0.95\n",
      "ep 200, batch 200, training accuracy 0.97\n",
      "valid accuracy: 0.1714 0.1388 0.1478 0.3466 0.9526 0.1151 0.1193\n",
      "valid accuracy: 0.1687 0.1324 0.1495 0.3523 0.9538 0.1153 0.1144\n",
      "valid accuracy: 0.1667 0.1358 0.1478 0.3492 0.9547 0.1113 0.1173\n",
      "valid accuracy: 0.167 0.1382 0.147 0.3532 0.9564 0.1118 0.1158\n",
      "valid accuracy: 0.1703 0.1415 0.1474 0.3489 0.9536 0.113 0.1154\n",
      "valid accuracy: 0.1701 0.1342 0.1509 0.3431 0.9542 0.113 0.1235\n",
      "valid accuracy: 0.1752 0.1339 0.1494 0.3488 0.9522 0.114 0.116\n",
      "valid accuracy: 0.1653 0.1375 0.1479 0.3541 0.9537 0.1151 0.1136\n",
      "valid accuracy: 0.1676 0.1335 0.1464 0.3482 0.9521 0.114 0.1161\n",
      "valid accuracy: 0.1679 0.1379 0.1484 0.3474 0.9558 0.1101 0.1188\n",
      "valid accuracy: 0.1636 0.1327 0.1471 0.3486 0.9541 0.1113 0.1176\n",
      "valid accuracy: 0.1696 0.1301 0.1462 0.3562 0.9541 0.1124 0.1141\n",
      "valid accuracy: 0.1668 0.1313 0.1462 0.3557 0.9538 0.1102 0.12\n",
      "valid accuracy: 0.1689 0.1377 0.148 0.3457 0.9553 0.1126 0.1166\n",
      "valid accuracy: 0.1687 0.1368 0.1517 0.3481 0.9534 0.1129 0.1144\n",
      "valid accuracy: 0.1676 0.137 0.1493 0.3549 0.954 0.1116 0.1175\n",
      "valid accuracy: 0.17 0.1363 0.1455 0.3531 0.9572 0.1095 0.1153\n",
      "valid accuracy: 0.1705 0.1378 0.1498 0.3486 0.9544 0.1116 0.1149\n",
      "valid accuracy: 0.1658 0.1322 0.148 0.3519 0.9568 0.1132 0.116\n",
      "valid accuracy: 0.17 0.1307 0.1499 0.3498 0.9549 0.1139 0.1161\n",
      "valid accuracy: 0.1683 0.1335 0.1449 0.3525 0.9566 0.1162 0.1131\n",
      "valid accuracy: 0.1671 0.136 0.1489 0.3552 0.9563 0.1125 0.1185\n",
      "valid accuracy: 0.1685 0.1335 0.1471 0.3436 0.9539 0.1111 0.1171\n",
      "valid accuracy: 0.169 0.1319 0.1432 0.3467 0.9531 0.1147 0.1182\n",
      "valid accuracy: 0.1706 0.132 0.1458 0.3505 0.9547 0.1122 0.1165\n",
      "valid accuracy: 0.174 0.1308 0.1485 0.35 0.9545 0.111 0.1188\n",
      "valid accuracy: 0.1684 0.136 0.155 0.3499 0.9547 0.1129 0.1127\n",
      "valid accuracy: 0.1669 0.1332 0.1486 0.3513 0.9539 0.1152 0.116\n",
      "valid accuracy: 0.1661 0.1364 0.1473 0.3471 0.9544 0.1134 0.1162\n",
      "valid accuracy: 0.1731 0.1328 0.1483 0.3509 0.953 0.1145 0.1094\n",
      "valid accuracy: 0.1664 0.1373 0.1507 0.3509 0.9532 0.1139 0.1129\n",
      "valid accuracy: 0.1701 0.1386 0.1458 0.347 0.9536 0.1144 0.1147\n",
      "valid accuracy: 0.1696 0.1355 0.1498 0.351 0.9556 0.1133 0.1179\n",
      "valid accuracy: 0.1705 0.1396 0.1493 0.3474 0.9551 0.1139 0.1143\n",
      "valid accuracy: 0.1642 0.1354 0.1495 0.3515 0.9556 0.111 0.1148\n",
      "valid accuracy: 0.1683 0.1361 0.1476 0.3533 0.9531 0.1143 0.1119\n",
      "valid accuracy: 0.1707 0.1289 0.1466 0.3522 0.9549 0.1141 0.1168\n",
      "valid accuracy: 0.1679 0.1318 0.1493 0.3508 0.9528 0.1137 0.1209\n",
      "valid accuracy: 0.1679 0.1341 0.1478 0.3478 0.954 0.1131 0.1181\n",
      "valid accuracy: 0.1709 0.1365 0.147 0.3509 0.9538 0.1158 0.1171\n",
      "valid accuracy: 0.1718 0.1342 0.1499 0.3603 0.9562 0.1107 0.1162\n",
      "valid accuracy: 0.1708 0.1388 0.15 0.3466 0.9539 0.1114 0.1162\n",
      "valid accuracy: 0.1683 0.1357 0.1474 0.35 0.9549 0.1132 0.116\n",
      "valid accuracy: 0.1705 0.1331 0.1437 0.3465 0.9551 0.114 0.1164\n",
      "valid accuracy: 0.1684 0.1367 0.1488 0.3436 0.955 0.1145 0.1173\n",
      "valid accuracy: 0.17 0.1344 0.1476 0.3507 0.9536 0.1179 0.1148\n",
      "valid accuracy: 0.1689 0.1311 0.1474 0.3543 0.9524 0.1191 0.1158\n",
      "valid accuracy: 0.1676 0.1304 0.1484 0.3534 0.9543 0.1175 0.1166\n",
      "valid accuracy: 0.1664 0.1349 0.146 0.3506 0.9543 0.1129 0.1157\n",
      "valid accuracy: 0.1696 0.1348 0.1453 0.3514 0.9544 0.1133 0.1193\n",
      "ep 250, batch 0, training accuracy 0.95\n",
      "ep 250, batch 50, training accuracy 0.94\n",
      "ep 250, batch 100, training accuracy 0.945\n",
      "ep 250, batch 150, training accuracy 0.95\n",
      "ep 250, batch 200, training accuracy 0.985\n",
      "valid accuracy: 0.1651 0.1387 0.1453 0.352 0.9539 0.1121 0.119\n",
      "valid accuracy: 0.1709 0.1377 0.15 0.3527 0.9547 0.1142 0.118\n",
      "valid accuracy: 0.1707 0.1362 0.1469 0.3449 0.9544 0.117 0.1134\n",
      "valid accuracy: 0.1713 0.1322 0.1491 0.3492 0.9551 0.116 0.1191\n",
      "valid accuracy: 0.172 0.1336 0.1461 0.3587 0.955 0.1187 0.1178\n",
      "valid accuracy: 0.166 0.1323 0.1498 0.3456 0.9535 0.1164 0.1237\n",
      "valid accuracy: 0.1697 0.131 0.1458 0.3515 0.9532 0.1134 0.1107\n",
      "valid accuracy: 0.1716 0.1297 0.1483 0.349 0.9558 0.1142 0.1173\n",
      "valid accuracy: 0.1724 0.1368 0.1458 0.3488 0.956 0.1128 0.1164\n",
      "valid accuracy: 0.1686 0.133 0.1472 0.3531 0.9553 0.1134 0.1187\n",
      "valid accuracy: 0.1712 0.1325 0.1481 0.3505 0.9542 0.1132 0.1174\n",
      "valid accuracy: 0.1694 0.137 0.15 0.3489 0.9528 0.1123 0.1149\n",
      "valid accuracy: 0.1655 0.1347 0.1462 0.3481 0.9534 0.1126 0.1193\n",
      "valid accuracy: 0.1676 0.1349 0.1479 0.353 0.9546 0.1148 0.1175\n",
      "valid accuracy: 0.1678 0.1305 0.1451 0.3446 0.9504 0.1116 0.1136\n",
      "valid accuracy: 0.166 0.1343 0.1462 0.3529 0.9551 0.1186 0.1142\n",
      "valid accuracy: 0.1648 0.1333 0.1516 0.3535 0.9554 0.1141 0.1198\n",
      "valid accuracy: 0.1698 0.1337 0.1472 0.3526 0.9561 0.1165 0.1172\n",
      "valid accuracy: 0.1683 0.1334 0.1486 0.346 0.9564 0.1151 0.1164\n",
      "valid accuracy: 0.1698 0.1369 0.1476 0.3511 0.9542 0.1129 0.1179\n",
      "valid accuracy: 0.173 0.1351 0.1454 0.3552 0.9553 0.1135 0.1165\n",
      "valid accuracy: 0.1669 0.1353 0.1442 0.3511 0.9549 0.1159 0.1211\n",
      "valid accuracy: 0.1721 0.1386 0.147 0.3493 0.9547 0.1119 0.1179\n",
      "valid accuracy: 0.1662 0.1318 0.146 0.349 0.9559 0.1153 0.1175\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.07\n",
      "ep 0, batch 50, training accuracy 0.53\n",
      "ep 0, batch 100, training accuracy 0.485\n",
      "ep 0, batch 150, training accuracy 0.49\n",
      "ep 0, batch 200, training accuracy 0.65\n",
      "valid accuracy: 0.1474 0.1269 0.18 0.2584 0.843 0.6636 0.1185\n",
      "valid accuracy: 0.1313 0.1075 0.151 0.2285 0.8363 0.7543 0.1211\n",
      "valid accuracy: 0.1271 0.1098 0.1485 0.2454 0.8119 0.7936 0.1157\n",
      "valid accuracy: 0.1165 0.1038 0.1166 0.2168 0.786 0.8423 0.1021\n",
      "valid accuracy: 0.111 0.1114 0.1097 0.2083 0.7814 0.8636 0.0987\n",
      "valid accuracy: 0.104 0.1024 0.1132 0.2144 0.7649 0.8771 0.1031\n",
      "valid accuracy: 0.1115 0.1205 0.1135 0.1983 0.7409 0.8902 0.1055\n",
      "valid accuracy: 0.1116 0.1063 0.1062 0.1965 0.7208 0.8929 0.0982\n",
      "valid accuracy: 0.1175 0.0963 0.1053 0.193 0.7205 0.9061 0.0929\n",
      "valid accuracy: 0.112 0.1164 0.1118 0.1948 0.6716 0.9085 0.1037\n",
      "valid accuracy: 0.1074 0.1137 0.0934 0.1835 0.6752 0.9123 0.1004\n",
      "valid accuracy: 0.1031 0.1176 0.1037 0.1902 0.6493 0.9154 0.1068\n",
      "valid accuracy: 0.0975 0.1114 0.0919 0.1948 0.6594 0.9184 0.1033\n",
      "valid accuracy: 0.1119 0.1118 0.1105 0.1917 0.6766 0.9207 0.1009\n",
      "valid accuracy: 0.1046 0.0964 0.0937 0.1789 0.631 0.9218 0.0935\n",
      "valid accuracy: 0.113 0.0976 0.1025 0.1894 0.5979 0.9252 0.091\n",
      "valid accuracy: 0.1136 0.101 0.0946 0.1967 0.5825 0.928 0.096\n",
      "valid accuracy: 0.1217 0.104 0.1077 0.1818 0.5784 0.9294 0.0966\n",
      "valid accuracy: 0.1189 0.1059 0.0957 0.1807 0.589 0.9331 0.0994\n",
      "valid accuracy: 0.102 0.0934 0.1084 0.1698 0.5351 0.9277 0.0914\n",
      "valid accuracy: 0.116 0.1185 0.1012 0.1775 0.5493 0.9298 0.0956\n",
      "valid accuracy: 0.1192 0.1031 0.0978 0.1842 0.5695 0.9361 0.0968\n",
      "valid accuracy: 0.1133 0.1251 0.0976 0.1952 0.5299 0.9352 0.1006\n",
      "valid accuracy: 0.1192 0.1009 0.1013 0.1588 0.5086 0.935 0.0907\n",
      "valid accuracy: 0.1185 0.1043 0.1039 0.1776 0.5322 0.9368 0.0978\n",
      "valid accuracy: 0.1118 0.0938 0.113 0.1504 0.5177 0.9352 0.0909\n",
      "valid accuracy: 0.1151 0.1038 0.1105 0.1788 0.5369 0.9394 0.0978\n",
      "valid accuracy: 0.1062 0.0989 0.1018 0.1669 0.5244 0.9401 0.0931\n",
      "valid accuracy: 0.1176 0.1113 0.1028 0.1837 0.5159 0.9396 0.0996\n",
      "valid accuracy: 0.1131 0.0921 0.0939 0.147 0.4966 0.9395 0.091\n",
      "valid accuracy: 0.1225 0.0951 0.0984 0.1661 0.5013 0.9411 0.1001\n",
      "valid accuracy: 0.1278 0.0999 0.1013 0.1588 0.5111 0.9397 0.0957\n",
      "valid accuracy: 0.113 0.1012 0.1029 0.1631 0.5085 0.9422 0.1017\n",
      "valid accuracy: 0.1029 0.1114 0.1129 0.1837 0.5316 0.9435 0.1046\n",
      "valid accuracy: 0.1171 0.1181 0.109 0.1731 0.516 0.9439 0.1014\n",
      "valid accuracy: 0.1011 0.1072 0.0999 0.1809 0.4985 0.9434 0.1003\n",
      "valid accuracy: 0.1144 0.094 0.0995 0.1642 0.473 0.9447 0.0965\n",
      "valid accuracy: 0.1076 0.0907 0.1046 0.1603 0.498 0.9431 0.0991\n",
      "valid accuracy: 0.1148 0.0983 0.1094 0.1558 0.4856 0.9426 0.1006\n",
      "valid accuracy: 0.1108 0.1197 0.1087 0.1796 0.5095 0.9449 0.1012\n",
      "valid accuracy: 0.1108 0.1025 0.1158 0.1733 0.4616 0.9445 0.1026\n",
      "valid accuracy: 0.1119 0.0855 0.1047 0.1683 0.4773 0.9466 0.1031\n",
      "valid accuracy: 0.1174 0.0959 0.1191 0.1681 0.4833 0.9472 0.1069\n",
      "valid accuracy: 0.1076 0.0886 0.113 0.1746 0.4715 0.9456 0.0982\n",
      "valid accuracy: 0.1066 0.1042 0.1043 0.1861 0.4755 0.9455 0.0974\n",
      "valid accuracy: 0.1155 0.1018 0.1076 0.1761 0.4749 0.9494 0.1113\n",
      "valid accuracy: 0.1152 0.0977 0.1012 0.1709 0.4778 0.9475 0.1074\n",
      "valid accuracy: 0.1101 0.095 0.1104 0.1706 0.4502 0.9483 0.1014\n",
      "valid accuracy: 0.0981 0.0978 0.1092 0.1723 0.4472 0.9466 0.1027\n",
      "valid accuracy: 0.1168 0.0991 0.1099 0.1787 0.4508 0.9485 0.0984\n",
      "ep 50, batch 0, training accuracy 0.96\n",
      "ep 50, batch 50, training accuracy 0.965\n",
      "ep 50, batch 100, training accuracy 0.92\n",
      "ep 50, batch 150, training accuracy 0.935\n",
      "ep 50, batch 200, training accuracy 0.955\n",
      "valid accuracy: 0.1153 0.0985 0.1121 0.1776 0.4447 0.9487 0.1105\n",
      "valid accuracy: 0.114 0.0985 0.1082 0.1641 0.4441 0.9521 0.1037\n",
      "valid accuracy: 0.0999 0.089 0.1135 0.1556 0.4346 0.9485 0.1012\n",
      "valid accuracy: 0.1129 0.0945 0.1063 0.1735 0.4335 0.951 0.1093\n",
      "valid accuracy: 0.1047 0.0922 0.1078 0.1435 0.4357 0.9479 0.1034\n",
      "valid accuracy: 0.1064 0.0954 0.1102 0.1539 0.4393 0.9499 0.1022\n",
      "valid accuracy: 0.1074 0.0933 0.1067 0.1623 0.454 0.9507 0.0992\n",
      "valid accuracy: 0.1054 0.095 0.1078 0.1626 0.4224 0.9522 0.1066\n",
      "valid accuracy: 0.1057 0.0896 0.1151 0.1547 0.4331 0.9518 0.1043\n",
      "valid accuracy: 0.1077 0.0921 0.1095 0.1598 0.4374 0.951 0.1036\n",
      "valid accuracy: 0.1049 0.0987 0.1063 0.1671 0.4414 0.9517 0.1029\n",
      "valid accuracy: 0.1077 0.099 0.106 0.1592 0.421 0.9544 0.1043\n",
      "valid accuracy: 0.1049 0.096 0.1113 0.167 0.4148 0.951 0.0987\n",
      "valid accuracy: 0.107 0.092 0.1061 0.16 0.4226 0.9514 0.1036\n",
      "valid accuracy: 0.1127 0.0988 0.1061 0.1598 0.4221 0.9557 0.0979\n",
      "valid accuracy: 0.1083 0.0986 0.1077 0.1654 0.4185 0.9527 0.1047\n",
      "valid accuracy: 0.1101 0.1033 0.1077 0.1715 0.4344 0.9525 0.1024\n",
      "valid accuracy: 0.1057 0.0993 0.1061 0.1677 0.4286 0.9539 0.1053\n",
      "valid accuracy: 0.1048 0.0999 0.104 0.1614 0.4248 0.9535 0.1053\n",
      "valid accuracy: 0.1057 0.0947 0.1091 0.164 0.429 0.9533 0.1066\n",
      "valid accuracy: 0.1108 0.097 0.109 0.1678 0.4205 0.9537 0.1051\n",
      "valid accuracy: 0.1057 0.0988 0.1095 0.1644 0.4226 0.9535 0.1046\n",
      "valid accuracy: 0.1123 0.1011 0.1076 0.166 0.4262 0.9556 0.1037\n",
      "valid accuracy: 0.109 0.0975 0.1107 0.1668 0.4178 0.9525 0.1049\n",
      "valid accuracy: 0.1061 0.0993 0.1056 0.1635 0.4198 0.9553 0.1037\n",
      "valid accuracy: 0.1093 0.0951 0.111 0.1591 0.4176 0.9542 0.1038\n",
      "valid accuracy: 0.1052 0.097 0.1059 0.1629 0.4213 0.9544 0.1074\n",
      "valid accuracy: 0.1091 0.097 0.1061 0.1625 0.4219 0.951 0.0989\n",
      "valid accuracy: 0.1056 0.0946 0.1091 0.156 0.42 0.9535 0.1093\n",
      "valid accuracy: 0.1094 0.0974 0.108 0.1547 0.4177 0.9539 0.1027\n",
      "valid accuracy: 0.1112 0.0987 0.1118 0.1612 0.4173 0.955 0.1062\n",
      "valid accuracy: 0.1113 0.1013 0.1074 0.1614 0.4236 0.9562 0.1058\n",
      "valid accuracy: 0.1089 0.0999 0.1067 0.1659 0.4187 0.9565 0.1037\n",
      "valid accuracy: 0.1084 0.1035 0.1042 0.1669 0.4224 0.9549 0.1078\n",
      "valid accuracy: 0.1101 0.1016 0.1075 0.1597 0.4197 0.9537 0.1036\n",
      "valid accuracy: 0.1072 0.0989 0.1076 0.1634 0.4209 0.9538 0.1038\n",
      "valid accuracy: 0.1076 0.1023 0.1056 0.1634 0.4217 0.9515 0.1026\n",
      "valid accuracy: 0.1075 0.0931 0.1032 0.1626 0.4187 0.9545 0.1089\n",
      "valid accuracy: 0.108 0.1007 0.1096 0.1605 0.4217 0.9546 0.1047\n",
      "valid accuracy: 0.1045 0.095 0.1091 0.1622 0.424 0.9542 0.1058\n",
      "valid accuracy: 0.1092 0.0996 0.1143 0.1658 0.4214 0.9547 0.1046\n",
      "valid accuracy: 0.107 0.0997 0.1041 0.1667 0.4278 0.953 0.1051\n",
      "valid accuracy: 0.108 0.0972 0.1079 0.1607 0.4188 0.9547 0.1031\n",
      "valid accuracy: 0.1058 0.1018 0.1072 0.1623 0.4182 0.954 0.1039\n",
      "valid accuracy: 0.1131 0.1007 0.1062 0.1633 0.417 0.9558 0.101\n",
      "valid accuracy: 0.1096 0.1012 0.1043 0.1622 0.4191 0.9522 0.1017\n",
      "valid accuracy: 0.1134 0.0969 0.1072 0.1637 0.4216 0.9568 0.1044\n",
      "valid accuracy: 0.108 0.096 0.109 0.1663 0.4237 0.9555 0.1069\n",
      "valid accuracy: 0.1066 0.095 0.1107 0.166 0.4155 0.9537 0.0986\n",
      "valid accuracy: 0.1089 0.0995 0.1041 0.1624 0.4113 0.9505 0.1072\n",
      "ep 100, batch 0, training accuracy 0.955\n",
      "ep 100, batch 50, training accuracy 0.975\n",
      "ep 100, batch 100, training accuracy 0.935\n",
      "ep 100, batch 150, training accuracy 0.935\n",
      "ep 100, batch 200, training accuracy 0.965\n",
      "valid accuracy: 0.1081 0.0942 0.1088 0.1614 0.4205 0.9546 0.1067\n",
      "valid accuracy: 0.1089 0.1006 0.107 0.16 0.4221 0.9533 0.1064\n",
      "valid accuracy: 0.1084 0.0948 0.1068 0.165 0.4235 0.9544 0.1073\n",
      "valid accuracy: 0.1047 0.0945 0.1076 0.1635 0.4206 0.9526 0.1034\n",
      "valid accuracy: 0.1109 0.0948 0.1096 0.1626 0.4212 0.9543 0.1015\n",
      "valid accuracy: 0.1094 0.099 0.1061 0.1629 0.421 0.9533 0.1046\n",
      "valid accuracy: 0.1091 0.1037 0.1106 0.1643 0.4178 0.9543 0.103\n",
      "valid accuracy: 0.1082 0.0979 0.1062 0.1581 0.4173 0.952 0.109\n",
      "valid accuracy: 0.1073 0.094 0.1097 0.1636 0.4243 0.9554 0.1035\n",
      "valid accuracy: 0.111 0.0941 0.1066 0.1639 0.4158 0.9531 0.1062\n",
      "valid accuracy: 0.1095 0.0999 0.1036 0.1607 0.4188 0.9534 0.1042\n",
      "valid accuracy: 0.1061 0.0937 0.1028 0.1629 0.4183 0.9526 0.1044\n",
      "valid accuracy: 0.1075 0.0971 0.1098 0.1598 0.4201 0.9556 0.1052\n",
      "valid accuracy: 0.1078 0.0993 0.1064 0.1656 0.4191 0.9541 0.1087\n",
      "valid accuracy: 0.1078 0.098 0.1055 0.164 0.4214 0.9558 0.1\n",
      "valid accuracy: 0.1061 0.0973 0.1055 0.1577 0.4194 0.9532 0.1096\n",
      "valid accuracy: 0.1054 0.0952 0.1063 0.1669 0.4215 0.9561 0.1029\n",
      "valid accuracy: 0.1112 0.097 0.1099 0.1617 0.4193 0.9547 0.1048\n",
      "valid accuracy: 0.1066 0.0929 0.109 0.158 0.4231 0.9551 0.101\n",
      "valid accuracy: 0.1074 0.0935 0.1054 0.1646 0.4178 0.954 0.1042\n",
      "valid accuracy: 0.1087 0.0941 0.1081 0.1609 0.4241 0.955 0.1063\n",
      "valid accuracy: 0.1082 0.0965 0.1125 0.1659 0.422 0.9536 0.1023\n",
      "=== cannot decay more. stop learning this batch ===\n",
      "ep 0, batch 0, training accuracy 0.05\n",
      "ep 0, batch 50, training accuracy 0.335\n",
      "ep 0, batch 100, training accuracy 0.48\n",
      "ep 0, batch 150, training accuracy 0.535\n",
      "ep 0, batch 200, training accuracy 0.685\n",
      "valid accuracy: 0.1488 0.131 0.1573 0.1384 0.3316 0.8358 0.6892\n",
      "valid accuracy: 0.1458 0.1275 0.1308 0.1278 0.312 0.768 0.8076\n",
      "valid accuracy: 0.1055 0.121 0.1287 0.1373 0.2995 0.7708 0.8406\n",
      "valid accuracy: 0.0885 0.1157 0.1217 0.1085 0.2354 0.6896 0.8661\n",
      "valid accuracy: 0.0753 0.1152 0.1188 0.1001 0.216 0.646 0.8784\n",
      "valid accuracy: 0.0877 0.1258 0.1234 0.1103 0.2211 0.6354 0.8885\n",
      "valid accuracy: 0.0869 0.1192 0.1192 0.112 0.2205 0.63 0.8972\n",
      "valid accuracy: 0.0923 0.1254 0.1165 0.1155 0.2414 0.6244 0.9059\n",
      "valid accuracy: 0.0838 0.1197 0.1073 0.1018 0.2165 0.5797 0.909\n",
      "valid accuracy: 0.0819 0.1193 0.12 0.114 0.2195 0.5903 0.9068\n",
      "valid accuracy: 0.0821 0.1151 0.1112 0.1075 0.2207 0.5699 0.9154\n",
      "valid accuracy: 0.0835 0.1161 0.1066 0.1133 0.207 0.5576 0.917\n",
      "valid accuracy: 0.0762 0.1169 0.1147 0.1143 0.202 0.5579 0.9174\n",
      "valid accuracy: 0.0712 0.1119 0.1089 0.1162 0.2006 0.5421 0.9229\n",
      "valid accuracy: 0.0806 0.118 0.1097 0.1084 0.2147 0.5624 0.9232\n",
      "valid accuracy: 0.0822 0.1292 0.1071 0.1165 0.212 0.5436 0.9252\n",
      "valid accuracy: 0.0741 0.1226 0.106 0.1179 0.223 0.5472 0.927\n",
      "valid accuracy: 0.0671 0.1173 0.1089 0.1198 0.2158 0.5627 0.9298\n",
      "valid accuracy: 0.0669 0.1157 0.1139 0.1144 0.2358 0.5555 0.9316\n",
      "valid accuracy: 0.0778 0.1168 0.1134 0.1099 0.2134 0.5412 0.9333\n",
      "valid accuracy: 0.0605 0.1157 0.1121 0.1158 0.2112 0.5165 0.9328\n",
      "valid accuracy: 0.0808 0.1138 0.1187 0.1147 0.1994 0.4705 0.934\n",
      "valid accuracy: 0.0806 0.1196 0.1162 0.1084 0.2207 0.5094 0.9341\n",
      "valid accuracy: 0.0815 0.1135 0.1112 0.1121 0.223 0.5246 0.9384\n",
      "valid accuracy: 0.0688 0.1187 0.1019 0.1152 0.2082 0.4941 0.9403\n",
      "valid accuracy: 0.0807 0.1222 0.1031 0.1111 0.2093 0.452 0.9383\n",
      "valid accuracy: 0.0704 0.1143 0.1077 0.1233 0.2305 0.5005 0.9374\n",
      "valid accuracy: 0.0728 0.1144 0.1067 0.1099 0.205 0.451 0.9382\n",
      "valid accuracy: 0.0649 0.115 0.1107 0.1167 0.2237 0.5162 0.9351\n",
      "valid accuracy: 0.0598 0.1185 0.0991 0.1073 0.2194 0.4812 0.9412\n",
      "valid accuracy: 0.0612 0.1168 0.1029 0.1129 0.2139 0.4888 0.94\n",
      "valid accuracy: 0.0632 0.1059 0.1113 0.1119 0.2164 0.457 0.9427\n",
      "valid accuracy: 0.0632 0.1119 0.103 0.1117 0.2158 0.4725 0.9422\n",
      "valid accuracy: 0.0676 0.1072 0.1043 0.117 0.1941 0.4508 0.9441\n",
      "valid accuracy: 0.0686 0.1086 0.1043 0.1057 0.2167 0.4761 0.9449\n",
      "valid accuracy: 0.059 0.1105 0.1102 0.1073 0.2331 0.4933 0.9429\n",
      "valid accuracy: 0.0614 0.1118 0.1064 0.1043 0.2067 0.4323 0.9419\n",
      "valid accuracy: 0.0595 0.1118 0.1153 0.1075 0.2116 0.4619 0.9434\n",
      "valid accuracy: 0.0553 0.1024 0.0948 0.1031 0.1784 0.366 0.9438\n",
      "valid accuracy: 0.0681 0.1112 0.1009 0.1044 0.2129 0.4525 0.9445\n",
      "valid accuracy: 0.068 0.1154 0.1009 0.1053 0.2253 0.4296 0.9458\n",
      "valid accuracy: 0.064 0.1115 0.0994 0.1001 0.2026 0.4136 0.9469\n",
      "valid accuracy: 0.0657 0.1094 0.1003 0.0994 0.2054 0.3769 0.945\n",
      "valid accuracy: 0.0642 0.1064 0.1013 0.0956 0.196 0.3779 0.946\n",
      "valid accuracy: 0.0618 0.11 0.1059 0.1009 0.2224 0.4156 0.9468\n",
      "valid accuracy: 0.0679 0.1093 0.1001 0.1037 0.2075 0.3805 0.9469\n",
      "valid accuracy: 0.0703 0.1102 0.1056 0.1052 0.2059 0.381 0.9486\n",
      "valid accuracy: 0.0617 0.1073 0.1023 0.1021 0.2158 0.3748 0.9481\n",
      "valid accuracy: 0.0536 0.1184 0.1044 0.0971 0.2324 0.4078 0.9489\n",
      "valid accuracy: 0.0638 0.1166 0.1028 0.1025 0.2133 0.3808 0.9459\n",
      "ep 50, batch 0, training accuracy 0.93\n",
      "ep 50, batch 50, training accuracy 0.945\n",
      "ep 50, batch 100, training accuracy 0.93\n",
      "ep 50, batch 150, training accuracy 0.925\n",
      "ep 50, batch 200, training accuracy 0.975\n",
      "valid accuracy: 0.0629 0.1067 0.1021 0.103 0.2251 0.3864 0.9473\n",
      "valid accuracy: 0.0591 0.1119 0.0947 0.0975 0.2096 0.3739 0.9514\n",
      "valid accuracy: 0.0566 0.1125 0.1048 0.0988 0.2129 0.3741 0.9493\n",
      "valid accuracy: 0.053 0.1109 0.1017 0.1034 0.2112 0.364 0.9508\n",
      "valid accuracy: 0.0611 0.1102 0.1009 0.1 0.2137 0.3551 0.9494\n",
      "valid accuracy: 0.0563 0.1121 0.099 0.0958 0.2079 0.3584 0.9515\n",
      "valid accuracy: 0.0551 0.1138 0.102 0.1069 0.2129 0.356 0.9514\n",
      "valid accuracy: 0.0604 0.1125 0.0974 0.1041 0.2101 0.3488 0.9523\n",
      "valid accuracy: 0.0539 0.1131 0.0926 0.1007 0.208 0.357 0.9524\n",
      "valid accuracy: 0.0558 0.1095 0.0941 0.1042 0.21 0.3435 0.9528\n",
      "valid accuracy: 0.0567 0.1077 0.0986 0.0998 0.2122 0.3623 0.9545\n",
      "valid accuracy: 0.0592 0.1092 0.0984 0.1035 0.2061 0.3566 0.9533\n",
      "valid accuracy: 0.0534 0.1128 0.0974 0.1031 0.2079 0.3512 0.9518\n",
      "valid accuracy: 0.0605 0.1092 0.0962 0.1027 0.2038 0.3411 0.9529\n",
      "valid accuracy: 0.055 0.1099 0.0949 0.0996 0.2039 0.3533 0.9527\n",
      "valid accuracy: 0.0578 0.1075 0.0967 0.1042 0.2074 0.3507 0.9518\n",
      "valid accuracy: 0.0563 0.1024 0.0966 0.0966 0.2054 0.354 0.9549\n",
      "valid accuracy: 0.0569 0.1056 0.0975 0.1001 0.2022 0.3506 0.9544\n",
      "valid accuracy: 0.0562 0.1067 0.0962 0.1019 0.2002 0.3576 0.9527\n",
      "valid accuracy: 0.0569 0.1076 0.0986 0.0965 0.2041 0.3603 0.9527\n",
      "valid accuracy: 0.0592 0.1089 0.1009 0.1015 0.2056 0.3562 0.9522\n",
      "valid accuracy: 0.0595 0.1091 0.1006 0.1025 0.2081 0.3589 0.955\n",
      "valid accuracy: 0.0619 0.1107 0.0984 0.0948 0.2035 0.3513 0.9517\n",
      "valid accuracy: 0.0588 0.1089 0.0984 0.1017 0.2002 0.3543 0.9517\n",
      "valid accuracy: 0.0605 0.1109 0.0937 0.0971 0.2068 0.3534 0.9521\n",
      "valid accuracy: 0.0598 0.1084 0.0996 0.0981 0.2054 0.357 0.9545\n",
      "valid accuracy: 0.0588 0.112 0.095 0.0993 0.2063 0.3563 0.953\n",
      "valid accuracy: 0.0591 0.1058 0.1011 0.0978 0.2005 0.3587 0.9534\n",
      "valid accuracy: 0.0573 0.1059 0.0986 0.0956 0.2069 0.35 0.9541\n",
      "valid accuracy: 0.056 0.1096 0.0975 0.0988 0.2062 0.3518 0.9543\n",
      "valid accuracy: 0.0571 0.1132 0.0985 0.1016 0.2109 0.3546 0.955\n",
      "valid accuracy: 0.058 0.11 0.0952 0.1012 0.2044 0.3518 0.9531\n",
      "valid accuracy: 0.0618 0.1076 0.0964 0.0988 0.2078 0.3516 0.9542\n",
      "valid accuracy: 0.0592 0.1098 0.0949 0.1006 0.2034 0.3495 0.9509\n",
      "valid accuracy: 0.0611 0.1103 0.0985 0.1002 0.204 0.3537 0.9524\n",
      "valid accuracy: 0.0581 0.1075 0.0947 0.1012 0.2049 0.3579 0.9543\n",
      "valid accuracy: 0.0602 0.1079 0.0936 0.1006 0.2032 0.3561 0.9562\n",
      "valid accuracy: 0.0598 0.1074 0.0943 0.0983 0.2078 0.3477 0.9516\n",
      "valid accuracy: 0.0632 0.1028 0.0961 0.0974 0.2063 0.3535 0.9547\n",
      "valid accuracy: 0.0578 0.1154 0.0974 0.0977 0.2042 0.3515 0.9561\n",
      "valid accuracy: 0.0639 0.111 0.0979 0.0988 0.1985 0.3527 0.9527\n",
      "valid accuracy: 0.0616 0.1133 0.0958 0.0999 0.2015 0.3448 0.9538\n",
      "valid accuracy: 0.0624 0.1077 0.0955 0.0979 0.2019 0.3537 0.955\n",
      "valid accuracy: 0.0619 0.1079 0.1023 0.0973 0.1999 0.3514 0.9538\n",
      "valid accuracy: 0.0623 0.1098 0.0943 0.0984 0.2043 0.3496 0.9545\n",
      "valid accuracy: 0.0587 0.1093 0.0963 0.0994 0.2059 0.3522 0.9555\n",
      "valid accuracy: 0.0591 0.1106 0.097 0.0996 0.2028 0.3516 0.9541\n",
      "valid accuracy: 0.0583 0.1067 0.0944 0.1041 0.2035 0.3459 0.955\n",
      "valid accuracy: 0.0644 0.1055 0.0973 0.0994 0.2036 0.3512 0.9534\n",
      "valid accuracy: 0.0619 0.1107 0.0977 0.1004 0.2056 0.3503 0.9548\n",
      "ep 100, batch 0, training accuracy 0.955\n",
      "ep 100, batch 50, training accuracy 0.93\n",
      "ep 100, batch 100, training accuracy 0.925\n",
      "ep 100, batch 150, training accuracy 0.95\n",
      "ep 100, batch 200, training accuracy 0.98\n",
      "valid accuracy: 0.0581 0.1084 0.0937 0.0992 0.2 0.3458 0.9537\n",
      "valid accuracy: 0.0595 0.1095 0.0945 0.0983 0.2022 0.3486 0.9542\n",
      "valid accuracy: 0.0595 0.1117 0.0966 0.1014 0.2045 0.3455 0.9522\n",
      "valid accuracy: 0.057 0.1048 0.0981 0.0979 0.2033 0.3455 0.9559\n",
      "valid accuracy: 0.059 0.1105 0.0967 0.1005 0.203 0.3524 0.9518\n",
      "valid accuracy: 0.0576 0.1102 0.0928 0.1008 0.2053 0.3493 0.9535\n",
      "valid accuracy: 0.0616 0.109 0.0959 0.101 0.2019 0.3467 0.9549\n",
      "valid accuracy: 0.0612 0.1148 0.0994 0.1005 0.2011 0.3453 0.9532\n",
      "valid accuracy: 0.0628 0.1116 0.0952 0.102 0.2051 0.3496 0.9522\n",
      "valid accuracy: 0.0599 0.1121 0.0953 0.101 0.211 0.3532 0.9527\n",
      "valid accuracy: 0.06 0.1147 0.0969 0.0977 0.2048 0.3505 0.9527\n",
      "valid accuracy: 0.061 0.1067 0.098 0.1009 0.204 0.3458 0.9536\n",
      "valid accuracy: 0.0622 0.1098 0.0936 0.0981 0.2029 0.3526 0.9551\n",
      "valid accuracy: 0.0618 0.1109 0.0956 0.0987 0.205 0.3495 0.9531\n",
      "valid accuracy: 0.0636 0.1119 0.0945 0.1009 0.2039 0.3481 0.9539\n",
      "valid accuracy: 0.059 0.1072 0.093 0.0972 0.204 0.3519 0.9538\n",
      "valid accuracy: 0.061 0.1131 0.0958 0.1001 0.2022 0.3485 0.9536\n",
      "valid accuracy: 0.0633 0.1139 0.096 0.0994 0.2042 0.351 0.9549\n",
      "valid accuracy: 0.0584 0.1111 0.0931 0.1 0.2004 0.3535 0.952\n",
      "valid accuracy: 0.0595 0.1109 0.0965 0.0999 0.204 0.3538 0.9537\n",
      "valid accuracy: 0.0633 0.1069 0.0931 0.098 0.2048 0.3508 0.9546\n",
      "valid accuracy: 0.0563 0.1077 0.0952 0.0985 0.2026 0.3429 0.9517\n",
      "valid accuracy: 0.0611 0.1086 0.0959 0.1001 0.1972 0.3539 0.9535\n",
      "valid accuracy: 0.0598 0.1069 0.0971 0.0981 0.2031 0.346 0.9544\n",
      "valid accuracy: 0.0612 0.1101 0.098 0.0991 0.1997 0.3515 0.9551\n",
      "valid accuracy: 0.0599 0.1094 0.0958 0.1007 0.2031 0.3522 0.9549\n",
      "valid accuracy: 0.0571 0.11 0.0992 0.1001 0.2058 0.3498 0.9556\n",
      "valid accuracy: 0.0589 0.1095 0.0962 0.1015 0.2078 0.3538 0.9537\n",
      "valid accuracy: 0.0587 0.1091 0.0954 0.0996 0.1972 0.3548 0.9547\n",
      "valid accuracy: 0.0587 0.1095 0.0937 0.1032 0.2062 0.3489 0.9541\n",
      "valid accuracy: 0.0588 0.113 0.1008 0.0988 0.1996 0.3521 0.9533\n",
      "valid accuracy: 0.0632 0.1052 0.0996 0.1019 0.2033 0.3495 0.9554\n",
      "valid accuracy: 0.0576 0.1058 0.1007 0.1017 0.2082 0.3526 0.953\n",
      "valid accuracy: 0.0547 0.1113 0.0923 0.1008 0.1993 0.3555 0.955\n",
      "valid accuracy: 0.0595 0.1084 0.0971 0.0974 0.2027 0.3524 0.9544\n",
      "valid accuracy: 0.058 0.1105 0.0994 0.0975 0.1988 0.3533 0.9545\n",
      "valid accuracy: 0.0612 0.1097 0.0979 0.1021 0.2056 0.3488 0.9543\n",
      "valid accuracy: 0.0606 0.1046 0.0952 0.1008 0.202 0.3501 0.9523\n",
      "valid accuracy: 0.0609 0.112 0.0986 0.1017 0.2059 0.3509 0.9548\n",
      "valid accuracy: 0.0613 0.1133 0.0977 0.0984 0.2015 0.3535 0.9548\n",
      "valid accuracy: 0.0605 0.1072 0.0962 0.1028 0.2031 0.3467 0.9543\n",
      "valid accuracy: 0.0616 0.1093 0.0941 0.0944 0.2036 0.3483 0.9542\n",
      "valid accuracy: 0.0582 0.1103 0.0958 0.0985 0.2029 0.3527 0.9553\n",
      "valid accuracy: 0.0626 0.1092 0.097 0.1016 0.2013 0.3482 0.9541\n",
      "valid accuracy: 0.0573 0.107 0.0959 0.1003 0.2018 0.347 0.9541\n",
      "valid accuracy: 0.0602 0.1095 0.1003 0.0983 0.2004 0.3562 0.9527\n",
      "valid accuracy: 0.0626 0.1137 0.1021 0.0975 0.2026 0.3541 0.9529\n",
      "valid accuracy: 0.0595 0.1098 0.0949 0.1008 0.2006 0.3516 0.9521\n",
      "valid accuracy: 0.0602 0.1109 0.0943 0.1016 0.2035 0.3532 0.9531\n",
      "valid accuracy: 0.062 0.1069 0.0978 0.097 0.2029 0.3509 0.9539\n",
      "ep 150, batch 0, training accuracy 0.955\n",
      "ep 150, batch 50, training accuracy 0.965\n",
      "ep 150, batch 100, training accuracy 0.95\n",
      "ep 150, batch 150, training accuracy 0.935\n",
      "ep 150, batch 200, training accuracy 0.965\n",
      "valid accuracy: 0.059 0.1102 0.0929 0.0966 0.2009 0.3475 0.9516\n",
      "valid accuracy: 0.0592 0.1127 0.0986 0.1008 0.2065 0.3473 0.9523\n",
      "valid accuracy: 0.0595 0.1083 0.0993 0.0973 0.206 0.3537 0.9537\n",
      "valid accuracy: 0.063 0.1081 0.0984 0.1026 0.1994 0.353 0.9544\n",
      "valid accuracy: 0.0614 0.1095 0.0985 0.1022 0.2 0.3474 0.9546\n",
      "valid accuracy: 0.0599 0.1105 0.0997 0.099 0.2067 0.347 0.9523\n",
      "valid accuracy: 0.0606 0.1053 0.0954 0.0989 0.2032 0.3549 0.9546\n",
      "valid accuracy: 0.0604 0.1086 0.1006 0.1014 0.2019 0.3495 0.9546\n",
      "valid accuracy: 0.0594 0.1092 0.0974 0.1002 0.1939 0.3469 0.9536\n",
      "valid accuracy: 0.0592 0.1073 0.0992 0.1001 0.2124 0.3543 0.9527\n",
      "valid accuracy: 0.0595 0.1069 0.0952 0.0986 0.2072 0.3572 0.9526\n",
      "valid accuracy: 0.0603 0.1077 0.0996 0.101 0.2059 0.3543 0.9549\n",
      "valid accuracy: 0.0587 0.1107 0.0954 0.1021 0.2011 0.3493 0.9527\n",
      "valid accuracy: 0.0605 0.1109 0.0973 0.1017 0.2042 0.3512 0.954\n",
      "valid accuracy: 0.0595 0.1087 0.0968 0.0996 0.2022 0.3504 0.9548\n",
      "valid accuracy: 0.059 0.1168 0.0989 0.0999 0.205 0.3593 0.9549\n",
      "valid accuracy: 0.0591 0.1066 0.0982 0.0984 0.2034 0.3574 0.9521\n",
      "valid accuracy: 0.0622 0.1076 0.0967 0.0988 0.1999 0.3551 0.9552\n",
      "valid accuracy: 0.0622 0.1074 0.0957 0.0994 0.1971 0.3527 0.9532\n",
      "valid accuracy: 0.0642 0.1116 0.0947 0.0945 0.2087 0.355 0.9546\n",
      "valid accuracy: 0.064 0.1139 0.0926 0.1014 0.2033 0.3546 0.9531\n",
      "valid accuracy: 0.0585 0.1084 0.0951 0.1007 0.2069 0.3455 0.9528\n",
      "valid accuracy: 0.0612 0.1109 0.0983 0.0997 0.2012 0.3429 0.9541\n",
      "valid accuracy: 0.0584 0.1074 0.1 0.0982 0.2065 0.3504 0.9543\n",
      "valid accuracy: 0.0599 0.105 0.0982 0.0999 0.2071 0.3462 0.9517\n",
      "valid accuracy: 0.0577 0.1101 0.0962 0.0967 0.2015 0.3477 0.9525\n",
      "valid accuracy: 0.0597 0.1082 0.0997 0.1033 0.2025 0.3502 0.9531\n",
      "valid accuracy: 0.0608 0.1133 0.0928 0.1008 0.2044 0.3566 0.9523\n",
      "valid accuracy: 0.06 0.1091 0.0944 0.0995 0.2015 0.3491 0.9552\n",
      "valid accuracy: 0.0581 0.1118 0.0937 0.1011 0.2048 0.3529 0.953\n",
      "valid accuracy: 0.0604 0.1115 0.0977 0.096 0.2019 0.348 0.9547\n",
      "valid accuracy: 0.06 0.1101 0.0966 0.1019 0.21 0.3479 0.9522\n",
      "valid accuracy: 0.0588 0.1083 0.09 0.0975 0.2057 0.3493 0.9536\n",
      "valid accuracy: 0.0595 0.1109 0.0932 0.0988 0.2018 0.3454 0.9548\n",
      "valid accuracy: 0.0586 0.1056 0.0953 0.1005 0.2001 0.3474 0.9554\n",
      "valid accuracy: 0.0607 0.1112 0.0979 0.1036 0.2013 0.3555 0.9548\n",
      "valid accuracy: 0.0606 0.1084 0.0984 0.0985 0.2022 0.3559 0.953\n",
      "valid accuracy: 0.0591 0.1086 0.0957 0.0988 0.2055 0.3487 0.9547\n",
      "valid accuracy: 0.0597 0.1132 0.1003 0.0962 0.2004 0.3533 0.953\n",
      "valid accuracy: 0.0592 0.1129 0.0957 0.1016 0.202 0.3538 0.9549\n",
      "valid accuracy: 0.0593 0.1079 0.0955 0.1015 0.2083 0.3552 0.9537\n",
      "valid accuracy: 0.0594 0.1093 0.0973 0.0984 0.2002 0.3505 0.9554\n",
      "valid accuracy: 0.0576 0.1116 0.0961 0.1025 0.2015 0.3543 0.9529\n",
      "valid accuracy: 0.0587 0.1093 0.0988 0.0987 0.2007 0.3538 0.9531\n",
      "valid accuracy: 0.0617 0.1074 0.0939 0.1006 0.2021 0.3507 0.9525\n",
      "valid accuracy: 0.0606 0.1084 0.0929 0.099 0.2025 0.3482 0.953\n",
      "valid accuracy: 0.0591 0.1072 0.099 0.105 0.2023 0.3579 0.9534\n",
      "valid accuracy: 0.059 0.1107 0.0954 0.1006 0.2007 0.346 0.9525\n",
      "valid accuracy: 0.0616 0.113 0.0965 0.0981 0.2 0.3495 0.9553\n",
      "valid accuracy: 0.0604 0.1101 0.092 0.1009 0.2044 0.3505 0.954\n",
      "ep 200, batch 0, training accuracy 0.955\n",
      "ep 200, batch 50, training accuracy 0.94\n",
      "ep 200, batch 100, training accuracy 0.95\n",
      "ep 200, batch 150, training accuracy 0.94\n",
      "ep 200, batch 200, training accuracy 0.985\n",
      "valid accuracy: 0.059 0.1094 0.0958 0.1011 0.2033 0.3495 0.9554\n",
      "valid accuracy: 0.063 0.1115 0.0961 0.0996 0.2044 0.3527 0.9547\n",
      "valid accuracy: 0.0578 0.1128 0.0926 0.098 0.2068 0.3578 0.9546\n",
      "valid accuracy: 0.0586 0.1074 0.0983 0.1006 0.2028 0.3435 0.9541\n",
      "valid accuracy: 0.0583 0.1134 0.0982 0.0973 0.2026 0.3489 0.9529\n",
      "valid accuracy: 0.0595 0.1085 0.0948 0.0961 0.207 0.351 0.953\n",
      "valid accuracy: 0.0622 0.1072 0.0945 0.1012 0.1989 0.3469 0.9553\n",
      "valid accuracy: 0.0639 0.1098 0.0943 0.0997 0.2038 0.3537 0.955\n",
      "valid accuracy: 0.0607 0.1114 0.0987 0.1005 0.2047 0.3549 0.956\n",
      "valid accuracy: 0.061 0.1063 0.0943 0.1009 0.2054 0.3535 0.9536\n",
      "valid accuracy: 0.0587 0.1086 0.0955 0.1025 0.2036 0.3482 0.9522\n",
      "valid accuracy: 0.0603 0.1113 0.0967 0.1019 0.202 0.3483 0.9539\n",
      "valid accuracy: 0.0606 0.1116 0.0963 0.0972 0.2026 0.3536 0.9532\n",
      "valid accuracy: 0.0571 0.1109 0.0946 0.1018 0.1999 0.3493 0.9536\n",
      "valid accuracy: 0.0591 0.1067 0.0976 0.0985 0.2002 0.3505 0.9554\n",
      "valid accuracy: 0.0605 0.1116 0.0979 0.0962 0.2037 0.3553 0.9538\n",
      "valid accuracy: 0.0592 0.1081 0.0949 0.0983 0.2004 0.3561 0.9535\n",
      "valid accuracy: 0.0613 0.1066 0.0978 0.0966 0.2055 0.3534 0.9538\n",
      "valid accuracy: 0.0613 0.1107 0.0962 0.1036 0.1983 0.3503 0.9543\n",
      "valid accuracy: 0.0582 0.1107 0.0984 0.0994 0.1988 0.3549 0.9541\n",
      "valid accuracy: 0.0599 0.1115 0.0958 0.0996 0.1986 0.3509 0.9547\n",
      "valid accuracy: 0.0596 0.1055 0.0986 0.0996 0.2066 0.3518 0.9552\n",
      "valid accuracy: 0.0602 0.1128 0.098 0.097 0.2032 0.3464 0.9537\n",
      "valid accuracy: 0.0578 0.1106 0.0945 0.0991 0.1988 0.3516 0.9546\n",
      "=== cannot decay more. stop learning this batch ===\n"
     ]
    }
   ],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "\n",
    "valid_size = batch_size\n",
    "n_split_valid = len(t_valid) / valid_size\n",
    "\n",
    "n_epochs = 500\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "taccs_bcnn_gal = list()\n",
    "#taccs_mean = list()\n",
    "vaccs_bcnn_gal = list()\n",
    "epochs_done = list()\n",
    "\n",
    "for i in range(n_datas):\n",
    "    vaccs_bcnn_gal.append(list())\n",
    "    \n",
    "for d in range(n_datas):\n",
    "    bcnn_gal.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "#             feed = {bcnn_gal.x: np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 28, 28, 1)), \\\n",
    "#                     bcnn_gal.t: t_train[i*batch_size:(i+1)*batch_size], \\\n",
    "#                     bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5], \\\n",
    "#                     bcnn_gal.n_samples: 1}\n",
    "            feed = {bcnn_gal.x: np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 28, 28, 1)), \\\n",
    "                    bcnn_gal.t: t_train[i*batch_size:(i+1)*batch_size], \\\n",
    "                    bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]}\n",
    "\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bcnn_gal.MCdropout(inp = np.reshape(x_train[d][i*batch_size:(i+1)*batch_size], (-1, 28, 28, 1)), \\\n",
    "                                                   tar = t_train[i*batch_size:(i+1)*batch_size], keep_probs = [0.5, 0.5, 0.5, 0.5], \\\n",
    "                                                   n_samples = 10)                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "\n",
    "            bcnn_gal.train(feed)\n",
    "\n",
    "        if ep > 5 and np.mean(taccs_bcnn_gal[-25:]) < taccs_bcnn_gal[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bcnn_gal.get_lr()\n",
    "                bcnn_gal.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bcnn_gal.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    epochs_done.append(ep)\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "                \n",
    "        if ep == (n_epochs) - 1: epochs_done.append(ep)\n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            valid_mean = 0.\n",
    "            for j in range(n_split_valid):\n",
    "                \n",
    "                valid_mean += bcnn_gal.MCdropout(inp = np.reshape(x_valid[i][j*valid_size:(j+1)*valid_size], (-1, 28, 28, 1)), \\\n",
    "                                                tar =  t_valid[j*valid_size:(j+1)*valid_size], keep_probs = [0.5, 0.5, 0.5, 0.5], \\\n",
    "                                                n_samples = 10)\n",
    "                \n",
    "            valid_mean /= n_split_valid\n",
    "            vaccs_bcnn_gal[i].append(valid_mean)\n",
    "            str_vacc += \" {:.5g}\".format(vaccs_bcnn_gal[i][-1])\n",
    "        \n",
    "        taccs_bcnn_gal.append(train_accuracy)\n",
    "        \n",
    "        print(str_vacc)\n",
    "\n",
    "        #summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "        #                                       bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]})\n",
    "        summary = sess.run(merged, feed_dict ={bcnn_gal.x: np.reshape(x_valid[d], (-1, 28, 28, 1)), \\\n",
    "                                               bcnn_gal.t: t_valid, bcnn_gal.keep_probs: [0.5, 0.5, 0.5, 0.5]})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid accuracy: 0.0578 0.1106 0.0945 0.0991 0.1988 0.3516 0.9546 0.054 0.112 0.095 0.099 0.2076 0.3775 0.9605\n"
     ]
    }
   ],
   "source": [
    "vaccs_bcnn_gal_add = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs_bcnn_gal_add.append(list())\n",
    "\n",
    "for i in range(n_datas): \n",
    "    valid_mean = 0.\n",
    "    for j in range(n_split_valid):\n",
    "\n",
    "        valid_mean += bcnn_gal.MCdropout(inp = np.reshape(x_valid[i][j*valid_size:(j+1)*valid_size], (-1, 28, 28, 1)), \\\n",
    "                                        tar =  t_valid[j*valid_size:(j+1)*valid_size], keep_probs = [0.5, 0.5, 0.5, 0.5], \\\n",
    "                                        n_samples = 40)\n",
    "\n",
    "    valid_mean /= n_split_valid\n",
    "    vaccs_bcnn_gal_add[i].append(valid_mean)\n",
    "    str_vacc += \" {:.5g}\".format(vaccs_bcnn_gal_add[i][-1])\n",
    "    \n",
    "print str_vacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFyCAYAAACgITN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f990aa610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Gal\\'s Bayesian CNN with MC Dropout')\n",
    "plt.plot(taccs_bcnn_gal, 'k')\n",
    "plt.plot(vaccs_bcnn_gal[0], 'b')\n",
    "plt.plot(vaccs_bcnn_gal[1], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[2], 'r')\n",
    "plt.plot(vaccs_bcnn_gal[3], 'c')\n",
    "plt.plot(vaccs_bcnn_gal[4], 'b')\n",
    "plt.plot(vaccs_bcnn_gal[5], 'g')\n",
    "plt.plot(vaccs_bcnn_gal[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blundell version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-1.0, 5.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = True, train_rho = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "# train_writer = tf.train.SummaryWriter(savedir + 'train', sess.graph)\n",
    "# test_writer = tf.train.SummaryWriter(savedir + 'test')\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "    \n",
    "for d in range(n_datas):\n",
    "    bnn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "        bnn.reset_klrw()\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            \n",
    "            bnn.decay_klrw()\n",
    "\n",
    "            feed = {bnn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "            fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bnn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "                \n",
    "            bnn.train(feed)\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "                \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(bnn.validate({bnn.x: x_valid[i], bnn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        \n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={bnn.x: x_valid[d], bnn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeff_klrw = 1 / n_batches\n",
    "\n",
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs*coeff_klrw, 'b')\n",
    "plt.plot(ps*coeff_klrw, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Blundell\\'s Bayesian NN')\n",
    "plt.plot(taccs, 'k')\n",
    "plt.plot(vaccs[0], 'tab:blue')\n",
    "plt.plot(vaccs[1], 'tab:orange')\n",
    "plt.plot(vaccs[2], 'tab:green')\n",
    "plt.plot(vaccs[3], 'tab:red')\n",
    "plt.plot(vaccs[4], 'tab:purple')\n",
    "plt.plot(vaccs[5], 'tab:brown')\n",
    "plt.plot(vaccs[6], 'tab:pink')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-5.0, 1.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False, train_rho = True, only_loglike = False)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    bnn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {bnn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "            fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "            bnn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bnn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "\n",
    "\n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(bnn.validate({bnn.x: x_valid[i], bnn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={bnn.x: x_valid[d], bnn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taccs_BNN_OL = taccs\n",
    "vaccs_BNN_OL = vaccs\n",
    "\n",
    "plt.title('Bayesian NN')\n",
    "\n",
    "plt.plot(taccs_BNN_OL, 'k')\n",
    "plt.plot(vaccs_BNN_OL[0], 'b')\n",
    "plt.plot(vaccs_BNN_OL[1], 'g')\n",
    "plt.plot(vaccs_BNN_OL[2], 'r')\n",
    "plt.plot(vaccs_BNN_OL[3], 'c')\n",
    "plt.plot(vaccs_BNN_OL[4], 'b')\n",
    "plt.plot(vaccs_BNN_OL[5], 'g')\n",
    "plt.plot(vaccs_BNN_OL[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_BNN_OL, 0)\n",
    "print_accs(vaccs_BNN_OL, 199)\n",
    "print_accs(vaccs_BNN_OL, 399)\n",
    "print_accs(vaccs_BNN_OL, 599)\n",
    "print_accs(vaccs_BNN_OL, 799)\n",
    "print_accs(vaccs_BNN_OL, 999)\n",
    "print_accs(vaccs_BNN_OL, 1199)\n",
    "print_accs(vaccs_BNN_OL, 1399)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Online version + EWC with rho_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "bnn = bnn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, rhos = [-5.0, 1.0, 10.0], n_samples = 10, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, kl_reweight = False, train_rho = True, only_loglike = False, ewc = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bnn.p_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 200\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    bnn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {bnn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    bnn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_q, v_p, v_l = bnn.get_fqpl(feed)\n",
    "            fs.append(v_f), qs.append(v_q), ps.append(v_p), ls.append(v_l)\n",
    "\n",
    "            bnn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = bnn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                print(\"f : {}, q : {}, p : {}, l : {}\".format(v_f, v_q, v_p, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = bnn.get_lr()\n",
    "                bnn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if bnn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "\n",
    "\n",
    "        if ep % 50 == 0: bnn.print_ewcgrads(feed)\n",
    "        \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(bnn.validate({bnn.x: x_valid[i], bnn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={bnn.x: x_valid[d], bnn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    bnn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(fs, 'r')\n",
    "plt.plot(qs, 'b')\n",
    "plt.plot(ps, 'g')\n",
    "plt.plot(ls, 'k')\n",
    "\n",
    "# plt.plot(fs[0:22], 'r')\n",
    "# plt.plot(qs[0:22], 'b')\n",
    "# plt.plot(ps[0:22], 'g')\n",
    "# plt.plot(ls[0:22], 'k')\n",
    "\n",
    "plt.legend(['f', 'q', 'p', 'l'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_BNN_MG = taccs\n",
    "vaccs_BNN_MG = vaccs\n",
    "\n",
    "plt.title('Bayesian NN with Modified Gradients')\n",
    "plt.plot(taccs_BNN_MG, 'k')\n",
    "plt.plot(vaccs_BNN_MG[0], 'b')\n",
    "plt.plot(vaccs_BNN_MG[1], 'g')\n",
    "plt.plot(vaccs_BNN_MG[2], 'r')\n",
    "plt.plot(vaccs_BNN_MG[3], 'c')\n",
    "plt.plot(vaccs_BNN_MG[4], 'b')\n",
    "plt.plot(vaccs_BNN_MG[5], 'g')\n",
    "plt.plot(vaccs_BNN_MG[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_BNN_MG, 0)\n",
    "print_accs(vaccs_BNN_MG, 199)\n",
    "print_accs(vaccs_BNN_MG, 399)\n",
    "print_accs(vaccs_BNN_MG, 599)\n",
    "print_accs(vaccs_BNN_MG, 799)\n",
    "print_accs(vaccs_BNN_MG, 999)\n",
    "print_accs(vaccs_BNN_MG, 1199)\n",
    "print_accs(vaccs_BNN_MG, 1399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_BNN_MG = taccs\n",
    "vaccs_BNN_MG = vaccs\n",
    "\n",
    "plt.title('Bayesian NN with Modified Gradients')\n",
    "plt.plot(taccs_BNN_MG, 'k')\n",
    "plt.plot(vaccs_BNN_MG[0], 'b')\n",
    "plt.plot(vaccs_BNN_MG[1], 'g')\n",
    "plt.plot(vaccs_BNN_MG[2], 'r')\n",
    "plt.plot(vaccs_BNN_MG[3], 'c')\n",
    "plt.plot(vaccs_BNN_MG[4], 'b')\n",
    "plt.plot(vaccs_BNN_MG[5], 'g')\n",
    "plt.plot(vaccs_BNN_MG[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_BNN_MG, 0)\n",
    "print_accs(vaccs_BNN_MG, 199)\n",
    "print_accs(vaccs_BNN_MG, 399)\n",
    "print_accs(vaccs_BNN_MG, 599)\n",
    "print_accs(vaccs_BNN_MG, 799)\n",
    "print_accs(vaccs_BNN_MG, 999)\n",
    "print_accs(vaccs_BNN_MG, 1199)\n",
    "print_accs(vaccs_BNN_MG, 1399)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "nn = nn_shson.nn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, only_loglike = True, ewc = False)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 2000\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    nn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {nn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    nn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_l = nn.get_fqpl(feed)\n",
    "            fs.append(v_f), ls.append(v_l)\n",
    "\n",
    "            nn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = nn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                #print(\"f : {}, l : {}\".format(v_f, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = nn.get_lr()\n",
    "                nn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if nn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "        \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(nn.validate({nn.x: x_valid[i], nn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={nn.x: x_valid[d], nn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    nn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_nNN = taccs\n",
    "vaccs_nNN = vaccs\n",
    "\n",
    "plt.title('Normal NN')\n",
    "\n",
    "plt.plot(taccs_nNN, 'k')\n",
    "plt.plot(vaccs_nNN[0], 'b')\n",
    "plt.plot(vaccs_nNN[1], 'g')\n",
    "plt.plot(vaccs_nNN[2], 'r')\n",
    "plt.plot(vaccs_nNN[3], 'c')\n",
    "plt.plot(vaccs_nNN[4], 'b')\n",
    "plt.plot(vaccs_nNN[5], 'g')\n",
    "plt.plot(vaccs_nNN[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_nNN, 0)\n",
    "print_accs(vaccs_nNN, 1999)\n",
    "print_accs(vaccs_nNN, 3999)\n",
    "print_accs(vaccs_nNN, 5999)\n",
    "print_accs(vaccs_nNN, 7999)\n",
    "print_accs(vaccs_nNN, 9999)\n",
    "print_accs(vaccs_nNN, 11999)\n",
    "print_accs(vaccs_nNN, 13999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal NN + EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bnn = bnn_model(shape, mu = 0.1, rho = 0.1, n_samples = 10, outact = tf.sigmoid, seed = 1234, lr = 1e-8)\n",
    "enn = nn_shson.nn_model([784, 50, 10], size_data = len(t_train), size_batch = batch_size, \\\n",
    "                mu = 0.02, outact = tf.sigmoid, seed = 1234, \\\n",
    "                lr = 1e-3, only_loglike = False, ewc = True)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "savedir = make_savedir(\"experiment_saves/\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter(savedir + 'train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(savedir + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sess.run(tf.initialize_all_variables())\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "n_datas = 7\n",
    "\n",
    "n_epochs = 2000\n",
    "n_batches = len(t_train) / batch_size\n",
    "patience = 3\n",
    "\n",
    "fs = list()\n",
    "qs = list()\n",
    "ps = list()\n",
    "ls = list()\n",
    "fs_mean = list()\n",
    "taccs = list()\n",
    "taccs_mean = list()\n",
    "vaccs = list()\n",
    "for i in range(n_datas):\n",
    "    vaccs.append(list())\n",
    "\n",
    "for d in range(n_datas):\n",
    "    enn.reset_lr()\n",
    "    #fs_mean = list()\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            feed = {enn.x: x_train[d][i*batch_size:(i+1)*batch_size], \\\n",
    "                    enn.t: t_train[i*batch_size:(i+1)*batch_size]}\n",
    "\n",
    "            v_f, v_l = enn.get_fqpl(feed)\n",
    "            fs.append(v_f), ls.append(v_l)\n",
    "\n",
    "            enn.train(feed)\n",
    "\n",
    "            if (i % 50 == 0) and (ep % 50 == 0):\n",
    "                train_accuracy = enn.validate(feed)\n",
    "                \n",
    "                print(\"ep %d, batch %d, training accuracy %g\"%(ep, i, train_accuracy))\n",
    "                #print(\"f : {}, l : {}\".format(v_f, v_l))\n",
    "\n",
    "        fs_mean.append(np.mean(fs[-n_batches:]))\n",
    "\n",
    "\n",
    "        if ep > 5 and np.mean(fs_mean[-25:]) < fs_mean[-1]:\n",
    "            if patience == 0:\n",
    "                last_lr = enn.get_lr()\n",
    "                enn.decay_lr()\n",
    "                patience = 3\n",
    "\n",
    "                if enn.get_lr() == last_lr:\n",
    "                    print(\"=== cannot decay more. stop learning this batch ===\")\n",
    "                    break\n",
    "            else:\n",
    "                patience -= 1\n",
    "        \n",
    "        str_vacc = \"valid accuracy:\"        \n",
    "        for i in range(n_datas): \n",
    "            vaccs[i].append(enn.validate({enn.x: x_valid[i], enn.t: t_valid}))\n",
    "            str_vacc += \" {:.5g}\".format(vaccs[i][-1])\n",
    "        \n",
    "        taccs.append(train_accuracy)\n",
    "        print(str_vacc)\n",
    "\n",
    "        summary = sess.run(merged, feed_dict ={enn.x: x_valid[d], enn.t: t_valid})\n",
    "        test_writer.add_summary(summary, (d+1)*(ep+1))\n",
    "\n",
    "    #     if i > 10 and np.mean(vaccs[-10:-5]) < np.mean(vaccs[-5:]):\n",
    "    #         bnn.decay_lr()\n",
    "\n",
    "    enn.update_prior()\n",
    "    #bnn.print_params()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_NNEWC = taccs\n",
    "vaccs_NNEWC = vaccs\n",
    "\n",
    "plt.title('Normal NN with EWC')\n",
    "plt.plot(taccs_NNEWC, 'k')\n",
    "plt.plot(vaccs_NNEWC[0], 'b')\n",
    "plt.plot(vaccs_NNEWC[1], 'g')\n",
    "plt.plot(vaccs_NNEWC[2], 'r')\n",
    "plt.plot(vaccs_NNEWC[3], 'c')\n",
    "plt.plot(vaccs_NNEWC[4], 'b')\n",
    "plt.plot(vaccs_NNEWC[5], 'g')\n",
    "plt.plot(vaccs_NNEWC[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_NNEWC, 0)\n",
    "print_accs(vaccs_NNEWC, 1999)\n",
    "print_accs(vaccs_NNEWC, 3999)\n",
    "print_accs(vaccs_NNEWC, 5999)\n",
    "print_accs(vaccs_NNEWC, 7999)\n",
    "print_accs(vaccs_NNEWC, 9999)\n",
    "print_accs(vaccs_NNEWC, 11999)\n",
    "print_accs(vaccs_NNEWC, 13999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taccs_NNEWC = taccs\n",
    "vaccs_NNEWC = vaccs\n",
    "\n",
    "plt.title('Normal NN with EWC')\n",
    "plt.plot(taccs_NNEWC, 'k')\n",
    "plt.plot(vaccs_NNEWC[0], 'b')\n",
    "plt.plot(vaccs_NNEWC[1], 'g')\n",
    "plt.plot(vaccs_NNEWC[2], 'r')\n",
    "plt.plot(vaccs_NNEWC[3], 'c')\n",
    "plt.plot(vaccs_NNEWC[4], 'b')\n",
    "plt.plot(vaccs_NNEWC[5], 'g')\n",
    "plt.plot(vaccs_NNEWC[6], 'r')\n",
    "\n",
    "plt.legend(['train_acc', 'valid_acc0', 'valid_acc1', 'valid_acc2', 'valid_acc3', 'valid_acc4', 'valid_acc5', 'valid_acc6'],loc = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_accs(vaccs_NNEWC, 0)\n",
    "print_accs(vaccs_NNEWC, 1999)\n",
    "print_accs(vaccs_NNEWC, 3999)\n",
    "print_accs(vaccs_NNEWC, 5999)\n",
    "print_accs(vaccs_NNEWC, 7999)\n",
    "print_accs(vaccs_NNEWC, 9999)\n",
    "print_accs(vaccs_NNEWC, 11999)\n",
    "print_accs(vaccs_NNEWC, 13999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
